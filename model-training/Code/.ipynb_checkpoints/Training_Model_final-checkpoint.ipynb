{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize paths for data input and weights output\n",
    "data_dir = \"../Data/\"\n",
    "data_file = \"Nottingham_Jigs_Hornpipes.txt\"\n",
    "save_weights_dir = '../Trained_Weights/Weights_Model_final/'\n",
    "log_dir = \"../Data/log.csv\"\n",
    "charToIndex_json = \"char_to_index.json\"\n",
    "\n",
    "transfer_weights_path = \"../Trained_Weights/Weights_Model1/Weights_70.h5\"\n",
    "# Parameters\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-e5ca90ff46e1>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-e5ca90ff46e1>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    for batch_row in range(0, BATCH_SIZE):             # iterates over columns in a batch\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Function used to create the batches\n",
    "def get_batches(chars, unique_chars):\n",
    "    char_no = chars.shape[0] # number of characters in the data\n",
    "    batch_chars = int(char_no / BATCH_SIZE)\n",
    "    \n",
    "    # outer loop iterates every time a new batch is created\n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, SEQ_LENGTH):\n",
    "        # number of batches wil be char_no/(BATCH_SIZE * SEQ_LENGTH)\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))  \n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))\n",
    "        # iterates over rows in a batch\n",
    "        for batch_row in range(0, BATCH_SIZE):             # iterates over columns in a batch\n",
    "            for i in range(0, SEQ_LENGTH):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_row, i] = chars[batch_row * batch_chars + start + i]\n",
    "                Y[batch_row, i, chars[batch_row * batch_chars + start + i + 1]] = 1 \n",
    "                    # by 1 we mark that the next character in the sequence is the correct one\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added 2 more LSTM layers\n",
    "# loading previously computed weights - transfer learning\n",
    "def build_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # inputs have to be the same length which is achieved when creating batches\n",
    "    # input dimension will be the number of unique characters in the training data\n",
    "    # output-dimention needs more validation - 8?\n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length), name = \"embd_1\")) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True, name = \"lstm_first\"))\n",
    "    model.add(Dropout(0.2, name = \"drp_1\"))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    model.load_weights(transfer_weights_path, by_name = True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, epochs = 70):\n",
    "    \n",
    "    # Mapping all unique characters to an index\n",
    "    char_to_index = {char: in for (in, char) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Unique characters in the training data = {}\".format(len(char_to_index)))  \n",
    "    # Saved the mapping in a json file\n",
    "    with open(os.path.join(data_dir, charToIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    # Build the model\n",
    "    model = build_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    # multi-class classification problem - using Categorical Cross entropy as loss function\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(get_batches(characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) #check documentation of train_on_batch here: https://keras.io/models/sequential/\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(save_weights_dir):\n",
    "                os.makedirs(save_weights_dir)\n",
    "            model.save_weights(os.path.join(save_weights_dir, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(log_dir, index = False)\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    pyplot.plot(accuracy, epoch_number)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 87\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (16, 64, 512)             44544     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (16, 64, 128)             197120    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (16, 64, 128)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (16, 64, 87)              11223     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (16, 64, 87)              0         \n",
      "=================================================================\n",
      "Total params: 1,040,343\n",
      "Trainable params: 1,040,343\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Total number of characters = 155222\n",
      "Epoch 1/80\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Batch: 1, Loss: 4.46653938293457, Accuracy: 0.0029296875\n",
      "Batch: 2, Loss: 4.4512434005737305, Accuracy: 0.16796875\n",
      "Batch: 3, Loss: 4.436254024505615, Accuracy: 0.134765625\n",
      "Batch: 4, Loss: 4.421352863311768, Accuracy: 0.1025390625\n",
      "Batch: 5, Loss: 4.344696998596191, Accuracy: 0.1435546875\n",
      "Batch: 6, Loss: 4.181085586547852, Accuracy: 0.166015625\n",
      "Batch: 7, Loss: 3.9635844230651855, Accuracy: 0.162109375\n",
      "Batch: 8, Loss: 3.8707900047302246, Accuracy: 0.1396484375\n",
      "Batch: 9, Loss: 3.865553379058838, Accuracy: 0.1357421875\n",
      "Batch: 10, Loss: 3.6550045013427734, Accuracy: 0.166015625\n",
      "Batch: 11, Loss: 3.4183149337768555, Accuracy: 0.1806640625\n",
      "Batch: 12, Loss: 3.5866971015930176, Accuracy: 0.15234375\n",
      "Batch: 13, Loss: 3.786694049835205, Accuracy: 0.12890625\n",
      "Batch: 14, Loss: 3.545654535293579, Accuracy: 0.1298828125\n",
      "Batch: 15, Loss: 3.744852066040039, Accuracy: 0.1181640625\n",
      "Batch: 16, Loss: 3.4594943523406982, Accuracy: 0.1474609375\n",
      "Batch: 17, Loss: 3.3657569885253906, Accuracy: 0.1708984375\n",
      "Batch: 18, Loss: 3.35684871673584, Accuracy: 0.1650390625\n",
      "Batch: 19, Loss: 3.6128742694854736, Accuracy: 0.130859375\n",
      "Batch: 20, Loss: 3.7115726470947266, Accuracy: 0.109375\n",
      "Batch: 21, Loss: 3.5592093467712402, Accuracy: 0.13671875\n",
      "Batch: 22, Loss: 3.3148536682128906, Accuracy: 0.171875\n",
      "Batch: 23, Loss: 3.4132473468780518, Accuracy: 0.1416015625\n",
      "Batch: 24, Loss: 3.590559720993042, Accuracy: 0.111328125\n",
      "Batch: 25, Loss: 3.5101444721221924, Accuracy: 0.126953125\n",
      "Batch: 26, Loss: 3.4798989295959473, Accuracy: 0.134765625\n",
      "Batch: 27, Loss: 3.4351916313171387, Accuracy: 0.1337890625\n",
      "Batch: 28, Loss: 3.2847788333892822, Accuracy: 0.13671875\n",
      "Batch: 29, Loss: 3.5023300647735596, Accuracy: 0.1318359375\n",
      "Batch: 30, Loss: 3.7976675033569336, Accuracy: 0.0966796875\n",
      "Batch: 31, Loss: 3.6788418292999268, Accuracy: 0.12109375\n",
      "Batch: 32, Loss: 3.4242186546325684, Accuracy: 0.1240234375\n",
      "Batch: 33, Loss: 3.451275587081909, Accuracy: 0.1328125\n",
      "Batch: 34, Loss: 3.3982019424438477, Accuracy: 0.1533203125\n",
      "Batch: 35, Loss: 3.4950308799743652, Accuracy: 0.119140625\n",
      "Batch: 36, Loss: 3.6530137062072754, Accuracy: 0.095703125\n",
      "Batch: 37, Loss: 3.4946224689483643, Accuracy: 0.1181640625\n",
      "Batch: 38, Loss: 3.4294986724853516, Accuracy: 0.125\n",
      "Batch: 39, Loss: 3.499201774597168, Accuracy: 0.126953125\n",
      "Batch: 40, Loss: 3.623518466949463, Accuracy: 0.125\n",
      "Batch: 41, Loss: 3.612361431121826, Accuracy: 0.11328125\n",
      "Batch: 42, Loss: 3.4442858695983887, Accuracy: 0.1357421875\n",
      "Batch: 43, Loss: 3.2986886501312256, Accuracy: 0.1630859375\n",
      "Batch: 44, Loss: 3.3427846431732178, Accuracy: 0.1630859375\n",
      "Batch: 45, Loss: 3.34320330619812, Accuracy: 0.154296875\n",
      "Batch: 46, Loss: 3.673316717147827, Accuracy: 0.1103515625\n",
      "Batch: 47, Loss: 3.6808273792266846, Accuracy: 0.107421875\n",
      "Batch: 48, Loss: 3.453392505645752, Accuracy: 0.138671875\n",
      "Batch: 49, Loss: 3.3864731788635254, Accuracy: 0.1376953125\n",
      "Batch: 50, Loss: 3.369772434234619, Accuracy: 0.140625\n",
      "Batch: 51, Loss: 3.3512063026428223, Accuracy: 0.13671875\n",
      "Batch: 52, Loss: 3.43843150138855, Accuracy: 0.119140625\n",
      "Batch: 53, Loss: 3.436490058898926, Accuracy: 0.126953125\n",
      "Batch: 54, Loss: 3.5031585693359375, Accuracy: 0.134765625\n",
      "Batch: 55, Loss: 3.393831491470337, Accuracy: 0.1318359375\n",
      "Batch: 56, Loss: 3.4669928550720215, Accuracy: 0.1328125\n",
      "Batch: 57, Loss: 3.468902826309204, Accuracy: 0.13671875\n",
      "Batch: 58, Loss: 3.367234230041504, Accuracy: 0.138671875\n",
      "Batch: 59, Loss: 3.654395341873169, Accuracy: 0.109375\n",
      "Batch: 60, Loss: 3.4307119846343994, Accuracy: 0.1396484375\n",
      "Batch: 61, Loss: 3.3932156562805176, Accuracy: 0.1435546875\n",
      "Batch: 62, Loss: 3.526313066482544, Accuracy: 0.1328125\n",
      "Batch: 63, Loss: 3.4544475078582764, Accuracy: 0.1357421875\n",
      "Batch: 64, Loss: 3.489744186401367, Accuracy: 0.1376953125\n",
      "Batch: 65, Loss: 3.4718706607818604, Accuracy: 0.1357421875\n",
      "Batch: 66, Loss: 3.4525394439697266, Accuracy: 0.1416015625\n",
      "Batch: 67, Loss: 3.3103363513946533, Accuracy: 0.169921875\n",
      "Batch: 68, Loss: 3.4189352989196777, Accuracy: 0.162109375\n",
      "Batch: 69, Loss: 3.4850096702575684, Accuracy: 0.1337890625\n",
      "Batch: 70, Loss: 3.4547181129455566, Accuracy: 0.1513671875\n",
      "Batch: 71, Loss: 3.357985258102417, Accuracy: 0.158203125\n",
      "Batch: 72, Loss: 3.406114101409912, Accuracy: 0.150390625\n",
      "Batch: 73, Loss: 3.5323333740234375, Accuracy: 0.126953125\n",
      "Batch: 74, Loss: 3.4547019004821777, Accuracy: 0.134765625\n",
      "Batch: 75, Loss: 3.307893991470337, Accuracy: 0.16015625\n",
      "Batch: 76, Loss: 3.1708383560180664, Accuracy: 0.1767578125\n",
      "Batch: 77, Loss: 3.2915310859680176, Accuracy: 0.16796875\n",
      "Batch: 79, Loss: 3.551067352294922, Accuracy: 0.1279296875\n",
      "Batch: 80, Loss: 3.149122953414917, Accuracy: 0.177734375\n",
      "Batch: 81, Loss: 3.0139081478118896, Accuracy: 0.1962890625\n",
      "Batch: 82, Loss: 3.127577543258667, Accuracy: 0.189453125\n",
      "Batch: 83, Loss: 3.267220973968506, Accuracy: 0.1669921875\n",
      "Batch: 84, Loss: 3.342378616333008, Accuracy: 0.162109375\n",
      "Batch: 85, Loss: 3.278651714324951, Accuracy: 0.15234375\n",
      "Batch: 86, Loss: 3.1223018169403076, Accuracy: 0.1748046875\n",
      "Batch: 87, Loss: 3.2186317443847656, Accuracy: 0.166015625\n",
      "Batch: 88, Loss: 3.195941925048828, Accuracy: 0.1767578125\n",
      "Batch: 89, Loss: 3.1732587814331055, Accuracy: 0.1767578125\n",
      "Batch: 90, Loss: 3.2166173458099365, Accuracy: 0.1728515625\n",
      "Batch: 91, Loss: 3.1708807945251465, Accuracy: 0.1689453125\n",
      "Batch: 92, Loss: 3.0915801525115967, Accuracy: 0.1982421875\n",
      "Batch: 93, Loss: 3.1118180751800537, Accuracy: 0.1884765625\n",
      "Batch: 94, Loss: 3.0467138290405273, Accuracy: 0.2236328125\n",
      "Batch: 95, Loss: 2.855210781097412, Accuracy: 0.2490234375\n",
      "Batch: 96, Loss: 3.121140956878662, Accuracy: 0.212890625\n",
      "Batch: 97, Loss: 3.134408950805664, Accuracy: 0.20703125\n",
      "Batch: 98, Loss: 3.115217924118042, Accuracy: 0.2099609375\n",
      "Batch: 99, Loss: 2.8974862098693848, Accuracy: 0.2333984375\n",
      "Batch: 100, Loss: 2.7836625576019287, Accuracy: 0.2626953125\n",
      "Batch: 101, Loss: 2.9115757942199707, Accuracy: 0.2451171875\n",
      "Batch: 102, Loss: 2.8994617462158203, Accuracy: 0.2587890625\n",
      "Batch: 103, Loss: 3.1216745376586914, Accuracy: 0.2275390625\n",
      "Batch: 104, Loss: 2.8878326416015625, Accuracy: 0.251953125\n",
      "Batch: 105, Loss: 2.871887683868408, Accuracy: 0.244140625\n",
      "Batch: 106, Loss: 2.9348578453063965, Accuracy: 0.2490234375\n",
      "Batch: 107, Loss: 2.9665794372558594, Accuracy: 0.2373046875\n",
      "Batch: 108, Loss: 2.948254108428955, Accuracy: 0.236328125\n",
      "Batch: 109, Loss: 2.8127243518829346, Accuracy: 0.2763671875\n",
      "Batch: 110, Loss: 2.828136682510376, Accuracy: 0.251953125\n",
      "Batch: 111, Loss: 2.7002921104431152, Accuracy: 0.291015625\n",
      "Batch: 112, Loss: 2.9489314556121826, Accuracy: 0.2412109375\n",
      "Batch: 113, Loss: 2.9389796257019043, Accuracy: 0.2490234375\n",
      "Batch: 114, Loss: 2.675999641418457, Accuracy: 0.2890625\n",
      "Batch: 115, Loss: 2.772928237915039, Accuracy: 0.2900390625\n",
      "Batch: 116, Loss: 2.8074703216552734, Accuracy: 0.259765625\n",
      "Batch: 117, Loss: 2.9618752002716064, Accuracy: 0.25390625\n",
      "Batch: 118, Loss: 2.979825258255005, Accuracy: 0.224609375\n",
      "Batch: 119, Loss: 2.951249122619629, Accuracy: 0.2275390625\n",
      "Batch: 120, Loss: 2.6979963779449463, Accuracy: 0.2822265625\n",
      "Batch: 121, Loss: 2.697111129760742, Accuracy: 0.2861328125\n",
      "Batch: 122, Loss: 2.9821434020996094, Accuracy: 0.224609375\n",
      "Batch: 124, Loss: 2.8385820388793945, Accuracy: 0.2392578125\n",
      "Batch: 125, Loss: 2.7237868309020996, Accuracy: 0.2529296875\n",
      "Batch: 126, Loss: 2.6994311809539795, Accuracy: 0.26171875\n",
      "Batch: 127, Loss: 2.85398268699646, Accuracy: 0.2353515625\n",
      "Batch: 128, Loss: 2.817711114883423, Accuracy: 0.2490234375\n",
      "Batch: 129, Loss: 2.736793279647827, Accuracy: 0.267578125\n",
      "Batch: 130, Loss: 2.771516799926758, Accuracy: 0.2705078125\n",
      "Batch: 131, Loss: 2.751955986022949, Accuracy: 0.267578125\n",
      "Batch: 132, Loss: 2.8536429405212402, Accuracy: 0.2451171875\n",
      "Batch: 133, Loss: 2.7308120727539062, Accuracy: 0.2919921875\n",
      "Batch: 134, Loss: 2.6664116382598877, Accuracy: 0.2841796875\n",
      "Batch: 135, Loss: 2.652674674987793, Accuracy: 0.29296875\n",
      "Batch: 136, Loss: 2.5609028339385986, Accuracy: 0.3076171875\n",
      "Batch: 137, Loss: 2.385382890701294, Accuracy: 0.34765625\n",
      "Batch: 138, Loss: 2.53902268409729, Accuracy: 0.328125\n",
      "Batch: 139, Loss: 2.4998703002929688, Accuracy: 0.3134765625\n",
      "Batch: 140, Loss: 2.619912624359131, Accuracy: 0.3037109375\n",
      "Batch: 141, Loss: 2.6267054080963135, Accuracy: 0.2919921875\n",
      "Batch: 142, Loss: 2.5551419258117676, Accuracy: 0.3134765625\n",
      "Batch: 143, Loss: 2.6919751167297363, Accuracy: 0.28515625\n",
      "Batch: 144, Loss: 2.654198169708252, Accuracy: 0.296875\n",
      "Batch: 145, Loss: 2.533289670944214, Accuracy: 0.3232421875\n",
      "Batch: 146, Loss: 2.617563247680664, Accuracy: 0.2822265625\n",
      "Batch: 147, Loss: 2.6107287406921387, Accuracy: 0.2900390625\n",
      "Batch: 148, Loss: 2.5371246337890625, Accuracy: 0.2958984375\n",
      "Batch: 149, Loss: 2.617889881134033, Accuracy: 0.2919921875\n",
      "Batch: 150, Loss: 2.563999652862549, Accuracy: 0.3037109375\n",
      "Batch: 151, Loss: 2.669647216796875, Accuracy: 0.2841796875\n",
      "Epoch 2/80\n",
      "Batch: 1, Loss: 2.378328323364258, Accuracy: 0.330078125\n",
      "Batch: 2, Loss: 2.297938823699951, Accuracy: 0.33203125\n",
      "Batch: 3, Loss: 2.5589914321899414, Accuracy: 0.2958984375\n",
      "Batch: 4, Loss: 2.658130168914795, Accuracy: 0.306640625\n",
      "Batch: 5, Loss: 2.4945712089538574, Accuracy: 0.3251953125\n",
      "Batch: 6, Loss: 2.3263473510742188, Accuracy: 0.3505859375\n",
      "Batch: 7, Loss: 2.3069448471069336, Accuracy: 0.345703125\n",
      "Batch: 8, Loss: 2.4292259216308594, Accuracy: 0.330078125\n",
      "Batch: 9, Loss: 2.4479403495788574, Accuracy: 0.3330078125\n",
      "Batch: 10, Loss: 2.4042162895202637, Accuracy: 0.333984375\n",
      "Batch: 11, Loss: 2.2265853881835938, Accuracy: 0.3642578125\n",
      "Batch: 12, Loss: 2.4301798343658447, Accuracy: 0.3251953125\n",
      "Batch: 13, Loss: 2.492558002471924, Accuracy: 0.3427734375\n",
      "Batch: 14, Loss: 2.4153659343719482, Accuracy: 0.3212890625\n",
      "Batch: 15, Loss: 2.5612998008728027, Accuracy: 0.3134765625\n",
      "Batch: 18, Loss: 2.299586057662964, Accuracy: 0.357421875\n",
      "Batch: 19, Loss: 2.440568208694458, Accuracy: 0.318359375\n",
      "Batch: 20, Loss: 2.5446343421936035, Accuracy: 0.3212890625\n",
      "Batch: 21, Loss: 2.3507702350616455, Accuracy: 0.34765625\n",
      "Batch: 22, Loss: 2.29007625579834, Accuracy: 0.3623046875\n",
      "Batch: 23, Loss: 2.29586124420166, Accuracy: 0.35546875\n",
      "Batch: 24, Loss: 2.4797160625457764, Accuracy: 0.3232421875\n",
      "Batch: 25, Loss: 2.3261454105377197, Accuracy: 0.33203125\n",
      "Batch: 26, Loss: 2.241262197494507, Accuracy: 0.3642578125\n",
      "Batch: 27, Loss: 2.339878559112549, Accuracy: 0.34375\n",
      "Batch: 28, Loss: 2.2600018978118896, Accuracy: 0.34375\n",
      "Batch: 29, Loss: 2.302908420562744, Accuracy: 0.337890625\n",
      "Batch: 30, Loss: 2.5671961307525635, Accuracy: 0.3125\n",
      "Batch: 31, Loss: 2.4829111099243164, Accuracy: 0.3408203125\n",
      "Batch: 32, Loss: 2.2721924781799316, Accuracy: 0.3525390625\n",
      "Batch: 33, Loss: 2.33170223236084, Accuracy: 0.3466796875\n",
      "Batch: 34, Loss: 2.399587869644165, Accuracy: 0.32421875\n",
      "Batch: 35, Loss: 2.3556532859802246, Accuracy: 0.330078125\n",
      "Batch: 36, Loss: 2.4675071239471436, Accuracy: 0.32421875\n",
      "Batch: 37, Loss: 2.3601250648498535, Accuracy: 0.353515625\n",
      "Batch: 38, Loss: 2.294238805770874, Accuracy: 0.33984375\n",
      "Batch: 39, Loss: 2.330855369567871, Accuracy: 0.353515625\n",
      "Batch: 40, Loss: 2.439218759536743, Accuracy: 0.3603515625\n",
      "Batch: 41, Loss: 2.342136859893799, Accuracy: 0.3701171875\n",
      "Batch: 42, Loss: 2.15503191947937, Accuracy: 0.388671875\n",
      "Batch: 43, Loss: 2.135385751724243, Accuracy: 0.3759765625\n",
      "Batch: 44, Loss: 2.1028287410736084, Accuracy: 0.40234375\n",
      "Batch: 45, Loss: 2.108851432800293, Accuracy: 0.408203125\n",
      "Batch: 46, Loss: 2.3255720138549805, Accuracy: 0.369140625\n",
      "Batch: 47, Loss: 2.4071578979492188, Accuracy: 0.35546875\n",
      "Batch: 48, Loss: 2.2708582878112793, Accuracy: 0.38671875\n",
      "Batch: 49, Loss: 2.2807366847991943, Accuracy: 0.3642578125\n",
      "Batch: 50, Loss: 2.237515926361084, Accuracy: 0.369140625\n",
      "Batch: 51, Loss: 2.3027682304382324, Accuracy: 0.3505859375\n",
      "Batch: 52, Loss: 2.3194150924682617, Accuracy: 0.384765625\n",
      "Batch: 53, Loss: 2.151876926422119, Accuracy: 0.3935546875\n",
      "Batch: 54, Loss: 2.2386817932128906, Accuracy: 0.3955078125\n",
      "Batch: 55, Loss: 2.140167236328125, Accuracy: 0.408203125\n",
      "Batch: 56, Loss: 2.240365982055664, Accuracy: 0.3798828125\n",
      "Batch: 57, Loss: 2.213792324066162, Accuracy: 0.3955078125\n",
      "Batch: 58, Loss: 2.239372491836548, Accuracy: 0.39453125\n",
      "Batch: 59, Loss: 2.189955234527588, Accuracy: 0.4111328125\n",
      "Batch: 60, Loss: 2.1318469047546387, Accuracy: 0.4033203125\n",
      "Batch: 61, Loss: 2.1523497104644775, Accuracy: 0.396484375\n",
      "Batch: 62, Loss: 2.2637035846710205, Accuracy: 0.3740234375\n",
      "Batch: 63, Loss: 2.178636312484741, Accuracy: 0.3818359375\n",
      "Batch: 64, Loss: 2.155017614364624, Accuracy: 0.3974609375\n",
      "Batch: 65, Loss: 2.1869044303894043, Accuracy: 0.396484375\n",
      "Batch: 66, Loss: 2.0800435543060303, Accuracy: 0.4169921875\n",
      "Batch: 67, Loss: 2.1035404205322266, Accuracy: 0.421875\n",
      "Batch: 68, Loss: 2.2344648838043213, Accuracy: 0.4150390625\n",
      "Batch: 69, Loss: 2.1880693435668945, Accuracy: 0.41796875\n",
      "Batch: 70, Loss: 2.223827362060547, Accuracy: 0.4208984375\n",
      "Batch: 71, Loss: 2.1639785766601562, Accuracy: 0.41015625\n",
      "Batch: 72, Loss: 2.1026976108551025, Accuracy: 0.43359375\n",
      "Batch: 73, Loss: 2.2425713539123535, Accuracy: 0.3984375\n",
      "Batch: 74, Loss: 2.1609346866607666, Accuracy: 0.39453125\n",
      "Batch: 75, Loss: 2.0461151599884033, Accuracy: 0.4345703125\n",
      "Batch: 76, Loss: 2.0877132415771484, Accuracy: 0.3896484375\n",
      "Batch: 77, Loss: 2.1474475860595703, Accuracy: 0.4091796875\n",
      "Batch: 78, Loss: 2.2527194023132324, Accuracy: 0.4208984375\n",
      "Batch: 79, Loss: 2.1433143615722656, Accuracy: 0.4580078125\n",
      "Batch: 80, Loss: 1.964962363243103, Accuracy: 0.4482421875\n",
      "Batch: 81, Loss: 1.9918467998504639, Accuracy: 0.423828125\n",
      "Batch: 82, Loss: 1.9957761764526367, Accuracy: 0.431640625\n",
      "Batch: 83, Loss: 2.030026435852051, Accuracy: 0.4541015625\n",
      "Batch: 84, Loss: 2.088693141937256, Accuracy: 0.4453125\n",
      "Batch: 85, Loss: 2.0193395614624023, Accuracy: 0.4697265625\n",
      "Batch: 86, Loss: 2.1313302516937256, Accuracy: 0.4140625\n",
      "Batch: 87, Loss: 2.0941319465637207, Accuracy: 0.4443359375\n",
      "Batch: 88, Loss: 2.125964641571045, Accuracy: 0.455078125\n",
      "Batch: 89, Loss: 2.094667673110962, Accuracy: 0.4287109375\n",
      "Batch: 90, Loss: 2.051921844482422, Accuracy: 0.4375\n",
      "Batch: 91, Loss: 2.0391252040863037, Accuracy: 0.4521484375\n",
      "Batch: 92, Loss: 2.061401844024658, Accuracy: 0.4501953125\n",
      "Batch: 93, Loss: 2.0032005310058594, Accuracy: 0.4482421875\n",
      "Batch: 94, Loss: 1.9793773889541626, Accuracy: 0.4609375\n",
      "Batch: 95, Loss: 1.9514167308807373, Accuracy: 0.4423828125\n",
      "Batch: 96, Loss: 2.0818514823913574, Accuracy: 0.447265625\n",
      "Batch: 97, Loss: 1.9900941848754883, Accuracy: 0.46875\n",
      "Batch: 98, Loss: 1.9471611976623535, Accuracy: 0.494140625\n",
      "Batch: 99, Loss: 1.8988325595855713, Accuracy: 0.4912109375\n",
      "Batch: 100, Loss: 1.8610378503799438, Accuracy: 0.494140625\n",
      "Batch: 101, Loss: 1.9356433153152466, Accuracy: 0.4765625\n",
      "Batch: 102, Loss: 1.8781020641326904, Accuracy: 0.4833984375\n",
      "Batch: 103, Loss: 2.0717973709106445, Accuracy: 0.4609375\n",
      "Batch: 104, Loss: 1.8797286748886108, Accuracy: 0.4892578125\n",
      "Batch: 105, Loss: 1.9502472877502441, Accuracy: 0.462890625\n",
      "Batch: 106, Loss: 2.018733501434326, Accuracy: 0.462890625\n",
      "Batch: 107, Loss: 2.0791263580322266, Accuracy: 0.4423828125\n",
      "Batch: 108, Loss: 2.1150946617126465, Accuracy: 0.453125\n",
      "Batch: 109, Loss: 2.087953567504883, Accuracy: 0.4658203125\n",
      "Batch: 112, Loss: 2.0239529609680176, Accuracy: 0.482421875\n",
      "Batch: 113, Loss: 2.0498199462890625, Accuracy: 0.466796875\n",
      "Batch: 114, Loss: 2.006929874420166, Accuracy: 0.458984375\n",
      "Batch: 115, Loss: 2.045949935913086, Accuracy: 0.4580078125\n",
      "Batch: 116, Loss: 2.044934034347534, Accuracy: 0.44140625\n",
      "Batch: 117, Loss: 2.076247215270996, Accuracy: 0.4775390625\n",
      "Batch: 118, Loss: 1.9154083728790283, Accuracy: 0.5166015625\n",
      "Batch: 119, Loss: 1.9608590602874756, Accuracy: 0.494140625\n",
      "Batch: 120, Loss: 1.947077751159668, Accuracy: 0.4677734375\n",
      "Batch: 121, Loss: 1.9969143867492676, Accuracy: 0.4482421875\n",
      "Batch: 122, Loss: 2.0014915466308594, Accuracy: 0.482421875\n",
      "Batch: 123, Loss: 1.9710869789123535, Accuracy: 0.4853515625\n",
      "Batch: 124, Loss: 1.9444935321807861, Accuracy: 0.4833984375\n",
      "Batch: 125, Loss: 1.9682321548461914, Accuracy: 0.44140625\n",
      "Batch: 126, Loss: 1.961223840713501, Accuracy: 0.4453125\n",
      "Batch: 127, Loss: 1.9154291152954102, Accuracy: 0.490234375\n",
      "Batch: 128, Loss: 2.0816447734832764, Accuracy: 0.4453125\n",
      "Batch: 129, Loss: 1.9440598487854004, Accuracy: 0.47265625\n",
      "Batch: 130, Loss: 2.100738763809204, Accuracy: 0.4443359375\n",
      "Batch: 131, Loss: 1.9879101514816284, Accuracy: 0.478515625\n",
      "Batch: 132, Loss: 2.012810707092285, Accuracy: 0.482421875\n",
      "Batch: 133, Loss: 1.942691683769226, Accuracy: 0.478515625\n",
      "Batch: 134, Loss: 1.9457693099975586, Accuracy: 0.4638671875\n",
      "Batch: 135, Loss: 1.8716144561767578, Accuracy: 0.50390625\n",
      "Batch: 136, Loss: 1.8926138877868652, Accuracy: 0.4736328125\n",
      "Batch: 137, Loss: 1.731165885925293, Accuracy: 0.509765625\n",
      "Batch: 138, Loss: 1.6840604543685913, Accuracy: 0.5400390625\n",
      "Batch: 139, Loss: 1.7544424533843994, Accuracy: 0.501953125\n",
      "Batch: 140, Loss: 1.9122679233551025, Accuracy: 0.4765625\n",
      "Batch: 141, Loss: 1.8788937330245972, Accuracy: 0.4990234375\n",
      "Batch: 142, Loss: 1.9044651985168457, Accuracy: 0.46875\n",
      "Batch: 143, Loss: 1.9611592292785645, Accuracy: 0.462890625\n",
      "Batch: 144, Loss: 1.908177375793457, Accuracy: 0.4794921875\n",
      "Batch: 145, Loss: 1.7902753353118896, Accuracy: 0.48828125\n",
      "Batch: 146, Loss: 1.928055763244629, Accuracy: 0.45703125\n",
      "Batch: 147, Loss: 1.8594776391983032, Accuracy: 0.4853515625\n",
      "Batch: 148, Loss: 1.9818460941314697, Accuracy: 0.42578125\n",
      "Batch: 149, Loss: 1.9121818542480469, Accuracy: 0.458984375\n",
      "Batch: 150, Loss: 1.8392802476882935, Accuracy: 0.4794921875\n",
      "Batch: 151, Loss: 1.8466429710388184, Accuracy: 0.505859375\n",
      "Epoch 3/80\n",
      "Batch: 1, Loss: 1.8868567943572998, Accuracy: 0.4482421875\n",
      "Batch: 2, Loss: 1.7204456329345703, Accuracy: 0.4990234375\n",
      "Batch: 3, Loss: 1.8134129047393799, Accuracy: 0.50390625\n",
      "Batch: 4, Loss: 1.792320966720581, Accuracy: 0.5361328125\n",
      "Batch: 5, Loss: 1.7776910066604614, Accuracy: 0.51953125\n",
      "Batch: 6, Loss: 1.750040888786316, Accuracy: 0.4921875\n",
      "Batch: 7, Loss: 1.7047905921936035, Accuracy: 0.4990234375\n",
      "Batch: 8, Loss: 1.7077919244766235, Accuracy: 0.525390625\n",
      "Batch: 9, Loss: 1.6867527961730957, Accuracy: 0.5283203125\n",
      "Batch: 10, Loss: 1.7705317735671997, Accuracy: 0.4951171875\n",
      "Batch: 11, Loss: 1.7764906883239746, Accuracy: 0.4609375\n",
      "Batch: 12, Loss: 1.8661091327667236, Accuracy: 0.4775390625\n",
      "Batch: 13, Loss: 1.6610572338104248, Accuracy: 0.5478515625\n",
      "Batch: 14, Loss: 1.8292112350463867, Accuracy: 0.494140625\n",
      "Batch: 15, Loss: 1.8258516788482666, Accuracy: 0.5087890625\n",
      "Batch: 16, Loss: 1.7438488006591797, Accuracy: 0.4912109375\n",
      "Batch: 17, Loss: 1.769723653793335, Accuracy: 0.478515625\n",
      "Batch: 18, Loss: 1.8132143020629883, Accuracy: 0.4599609375\n",
      "Batch: 19, Loss: 1.8265388011932373, Accuracy: 0.4921875\n",
      "Batch: 20, Loss: 1.8153820037841797, Accuracy: 0.5205078125\n",
      "Batch: 21, Loss: 1.6933120489120483, Accuracy: 0.5361328125\n",
      "Batch: 22, Loss: 1.8426847457885742, Accuracy: 0.486328125\n",
      "Batch: 23, Loss: 1.7154126167297363, Accuracy: 0.509765625\n",
      "Batch: 24, Loss: 1.8239974975585938, Accuracy: 0.5068359375\n",
      "Batch: 25, Loss: 1.7358670234680176, Accuracy: 0.5029296875\n",
      "Batch: 26, Loss: 1.6211800575256348, Accuracy: 0.544921875\n",
      "Batch: 27, Loss: 1.7568528652191162, Accuracy: 0.4814453125\n",
      "Batch: 28, Loss: 1.7219290733337402, Accuracy: 0.4990234375\n",
      "Batch: 29, Loss: 1.7672123908996582, Accuracy: 0.494140625\n",
      "Batch: 30, Loss: 1.796257495880127, Accuracy: 0.5244140625\n",
      "Batch: 31, Loss: 1.7893829345703125, Accuracy: 0.505859375\n",
      "Batch: 32, Loss: 1.6629387140274048, Accuracy: 0.533203125\n",
      "Batch: 33, Loss: 1.8458251953125, Accuracy: 0.474609375\n",
      "Batch: 34, Loss: 1.9497418403625488, Accuracy: 0.4521484375\n",
      "Batch: 35, Loss: 1.7972412109375, Accuracy: 0.5\n",
      "Batch: 36, Loss: 1.8109917640686035, Accuracy: 0.50390625\n",
      "Batch: 37, Loss: 1.8338825702667236, Accuracy: 0.4990234375\n",
      "Batch: 38, Loss: 1.7716498374938965, Accuracy: 0.48828125\n",
      "Batch: 39, Loss: 1.8012630939483643, Accuracy: 0.4931640625\n",
      "Batch: 40, Loss: 1.836148738861084, Accuracy: 0.5185546875\n",
      "Batch: 41, Loss: 1.7986866235733032, Accuracy: 0.53125\n",
      "Batch: 42, Loss: 1.566713571548462, Accuracy: 0.552734375\n",
      "Batch: 43, Loss: 1.6694796085357666, Accuracy: 0.5068359375\n",
      "Batch: 44, Loss: 1.641672134399414, Accuracy: 0.5048828125\n",
      "Batch: 45, Loss: 1.567739486694336, Accuracy: 0.5419921875\n",
      "Batch: 46, Loss: 1.7980072498321533, Accuracy: 0.5244140625\n",
      "Batch: 47, Loss: 1.8107448816299438, Accuracy: 0.5048828125\n",
      "Batch: 48, Loss: 1.777285099029541, Accuracy: 0.521484375\n",
      "Batch: 49, Loss: 1.8269827365875244, Accuracy: 0.48046875\n",
      "Batch: 50, Loss: 1.848678708076477, Accuracy: 0.4853515625\n",
      "Batch: 51, Loss: 1.882356882095337, Accuracy: 0.4716796875\n",
      "Batch: 52, Loss: 1.8573577404022217, Accuracy: 0.494140625\n",
      "Batch: 53, Loss: 1.5983874797821045, Accuracy: 0.5458984375\n",
      "Batch: 54, Loss: 1.7259767055511475, Accuracy: 0.529296875\n",
      "Batch: 55, Loss: 1.6734435558319092, Accuracy: 0.5146484375\n",
      "Batch: 56, Loss: 1.8356499671936035, Accuracy: 0.4931640625\n",
      "Batch: 57, Loss: 1.7174265384674072, Accuracy: 0.521484375\n",
      "Batch: 58, Loss: 1.806673288345337, Accuracy: 0.5029296875\n",
      "Batch: 59, Loss: 1.5878052711486816, Accuracy: 0.56640625\n",
      "Batch: 60, Loss: 1.6373974084854126, Accuracy: 0.5517578125\n",
      "Batch: 61, Loss: 1.6974318027496338, Accuracy: 0.509765625\n",
      "Batch: 62, Loss: 1.7500954866409302, Accuracy: 0.5283203125\n",
      "Batch: 63, Loss: 1.7358815670013428, Accuracy: 0.5029296875\n",
      "Batch: 64, Loss: 1.6861951351165771, Accuracy: 0.5126953125\n",
      "Batch: 65, Loss: 1.733184576034546, Accuracy: 0.5078125\n",
      "Batch: 66, Loss: 1.6359896659851074, Accuracy: 0.537109375\n",
      "Batch: 67, Loss: 1.7425529956817627, Accuracy: 0.50390625\n",
      "Batch: 68, Loss: 1.7819017171859741, Accuracy: 0.521484375\n",
      "Batch: 69, Loss: 1.7374470233917236, Accuracy: 0.5107421875\n",
      "Batch: 70, Loss: 1.7611042261123657, Accuracy: 0.515625\n",
      "Batch: 71, Loss: 1.7097467184066772, Accuracy: 0.509765625\n",
      "Batch: 72, Loss: 1.6178553104400635, Accuracy: 0.5390625\n",
      "Batch: 73, Loss: 1.755001425743103, Accuracy: 0.505859375\n",
      "Batch: 74, Loss: 1.619572639465332, Accuracy: 0.529296875\n",
      "Batch: 75, Loss: 1.6038968563079834, Accuracy: 0.5341796875\n",
      "Batch: 76, Loss: 1.6843714714050293, Accuracy: 0.482421875\n",
      "Batch: 77, Loss: 1.7145166397094727, Accuracy: 0.4873046875\n",
      "Batch: 78, Loss: 1.7420204877853394, Accuracy: 0.5361328125\n",
      "Batch: 79, Loss: 1.5810104608535767, Accuracy: 0.5625\n",
      "Batch: 80, Loss: 1.5602481365203857, Accuracy: 0.541015625\n",
      "Batch: 81, Loss: 1.7001540660858154, Accuracy: 0.484375\n",
      "Batch: 82, Loss: 1.6507093906402588, Accuracy: 0.5126953125\n",
      "Batch: 83, Loss: 1.5482631921768188, Accuracy: 0.564453125\n",
      "Batch: 84, Loss: 1.6455504894256592, Accuracy: 0.5478515625\n",
      "Batch: 85, Loss: 1.6000622510910034, Accuracy: 0.55078125\n",
      "Batch: 86, Loss: 1.7964606285095215, Accuracy: 0.478515625\n",
      "Batch: 87, Loss: 1.6426727771759033, Accuracy: 0.546875\n",
      "Batch: 88, Loss: 1.7181799411773682, Accuracy: 0.509765625\n",
      "Batch: 89, Loss: 1.7404528856277466, Accuracy: 0.498046875\n",
      "Batch: 90, Loss: 1.6185667514801025, Accuracy: 0.546875\n",
      "Batch: 91, Loss: 1.6034321784973145, Accuracy: 0.529296875\n",
      "Batch: 92, Loss: 1.7254021167755127, Accuracy: 0.498046875\n",
      "Batch: 93, Loss: 1.62404203414917, Accuracy: 0.5263671875\n",
      "Batch: 94, Loss: 1.59488046169281, Accuracy: 0.5322265625\n",
      "Batch: 95, Loss: 1.6355111598968506, Accuracy: 0.4931640625\n",
      "Batch: 96, Loss: 1.6633304357528687, Accuracy: 0.5390625\n",
      "Batch: 97, Loss: 1.5261591672897339, Accuracy: 0.5556640625\n",
      "Batch: 98, Loss: 1.544603705406189, Accuracy: 0.5751953125\n",
      "Batch: 101, Loss: 1.600441575050354, Accuracy: 0.5263671875\n",
      "Batch: 102, Loss: 1.526937484741211, Accuracy: 0.53515625\n",
      "Batch: 103, Loss: 1.6559672355651855, Accuracy: 0.546875\n",
      "Batch: 104, Loss: 1.5391103029251099, Accuracy: 0.5576171875\n",
      "Batch: 105, Loss: 1.661004900932312, Accuracy: 0.517578125\n",
      "Batch: 106, Loss: 1.6990326642990112, Accuracy: 0.5048828125\n",
      "Batch: 107, Loss: 1.8214688301086426, Accuracy: 0.4775390625\n",
      "Batch: 108, Loss: 1.8036370277404785, Accuracy: 0.49609375\n",
      "Batch: 109, Loss: 1.7823957204818726, Accuracy: 0.4951171875\n",
      "Batch: 110, Loss: 1.5140525102615356, Accuracy: 0.5556640625\n",
      "Batch: 111, Loss: 1.6541996002197266, Accuracy: 0.51171875\n",
      "Batch: 112, Loss: 1.668107271194458, Accuracy: 0.5322265625\n",
      "Batch: 113, Loss: 1.720212697982788, Accuracy: 0.5224609375\n",
      "Batch: 114, Loss: 1.7654316425323486, Accuracy: 0.4814453125\n",
      "Batch: 115, Loss: 1.799268126487732, Accuracy: 0.5087890625\n",
      "Batch: 116, Loss: 1.7473698854446411, Accuracy: 0.4853515625\n",
      "Batch: 117, Loss: 1.752507209777832, Accuracy: 0.5166015625\n",
      "Batch: 118, Loss: 1.5203105211257935, Accuracy: 0.568359375\n",
      "Batch: 119, Loss: 1.5865774154663086, Accuracy: 0.56640625\n",
      "Batch: 120, Loss: 1.7125983238220215, Accuracy: 0.494140625\n",
      "Batch: 121, Loss: 1.750030279159546, Accuracy: 0.4833984375\n",
      "Batch: 122, Loss: 1.628739833831787, Accuracy: 0.5400390625\n",
      "Batch: 123, Loss: 1.5988739728927612, Accuracy: 0.546875\n",
      "Batch: 124, Loss: 1.643247127532959, Accuracy: 0.533203125\n",
      "Batch: 125, Loss: 1.704588532447815, Accuracy: 0.4921875\n",
      "Batch: 126, Loss: 1.6872538328170776, Accuracy: 0.486328125\n",
      "Batch: 127, Loss: 1.5414016246795654, Accuracy: 0.57421875\n",
      "Batch: 128, Loss: 1.7981950044631958, Accuracy: 0.5126953125\n",
      "Batch: 129, Loss: 1.659596562385559, Accuracy: 0.5166015625\n",
      "Batch: 130, Loss: 1.8617507219314575, Accuracy: 0.4873046875\n",
      "Batch: 131, Loss: 1.7070555686950684, Accuracy: 0.521484375\n",
      "Batch: 132, Loss: 1.6973202228546143, Accuracy: 0.5302734375\n",
      "Batch: 133, Loss: 1.6223227977752686, Accuracy: 0.5380859375\n",
      "Batch: 134, Loss: 1.6456953287124634, Accuracy: 0.5185546875\n",
      "Batch: 135, Loss: 1.6193230152130127, Accuracy: 0.5419921875\n",
      "Batch: 136, Loss: 1.608784794807434, Accuracy: 0.5244140625\n",
      "Batch: 137, Loss: 1.5198333263397217, Accuracy: 0.53125\n",
      "Batch: 138, Loss: 1.4189116954803467, Accuracy: 0.560546875\n",
      "Batch: 139, Loss: 1.4715442657470703, Accuracy: 0.5556640625\n",
      "Batch: 140, Loss: 1.6274540424346924, Accuracy: 0.513671875\n",
      "Batch: 141, Loss: 1.618433952331543, Accuracy: 0.5419921875\n",
      "Batch: 142, Loss: 1.6344300508499146, Accuracy: 0.5146484375\n",
      "Batch: 143, Loss: 1.662285327911377, Accuracy: 0.5126953125\n",
      "Batch: 144, Loss: 1.5968425273895264, Accuracy: 0.5380859375\n",
      "Batch: 145, Loss: 1.5314316749572754, Accuracy: 0.5302734375\n",
      "Batch: 146, Loss: 1.6830639839172363, Accuracy: 0.5146484375\n",
      "Batch: 147, Loss: 1.5992317199707031, Accuracy: 0.5380859375\n",
      "Batch: 148, Loss: 1.7399486303329468, Accuracy: 0.458984375\n",
      "Batch: 149, Loss: 1.6256433725357056, Accuracy: 0.515625\n",
      "Batch: 151, Loss: 1.5503647327423096, Accuracy: 0.552734375\n",
      "Epoch 4/80\n",
      "Batch: 1, Loss: 1.7129113674163818, Accuracy: 0.47265625\n",
      "Batch: 2, Loss: 1.5379507541656494, Accuracy: 0.5107421875\n",
      "Batch: 3, Loss: 1.5608880519866943, Accuracy: 0.54296875\n",
      "Batch: 4, Loss: 1.4614598751068115, Accuracy: 0.58984375\n",
      "Batch: 5, Loss: 1.5281264781951904, Accuracy: 0.55078125\n",
      "Batch: 6, Loss: 1.5923453569412231, Accuracy: 0.521484375\n",
      "Batch: 7, Loss: 1.5213273763656616, Accuracy: 0.5166015625\n",
      "Batch: 8, Loss: 1.4788901805877686, Accuracy: 0.55859375\n",
      "Batch: 9, Loss: 1.4622471332550049, Accuracy: 0.5751953125\n",
      "Batch: 10, Loss: 1.5253536701202393, Accuracy: 0.537109375\n",
      "Batch: 11, Loss: 1.6021852493286133, Accuracy: 0.5078125\n",
      "Batch: 12, Loss: 1.6943538188934326, Accuracy: 0.4873046875\n",
      "Batch: 13, Loss: 1.4006415605545044, Accuracy: 0.5888671875\n",
      "Batch: 14, Loss: 1.6643238067626953, Accuracy: 0.5078125\n",
      "Batch: 15, Loss: 1.578739881515503, Accuracy: 0.5556640625\n",
      "Batch: 16, Loss: 1.5218183994293213, Accuracy: 0.5322265625\n",
      "Batch: 17, Loss: 1.5645735263824463, Accuracy: 0.5078125\n",
      "Batch: 18, Loss: 1.6080372333526611, Accuracy: 0.5029296875\n",
      "Batch: 19, Loss: 1.6122865676879883, Accuracy: 0.5234375\n",
      "Batch: 20, Loss: 1.533724069595337, Accuracy: 0.57421875\n",
      "Batch: 21, Loss: 1.4992619752883911, Accuracy: 0.544921875\n",
      "Batch: 22, Loss: 1.6515347957611084, Accuracy: 0.501953125\n",
      "Batch: 23, Loss: 1.4991223812103271, Accuracy: 0.5419921875\n",
      "Batch: 24, Loss: 1.6074464321136475, Accuracy: 0.5224609375\n",
      "Batch: 25, Loss: 1.531205177307129, Accuracy: 0.52734375\n",
      "Batch: 26, Loss: 1.401216745376587, Accuracy: 0.5693359375\n",
      "Batch: 27, Loss: 1.5239068269729614, Accuracy: 0.5302734375\n",
      "Batch: 28, Loss: 1.5540177822113037, Accuracy: 0.533203125\n",
      "Batch: 29, Loss: 1.5787702798843384, Accuracy: 0.525390625\n",
      "Batch: 30, Loss: 1.579218864440918, Accuracy: 0.5634765625\n",
      "Batch: 31, Loss: 1.5327997207641602, Accuracy: 0.57421875\n",
      "Batch: 32, Loss: 1.495748519897461, Accuracy: 0.5576171875\n",
      "Batch: 33, Loss: 1.6702330112457275, Accuracy: 0.505859375\n",
      "Batch: 34, Loss: 1.7709981203079224, Accuracy: 0.4814453125\n",
      "Batch: 35, Loss: 1.5698306560516357, Accuracy: 0.5224609375\n",
      "Batch: 36, Loss: 1.5803534984588623, Accuracy: 0.5380859375\n",
      "Batch: 37, Loss: 1.632758617401123, Accuracy: 0.5322265625\n",
      "Batch: 38, Loss: 1.580958366394043, Accuracy: 0.51171875\n",
      "Batch: 39, Loss: 1.6044209003448486, Accuracy: 0.5205078125\n",
      "Batch: 40, Loss: 1.6248282194137573, Accuracy: 0.55078125\n",
      "Batch: 41, Loss: 1.621563196182251, Accuracy: 0.5361328125\n",
      "Batch: 42, Loss: 1.364941954612732, Accuracy: 0.5927734375\n",
      "Batch: 43, Loss: 1.5090115070343018, Accuracy: 0.5263671875\n",
      "Batch: 44, Loss: 1.4980213642120361, Accuracy: 0.529296875\n",
      "Batch: 45, Loss: 1.4012571573257446, Accuracy: 0.55078125\n",
      "Batch: 46, Loss: 1.5759954452514648, Accuracy: 0.5546875\n",
      "Batch: 48, Loss: 1.54134202003479, Accuracy: 0.546875\n",
      "Batch: 49, Loss: 1.6736561059951782, Accuracy: 0.5048828125\n",
      "Batch: 50, Loss: 1.622765302658081, Accuracy: 0.517578125\n",
      "Batch: 51, Loss: 1.7298518419265747, Accuracy: 0.4873046875\n",
      "Batch: 52, Loss: 1.6737027168273926, Accuracy: 0.521484375\n",
      "Batch: 53, Loss: 1.4550061225891113, Accuracy: 0.5693359375\n",
      "Batch: 54, Loss: 1.519094467163086, Accuracy: 0.5546875\n",
      "Batch: 55, Loss: 1.5013116598129272, Accuracy: 0.5302734375\n",
      "Batch: 56, Loss: 1.6406829357147217, Accuracy: 0.5146484375\n",
      "Batch: 57, Loss: 1.5859042406082153, Accuracy: 0.537109375\n",
      "Batch: 58, Loss: 1.6519771814346313, Accuracy: 0.53125\n",
      "Batch: 59, Loss: 1.4026849269866943, Accuracy: 0.58984375\n",
      "Batch: 60, Loss: 1.4533531665802002, Accuracy: 0.5712890625\n",
      "Batch: 61, Loss: 1.5515450239181519, Accuracy: 0.5263671875\n",
      "Batch: 62, Loss: 1.544684648513794, Accuracy: 0.541015625\n",
      "Batch: 63, Loss: 1.5531983375549316, Accuracy: 0.5322265625\n",
      "Batch: 64, Loss: 1.497448205947876, Accuracy: 0.54296875\n",
      "Batch: 65, Loss: 1.5603485107421875, Accuracy: 0.5224609375\n",
      "Batch: 66, Loss: 1.4375418424606323, Accuracy: 0.568359375\n",
      "Batch: 67, Loss: 1.6023401021957397, Accuracy: 0.529296875\n",
      "Batch: 68, Loss: 1.6341173648834229, Accuracy: 0.548828125\n",
      "Batch: 69, Loss: 1.5575954914093018, Accuracy: 0.5517578125\n",
      "Batch: 70, Loss: 1.5733373165130615, Accuracy: 0.5458984375\n",
      "Batch: 71, Loss: 1.5902414321899414, Accuracy: 0.51953125\n",
      "Batch: 72, Loss: 1.456819772720337, Accuracy: 0.5498046875\n",
      "Batch: 73, Loss: 1.5672101974487305, Accuracy: 0.5380859375\n",
      "Batch: 74, Loss: 1.4559242725372314, Accuracy: 0.5712890625\n",
      "Batch: 75, Loss: 1.4279720783233643, Accuracy: 0.560546875\n",
      "Batch: 76, Loss: 1.5426368713378906, Accuracy: 0.5224609375\n",
      "Batch: 77, Loss: 1.5367286205291748, Accuracy: 0.5322265625\n",
      "Batch: 78, Loss: 1.5509587526321411, Accuracy: 0.5595703125\n",
      "Batch: 79, Loss: 1.3960695266723633, Accuracy: 0.599609375\n",
      "Batch: 80, Loss: 1.4197365045547485, Accuracy: 0.5546875\n",
      "Batch: 81, Loss: 1.5519829988479614, Accuracy: 0.5048828125\n",
      "Batch: 82, Loss: 1.5033220052719116, Accuracy: 0.5263671875\n",
      "Batch: 83, Loss: 1.369795322418213, Accuracy: 0.5810546875\n",
      "Batch: 84, Loss: 1.4642844200134277, Accuracy: 0.578125\n",
      "Batch: 85, Loss: 1.4055359363555908, Accuracy: 0.587890625\n",
      "Batch: 86, Loss: 1.6390610933303833, Accuracy: 0.5\n",
      "Batch: 87, Loss: 1.4702041149139404, Accuracy: 0.5849609375\n",
      "Batch: 88, Loss: 1.5511929988861084, Accuracy: 0.546875\n",
      "Batch: 89, Loss: 1.5818209648132324, Accuracy: 0.53125\n",
      "Batch: 90, Loss: 1.458566665649414, Accuracy: 0.552734375\n",
      "Batch: 91, Loss: 1.439583420753479, Accuracy: 0.5595703125\n",
      "Batch: 92, Loss: 1.5665600299835205, Accuracy: 0.513671875\n",
      "Batch: 93, Loss: 1.4501075744628906, Accuracy: 0.5546875\n",
      "Batch: 94, Loss: 1.4537686109542847, Accuracy: 0.5546875\n",
      "Batch: 95, Loss: 1.5041799545288086, Accuracy: 0.52734375\n",
      "Batch: 96, Loss: 1.486294150352478, Accuracy: 0.552734375\n",
      "Batch: 97, Loss: 1.373016595840454, Accuracy: 0.5888671875\n",
      "Batch: 98, Loss: 1.3779642581939697, Accuracy: 0.60546875\n",
      "Batch: 99, Loss: 1.3894062042236328, Accuracy: 0.5693359375\n",
      "Batch: 100, Loss: 1.4593794345855713, Accuracy: 0.552734375\n",
      "Batch: 101, Loss: 1.4894161224365234, Accuracy: 0.5361328125\n",
      "Batch: 102, Loss: 1.3956725597381592, Accuracy: 0.56640625\n",
      "Batch: 103, Loss: 1.504634976387024, Accuracy: 0.5673828125\n",
      "Batch: 104, Loss: 1.4107259511947632, Accuracy: 0.57421875\n",
      "Batch: 105, Loss: 1.5106449127197266, Accuracy: 0.5390625\n",
      "Batch: 106, Loss: 1.542315125465393, Accuracy: 0.541015625\n",
      "Batch: 107, Loss: 1.6671494245529175, Accuracy: 0.505859375\n",
      "Batch: 108, Loss: 1.6140819787979126, Accuracy: 0.5380859375\n",
      "Batch: 109, Loss: 1.6505765914916992, Accuracy: 0.525390625\n",
      "Batch: 110, Loss: 1.3532177209854126, Accuracy: 0.578125\n",
      "Batch: 111, Loss: 1.5080766677856445, Accuracy: 0.53125\n",
      "Batch: 112, Loss: 1.5103304386138916, Accuracy: 0.5517578125\n",
      "Batch: 113, Loss: 1.5435407161712646, Accuracy: 0.564453125\n",
      "Batch: 114, Loss: 1.6310584545135498, Accuracy: 0.50390625\n",
      "Batch: 115, Loss: 1.6629598140716553, Accuracy: 0.5234375\n",
      "Batch: 116, Loss: 1.6037431955337524, Accuracy: 0.509765625\n",
      "Batch: 117, Loss: 1.6018221378326416, Accuracy: 0.5361328125\n",
      "Batch: 118, Loss: 1.343278169631958, Accuracy: 0.6083984375\n",
      "Batch: 119, Loss: 1.4135994911193848, Accuracy: 0.578125\n",
      "Batch: 120, Loss: 1.54700767993927, Accuracy: 0.53125\n",
      "Batch: 121, Loss: 1.6083391904830933, Accuracy: 0.5263671875\n",
      "Batch: 122, Loss: 1.4706108570098877, Accuracy: 0.5634765625\n",
      "Batch: 123, Loss: 1.4601240158081055, Accuracy: 0.578125\n",
      "Batch: 124, Loss: 1.4902863502502441, Accuracy: 0.5810546875\n",
      "Batch: 125, Loss: 1.5759798288345337, Accuracy: 0.513671875\n",
      "Batch: 126, Loss: 1.5524277687072754, Accuracy: 0.525390625\n",
      "Batch: 127, Loss: 1.4159564971923828, Accuracy: 0.5908203125\n",
      "Batch: 128, Loss: 1.6568858623504639, Accuracy: 0.5400390625\n",
      "Batch: 129, Loss: 1.5062745809555054, Accuracy: 0.5458984375\n",
      "Batch: 130, Loss: 1.750046968460083, Accuracy: 0.515625\n",
      "Batch: 131, Loss: 1.5683376789093018, Accuracy: 0.5361328125\n",
      "Batch: 132, Loss: 1.5681747198104858, Accuracy: 0.5302734375\n",
      "Batch: 133, Loss: 1.4703214168548584, Accuracy: 0.568359375\n",
      "Batch: 134, Loss: 1.526764154434204, Accuracy: 0.5400390625\n",
      "Batch: 135, Loss: 1.4513750076293945, Accuracy: 0.5576171875\n",
      "Batch: 136, Loss: 1.4664064645767212, Accuracy: 0.55078125\n",
      "Batch: 137, Loss: 1.3952490091323853, Accuracy: 0.544921875\n",
      "Batch: 138, Loss: 1.2589771747589111, Accuracy: 0.607421875\n",
      "Batch: 139, Loss: 1.351996660232544, Accuracy: 0.560546875\n",
      "Batch: 140, Loss: 1.4854393005371094, Accuracy: 0.52734375\n",
      "Batch: 143, Loss: 1.5354974269866943, Accuracy: 0.5341796875\n",
      "Batch: 144, Loss: 1.4687507152557373, Accuracy: 0.5673828125\n",
      "Batch: 145, Loss: 1.3923176527023315, Accuracy: 0.5615234375\n",
      "Batch: 146, Loss: 1.5438205003738403, Accuracy: 0.529296875\n",
      "Batch: 147, Loss: 1.4775466918945312, Accuracy: 0.5556640625\n",
      "Batch: 148, Loss: 1.6557918787002563, Accuracy: 0.4736328125\n",
      "Batch: 149, Loss: 1.5240228176116943, Accuracy: 0.5234375\n",
      "Batch: 150, Loss: 1.4543159008026123, Accuracy: 0.5458984375\n",
      "Batch: 151, Loss: 1.4237339496612549, Accuracy: 0.578125\n",
      "Epoch 5/80\n",
      "Batch: 1, Loss: 1.6574972867965698, Accuracy: 0.48046875\n",
      "Batch: 2, Loss: 1.4600963592529297, Accuracy: 0.51953125\n",
      "Batch: 3, Loss: 1.4203678369522095, Accuracy: 0.556640625\n",
      "Batch: 4, Loss: 1.3254764080047607, Accuracy: 0.623046875\n",
      "Batch: 5, Loss: 1.3975472450256348, Accuracy: 0.580078125\n",
      "Batch: 6, Loss: 1.4943320751190186, Accuracy: 0.53125\n",
      "Batch: 7, Loss: 1.411222219467163, Accuracy: 0.556640625\n",
      "Batch: 8, Loss: 1.3603183031082153, Accuracy: 0.5673828125\n",
      "Batch: 9, Loss: 1.3374038934707642, Accuracy: 0.599609375\n",
      "Batch: 10, Loss: 1.39838707447052, Accuracy: 0.5654296875\n",
      "Batch: 11, Loss: 1.5181164741516113, Accuracy: 0.52734375\n",
      "Batch: 12, Loss: 1.5649330615997314, Accuracy: 0.5322265625\n",
      "Batch: 13, Loss: 1.274003267288208, Accuracy: 0.61328125\n",
      "Batch: 14, Loss: 1.543775200843811, Accuracy: 0.5419921875\n",
      "Batch: 15, Loss: 1.4427578449249268, Accuracy: 0.5791015625\n",
      "Batch: 16, Loss: 1.4080427885055542, Accuracy: 0.5576171875\n",
      "Batch: 17, Loss: 1.484783411026001, Accuracy: 0.5380859375\n",
      "Batch: 18, Loss: 1.5140058994293213, Accuracy: 0.521484375\n",
      "Batch: 19, Loss: 1.5071275234222412, Accuracy: 0.5498046875\n",
      "Batch: 20, Loss: 1.4144737720489502, Accuracy: 0.5947265625\n",
      "Batch: 21, Loss: 1.3989516496658325, Accuracy: 0.5654296875\n",
      "Batch: 22, Loss: 1.5510568618774414, Accuracy: 0.5283203125\n",
      "Batch: 23, Loss: 1.3974236249923706, Accuracy: 0.552734375\n",
      "Batch: 24, Loss: 1.5021395683288574, Accuracy: 0.5546875\n",
      "Batch: 25, Loss: 1.4164574146270752, Accuracy: 0.568359375\n",
      "Batch: 26, Loss: 1.3204962015151978, Accuracy: 0.5869140625\n",
      "Batch: 27, Loss: 1.4137786626815796, Accuracy: 0.5615234375\n",
      "Batch: 28, Loss: 1.4683737754821777, Accuracy: 0.5478515625\n",
      "Batch: 29, Loss: 1.4912902116775513, Accuracy: 0.5419921875\n",
      "Batch: 30, Loss: 1.451552152633667, Accuracy: 0.5810546875\n",
      "Batch: 31, Loss: 1.3996630907058716, Accuracy: 0.5849609375\n",
      "Batch: 32, Loss: 1.374898910522461, Accuracy: 0.580078125\n",
      "Batch: 33, Loss: 1.6057703495025635, Accuracy: 0.5146484375\n",
      "Batch: 34, Loss: 1.6570252180099487, Accuracy: 0.5068359375\n",
      "Batch: 35, Loss: 1.4838401079177856, Accuracy: 0.5458984375\n",
      "Batch: 36, Loss: 1.503075361251831, Accuracy: 0.5595703125\n",
      "Batch: 37, Loss: 1.5106964111328125, Accuracy: 0.556640625\n",
      "Batch: 38, Loss: 1.470240831375122, Accuracy: 0.5419921875\n",
      "Batch: 39, Loss: 1.5248503684997559, Accuracy: 0.537109375\n",
      "Batch: 40, Loss: 1.5189095735549927, Accuracy: 0.5703125\n",
      "Batch: 41, Loss: 1.5059151649475098, Accuracy: 0.5537109375\n",
      "Batch: 42, Loss: 1.26479172706604, Accuracy: 0.5927734375\n",
      "Batch: 43, Loss: 1.4276238679885864, Accuracy: 0.5341796875\n",
      "Batch: 44, Loss: 1.4124380350112915, Accuracy: 0.541015625\n",
      "Batch: 45, Loss: 1.2988097667694092, Accuracy: 0.5732421875\n",
      "Batch: 46, Loss: 1.458794355392456, Accuracy: 0.5791015625\n",
      "Batch: 47, Loss: 1.4860478639602661, Accuracy: 0.5546875\n",
      "Batch: 48, Loss: 1.4076415300369263, Accuracy: 0.5751953125\n",
      "Batch: 49, Loss: 1.5884504318237305, Accuracy: 0.52734375\n",
      "Batch: 50, Loss: 1.5625065565109253, Accuracy: 0.5244140625\n",
      "Batch: 51, Loss: 1.629817008972168, Accuracy: 0.525390625\n",
      "Batch: 52, Loss: 1.5721509456634521, Accuracy: 0.5361328125\n",
      "Batch: 53, Loss: 1.3398864269256592, Accuracy: 0.5947265625\n",
      "Batch: 54, Loss: 1.45913565158844, Accuracy: 0.5791015625\n",
      "Batch: 55, Loss: 1.4275741577148438, Accuracy: 0.556640625\n",
      "Batch: 56, Loss: 1.5492595434188843, Accuracy: 0.5302734375\n",
      "Batch: 57, Loss: 1.45949125289917, Accuracy: 0.55859375\n",
      "Batch: 58, Loss: 1.565481185913086, Accuracy: 0.5478515625\n",
      "Batch: 59, Loss: 1.315787672996521, Accuracy: 0.6162109375\n",
      "Batch: 60, Loss: 1.3405591249465942, Accuracy: 0.595703125\n",
      "Batch: 61, Loss: 1.4660749435424805, Accuracy: 0.544921875\n",
      "Batch: 62, Loss: 1.457817554473877, Accuracy: 0.5458984375\n",
      "Batch: 65, Loss: 1.481818675994873, Accuracy: 0.5439453125\n",
      "Batch: 66, Loss: 1.3555573225021362, Accuracy: 0.5947265625\n",
      "Batch: 67, Loss: 1.5153930187225342, Accuracy: 0.5546875\n",
      "Batch: 68, Loss: 1.5455480813980103, Accuracy: 0.5595703125\n",
      "Batch: 69, Loss: 1.4385896921157837, Accuracy: 0.5625\n",
      "Batch: 70, Loss: 1.4779186248779297, Accuracy: 0.5654296875\n",
      "Batch: 71, Loss: 1.5034098625183105, Accuracy: 0.546875\n",
      "Batch: 72, Loss: 1.3625633716583252, Accuracy: 0.5888671875\n",
      "Batch: 73, Loss: 1.4525740146636963, Accuracy: 0.564453125\n",
      "Batch: 74, Loss: 1.3676235675811768, Accuracy: 0.5791015625\n",
      "Batch: 75, Loss: 1.343961477279663, Accuracy: 0.5830078125\n",
      "Batch: 76, Loss: 1.474939227104187, Accuracy: 0.5361328125\n",
      "Batch: 77, Loss: 1.4573801755905151, Accuracy: 0.5390625\n",
      "Batch: 78, Loss: 1.4341484308242798, Accuracy: 0.5869140625\n",
      "Batch: 79, Loss: 1.2764453887939453, Accuracy: 0.62109375\n",
      "Batch: 80, Loss: 1.3122178316116333, Accuracy: 0.57421875\n",
      "Batch: 81, Loss: 1.5065923929214478, Accuracy: 0.513671875\n",
      "Batch: 82, Loss: 1.4280328750610352, Accuracy: 0.5419921875\n",
      "Batch: 83, Loss: 1.2930333614349365, Accuracy: 0.6103515625\n",
      "Batch: 84, Loss: 1.354539394378662, Accuracy: 0.59765625\n",
      "Batch: 85, Loss: 1.3073112964630127, Accuracy: 0.595703125\n",
      "Batch: 86, Loss: 1.6023633480072021, Accuracy: 0.5087890625\n",
      "Batch: 87, Loss: 1.348895788192749, Accuracy: 0.60546875\n",
      "Batch: 88, Loss: 1.4787266254425049, Accuracy: 0.5478515625\n",
      "Batch: 89, Loss: 1.496907114982605, Accuracy: 0.5478515625\n",
      "Batch: 90, Loss: 1.3823819160461426, Accuracy: 0.5634765625\n",
      "Batch: 91, Loss: 1.3556392192840576, Accuracy: 0.58203125\n",
      "Batch: 92, Loss: 1.4464761018753052, Accuracy: 0.548828125\n",
      "Batch: 93, Loss: 1.3533849716186523, Accuracy: 0.578125\n",
      "Batch: 94, Loss: 1.3772361278533936, Accuracy: 0.572265625\n",
      "Batch: 95, Loss: 1.4291167259216309, Accuracy: 0.5419921875\n",
      "Batch: 96, Loss: 1.4129656553268433, Accuracy: 0.58203125\n",
      "Batch: 97, Loss: 1.2707862854003906, Accuracy: 0.609375\n",
      "Batch: 98, Loss: 1.2967594861984253, Accuracy: 0.6201171875\n",
      "Batch: 99, Loss: 1.2881102561950684, Accuracy: 0.6064453125\n",
      "Batch: 100, Loss: 1.3974363803863525, Accuracy: 0.57421875\n",
      "Batch: 101, Loss: 1.434715986251831, Accuracy: 0.5439453125\n",
      "Batch: 102, Loss: 1.3168468475341797, Accuracy: 0.5869140625\n",
      "Batch: 103, Loss: 1.4238345623016357, Accuracy: 0.5849609375\n",
      "Batch: 104, Loss: 1.3532447814941406, Accuracy: 0.5732421875\n",
      "Batch: 105, Loss: 1.4209105968475342, Accuracy: 0.5390625\n",
      "Batch: 106, Loss: 1.454404354095459, Accuracy: 0.556640625\n",
      "Batch: 107, Loss: 1.581092357635498, Accuracy: 0.53515625\n",
      "Batch: 108, Loss: 1.532299518585205, Accuracy: 0.5498046875\n",
      "Batch: 109, Loss: 1.5756723880767822, Accuracy: 0.5234375\n",
      "Batch: 110, Loss: 1.2572283744812012, Accuracy: 0.5966796875\n",
      "Batch: 111, Loss: 1.4488909244537354, Accuracy: 0.5400390625\n",
      "Batch: 112, Loss: 1.4124035835266113, Accuracy: 0.5908203125\n",
      "Batch: 114, Loss: 1.5764117240905762, Accuracy: 0.5244140625\n",
      "Batch: 115, Loss: 1.5788904428482056, Accuracy: 0.53515625\n",
      "Batch: 116, Loss: 1.5277478694915771, Accuracy: 0.5244140625\n",
      "Batch: 117, Loss: 1.5197217464447021, Accuracy: 0.5654296875\n",
      "Batch: 118, Loss: 1.264063835144043, Accuracy: 0.6240234375\n",
      "Batch: 119, Loss: 1.3220698833465576, Accuracy: 0.59765625\n",
      "Batch: 120, Loss: 1.4890743494033813, Accuracy: 0.5302734375\n",
      "Batch: 121, Loss: 1.519842267036438, Accuracy: 0.5322265625\n",
      "Batch: 122, Loss: 1.3746497631072998, Accuracy: 0.5947265625\n",
      "Batch: 123, Loss: 1.3881714344024658, Accuracy: 0.5908203125\n",
      "Batch: 124, Loss: 1.4179805517196655, Accuracy: 0.5771484375\n",
      "Batch: 125, Loss: 1.5083930492401123, Accuracy: 0.5458984375\n",
      "Batch: 126, Loss: 1.4554216861724854, Accuracy: 0.556640625\n",
      "Batch: 127, Loss: 1.3198750019073486, Accuracy: 0.60546875\n",
      "Batch: 128, Loss: 1.5831918716430664, Accuracy: 0.544921875\n",
      "Batch: 129, Loss: 1.4071273803710938, Accuracy: 0.5634765625\n",
      "Batch: 130, Loss: 1.6524642705917358, Accuracy: 0.5146484375\n",
      "Batch: 131, Loss: 1.4807920455932617, Accuracy: 0.5458984375\n",
      "Batch: 132, Loss: 1.4919147491455078, Accuracy: 0.5498046875\n",
      "Batch: 133, Loss: 1.3511027097702026, Accuracy: 0.5908203125\n",
      "Batch: 134, Loss: 1.4205018281936646, Accuracy: 0.5517578125\n",
      "Batch: 135, Loss: 1.361038088798523, Accuracy: 0.5908203125\n",
      "Batch: 136, Loss: 1.3787636756896973, Accuracy: 0.5712890625\n",
      "Batch: 137, Loss: 1.3367931842803955, Accuracy: 0.5625\n",
      "Batch: 138, Loss: 1.202487587928772, Accuracy: 0.619140625\n",
      "Batch: 139, Loss: 1.2710299491882324, Accuracy: 0.5791015625\n",
      "Batch: 140, Loss: 1.392322063446045, Accuracy: 0.5517578125\n",
      "Batch: 141, Loss: 1.4227650165557861, Accuracy: 0.572265625\n",
      "Batch: 142, Loss: 1.431631088256836, Accuracy: 0.55078125\n",
      "Batch: 143, Loss: 1.4563506841659546, Accuracy: 0.5498046875\n",
      "Batch: 144, Loss: 1.4079985618591309, Accuracy: 0.5634765625\n",
      "Batch: 145, Loss: 1.3378984928131104, Accuracy: 0.568359375\n",
      "Batch: 146, Loss: 1.478677749633789, Accuracy: 0.53125\n",
      "Batch: 147, Loss: 1.409566044807434, Accuracy: 0.5634765625\n",
      "Batch: 148, Loss: 1.5798181295394897, Accuracy: 0.49609375\n",
      "Batch: 149, Loss: 1.459639310836792, Accuracy: 0.5400390625\n",
      "Batch: 150, Loss: 1.3604683876037598, Accuracy: 0.5810546875\n",
      "Batch: 151, Loss: 1.3167619705200195, Accuracy: 0.6015625\n",
      "Epoch 6/80\n",
      "Batch: 1, Loss: 1.5810209512710571, Accuracy: 0.4970703125\n",
      "Batch: 2, Loss: 1.4002795219421387, Accuracy: 0.54296875\n",
      "Batch: 3, Loss: 1.3350868225097656, Accuracy: 0.578125\n",
      "Batch: 4, Loss: 1.2754076719284058, Accuracy: 0.6279296875\n",
      "Batch: 5, Loss: 1.3269526958465576, Accuracy: 0.58984375\n",
      "Batch: 6, Loss: 1.4263172149658203, Accuracy: 0.5322265625\n",
      "Batch: 7, Loss: 1.3539958000183105, Accuracy: 0.564453125\n",
      "Batch: 8, Loss: 1.2945518493652344, Accuracy: 0.591796875\n",
      "Batch: 9, Loss: 1.252873182296753, Accuracy: 0.60546875\n",
      "Batch: 12, Loss: 1.5244133472442627, Accuracy: 0.517578125\n",
      "Batch: 13, Loss: 1.1983197927474976, Accuracy: 0.64453125\n",
      "Batch: 14, Loss: 1.4781134128570557, Accuracy: 0.5341796875\n",
      "Batch: 15, Loss: 1.3766210079193115, Accuracy: 0.5986328125\n",
      "Batch: 16, Loss: 1.3488810062408447, Accuracy: 0.5654296875\n",
      "Batch: 17, Loss: 1.4033125638961792, Accuracy: 0.5517578125\n",
      "Batch: 18, Loss: 1.4318079948425293, Accuracy: 0.55078125\n",
      "Batch: 19, Loss: 1.4521151781082153, Accuracy: 0.564453125\n",
      "Batch: 20, Loss: 1.3465182781219482, Accuracy: 0.599609375\n",
      "Batch: 21, Loss: 1.3338232040405273, Accuracy: 0.5830078125\n",
      "Batch: 22, Loss: 1.4562660455703735, Accuracy: 0.556640625\n",
      "Batch: 23, Loss: 1.3283746242523193, Accuracy: 0.5732421875\n",
      "Batch: 24, Loss: 1.430721402168274, Accuracy: 0.552734375\n",
      "Batch: 25, Loss: 1.357534408569336, Accuracy: 0.58984375\n",
      "Batch: 26, Loss: 1.272993803024292, Accuracy: 0.6015625\n",
      "Batch: 27, Loss: 1.3551735877990723, Accuracy: 0.5625\n",
      "Batch: 28, Loss: 1.4230260848999023, Accuracy: 0.5390625\n",
      "Batch: 29, Loss: 1.4368928670883179, Accuracy: 0.544921875\n",
      "Batch: 30, Loss: 1.368295431137085, Accuracy: 0.59765625\n",
      "Batch: 31, Loss: 1.327812671661377, Accuracy: 0.6259765625\n",
      "Batch: 32, Loss: 1.286489486694336, Accuracy: 0.587890625\n",
      "Batch: 33, Loss: 1.5470373630523682, Accuracy: 0.5283203125\n",
      "Batch: 34, Loss: 1.5956075191497803, Accuracy: 0.5107421875\n",
      "Batch: 35, Loss: 1.424368977546692, Accuracy: 0.5615234375\n",
      "Batch: 36, Loss: 1.4206511974334717, Accuracy: 0.578125\n",
      "Batch: 37, Loss: 1.4453885555267334, Accuracy: 0.5703125\n",
      "Batch: 38, Loss: 1.4136779308319092, Accuracy: 0.5439453125\n",
      "Batch: 39, Loss: 1.4460941553115845, Accuracy: 0.560546875\n",
      "Batch: 40, Loss: 1.4376128911972046, Accuracy: 0.58203125\n",
      "Batch: 41, Loss: 1.464395523071289, Accuracy: 0.5439453125\n",
      "Batch: 42, Loss: 1.2180311679840088, Accuracy: 0.6279296875\n",
      "Batch: 43, Loss: 1.3666155338287354, Accuracy: 0.55859375\n",
      "Batch: 44, Loss: 1.3652738332748413, Accuracy: 0.5537109375\n",
      "Batch: 45, Loss: 1.2255969047546387, Accuracy: 0.5966796875\n",
      "Batch: 46, Loss: 1.398181438446045, Accuracy: 0.57421875\n",
      "Batch: 47, Loss: 1.4318480491638184, Accuracy: 0.568359375\n",
      "Batch: 48, Loss: 1.3671904802322388, Accuracy: 0.583984375\n",
      "Batch: 49, Loss: 1.4998447895050049, Accuracy: 0.5439453125\n",
      "Batch: 50, Loss: 1.4733216762542725, Accuracy: 0.5478515625\n",
      "Batch: 51, Loss: 1.5520623922348022, Accuracy: 0.517578125\n",
      "Batch: 52, Loss: 1.5226436853408813, Accuracy: 0.5361328125\n",
      "Batch: 53, Loss: 1.2486544847488403, Accuracy: 0.6025390625\n",
      "Batch: 54, Loss: 1.3832975625991821, Accuracy: 0.5888671875\n",
      "Batch: 55, Loss: 1.3664095401763916, Accuracy: 0.572265625\n",
      "Batch: 56, Loss: 1.460518479347229, Accuracy: 0.55078125\n",
      "Batch: 57, Loss: 1.3892533779144287, Accuracy: 0.587890625\n",
      "Batch: 58, Loss: 1.5247031450271606, Accuracy: 0.5576171875\n",
      "Batch: 59, Loss: 1.2657757997512817, Accuracy: 0.6259765625\n",
      "Batch: 60, Loss: 1.2663213014602661, Accuracy: 0.619140625\n",
      "Batch: 61, Loss: 1.4138424396514893, Accuracy: 0.5576171875\n",
      "Batch: 62, Loss: 1.3830952644348145, Accuracy: 0.58203125\n",
      "Batch: 63, Loss: 1.4094398021697998, Accuracy: 0.5615234375\n",
      "Batch: 64, Loss: 1.3455073833465576, Accuracy: 0.5849609375\n",
      "Batch: 65, Loss: 1.4139186143875122, Accuracy: 0.5576171875\n",
      "Batch: 66, Loss: 1.2943469285964966, Accuracy: 0.5986328125\n",
      "Batch: 67, Loss: 1.4650964736938477, Accuracy: 0.568359375\n",
      "Batch: 68, Loss: 1.4921164512634277, Accuracy: 0.568359375\n",
      "Batch: 69, Loss: 1.3563129901885986, Accuracy: 0.5810546875\n",
      "Batch: 70, Loss: 1.3949682712554932, Accuracy: 0.599609375\n",
      "Batch: 71, Loss: 1.40824556350708, Accuracy: 0.572265625\n",
      "Batch: 72, Loss: 1.2992018461227417, Accuracy: 0.60546875\n",
      "Batch: 73, Loss: 1.3551621437072754, Accuracy: 0.5947265625\n",
      "Batch: 74, Loss: 1.313645362854004, Accuracy: 0.6015625\n",
      "Batch: 75, Loss: 1.2693848609924316, Accuracy: 0.609375\n",
      "Batch: 76, Loss: 1.4205963611602783, Accuracy: 0.5478515625\n",
      "Batch: 77, Loss: 1.3735439777374268, Accuracy: 0.5673828125\n",
      "Batch: 78, Loss: 1.3647030591964722, Accuracy: 0.6162109375\n",
      "Batch: 79, Loss: 1.2202692031860352, Accuracy: 0.6494140625\n",
      "Batch: 80, Loss: 1.255286455154419, Accuracy: 0.5927734375\n",
      "Batch: 81, Loss: 1.446593999862671, Accuracy: 0.53515625\n",
      "Batch: 82, Loss: 1.3818196058273315, Accuracy: 0.564453125\n",
      "Batch: 83, Loss: 1.2241315841674805, Accuracy: 0.6396484375\n",
      "Batch: 84, Loss: 1.2882988452911377, Accuracy: 0.6298828125\n",
      "Batch: 85, Loss: 1.2344748973846436, Accuracy: 0.62890625\n",
      "Batch: 86, Loss: 1.5112991333007812, Accuracy: 0.525390625\n",
      "Batch: 87, Loss: 1.2854763269424438, Accuracy: 0.6171875\n",
      "Batch: 88, Loss: 1.4306538105010986, Accuracy: 0.57421875\n",
      "Batch: 89, Loss: 1.4356672763824463, Accuracy: 0.564453125\n",
      "Batch: 90, Loss: 1.3235561847686768, Accuracy: 0.576171875\n",
      "Batch: 91, Loss: 1.3032429218292236, Accuracy: 0.587890625\n",
      "Batch: 92, Loss: 1.3900588750839233, Accuracy: 0.5634765625\n",
      "Batch: 93, Loss: 1.3025972843170166, Accuracy: 0.61328125\n",
      "Batch: 94, Loss: 1.3060333728790283, Accuracy: 0.5869140625\n",
      "Batch: 95, Loss: 1.3640977144241333, Accuracy: 0.5537109375\n",
      "Batch: 96, Loss: 1.3272218704223633, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.1813428401947021, Accuracy: 0.6435546875\n",
      "Batch: 98, Loss: 1.2510367631912231, Accuracy: 0.6259765625\n",
      "Batch: 99, Loss: 1.2390658855438232, Accuracy: 0.6103515625\n",
      "Batch: 100, Loss: 1.3260865211486816, Accuracy: 0.5986328125\n",
      "Batch: 101, Loss: 1.378936767578125, Accuracy: 0.5751953125\n",
      "Batch: 105, Loss: 1.3858364820480347, Accuracy: 0.5615234375\n",
      "Batch: 106, Loss: 1.3846564292907715, Accuracy: 0.5693359375\n",
      "Batch: 107, Loss: 1.5069739818572998, Accuracy: 0.5419921875\n",
      "Batch: 108, Loss: 1.4721399545669556, Accuracy: 0.5673828125\n",
      "Batch: 109, Loss: 1.5248336791992188, Accuracy: 0.515625\n",
      "Batch: 110, Loss: 1.2048301696777344, Accuracy: 0.611328125\n",
      "Batch: 111, Loss: 1.386265516281128, Accuracy: 0.5625\n",
      "Batch: 112, Loss: 1.375335931777954, Accuracy: 0.587890625\n",
      "Batch: 113, Loss: 1.4145941734313965, Accuracy: 0.5908203125\n",
      "Batch: 114, Loss: 1.5185933113098145, Accuracy: 0.533203125\n",
      "Batch: 115, Loss: 1.5334513187408447, Accuracy: 0.5478515625\n",
      "Batch: 116, Loss: 1.4598805904388428, Accuracy: 0.5361328125\n",
      "Batch: 117, Loss: 1.4582605361938477, Accuracy: 0.56640625\n",
      "Batch: 118, Loss: 1.203519582748413, Accuracy: 0.6376953125\n",
      "Batch: 119, Loss: 1.2679955959320068, Accuracy: 0.62109375\n",
      "Batch: 120, Loss: 1.4240076541900635, Accuracy: 0.54296875\n",
      "Batch: 121, Loss: 1.4621450901031494, Accuracy: 0.5478515625\n",
      "Batch: 122, Loss: 1.329014539718628, Accuracy: 0.59765625\n",
      "Batch: 123, Loss: 1.3276114463806152, Accuracy: 0.5986328125\n",
      "Batch: 124, Loss: 1.3700885772705078, Accuracy: 0.5927734375\n",
      "Batch: 125, Loss: 1.4414527416229248, Accuracy: 0.556640625\n",
      "Batch: 126, Loss: 1.4217714071273804, Accuracy: 0.5400390625\n",
      "Batch: 127, Loss: 1.2567119598388672, Accuracy: 0.626953125\n",
      "Batch: 128, Loss: 1.520341396331787, Accuracy: 0.556640625\n",
      "Batch: 129, Loss: 1.3347289562225342, Accuracy: 0.58203125\n",
      "Batch: 130, Loss: 1.5929462909698486, Accuracy: 0.5224609375\n",
      "Batch: 131, Loss: 1.412385106086731, Accuracy: 0.5732421875\n",
      "Batch: 132, Loss: 1.4229767322540283, Accuracy: 0.5654296875\n",
      "Batch: 133, Loss: 1.31423020362854, Accuracy: 0.59375\n",
      "Batch: 134, Loss: 1.3654069900512695, Accuracy: 0.564453125\n",
      "Batch: 135, Loss: 1.316521167755127, Accuracy: 0.609375\n",
      "Batch: 136, Loss: 1.329960823059082, Accuracy: 0.5908203125\n",
      "Batch: 137, Loss: 1.2696607112884521, Accuracy: 0.5712890625\n",
      "Batch: 138, Loss: 1.148300290107727, Accuracy: 0.607421875\n",
      "Batch: 139, Loss: 1.2195394039154053, Accuracy: 0.6005859375\n",
      "Batch: 140, Loss: 1.3520145416259766, Accuracy: 0.5673828125\n",
      "Batch: 141, Loss: 1.3665385246276855, Accuracy: 0.599609375\n",
      "Batch: 142, Loss: 1.4005777835845947, Accuracy: 0.5615234375\n",
      "Batch: 143, Loss: 1.3882369995117188, Accuracy: 0.580078125\n",
      "Batch: 144, Loss: 1.3292920589447021, Accuracy: 0.595703125\n",
      "Batch: 145, Loss: 1.2816158533096313, Accuracy: 0.58203125\n",
      "Batch: 146, Loss: 1.414963960647583, Accuracy: 0.5498046875\n",
      "Batch: 148, Loss: 1.5393025875091553, Accuracy: 0.515625\n",
      "Batch: 149, Loss: 1.3702903985977173, Accuracy: 0.5732421875\n",
      "Batch: 150, Loss: 1.300715446472168, Accuracy: 0.5908203125\n",
      "Batch: 151, Loss: 1.2834467887878418, Accuracy: 0.6103515625\n",
      "Epoch 7/80\n",
      "Batch: 1, Loss: 1.5609166622161865, Accuracy: 0.505859375\n",
      "Batch: 2, Loss: 1.3434996604919434, Accuracy: 0.5556640625\n",
      "Batch: 3, Loss: 1.273895502090454, Accuracy: 0.587890625\n",
      "Batch: 4, Loss: 1.222762107849121, Accuracy: 0.634765625\n",
      "Batch: 5, Loss: 1.262101173400879, Accuracy: 0.611328125\n",
      "Batch: 6, Loss: 1.3521671295166016, Accuracy: 0.56640625\n",
      "Batch: 7, Loss: 1.2935187816619873, Accuracy: 0.578125\n",
      "Batch: 8, Loss: 1.2398320436477661, Accuracy: 0.6005859375\n",
      "Batch: 9, Loss: 1.2139499187469482, Accuracy: 0.6259765625\n",
      "Batch: 10, Loss: 1.2544496059417725, Accuracy: 0.6005859375\n",
      "Batch: 11, Loss: 1.422235369682312, Accuracy: 0.53515625\n",
      "Batch: 12, Loss: 1.4618107080459595, Accuracy: 0.55078125\n",
      "Batch: 13, Loss: 1.1479377746582031, Accuracy: 0.6416015625\n",
      "Batch: 14, Loss: 1.4258801937103271, Accuracy: 0.5478515625\n",
      "Batch: 15, Loss: 1.2980059385299683, Accuracy: 0.6083984375\n",
      "Batch: 16, Loss: 1.28057861328125, Accuracy: 0.607421875\n",
      "Batch: 17, Loss: 1.3788594007492065, Accuracy: 0.5576171875\n",
      "Batch: 18, Loss: 1.3715367317199707, Accuracy: 0.55859375\n",
      "Batch: 19, Loss: 1.3833673000335693, Accuracy: 0.580078125\n",
      "Batch: 20, Loss: 1.3066799640655518, Accuracy: 0.607421875\n",
      "Batch: 21, Loss: 1.2442736625671387, Accuracy: 0.6103515625\n",
      "Batch: 22, Loss: 1.4085140228271484, Accuracy: 0.55078125\n",
      "Batch: 23, Loss: 1.2740874290466309, Accuracy: 0.5830078125\n",
      "Batch: 24, Loss: 1.3629100322723389, Accuracy: 0.5751953125\n",
      "Batch: 25, Loss: 1.3002279996871948, Accuracy: 0.59765625\n",
      "Batch: 26, Loss: 1.204688549041748, Accuracy: 0.6220703125\n",
      "Batch: 27, Loss: 1.2905471324920654, Accuracy: 0.58203125\n",
      "Batch: 28, Loss: 1.358720302581787, Accuracy: 0.580078125\n",
      "Batch: 29, Loss: 1.3729441165924072, Accuracy: 0.576171875\n",
      "Batch: 30, Loss: 1.2994496822357178, Accuracy: 0.6103515625\n",
      "Batch: 31, Loss: 1.2399369478225708, Accuracy: 0.65234375\n",
      "Batch: 32, Loss: 1.2424596548080444, Accuracy: 0.5986328125\n",
      "Batch: 33, Loss: 1.462735891342163, Accuracy: 0.5546875\n",
      "Batch: 34, Loss: 1.5284596681594849, Accuracy: 0.54296875\n",
      "Batch: 35, Loss: 1.3718559741973877, Accuracy: 0.564453125\n",
      "Batch: 36, Loss: 1.3813635110855103, Accuracy: 0.5908203125\n",
      "Batch: 37, Loss: 1.345407247543335, Accuracy: 0.595703125\n",
      "Batch: 38, Loss: 1.3764923810958862, Accuracy: 0.56640625\n",
      "Batch: 39, Loss: 1.3718494176864624, Accuracy: 0.5732421875\n",
      "Batch: 40, Loss: 1.3691351413726807, Accuracy: 0.6044921875\n",
      "Batch: 41, Loss: 1.385891079902649, Accuracy: 0.5869140625\n",
      "Batch: 42, Loss: 1.1404343843460083, Accuracy: 0.6298828125\n",
      "Batch: 46, Loss: 1.3405004739761353, Accuracy: 0.6123046875\n",
      "Batch: 47, Loss: 1.3289906978607178, Accuracy: 0.6005859375\n",
      "Batch: 48, Loss: 1.2986602783203125, Accuracy: 0.5986328125\n",
      "Batch: 49, Loss: 1.4483239650726318, Accuracy: 0.556640625\n",
      "Batch: 50, Loss: 1.3948006629943848, Accuracy: 0.5712890625\n",
      "Batch: 51, Loss: 1.4906553030014038, Accuracy: 0.5439453125\n",
      "Batch: 52, Loss: 1.4558329582214355, Accuracy: 0.560546875\n",
      "Batch: 53, Loss: 1.1851381063461304, Accuracy: 0.6328125\n",
      "Batch: 54, Loss: 1.3065879344940186, Accuracy: 0.5966796875\n",
      "Batch: 55, Loss: 1.3430498838424683, Accuracy: 0.5810546875\n",
      "Batch: 56, Loss: 1.3930606842041016, Accuracy: 0.5859375\n",
      "Batch: 57, Loss: 1.330098032951355, Accuracy: 0.6005859375\n",
      "Batch: 58, Loss: 1.4211220741271973, Accuracy: 0.5732421875\n",
      "Batch: 59, Loss: 1.1990556716918945, Accuracy: 0.65234375\n",
      "Batch: 60, Loss: 1.2237465381622314, Accuracy: 0.6279296875\n",
      "Batch: 61, Loss: 1.3439950942993164, Accuracy: 0.5712890625\n",
      "Batch: 62, Loss: 1.340449571609497, Accuracy: 0.591796875\n",
      "Batch: 63, Loss: 1.3399475812911987, Accuracy: 0.5810546875\n",
      "Batch: 64, Loss: 1.277897596359253, Accuracy: 0.5908203125\n",
      "Batch: 65, Loss: 1.3547810316085815, Accuracy: 0.5810546875\n",
      "Batch: 66, Loss: 1.2617273330688477, Accuracy: 0.611328125\n",
      "Batch: 67, Loss: 1.4370933771133423, Accuracy: 0.5771484375\n",
      "Batch: 68, Loss: 1.420095682144165, Accuracy: 0.599609375\n",
      "Batch: 69, Loss: 1.3168525695800781, Accuracy: 0.6015625\n",
      "Batch: 70, Loss: 1.339924931526184, Accuracy: 0.6044921875\n",
      "Batch: 71, Loss: 1.3606352806091309, Accuracy: 0.5751953125\n",
      "Batch: 72, Loss: 1.247314453125, Accuracy: 0.615234375\n",
      "Batch: 73, Loss: 1.2912781238555908, Accuracy: 0.611328125\n",
      "Batch: 74, Loss: 1.241147756576538, Accuracy: 0.6162109375\n",
      "Batch: 75, Loss: 1.204681396484375, Accuracy: 0.6298828125\n",
      "Batch: 76, Loss: 1.343551754951477, Accuracy: 0.56640625\n",
      "Batch: 77, Loss: 1.3211933374404907, Accuracy: 0.5771484375\n",
      "Batch: 78, Loss: 1.320591688156128, Accuracy: 0.609375\n",
      "Batch: 79, Loss: 1.1834609508514404, Accuracy: 0.65625\n",
      "Batch: 80, Loss: 1.2078793048858643, Accuracy: 0.6015625\n",
      "Batch: 81, Loss: 1.3804035186767578, Accuracy: 0.5478515625\n",
      "Batch: 82, Loss: 1.3296284675598145, Accuracy: 0.56640625\n",
      "Batch: 83, Loss: 1.1787750720977783, Accuracy: 0.6416015625\n",
      "Batch: 84, Loss: 1.2526953220367432, Accuracy: 0.642578125\n",
      "Batch: 85, Loss: 1.1787360906600952, Accuracy: 0.6337890625\n",
      "Batch: 86, Loss: 1.4986889362335205, Accuracy: 0.5380859375\n",
      "Batch: 87, Loss: 1.2322022914886475, Accuracy: 0.6337890625\n",
      "Batch: 88, Loss: 1.3483655452728271, Accuracy: 0.6015625\n",
      "Batch: 89, Loss: 1.3673135042190552, Accuracy: 0.5830078125\n",
      "Batch: 90, Loss: 1.2397494316101074, Accuracy: 0.60546875\n",
      "Batch: 91, Loss: 1.2792854309082031, Accuracy: 0.6123046875\n",
      "Batch: 92, Loss: 1.3242357969284058, Accuracy: 0.5986328125\n",
      "Batch: 93, Loss: 1.2530760765075684, Accuracy: 0.61328125\n",
      "Batch: 94, Loss: 1.2658008337020874, Accuracy: 0.611328125\n",
      "Batch: 96, Loss: 1.2713274955749512, Accuracy: 0.6259765625\n",
      "Batch: 97, Loss: 1.1340359449386597, Accuracy: 0.650390625\n",
      "Batch: 98, Loss: 1.2037734985351562, Accuracy: 0.638671875\n",
      "Batch: 99, Loss: 1.20009446144104, Accuracy: 0.6318359375\n",
      "Batch: 100, Loss: 1.2874109745025635, Accuracy: 0.60546875\n",
      "Batch: 101, Loss: 1.325303077697754, Accuracy: 0.5751953125\n",
      "Batch: 102, Loss: 1.2041332721710205, Accuracy: 0.62890625\n",
      "Batch: 103, Loss: 1.3214432001113892, Accuracy: 0.595703125\n",
      "Batch: 104, Loss: 1.2076104879379272, Accuracy: 0.609375\n",
      "Batch: 105, Loss: 1.3276267051696777, Accuracy: 0.59375\n",
      "Batch: 106, Loss: 1.3186023235321045, Accuracy: 0.6025390625\n",
      "Batch: 107, Loss: 1.4740500450134277, Accuracy: 0.5732421875\n",
      "Batch: 108, Loss: 1.4307940006256104, Accuracy: 0.5634765625\n",
      "Batch: 109, Loss: 1.4838922023773193, Accuracy: 0.5322265625\n",
      "Batch: 110, Loss: 1.138054370880127, Accuracy: 0.6318359375\n",
      "Batch: 111, Loss: 1.3493975400924683, Accuracy: 0.5576171875\n",
      "Batch: 112, Loss: 1.3113973140716553, Accuracy: 0.6005859375\n",
      "Batch: 113, Loss: 1.3518240451812744, Accuracy: 0.61328125\n",
      "Batch: 114, Loss: 1.4690618515014648, Accuracy: 0.5498046875\n",
      "Batch: 115, Loss: 1.4861819744110107, Accuracy: 0.5615234375\n",
      "Batch: 116, Loss: 1.398197889328003, Accuracy: 0.56640625\n",
      "Batch: 117, Loss: 1.4050483703613281, Accuracy: 0.5791015625\n",
      "Batch: 118, Loss: 1.1695442199707031, Accuracy: 0.646484375\n",
      "Batch: 119, Loss: 1.2001757621765137, Accuracy: 0.642578125\n",
      "Batch: 120, Loss: 1.3741366863250732, Accuracy: 0.5673828125\n",
      "Batch: 121, Loss: 1.4203240871429443, Accuracy: 0.568359375\n",
      "Batch: 122, Loss: 1.278864860534668, Accuracy: 0.619140625\n",
      "Batch: 123, Loss: 1.2658699750900269, Accuracy: 0.61328125\n",
      "Batch: 124, Loss: 1.3301010131835938, Accuracy: 0.5888671875\n",
      "Batch: 125, Loss: 1.371413230895996, Accuracy: 0.5791015625\n",
      "Batch: 126, Loss: 1.3572794198989868, Accuracy: 0.5771484375\n",
      "Batch: 127, Loss: 1.1986331939697266, Accuracy: 0.6435546875\n",
      "Batch: 128, Loss: 1.4482945203781128, Accuracy: 0.5791015625\n",
      "Batch: 129, Loss: 1.2925496101379395, Accuracy: 0.5927734375\n",
      "Batch: 130, Loss: 1.5444836616516113, Accuracy: 0.54296875\n",
      "Batch: 131, Loss: 1.3550662994384766, Accuracy: 0.5849609375\n",
      "Batch: 132, Loss: 1.3759360313415527, Accuracy: 0.5732421875\n",
      "Batch: 133, Loss: 1.2277792692184448, Accuracy: 0.6064453125\n",
      "Batch: 134, Loss: 1.3337064981460571, Accuracy: 0.5673828125\n",
      "Batch: 135, Loss: 1.2460931539535522, Accuracy: 0.603515625\n",
      "Batch: 136, Loss: 1.2878499031066895, Accuracy: 0.599609375\n",
      "Batch: 137, Loss: 1.2201677560806274, Accuracy: 0.58984375\n",
      "Batch: 138, Loss: 1.09126615524292, Accuracy: 0.638671875\n",
      "Batch: 139, Loss: 1.1632357835769653, Accuracy: 0.6220703125\n",
      "Batch: 140, Loss: 1.275870680809021, Accuracy: 0.5966796875\n",
      "Batch: 141, Loss: 1.3248651027679443, Accuracy: 0.5693359375\n",
      "Batch: 142, Loss: 1.3440041542053223, Accuracy: 0.5830078125\n",
      "Batch: 143, Loss: 1.325359582901001, Accuracy: 0.6015625\n",
      "Batch: 144, Loss: 1.2969322204589844, Accuracy: 0.599609375\n",
      "Batch: 147, Loss: 1.3208141326904297, Accuracy: 0.591796875\n",
      "Batch: 148, Loss: 1.4851442575454712, Accuracy: 0.5244140625\n",
      "Batch: 149, Loss: 1.3220460414886475, Accuracy: 0.5830078125\n",
      "Batch: 150, Loss: 1.238267421722412, Accuracy: 0.611328125\n",
      "Batch: 151, Loss: 1.1966021060943604, Accuracy: 0.6279296875\n",
      "Epoch 8/80\n",
      "Batch: 1, Loss: 1.5292634963989258, Accuracy: 0.515625\n",
      "Batch: 2, Loss: 1.3128421306610107, Accuracy: 0.5537109375\n",
      "Batch: 3, Loss: 1.222138524055481, Accuracy: 0.58203125\n",
      "Batch: 4, Loss: 1.1585018634796143, Accuracy: 0.6376953125\n",
      "Batch: 5, Loss: 1.219252347946167, Accuracy: 0.6396484375\n",
      "Batch: 6, Loss: 1.2921031713485718, Accuracy: 0.583984375\n",
      "Batch: 7, Loss: 1.24515962600708, Accuracy: 0.58984375\n",
      "Batch: 8, Loss: 1.1833522319793701, Accuracy: 0.6279296875\n",
      "Batch: 9, Loss: 1.1542969942092896, Accuracy: 0.630859375\n",
      "Batch: 10, Loss: 1.2102744579315186, Accuracy: 0.619140625\n",
      "Batch: 11, Loss: 1.3699662685394287, Accuracy: 0.5517578125\n",
      "Batch: 12, Loss: 1.4178078174591064, Accuracy: 0.5546875\n",
      "Batch: 13, Loss: 1.109266757965088, Accuracy: 0.666015625\n",
      "Batch: 14, Loss: 1.390385627746582, Accuracy: 0.572265625\n",
      "Batch: 15, Loss: 1.2082629203796387, Accuracy: 0.6171875\n",
      "Batch: 16, Loss: 1.206908941268921, Accuracy: 0.6201171875\n",
      "Batch: 17, Loss: 1.2865889072418213, Accuracy: 0.599609375\n",
      "Batch: 18, Loss: 1.3077542781829834, Accuracy: 0.5830078125\n",
      "Batch: 19, Loss: 1.322376012802124, Accuracy: 0.58984375\n",
      "Batch: 20, Loss: 1.2330873012542725, Accuracy: 0.625\n",
      "Batch: 21, Loss: 1.2225854396820068, Accuracy: 0.6064453125\n",
      "Batch: 22, Loss: 1.3389132022857666, Accuracy: 0.576171875\n",
      "Batch: 23, Loss: 1.2238621711730957, Accuracy: 0.6123046875\n",
      "Batch: 24, Loss: 1.2944517135620117, Accuracy: 0.5810546875\n",
      "Batch: 25, Loss: 1.2472734451293945, Accuracy: 0.6181640625\n",
      "Batch: 26, Loss: 1.1764395236968994, Accuracy: 0.634765625\n",
      "Batch: 27, Loss: 1.2193485498428345, Accuracy: 0.611328125\n",
      "Batch: 28, Loss: 1.3124903440475464, Accuracy: 0.5869140625\n",
      "Batch: 29, Loss: 1.3102720975875854, Accuracy: 0.5869140625\n",
      "Batch: 30, Loss: 1.237723708152771, Accuracy: 0.6376953125\n",
      "Batch: 31, Loss: 1.194354772567749, Accuracy: 0.63671875\n",
      "Batch: 32, Loss: 1.1950002908706665, Accuracy: 0.6171875\n",
      "Batch: 33, Loss: 1.4135653972625732, Accuracy: 0.5693359375\n",
      "Batch: 34, Loss: 1.4759392738342285, Accuracy: 0.54296875\n",
      "Batch: 35, Loss: 1.3253753185272217, Accuracy: 0.5712890625\n",
      "Batch: 36, Loss: 1.3110102415084839, Accuracy: 0.603515625\n",
      "Batch: 37, Loss: 1.3302981853485107, Accuracy: 0.578125\n",
      "Batch: 38, Loss: 1.3160300254821777, Accuracy: 0.5693359375\n",
      "Batch: 39, Loss: 1.3142727613449097, Accuracy: 0.6005859375\n",
      "Batch: 41, Loss: 1.3248252868652344, Accuracy: 0.5908203125\n",
      "Batch: 42, Loss: 1.076550006866455, Accuracy: 0.65234375\n",
      "Batch: 43, Loss: 1.2686636447906494, Accuracy: 0.5869140625\n",
      "Batch: 44, Loss: 1.2555855512619019, Accuracy: 0.576171875\n",
      "Batch: 45, Loss: 1.1202261447906494, Accuracy: 0.6357421875\n",
      "Batch: 46, Loss: 1.2840244770050049, Accuracy: 0.609375\n",
      "Batch: 47, Loss: 1.3127801418304443, Accuracy: 0.607421875\n",
      "Batch: 48, Loss: 1.2373528480529785, Accuracy: 0.6279296875\n",
      "Batch: 49, Loss: 1.4254601001739502, Accuracy: 0.5537109375\n",
      "Batch: 50, Loss: 1.3579356670379639, Accuracy: 0.5703125\n",
      "Batch: 51, Loss: 1.4701182842254639, Accuracy: 0.5419921875\n",
      "Batch: 52, Loss: 1.3925172090530396, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.1455762386322021, Accuracy: 0.6318359375\n",
      "Batch: 54, Loss: 1.2574560642242432, Accuracy: 0.6259765625\n",
      "Batch: 55, Loss: 1.2866978645324707, Accuracy: 0.5908203125\n",
      "Batch: 56, Loss: 1.3628172874450684, Accuracy: 0.5830078125\n",
      "Batch: 57, Loss: 1.29752516746521, Accuracy: 0.6015625\n",
      "Batch: 58, Loss: 1.40603506565094, Accuracy: 0.5810546875\n",
      "Batch: 59, Loss: 1.1577070951461792, Accuracy: 0.6611328125\n",
      "Batch: 60, Loss: 1.163620948791504, Accuracy: 0.6513671875\n",
      "Batch: 61, Loss: 1.3225042819976807, Accuracy: 0.5859375\n",
      "Batch: 62, Loss: 1.28098726272583, Accuracy: 0.591796875\n",
      "Batch: 63, Loss: 1.3138253688812256, Accuracy: 0.587890625\n",
      "Batch: 64, Loss: 1.2586205005645752, Accuracy: 0.5927734375\n",
      "Batch: 65, Loss: 1.311650276184082, Accuracy: 0.6015625\n",
      "Batch: 66, Loss: 1.2328572273254395, Accuracy: 0.619140625\n",
      "Batch: 67, Loss: 1.3554497957229614, Accuracy: 0.5830078125\n",
      "Batch: 68, Loss: 1.3877501487731934, Accuracy: 0.599609375\n",
      "Batch: 69, Loss: 1.3031926155090332, Accuracy: 0.59765625\n",
      "Batch: 70, Loss: 1.2769956588745117, Accuracy: 0.623046875\n",
      "Batch: 71, Loss: 1.3187222480773926, Accuracy: 0.6015625\n",
      "Batch: 72, Loss: 1.1748157739639282, Accuracy: 0.64453125\n",
      "Batch: 73, Loss: 1.2560186386108398, Accuracy: 0.6171875\n",
      "Batch: 74, Loss: 1.199932336807251, Accuracy: 0.6279296875\n",
      "Batch: 75, Loss: 1.157444953918457, Accuracy: 0.634765625\n",
      "Batch: 76, Loss: 1.3132352828979492, Accuracy: 0.5751953125\n",
      "Batch: 77, Loss: 1.2867047786712646, Accuracy: 0.5849609375\n",
      "Batch: 78, Loss: 1.269893765449524, Accuracy: 0.625\n",
      "Batch: 79, Loss: 1.1282517910003662, Accuracy: 0.671875\n",
      "Batch: 80, Loss: 1.1803429126739502, Accuracy: 0.6044921875\n",
      "Batch: 81, Loss: 1.34905207157135, Accuracy: 0.56640625\n",
      "Batch: 82, Loss: 1.2791848182678223, Accuracy: 0.6025390625\n",
      "Batch: 83, Loss: 1.1311347484588623, Accuracy: 0.6552734375\n",
      "Batch: 84, Loss: 1.2052040100097656, Accuracy: 0.64453125\n",
      "Batch: 85, Loss: 1.137343406677246, Accuracy: 0.6474609375\n",
      "Batch: 86, Loss: 1.4436367750167847, Accuracy: 0.5537109375\n",
      "Batch: 88, Loss: 1.2799750566482544, Accuracy: 0.619140625\n",
      "Batch: 89, Loss: 1.294037103652954, Accuracy: 0.6015625\n",
      "Batch: 90, Loss: 1.198826789855957, Accuracy: 0.6201171875\n",
      "Batch: 91, Loss: 1.229394793510437, Accuracy: 0.611328125\n",
      "Batch: 92, Loss: 1.2833895683288574, Accuracy: 0.59375\n",
      "Batch: 93, Loss: 1.2007653713226318, Accuracy: 0.6240234375\n",
      "Batch: 94, Loss: 1.2149426937103271, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.2598010301589966, Accuracy: 0.5830078125\n",
      "Batch: 96, Loss: 1.2397334575653076, Accuracy: 0.6171875\n",
      "Batch: 97, Loss: 1.1057381629943848, Accuracy: 0.6455078125\n",
      "Batch: 98, Loss: 1.1568089723587036, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.1476130485534668, Accuracy: 0.6357421875\n",
      "Batch: 100, Loss: 1.2436100244522095, Accuracy: 0.611328125\n",
      "Batch: 101, Loss: 1.2908332347869873, Accuracy: 0.587890625\n",
      "Batch: 102, Loss: 1.1811044216156006, Accuracy: 0.6181640625\n",
      "Batch: 103, Loss: 1.2910451889038086, Accuracy: 0.6181640625\n",
      "Batch: 104, Loss: 1.1594889163970947, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.2782342433929443, Accuracy: 0.5986328125\n",
      "Batch: 106, Loss: 1.2835350036621094, Accuracy: 0.6064453125\n",
      "Batch: 107, Loss: 1.4292572736740112, Accuracy: 0.576171875\n",
      "Batch: 108, Loss: 1.3714276552200317, Accuracy: 0.5732421875\n",
      "Batch: 109, Loss: 1.4558994770050049, Accuracy: 0.541015625\n",
      "Batch: 110, Loss: 1.0914860963821411, Accuracy: 0.65625\n",
      "Batch: 111, Loss: 1.3063716888427734, Accuracy: 0.57421875\n",
      "Batch: 112, Loss: 1.2598543167114258, Accuracy: 0.609375\n",
      "Batch: 113, Loss: 1.2900362014770508, Accuracy: 0.6220703125\n",
      "Batch: 114, Loss: 1.4143707752227783, Accuracy: 0.5712890625\n",
      "Batch: 115, Loss: 1.436398983001709, Accuracy: 0.5771484375\n",
      "Batch: 116, Loss: 1.3408112525939941, Accuracy: 0.5869140625\n",
      "Batch: 117, Loss: 1.3569269180297852, Accuracy: 0.5908203125\n",
      "Batch: 118, Loss: 1.127770185470581, Accuracy: 0.642578125\n",
      "Batch: 119, Loss: 1.1601309776306152, Accuracy: 0.6552734375\n",
      "Batch: 120, Loss: 1.3267849683761597, Accuracy: 0.58203125\n",
      "Batch: 121, Loss: 1.3638745546340942, Accuracy: 0.556640625\n",
      "Batch: 122, Loss: 1.21358323097229, Accuracy: 0.611328125\n",
      "Batch: 123, Loss: 1.220930814743042, Accuracy: 0.6171875\n",
      "Batch: 124, Loss: 1.2744852304458618, Accuracy: 0.6201171875\n",
      "Batch: 125, Loss: 1.3202831745147705, Accuracy: 0.59375\n",
      "Batch: 126, Loss: 1.3102080821990967, Accuracy: 0.5830078125\n",
      "Batch: 127, Loss: 1.1775705814361572, Accuracy: 0.6611328125\n",
      "Batch: 128, Loss: 1.4232735633850098, Accuracy: 0.5810546875\n",
      "Batch: 129, Loss: 1.2176392078399658, Accuracy: 0.6064453125\n",
      "Batch: 130, Loss: 1.4832345247268677, Accuracy: 0.5595703125\n",
      "Batch: 131, Loss: 1.3420960903167725, Accuracy: 0.5751953125\n",
      "Batch: 132, Loss: 1.338158130645752, Accuracy: 0.5869140625\n",
      "Batch: 133, Loss: 1.2149654626846313, Accuracy: 0.603515625\n",
      "Batch: 134, Loss: 1.2898868322372437, Accuracy: 0.583984375\n",
      "Batch: 135, Loss: 1.1957623958587646, Accuracy: 0.6318359375\n",
      "Batch: 136, Loss: 1.25258469581604, Accuracy: 0.6142578125\n",
      "Batch: 137, Loss: 1.1703530550003052, Accuracy: 0.5908203125\n",
      "Batch: 138, Loss: 1.0419743061065674, Accuracy: 0.65625\n",
      "Batch: 139, Loss: 1.117917537689209, Accuracy: 0.634765625\n",
      "Batch: 142, Loss: 1.288309097290039, Accuracy: 0.6005859375\n",
      "Batch: 143, Loss: 1.2990925312042236, Accuracy: 0.6044921875\n",
      "Batch: 144, Loss: 1.2487750053405762, Accuracy: 0.62109375\n",
      "Batch: 145, Loss: 1.1986193656921387, Accuracy: 0.6142578125\n",
      "Batch: 146, Loss: 1.343865990638733, Accuracy: 0.5751953125\n",
      "Batch: 147, Loss: 1.2877922058105469, Accuracy: 0.607421875\n",
      "Batch: 148, Loss: 1.4214544296264648, Accuracy: 0.546875\n",
      "Batch: 149, Loss: 1.3008685111999512, Accuracy: 0.5693359375\n",
      "Batch: 150, Loss: 1.185861349105835, Accuracy: 0.623046875\n",
      "Batch: 151, Loss: 1.1478931903839111, Accuracy: 0.6455078125\n",
      "Epoch 9/80\n",
      "Batch: 1, Loss: 1.490377426147461, Accuracy: 0.51953125\n",
      "Batch: 2, Loss: 1.256670594215393, Accuracy: 0.56640625\n",
      "Batch: 3, Loss: 1.1964738368988037, Accuracy: 0.6044921875\n",
      "Batch: 4, Loss: 1.120187520980835, Accuracy: 0.642578125\n",
      "Batch: 5, Loss: 1.1625852584838867, Accuracy: 0.6337890625\n",
      "Batch: 6, Loss: 1.251431941986084, Accuracy: 0.5947265625\n",
      "Batch: 7, Loss: 1.2013293504714966, Accuracy: 0.599609375\n",
      "Batch: 8, Loss: 1.1491795778274536, Accuracy: 0.6162109375\n",
      "Batch: 9, Loss: 1.1181708574295044, Accuracy: 0.650390625\n",
      "Batch: 10, Loss: 1.1621170043945312, Accuracy: 0.619140625\n",
      "Batch: 11, Loss: 1.3365447521209717, Accuracy: 0.5576171875\n",
      "Batch: 12, Loss: 1.3627099990844727, Accuracy: 0.5615234375\n",
      "Batch: 13, Loss: 1.0762009620666504, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 1.3305541276931763, Accuracy: 0.56640625\n",
      "Batch: 15, Loss: 1.1825922727584839, Accuracy: 0.63671875\n",
      "Batch: 16, Loss: 1.2094981670379639, Accuracy: 0.62109375\n",
      "Batch: 17, Loss: 1.2738349437713623, Accuracy: 0.6142578125\n",
      "Batch: 18, Loss: 1.2891526222229004, Accuracy: 0.595703125\n",
      "Batch: 19, Loss: 1.2736988067626953, Accuracy: 0.6083984375\n",
      "Batch: 20, Loss: 1.2040960788726807, Accuracy: 0.638671875\n",
      "Batch: 21, Loss: 1.179145336151123, Accuracy: 0.62109375\n",
      "Batch: 22, Loss: 1.308835744857788, Accuracy: 0.58984375\n",
      "Batch: 23, Loss: 1.1932415962219238, Accuracy: 0.6103515625\n",
      "Batch: 24, Loss: 1.2393546104431152, Accuracy: 0.61328125\n",
      "Batch: 25, Loss: 1.2312607765197754, Accuracy: 0.6142578125\n",
      "Batch: 26, Loss: 1.1342604160308838, Accuracy: 0.642578125\n",
      "Batch: 27, Loss: 1.192383050918579, Accuracy: 0.6201171875\n",
      "Batch: 28, Loss: 1.27161705493927, Accuracy: 0.5849609375\n",
      "Batch: 29, Loss: 1.2544481754302979, Accuracy: 0.6044921875\n",
      "Batch: 30, Loss: 1.2037662267684937, Accuracy: 0.640625\n",
      "Batch: 31, Loss: 1.1691713333129883, Accuracy: 0.650390625\n",
      "Batch: 32, Loss: 1.161365270614624, Accuracy: 0.642578125\n",
      "Batch: 33, Loss: 1.3714375495910645, Accuracy: 0.5703125\n",
      "Batch: 34, Loss: 1.432485580444336, Accuracy: 0.5517578125\n",
      "Batch: 35, Loss: 1.280113697052002, Accuracy: 0.5859375\n",
      "Batch: 36, Loss: 1.288515329360962, Accuracy: 0.5986328125\n",
      "Batch: 37, Loss: 1.2804763317108154, Accuracy: 0.60546875\n",
      "Batch: 38, Loss: 1.2743685245513916, Accuracy: 0.59765625\n",
      "Batch: 39, Loss: 1.288000464439392, Accuracy: 0.6025390625\n",
      "Batch: 40, Loss: 1.2885093688964844, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.285984754562378, Accuracy: 0.60546875\n",
      "Batch: 42, Loss: 1.0575411319732666, Accuracy: 0.6552734375\n",
      "Batch: 43, Loss: 1.2600157260894775, Accuracy: 0.591796875\n",
      "Batch: 44, Loss: 1.2241182327270508, Accuracy: 0.607421875\n",
      "Batch: 45, Loss: 1.0890754461288452, Accuracy: 0.6279296875\n",
      "Batch: 46, Loss: 1.2393569946289062, Accuracy: 0.615234375\n",
      "Batch: 47, Loss: 1.261622428894043, Accuracy: 0.6103515625\n",
      "Batch: 48, Loss: 1.1686089038848877, Accuracy: 0.6318359375\n",
      "Batch: 49, Loss: 1.3681974411010742, Accuracy: 0.556640625\n",
      "Batch: 50, Loss: 1.322974681854248, Accuracy: 0.5791015625\n",
      "Batch: 51, Loss: 1.4242689609527588, Accuracy: 0.5673828125\n",
      "Batch: 52, Loss: 1.3636726140975952, Accuracy: 0.5908203125\n",
      "Batch: 53, Loss: 1.1181647777557373, Accuracy: 0.63671875\n",
      "Batch: 54, Loss: 1.2013366222381592, Accuracy: 0.6396484375\n",
      "Batch: 55, Loss: 1.2601715326309204, Accuracy: 0.5908203125\n",
      "Batch: 56, Loss: 1.3285824060440063, Accuracy: 0.5634765625\n",
      "Batch: 57, Loss: 1.2481731176376343, Accuracy: 0.6103515625\n",
      "Batch: 58, Loss: 1.3450891971588135, Accuracy: 0.60546875\n",
      "Batch: 59, Loss: 1.1203452348709106, Accuracy: 0.6591796875\n",
      "Batch: 60, Loss: 1.1438918113708496, Accuracy: 0.64453125\n",
      "Batch: 61, Loss: 1.295636773109436, Accuracy: 0.591796875\n",
      "Batch: 62, Loss: 1.2339154481887817, Accuracy: 0.60546875\n",
      "Batch: 63, Loss: 1.2763420343399048, Accuracy: 0.59375\n",
      "Batch: 64, Loss: 1.2146282196044922, Accuracy: 0.6103515625\n",
      "Batch: 65, Loss: 1.254666805267334, Accuracy: 0.60546875\n",
      "Batch: 66, Loss: 1.2039060592651367, Accuracy: 0.6259765625\n",
      "Batch: 67, Loss: 1.3256043195724487, Accuracy: 0.5927734375\n",
      "Batch: 68, Loss: 1.3360166549682617, Accuracy: 0.6123046875\n",
      "Batch: 69, Loss: 1.2473241090774536, Accuracy: 0.6142578125\n",
      "Batch: 70, Loss: 1.2484214305877686, Accuracy: 0.6259765625\n",
      "Batch: 71, Loss: 1.2701411247253418, Accuracy: 0.6005859375\n",
      "Batch: 72, Loss: 1.143839716911316, Accuracy: 0.6396484375\n",
      "Batch: 73, Loss: 1.2475634813308716, Accuracy: 0.634765625\n",
      "Batch: 74, Loss: 1.1558648347854614, Accuracy: 0.646484375\n",
      "Batch: 75, Loss: 1.1492615938186646, Accuracy: 0.638671875\n",
      "Batch: 76, Loss: 1.261090636253357, Accuracy: 0.5947265625\n",
      "Batch: 77, Loss: 1.2475736141204834, Accuracy: 0.6083984375\n",
      "Batch: 78, Loss: 1.2156083583831787, Accuracy: 0.640625\n",
      "Batch: 79, Loss: 1.1027594804763794, Accuracy: 0.666015625\n",
      "Batch: 81, Loss: 1.3082154989242554, Accuracy: 0.580078125\n",
      "Batch: 82, Loss: 1.2570953369140625, Accuracy: 0.59375\n",
      "Batch: 83, Loss: 1.0876178741455078, Accuracy: 0.67578125\n",
      "Batch: 84, Loss: 1.18834388256073, Accuracy: 0.6416015625\n",
      "Batch: 85, Loss: 1.1009869575500488, Accuracy: 0.646484375\n",
      "Batch: 86, Loss: 1.380129337310791, Accuracy: 0.5673828125\n",
      "Batch: 87, Loss: 1.1480680704116821, Accuracy: 0.6484375\n",
      "Batch: 88, Loss: 1.2468159198760986, Accuracy: 0.6162109375\n",
      "Batch: 89, Loss: 1.2516112327575684, Accuracy: 0.623046875\n",
      "Batch: 90, Loss: 1.1453933715820312, Accuracy: 0.634765625\n",
      "Batch: 91, Loss: 1.1821143627166748, Accuracy: 0.6376953125\n",
      "Batch: 92, Loss: 1.225284457206726, Accuracy: 0.6240234375\n",
      "Batch: 93, Loss: 1.1697818040847778, Accuracy: 0.6298828125\n",
      "Batch: 94, Loss: 1.2033674716949463, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.234947681427002, Accuracy: 0.59375\n",
      "Batch: 96, Loss: 1.1954336166381836, Accuracy: 0.6318359375\n",
      "Batch: 97, Loss: 1.0710673332214355, Accuracy: 0.658203125\n",
      "Batch: 98, Loss: 1.1061971187591553, Accuracy: 0.6611328125\n",
      "Batch: 99, Loss: 1.1213067770004272, Accuracy: 0.650390625\n",
      "Batch: 100, Loss: 1.195342779159546, Accuracy: 0.6279296875\n",
      "Batch: 101, Loss: 1.2626216411590576, Accuracy: 0.6171875\n",
      "Batch: 102, Loss: 1.1480554342269897, Accuracy: 0.6376953125\n",
      "Batch: 103, Loss: 1.2353813648223877, Accuracy: 0.6240234375\n",
      "Batch: 104, Loss: 1.1318182945251465, Accuracy: 0.625\n",
      "Batch: 105, Loss: 1.2453571557998657, Accuracy: 0.6005859375\n",
      "Batch: 106, Loss: 1.2596285343170166, Accuracy: 0.611328125\n",
      "Batch: 107, Loss: 1.3985178470611572, Accuracy: 0.5810546875\n",
      "Batch: 108, Loss: 1.3273286819458008, Accuracy: 0.5859375\n",
      "Batch: 109, Loss: 1.4082428216934204, Accuracy: 0.5302734375\n",
      "Batch: 110, Loss: 1.0568679571151733, Accuracy: 0.650390625\n",
      "Batch: 111, Loss: 1.2825965881347656, Accuracy: 0.572265625\n",
      "Batch: 112, Loss: 1.2078779935836792, Accuracy: 0.634765625\n",
      "Batch: 113, Loss: 1.2449525594711304, Accuracy: 0.619140625\n",
      "Batch: 114, Loss: 1.3512413501739502, Accuracy: 0.5712890625\n",
      "Batch: 115, Loss: 1.391169548034668, Accuracy: 0.5810546875\n",
      "Batch: 116, Loss: 1.298454761505127, Accuracy: 0.58984375\n",
      "Batch: 117, Loss: 1.3499491214752197, Accuracy: 0.5830078125\n",
      "Batch: 118, Loss: 1.078101634979248, Accuracy: 0.65234375\n",
      "Batch: 119, Loss: 1.1194236278533936, Accuracy: 0.6494140625\n",
      "Batch: 120, Loss: 1.3001078367233276, Accuracy: 0.591796875\n",
      "Batch: 121, Loss: 1.3219809532165527, Accuracy: 0.5712890625\n",
      "Batch: 122, Loss: 1.1911733150482178, Accuracy: 0.6416015625\n",
      "Batch: 123, Loss: 1.1832507848739624, Accuracy: 0.630859375\n",
      "Batch: 124, Loss: 1.2483443021774292, Accuracy: 0.6123046875\n",
      "Batch: 125, Loss: 1.2950407266616821, Accuracy: 0.595703125\n",
      "Batch: 126, Loss: 1.2755043506622314, Accuracy: 0.58984375\n",
      "Batch: 127, Loss: 1.0997998714447021, Accuracy: 0.6689453125\n",
      "Batch: 128, Loss: 1.3661384582519531, Accuracy: 0.5927734375\n",
      "Batch: 131, Loss: 1.2786717414855957, Accuracy: 0.6083984375\n",
      "Batch: 132, Loss: 1.3182295560836792, Accuracy: 0.607421875\n",
      "Batch: 133, Loss: 1.1653940677642822, Accuracy: 0.6162109375\n",
      "Batch: 134, Loss: 1.238637924194336, Accuracy: 0.607421875\n",
      "Batch: 135, Loss: 1.1430573463439941, Accuracy: 0.6455078125\n",
      "Batch: 136, Loss: 1.2247540950775146, Accuracy: 0.6201171875\n",
      "Batch: 137, Loss: 1.1538829803466797, Accuracy: 0.6142578125\n",
      "Batch: 138, Loss: 1.018746018409729, Accuracy: 0.654296875\n",
      "Batch: 139, Loss: 1.0905561447143555, Accuracy: 0.630859375\n",
      "Batch: 140, Loss: 1.2124300003051758, Accuracy: 0.6162109375\n",
      "Batch: 141, Loss: 1.2398972511291504, Accuracy: 0.607421875\n",
      "Batch: 142, Loss: 1.275933861732483, Accuracy: 0.5947265625\n",
      "Batch: 143, Loss: 1.2479643821716309, Accuracy: 0.599609375\n",
      "Batch: 144, Loss: 1.2426252365112305, Accuracy: 0.61328125\n",
      "Batch: 145, Loss: 1.1693098545074463, Accuracy: 0.603515625\n",
      "Batch: 146, Loss: 1.312448501586914, Accuracy: 0.5810546875\n",
      "Batch: 147, Loss: 1.2440884113311768, Accuracy: 0.6064453125\n",
      "Batch: 148, Loss: 1.3820812702178955, Accuracy: 0.5537109375\n",
      "Batch: 149, Loss: 1.252652883529663, Accuracy: 0.5869140625\n",
      "Batch: 150, Loss: 1.1814146041870117, Accuracy: 0.615234375\n",
      "Batch: 151, Loss: 1.0834598541259766, Accuracy: 0.65234375\n",
      "Epoch 10/80\n",
      "Batch: 1, Loss: 1.4479920864105225, Accuracy: 0.5224609375\n",
      "Batch: 2, Loss: 1.2169806957244873, Accuracy: 0.578125\n",
      "Batch: 3, Loss: 1.142549991607666, Accuracy: 0.6171875\n",
      "Batch: 4, Loss: 1.0991888046264648, Accuracy: 0.66796875\n",
      "Batch: 5, Loss: 1.1524083614349365, Accuracy: 0.650390625\n",
      "Batch: 6, Loss: 1.233644962310791, Accuracy: 0.58984375\n",
      "Batch: 7, Loss: 1.1575376987457275, Accuracy: 0.6103515625\n",
      "Batch: 8, Loss: 1.105974793434143, Accuracy: 0.634765625\n",
      "Batch: 9, Loss: 1.0871098041534424, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 1.143406629562378, Accuracy: 0.640625\n",
      "Batch: 11, Loss: 1.2947620153427124, Accuracy: 0.568359375\n",
      "Batch: 12, Loss: 1.3410193920135498, Accuracy: 0.5673828125\n",
      "Batch: 13, Loss: 1.0398170948028564, Accuracy: 0.6650390625\n",
      "Batch: 14, Loss: 1.3016561269760132, Accuracy: 0.5703125\n",
      "Batch: 15, Loss: 1.1322226524353027, Accuracy: 0.6494140625\n",
      "Batch: 16, Loss: 1.1785856485366821, Accuracy: 0.6259765625\n",
      "Batch: 17, Loss: 1.253603219985962, Accuracy: 0.6015625\n",
      "Batch: 18, Loss: 1.2337608337402344, Accuracy: 0.6142578125\n",
      "Batch: 19, Loss: 1.2491724491119385, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.1632088422775269, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.1503329277038574, Accuracy: 0.6123046875\n",
      "Batch: 22, Loss: 1.2804899215698242, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.1681811809539795, Accuracy: 0.625\n",
      "Batch: 24, Loss: 1.2106950283050537, Accuracy: 0.6142578125\n",
      "Batch: 25, Loss: 1.1830918788909912, Accuracy: 0.623046875\n",
      "Batch: 26, Loss: 1.1067196130752563, Accuracy: 0.642578125\n",
      "Batch: 27, Loss: 1.1508334875106812, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.2246109247207642, Accuracy: 0.607421875\n",
      "Batch: 29, Loss: 1.2365697622299194, Accuracy: 0.607421875\n",
      "Batch: 31, Loss: 1.135634183883667, Accuracy: 0.6591796875\n",
      "Batch: 32, Loss: 1.1095292568206787, Accuracy: 0.6416015625\n",
      "Batch: 33, Loss: 1.3083508014678955, Accuracy: 0.5810546875\n",
      "Batch: 34, Loss: 1.365357518196106, Accuracy: 0.5673828125\n",
      "Batch: 35, Loss: 1.2544565200805664, Accuracy: 0.5986328125\n",
      "Batch: 36, Loss: 1.260265588760376, Accuracy: 0.61328125\n",
      "Batch: 37, Loss: 1.2431235313415527, Accuracy: 0.61328125\n",
      "Batch: 38, Loss: 1.2625503540039062, Accuracy: 0.6025390625\n",
      "Batch: 39, Loss: 1.2677690982818604, Accuracy: 0.6142578125\n",
      "Batch: 40, Loss: 1.2564175128936768, Accuracy: 0.61328125\n",
      "Batch: 41, Loss: 1.2674583196640015, Accuracy: 0.6015625\n",
      "Batch: 42, Loss: 1.0254414081573486, Accuracy: 0.6640625\n",
      "Batch: 43, Loss: 1.2247300148010254, Accuracy: 0.5986328125\n",
      "Batch: 44, Loss: 1.2239346504211426, Accuracy: 0.5986328125\n",
      "Batch: 45, Loss: 1.0596697330474854, Accuracy: 0.6357421875\n",
      "Batch: 46, Loss: 1.2207865715026855, Accuracy: 0.625\n",
      "Batch: 47, Loss: 1.2474241256713867, Accuracy: 0.623046875\n",
      "Batch: 48, Loss: 1.139914631843567, Accuracy: 0.638671875\n",
      "Batch: 49, Loss: 1.3379106521606445, Accuracy: 0.580078125\n",
      "Batch: 50, Loss: 1.2977800369262695, Accuracy: 0.583984375\n",
      "Batch: 51, Loss: 1.3942594528198242, Accuracy: 0.5673828125\n",
      "Batch: 52, Loss: 1.3107184171676636, Accuracy: 0.5908203125\n",
      "Batch: 53, Loss: 1.0986438989639282, Accuracy: 0.64453125\n",
      "Batch: 54, Loss: 1.1778125762939453, Accuracy: 0.6396484375\n",
      "Batch: 55, Loss: 1.2387558221817017, Accuracy: 0.591796875\n",
      "Batch: 56, Loss: 1.2681816816329956, Accuracy: 0.59765625\n",
      "Batch: 57, Loss: 1.2103188037872314, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.3210692405700684, Accuracy: 0.5947265625\n",
      "Batch: 59, Loss: 1.1043490171432495, Accuracy: 0.6630859375\n",
      "Batch: 60, Loss: 1.1285700798034668, Accuracy: 0.6494140625\n",
      "Batch: 61, Loss: 1.2407251596450806, Accuracy: 0.6015625\n",
      "Batch: 62, Loss: 1.208653450012207, Accuracy: 0.625\n",
      "Batch: 63, Loss: 1.2483773231506348, Accuracy: 0.6044921875\n",
      "Batch: 64, Loss: 1.1931570768356323, Accuracy: 0.625\n",
      "Batch: 65, Loss: 1.2414634227752686, Accuracy: 0.6044921875\n",
      "Batch: 66, Loss: 1.1879727840423584, Accuracy: 0.62109375\n",
      "Batch: 67, Loss: 1.2954537868499756, Accuracy: 0.6142578125\n",
      "Batch: 68, Loss: 1.2786753177642822, Accuracy: 0.615234375\n",
      "Batch: 69, Loss: 1.2076869010925293, Accuracy: 0.611328125\n",
      "Batch: 70, Loss: 1.208748459815979, Accuracy: 0.625\n",
      "Batch: 71, Loss: 1.2546989917755127, Accuracy: 0.6025390625\n",
      "Batch: 72, Loss: 1.0987188816070557, Accuracy: 0.654296875\n",
      "Batch: 73, Loss: 1.1871986389160156, Accuracy: 0.626953125\n",
      "Batch: 74, Loss: 1.1408758163452148, Accuracy: 0.6357421875\n",
      "Batch: 75, Loss: 1.093201994895935, Accuracy: 0.6650390625\n",
      "Batch: 76, Loss: 1.2368426322937012, Accuracy: 0.5888671875\n",
      "Batch: 77, Loss: 1.2180840969085693, Accuracy: 0.5966796875\n",
      "Batch: 78, Loss: 1.187380075454712, Accuracy: 0.6455078125\n",
      "Batch: 79, Loss: 1.065694808959961, Accuracy: 0.6787109375\n",
      "Batch: 80, Loss: 1.1117019653320312, Accuracy: 0.6201171875\n",
      "Batch: 81, Loss: 1.283479928970337, Accuracy: 0.56640625\n",
      "Batch: 82, Loss: 1.237022876739502, Accuracy: 0.6123046875\n",
      "Batch: 83, Loss: 1.0756103992462158, Accuracy: 0.6748046875\n",
      "Batch: 84, Loss: 1.1418780088424683, Accuracy: 0.6572265625\n",
      "Batch: 85, Loss: 1.0800857543945312, Accuracy: 0.66796875\n",
      "Batch: 86, Loss: 1.35805082321167, Accuracy: 0.5830078125\n",
      "Batch: 87, Loss: 1.11195707321167, Accuracy: 0.662109375\n",
      "Batch: 88, Loss: 1.2386231422424316, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.2362124919891357, Accuracy: 0.6162109375\n",
      "Batch: 90, Loss: 1.1042466163635254, Accuracy: 0.658203125\n",
      "Batch: 91, Loss: 1.1651610136032104, Accuracy: 0.638671875\n",
      "Batch: 92, Loss: 1.2200753688812256, Accuracy: 0.6201171875\n",
      "Batch: 93, Loss: 1.1180927753448486, Accuracy: 0.6484375\n",
      "Batch: 94, Loss: 1.148735523223877, Accuracy: 0.6279296875\n",
      "Batch: 95, Loss: 1.188368797302246, Accuracy: 0.595703125\n",
      "Batch: 96, Loss: 1.183462381362915, Accuracy: 0.6357421875\n",
      "Batch: 97, Loss: 1.0179786682128906, Accuracy: 0.6630859375\n",
      "Batch: 98, Loss: 1.0775227546691895, Accuracy: 0.6787109375\n",
      "Batch: 99, Loss: 1.0913207530975342, Accuracy: 0.65234375\n",
      "Batch: 100, Loss: 1.1435288190841675, Accuracy: 0.6455078125\n",
      "Batch: 101, Loss: 1.2506635189056396, Accuracy: 0.607421875\n",
      "Batch: 102, Loss: 1.1107351779937744, Accuracy: 0.6552734375\n",
      "Batch: 103, Loss: 1.2308502197265625, Accuracy: 0.63671875\n",
      "Batch: 104, Loss: 1.1105419397354126, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.2307580709457397, Accuracy: 0.6064453125\n",
      "Batch: 106, Loss: 1.2072052955627441, Accuracy: 0.6201171875\n",
      "Batch: 107, Loss: 1.338537573814392, Accuracy: 0.5966796875\n",
      "Batch: 108, Loss: 1.2862964868545532, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.3753178119659424, Accuracy: 0.5712890625\n",
      "Batch: 110, Loss: 1.0277690887451172, Accuracy: 0.6650390625\n",
      "Batch: 111, Loss: 1.2297829389572144, Accuracy: 0.576171875\n",
      "Batch: 112, Loss: 1.203329086303711, Accuracy: 0.626953125\n",
      "Batch: 113, Loss: 1.2117154598236084, Accuracy: 0.6376953125\n",
      "Batch: 114, Loss: 1.35758376121521, Accuracy: 0.578125\n",
      "Batch: 115, Loss: 1.3658998012542725, Accuracy: 0.5849609375\n",
      "Batch: 116, Loss: 1.2657115459442139, Accuracy: 0.6044921875\n",
      "Batch: 117, Loss: 1.306670904159546, Accuracy: 0.607421875\n",
      "Batch: 118, Loss: 1.0652366876602173, Accuracy: 0.6630859375\n",
      "Batch: 119, Loss: 1.107272744178772, Accuracy: 0.66796875\n",
      "Batch: 120, Loss: 1.270796775817871, Accuracy: 0.58203125\n",
      "Batch: 121, Loss: 1.2959542274475098, Accuracy: 0.5673828125\n",
      "Batch: 122, Loss: 1.148160457611084, Accuracy: 0.6240234375\n",
      "Batch: 123, Loss: 1.1821575164794922, Accuracy: 0.619140625\n",
      "Batch: 124, Loss: 1.2138359546661377, Accuracy: 0.630859375\n",
      "Batch: 125, Loss: 1.2491695880889893, Accuracy: 0.6220703125\n",
      "Batch: 126, Loss: 1.2469130754470825, Accuracy: 0.580078125\n",
      "Batch: 127, Loss: 1.0916659832000732, Accuracy: 0.666015625\n",
      "Batch: 128, Loss: 1.3489868640899658, Accuracy: 0.6005859375\n",
      "Batch: 129, Loss: 1.1347312927246094, Accuracy: 0.6474609375\n",
      "Batch: 130, Loss: 1.3925243616104126, Accuracy: 0.5888671875\n",
      "Batch: 131, Loss: 1.2570781707763672, Accuracy: 0.599609375\n",
      "Batch: 132, Loss: 1.2529971599578857, Accuracy: 0.615234375\n",
      "Batch: 133, Loss: 1.1326169967651367, Accuracy: 0.6240234375\n",
      "Batch: 134, Loss: 1.207874059677124, Accuracy: 0.60546875\n",
      "Batch: 135, Loss: 1.1157408952713013, Accuracy: 0.6611328125\n",
      "Batch: 136, Loss: 1.2030364274978638, Accuracy: 0.626953125\n",
      "Batch: 137, Loss: 1.113093614578247, Accuracy: 0.6123046875\n",
      "Batch: 138, Loss: 0.984435498714447, Accuracy: 0.6728515625\n",
      "Batch: 139, Loss: 1.068190097808838, Accuracy: 0.6357421875\n",
      "Batch: 140, Loss: 1.1873351335525513, Accuracy: 0.62109375\n",
      "Batch: 141, Loss: 1.2086191177368164, Accuracy: 0.6201171875\n",
      "Batch: 142, Loss: 1.2397675514221191, Accuracy: 0.599609375\n",
      "Batch: 143, Loss: 1.2292191982269287, Accuracy: 0.6259765625\n",
      "Batch: 144, Loss: 1.1973248720169067, Accuracy: 0.6240234375\n",
      "Batch: 145, Loss: 1.1439931392669678, Accuracy: 0.61328125\n",
      "Batch: 146, Loss: 1.2612510919570923, Accuracy: 0.603515625\n",
      "Batch: 147, Loss: 1.2248973846435547, Accuracy: 0.6171875\n",
      "Batch: 148, Loss: 1.3303914070129395, Accuracy: 0.56640625\n",
      "Batch: 149, Loss: 1.2260202169418335, Accuracy: 0.5927734375\n",
      "Batch: 150, Loss: 1.1483826637268066, Accuracy: 0.634765625\n",
      "Batch: 151, Loss: 1.0701717138290405, Accuracy: 0.669921875\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/80\n",
      "Batch: 1, Loss: 1.4182884693145752, Accuracy: 0.5478515625\n",
      "Batch: 2, Loss: 1.2146952152252197, Accuracy: 0.572265625\n",
      "Batch: 3, Loss: 1.119477391242981, Accuracy: 0.6240234375\n",
      "Batch: 4, Loss: 1.0750420093536377, Accuracy: 0.650390625\n",
      "Batch: 5, Loss: 1.115538239479065, Accuracy: 0.6455078125\n",
      "Batch: 6, Loss: 1.202760934829712, Accuracy: 0.611328125\n",
      "Batch: 7, Loss: 1.155390977859497, Accuracy: 0.619140625\n",
      "Batch: 8, Loss: 1.077106237411499, Accuracy: 0.6455078125\n",
      "Batch: 9, Loss: 1.0755929946899414, Accuracy: 0.6552734375\n",
      "Batch: 10, Loss: 1.092732310295105, Accuracy: 0.6455078125\n",
      "Batch: 11, Loss: 1.2845823764801025, Accuracy: 0.5751953125\n",
      "Batch: 12, Loss: 1.3056316375732422, Accuracy: 0.587890625\n",
      "Batch: 13, Loss: 1.0307570695877075, Accuracy: 0.671875\n",
      "Batch: 14, Loss: 1.2724169492721558, Accuracy: 0.587890625\n",
      "Batch: 15, Loss: 1.1216764450073242, Accuracy: 0.6494140625\n",
      "Batch: 16, Loss: 1.1373066902160645, Accuracy: 0.623046875\n",
      "Batch: 17, Loss: 1.2254583835601807, Accuracy: 0.6171875\n",
      "Batch: 18, Loss: 1.2123184204101562, Accuracy: 0.6181640625\n",
      "Batch: 19, Loss: 1.2444279193878174, Accuracy: 0.623046875\n",
      "Batch: 20, Loss: 1.1275475025177002, Accuracy: 0.662109375\n",
      "Batch: 21, Loss: 1.1290488243103027, Accuracy: 0.625\n",
      "Batch: 23, Loss: 1.1193199157714844, Accuracy: 0.6328125\n",
      "Batch: 24, Loss: 1.1781246662139893, Accuracy: 0.625\n",
      "Batch: 25, Loss: 1.1630973815917969, Accuracy: 0.609375\n",
      "Batch: 26, Loss: 1.0769374370574951, Accuracy: 0.658203125\n",
      "Batch: 27, Loss: 1.143378496170044, Accuracy: 0.6298828125\n",
      "Batch: 28, Loss: 1.2230145931243896, Accuracy: 0.6083984375\n",
      "Batch: 29, Loss: 1.179600477218628, Accuracy: 0.6181640625\n",
      "Batch: 30, Loss: 1.1300855875015259, Accuracy: 0.6630859375\n",
      "Batch: 31, Loss: 1.097609043121338, Accuracy: 0.6640625\n",
      "Batch: 32, Loss: 1.1011369228363037, Accuracy: 0.6494140625\n",
      "Batch: 33, Loss: 1.3131128549575806, Accuracy: 0.57421875\n",
      "Batch: 34, Loss: 1.3585526943206787, Accuracy: 0.568359375\n",
      "Batch: 35, Loss: 1.2339239120483398, Accuracy: 0.607421875\n",
      "Batch: 36, Loss: 1.2069568634033203, Accuracy: 0.6259765625\n",
      "Batch: 37, Loss: 1.21631920337677, Accuracy: 0.615234375\n",
      "Batch: 38, Loss: 1.2360354661941528, Accuracy: 0.599609375\n",
      "Batch: 39, Loss: 1.225276231765747, Accuracy: 0.630859375\n",
      "Batch: 40, Loss: 1.213080883026123, Accuracy: 0.6259765625\n",
      "Batch: 41, Loss: 1.2307953834533691, Accuracy: 0.6201171875\n",
      "Batch: 42, Loss: 1.0076955556869507, Accuracy: 0.654296875\n",
      "Batch: 43, Loss: 1.1902031898498535, Accuracy: 0.6005859375\n",
      "Batch: 44, Loss: 1.1834585666656494, Accuracy: 0.5927734375\n",
      "Batch: 45, Loss: 1.0311756134033203, Accuracy: 0.6552734375\n",
      "Batch: 46, Loss: 1.1895962953567505, Accuracy: 0.6318359375\n",
      "Batch: 47, Loss: 1.2063180208206177, Accuracy: 0.6357421875\n",
      "Batch: 48, Loss: 1.0965602397918701, Accuracy: 0.65234375\n",
      "Batch: 49, Loss: 1.2978153228759766, Accuracy: 0.58203125\n",
      "Batch: 50, Loss: 1.2641304731369019, Accuracy: 0.5869140625\n",
      "Batch: 51, Loss: 1.3393237590789795, Accuracy: 0.5751953125\n",
      "Batch: 52, Loss: 1.310104489326477, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.1135176420211792, Accuracy: 0.63671875\n",
      "Batch: 54, Loss: 1.1618565320968628, Accuracy: 0.6357421875\n",
      "Batch: 55, Loss: 1.2190585136413574, Accuracy: 0.6123046875\n",
      "Batch: 56, Loss: 1.234033226966858, Accuracy: 0.6142578125\n",
      "Batch: 57, Loss: 1.1960841417312622, Accuracy: 0.625\n",
      "Batch: 58, Loss: 1.2656874656677246, Accuracy: 0.6123046875\n",
      "Batch: 59, Loss: 1.059388518333435, Accuracy: 0.6728515625\n",
      "Batch: 60, Loss: 1.0931240320205688, Accuracy: 0.6552734375\n",
      "Batch: 61, Loss: 1.2002547979354858, Accuracy: 0.6171875\n",
      "Batch: 62, Loss: 1.1735570430755615, Accuracy: 0.64453125\n",
      "Batch: 63, Loss: 1.219614028930664, Accuracy: 0.6103515625\n",
      "Batch: 64, Loss: 1.1648950576782227, Accuracy: 0.6396484375\n",
      "Batch: 65, Loss: 1.21379554271698, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.1411267518997192, Accuracy: 0.6435546875\n",
      "Batch: 67, Loss: 1.2594003677368164, Accuracy: 0.607421875\n",
      "Batch: 68, Loss: 1.2594749927520752, Accuracy: 0.62890625\n",
      "Batch: 69, Loss: 1.2073546648025513, Accuracy: 0.626953125\n",
      "Batch: 70, Loss: 1.1645915508270264, Accuracy: 0.6552734375\n",
      "Batch: 71, Loss: 1.209621787071228, Accuracy: 0.6181640625\n",
      "Batch: 72, Loss: 1.103338360786438, Accuracy: 0.6611328125\n",
      "Batch: 73, Loss: 1.158818006515503, Accuracy: 0.6455078125\n",
      "Batch: 74, Loss: 1.1258032321929932, Accuracy: 0.640625\n",
      "Batch: 75, Loss: 1.0956230163574219, Accuracy: 0.646484375\n",
      "Batch: 76, Loss: 1.1769039630889893, Accuracy: 0.6064453125\n",
      "Batch: 79, Loss: 1.0711696147918701, Accuracy: 0.68359375\n",
      "Batch: 80, Loss: 1.0976474285125732, Accuracy: 0.6318359375\n",
      "Batch: 81, Loss: 1.2476298809051514, Accuracy: 0.572265625\n",
      "Batch: 82, Loss: 1.2067725658416748, Accuracy: 0.6083984375\n",
      "Batch: 83, Loss: 1.066143274307251, Accuracy: 0.673828125\n",
      "Batch: 84, Loss: 1.1214700937271118, Accuracy: 0.66015625\n",
      "Batch: 85, Loss: 1.0607857704162598, Accuracy: 0.66796875\n",
      "Batch: 86, Loss: 1.336084008216858, Accuracy: 0.5869140625\n",
      "Batch: 87, Loss: 1.0911235809326172, Accuracy: 0.669921875\n",
      "Batch: 88, Loss: 1.200008511543274, Accuracy: 0.650390625\n",
      "Batch: 89, Loss: 1.2352745532989502, Accuracy: 0.6357421875\n",
      "Batch: 90, Loss: 1.095259666442871, Accuracy: 0.646484375\n",
      "Batch: 91, Loss: 1.1356295347213745, Accuracy: 0.642578125\n",
      "Batch: 92, Loss: 1.186152458190918, Accuracy: 0.6337890625\n",
      "Batch: 93, Loss: 1.1132227182388306, Accuracy: 0.6513671875\n",
      "Batch: 94, Loss: 1.1460773944854736, Accuracy: 0.6396484375\n",
      "Batch: 95, Loss: 1.1761324405670166, Accuracy: 0.6142578125\n",
      "Batch: 96, Loss: 1.1457679271697998, Accuracy: 0.640625\n",
      "Batch: 97, Loss: 1.008837103843689, Accuracy: 0.6865234375\n",
      "Batch: 98, Loss: 1.0590980052947998, Accuracy: 0.6806640625\n",
      "Batch: 99, Loss: 1.0700342655181885, Accuracy: 0.64453125\n",
      "Batch: 100, Loss: 1.1443943977355957, Accuracy: 0.625\n",
      "Batch: 101, Loss: 1.215134859085083, Accuracy: 0.6201171875\n",
      "Batch: 102, Loss: 1.0983071327209473, Accuracy: 0.6650390625\n",
      "Batch: 103, Loss: 1.1921000480651855, Accuracy: 0.6435546875\n",
      "Batch: 104, Loss: 1.0785777568817139, Accuracy: 0.640625\n",
      "Batch: 105, Loss: 1.1955304145812988, Accuracy: 0.6220703125\n",
      "Batch: 106, Loss: 1.1855380535125732, Accuracy: 0.623046875\n",
      "Batch: 107, Loss: 1.3056530952453613, Accuracy: 0.61328125\n",
      "Batch: 108, Loss: 1.2541505098342896, Accuracy: 0.59375\n",
      "Batch: 109, Loss: 1.3738374710083008, Accuracy: 0.564453125\n",
      "Batch: 110, Loss: 1.0010120868682861, Accuracy: 0.6630859375\n",
      "Batch: 111, Loss: 1.2132701873779297, Accuracy: 0.5986328125\n",
      "Batch: 112, Loss: 1.1641162633895874, Accuracy: 0.638671875\n",
      "Batch: 113, Loss: 1.201799750328064, Accuracy: 0.63671875\n",
      "Batch: 114, Loss: 1.30562424659729, Accuracy: 0.5859375\n",
      "Batch: 115, Loss: 1.3218777179718018, Accuracy: 0.5888671875\n",
      "Batch: 116, Loss: 1.2529478073120117, Accuracy: 0.6201171875\n",
      "Batch: 117, Loss: 1.2541618347167969, Accuracy: 0.609375\n",
      "Batch: 118, Loss: 1.020214319229126, Accuracy: 0.67578125\n",
      "Batch: 119, Loss: 1.0530043840408325, Accuracy: 0.6728515625\n",
      "Batch: 120, Loss: 1.2209908962249756, Accuracy: 0.607421875\n",
      "Batch: 121, Loss: 1.2638347148895264, Accuracy: 0.60546875\n",
      "Batch: 122, Loss: 1.1304993629455566, Accuracy: 0.6416015625\n",
      "Batch: 123, Loss: 1.1493690013885498, Accuracy: 0.6513671875\n",
      "Batch: 124, Loss: 1.1775728464126587, Accuracy: 0.6240234375\n",
      "Batch: 125, Loss: 1.2369709014892578, Accuracy: 0.599609375\n",
      "Batch: 126, Loss: 1.2061158418655396, Accuracy: 0.60546875\n",
      "Batch: 127, Loss: 1.0621472597122192, Accuracy: 0.6826171875\n",
      "Batch: 128, Loss: 1.318605661392212, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.1148812770843506, Accuracy: 0.6435546875\n",
      "Batch: 130, Loss: 1.3774067163467407, Accuracy: 0.5751953125\n",
      "Batch: 131, Loss: 1.2376267910003662, Accuracy: 0.6162109375\n",
      "Batch: 132, Loss: 1.256683349609375, Accuracy: 0.615234375\n",
      "Batch: 133, Loss: 1.0942742824554443, Accuracy: 0.6357421875\n",
      "Batch: 134, Loss: 1.1864126920700073, Accuracy: 0.6044921875\n",
      "Batch: 135, Loss: 1.094930648803711, Accuracy: 0.6669921875\n",
      "Batch: 136, Loss: 1.1676207780838013, Accuracy: 0.63671875\n",
      "Batch: 137, Loss: 1.105180025100708, Accuracy: 0.6220703125\n",
      "Batch: 138, Loss: 0.9811410903930664, Accuracy: 0.6611328125\n",
      "Batch: 139, Loss: 1.0486418008804321, Accuracy: 0.638671875\n",
      "Batch: 140, Loss: 1.1568474769592285, Accuracy: 0.62109375\n",
      "Batch: 141, Loss: 1.18943452835083, Accuracy: 0.63671875\n",
      "Batch: 142, Loss: 1.2102382183074951, Accuracy: 0.615234375\n",
      "Batch: 143, Loss: 1.184816598892212, Accuracy: 0.6298828125\n",
      "Batch: 144, Loss: 1.1811774969100952, Accuracy: 0.638671875\n",
      "Batch: 145, Loss: 1.1172207593917847, Accuracy: 0.623046875\n",
      "Batch: 146, Loss: 1.2622472047805786, Accuracy: 0.5859375\n",
      "Batch: 147, Loss: 1.2077716588974, Accuracy: 0.619140625\n",
      "Batch: 148, Loss: 1.3356298208236694, Accuracy: 0.5517578125\n",
      "Batch: 149, Loss: 1.2035317420959473, Accuracy: 0.60546875\n",
      "Batch: 150, Loss: 1.1355876922607422, Accuracy: 0.64453125\n",
      "Batch: 151, Loss: 1.0641652345657349, Accuracy: 0.662109375\n",
      "Epoch 12/80\n",
      "Batch: 1, Loss: 1.4231951236724854, Accuracy: 0.552734375\n",
      "Batch: 2, Loss: 1.201216697692871, Accuracy: 0.5830078125\n",
      "Batch: 3, Loss: 1.1034929752349854, Accuracy: 0.6171875\n",
      "Batch: 4, Loss: 1.0526611804962158, Accuracy: 0.6611328125\n",
      "Batch: 5, Loss: 1.0665833950042725, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.1957039833068848, Accuracy: 0.611328125\n",
      "Batch: 7, Loss: 1.1353422403335571, Accuracy: 0.6181640625\n",
      "Batch: 8, Loss: 1.0847899913787842, Accuracy: 0.626953125\n",
      "Batch: 9, Loss: 1.0322564840316772, Accuracy: 0.666015625\n",
      "Batch: 10, Loss: 1.0493097305297852, Accuracy: 0.662109375\n",
      "Batch: 11, Loss: 1.2558021545410156, Accuracy: 0.5859375\n",
      "Batch: 12, Loss: 1.2476375102996826, Accuracy: 0.59375\n",
      "Batch: 13, Loss: 1.0105376243591309, Accuracy: 0.6708984375\n",
      "Batch: 14, Loss: 1.2581939697265625, Accuracy: 0.587890625\n",
      "Batch: 15, Loss: 1.1116957664489746, Accuracy: 0.6640625\n",
      "Batch: 18, Loss: 1.183912992477417, Accuracy: 0.6220703125\n",
      "Batch: 19, Loss: 1.2178733348846436, Accuracy: 0.6279296875\n",
      "Batch: 20, Loss: 1.104905128479004, Accuracy: 0.6708984375\n",
      "Batch: 21, Loss: 1.1081715822219849, Accuracy: 0.63671875\n",
      "Batch: 22, Loss: 1.238041639328003, Accuracy: 0.60546875\n",
      "Batch: 23, Loss: 1.1269876956939697, Accuracy: 0.6396484375\n",
      "Batch: 24, Loss: 1.1720948219299316, Accuracy: 0.634765625\n",
      "Batch: 25, Loss: 1.142082929611206, Accuracy: 0.6337890625\n",
      "Batch: 26, Loss: 1.0456552505493164, Accuracy: 0.6650390625\n",
      "Batch: 27, Loss: 1.107093095779419, Accuracy: 0.63671875\n",
      "Batch: 28, Loss: 1.1975462436676025, Accuracy: 0.6123046875\n",
      "Batch: 29, Loss: 1.1733720302581787, Accuracy: 0.6201171875\n",
      "Batch: 30, Loss: 1.1063170433044434, Accuracy: 0.6630859375\n",
      "Batch: 31, Loss: 1.0841776132583618, Accuracy: 0.677734375\n",
      "Batch: 32, Loss: 1.0626848936080933, Accuracy: 0.6689453125\n",
      "Batch: 33, Loss: 1.289597749710083, Accuracy: 0.595703125\n",
      "Batch: 34, Loss: 1.3477035760879517, Accuracy: 0.5830078125\n",
      "Batch: 35, Loss: 1.213566780090332, Accuracy: 0.623046875\n",
      "Batch: 36, Loss: 1.197141170501709, Accuracy: 0.611328125\n",
      "Batch: 37, Loss: 1.1736359596252441, Accuracy: 0.6259765625\n",
      "Batch: 38, Loss: 1.208101749420166, Accuracy: 0.6044921875\n",
      "Batch: 39, Loss: 1.2007577419281006, Accuracy: 0.6337890625\n",
      "Batch: 40, Loss: 1.1927087306976318, Accuracy: 0.623046875\n",
      "Batch: 41, Loss: 1.1815769672393799, Accuracy: 0.6376953125\n",
      "Batch: 42, Loss: 0.9948651790618896, Accuracy: 0.6708984375\n",
      "Batch: 43, Loss: 1.1499943733215332, Accuracy: 0.625\n",
      "Batch: 44, Loss: 1.1640557050704956, Accuracy: 0.6123046875\n",
      "Batch: 45, Loss: 1.018212080001831, Accuracy: 0.6611328125\n",
      "Batch: 46, Loss: 1.142049789428711, Accuracy: 0.6572265625\n",
      "Batch: 47, Loss: 1.1665997505187988, Accuracy: 0.642578125\n",
      "Batch: 48, Loss: 1.0820870399475098, Accuracy: 0.6630859375\n",
      "Batch: 49, Loss: 1.2857595682144165, Accuracy: 0.572265625\n",
      "Batch: 50, Loss: 1.2398574352264404, Accuracy: 0.6064453125\n",
      "Batch: 51, Loss: 1.3218426704406738, Accuracy: 0.580078125\n",
      "Batch: 52, Loss: 1.2790610790252686, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.0746134519577026, Accuracy: 0.650390625\n",
      "Batch: 54, Loss: 1.1309633255004883, Accuracy: 0.642578125\n",
      "Batch: 55, Loss: 1.1872937679290771, Accuracy: 0.619140625\n",
      "Batch: 56, Loss: 1.2518608570098877, Accuracy: 0.611328125\n",
      "Batch: 57, Loss: 1.1779742240905762, Accuracy: 0.6357421875\n",
      "Batch: 58, Loss: 1.2458451986312866, Accuracy: 0.625\n",
      "Batch: 59, Loss: 1.0560929775238037, Accuracy: 0.669921875\n",
      "Batch: 60, Loss: 1.0705764293670654, Accuracy: 0.658203125\n",
      "Batch: 61, Loss: 1.1986479759216309, Accuracy: 0.61328125\n",
      "Batch: 62, Loss: 1.1485594511032104, Accuracy: 0.6337890625\n",
      "Batch: 63, Loss: 1.1859395503997803, Accuracy: 0.6201171875\n",
      "Batch: 64, Loss: 1.1671985387802124, Accuracy: 0.6337890625\n",
      "Batch: 65, Loss: 1.2210662364959717, Accuracy: 0.6259765625\n",
      "Batch: 66, Loss: 1.122122883796692, Accuracy: 0.646484375\n",
      "Batch: 68, Loss: 1.236785888671875, Accuracy: 0.6220703125\n",
      "Batch: 69, Loss: 1.18611741065979, Accuracy: 0.6240234375\n",
      "Batch: 70, Loss: 1.178494930267334, Accuracy: 0.654296875\n",
      "Batch: 71, Loss: 1.2029027938842773, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.0737276077270508, Accuracy: 0.654296875\n",
      "Batch: 73, Loss: 1.1378991603851318, Accuracy: 0.6435546875\n",
      "Batch: 74, Loss: 1.067277193069458, Accuracy: 0.666015625\n",
      "Batch: 75, Loss: 1.0814852714538574, Accuracy: 0.658203125\n",
      "Batch: 76, Loss: 1.1802983283996582, Accuracy: 0.615234375\n",
      "Batch: 77, Loss: 1.1500638723373413, Accuracy: 0.64453125\n",
      "Batch: 78, Loss: 1.1250052452087402, Accuracy: 0.658203125\n",
      "Batch: 79, Loss: 1.0320849418640137, Accuracy: 0.6826171875\n",
      "Batch: 80, Loss: 1.072016716003418, Accuracy: 0.6376953125\n",
      "Batch: 81, Loss: 1.2265026569366455, Accuracy: 0.595703125\n",
      "Batch: 82, Loss: 1.166946291923523, Accuracy: 0.6162109375\n",
      "Batch: 83, Loss: 1.0231051445007324, Accuracy: 0.6875\n",
      "Batch: 84, Loss: 1.1108589172363281, Accuracy: 0.6640625\n",
      "Batch: 85, Loss: 1.0494725704193115, Accuracy: 0.6650390625\n",
      "Batch: 86, Loss: 1.3034673929214478, Accuracy: 0.6015625\n",
      "Batch: 87, Loss: 1.089799165725708, Accuracy: 0.669921875\n",
      "Batch: 88, Loss: 1.1840630769729614, Accuracy: 0.6494140625\n",
      "Batch: 89, Loss: 1.1865262985229492, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 1.0856361389160156, Accuracy: 0.65234375\n",
      "Batch: 91, Loss: 1.127873420715332, Accuracy: 0.6318359375\n",
      "Batch: 92, Loss: 1.1822879314422607, Accuracy: 0.626953125\n",
      "Batch: 93, Loss: 1.1079962253570557, Accuracy: 0.6396484375\n",
      "Batch: 94, Loss: 1.112349271774292, Accuracy: 0.634765625\n",
      "Batch: 95, Loss: 1.1447219848632812, Accuracy: 0.6220703125\n",
      "Batch: 96, Loss: 1.1131384372711182, Accuracy: 0.6484375\n",
      "Batch: 97, Loss: 0.9854735732078552, Accuracy: 0.67578125\n",
      "Batch: 98, Loss: 1.0475777387619019, Accuracy: 0.6806640625\n",
      "Batch: 99, Loss: 1.0647978782653809, Accuracy: 0.671875\n",
      "Batch: 100, Loss: 1.0997824668884277, Accuracy: 0.65625\n",
      "Batch: 101, Loss: 1.1782362461090088, Accuracy: 0.625\n",
      "Batch: 102, Loss: 1.0784475803375244, Accuracy: 0.65234375\n",
      "Batch: 103, Loss: 1.1839433908462524, Accuracy: 0.6328125\n",
      "Batch: 104, Loss: 1.0682647228240967, Accuracy: 0.6455078125\n",
      "Batch: 105, Loss: 1.1744709014892578, Accuracy: 0.6279296875\n",
      "Batch: 106, Loss: 1.1645002365112305, Accuracy: 0.6455078125\n",
      "Batch: 107, Loss: 1.277830719947815, Accuracy: 0.595703125\n",
      "Batch: 108, Loss: 1.209509253501892, Accuracy: 0.607421875\n",
      "Batch: 109, Loss: 1.33198881149292, Accuracy: 0.5791015625\n",
      "Batch: 110, Loss: 0.9795544743537903, Accuracy: 0.68359375\n",
      "Batch: 111, Loss: 1.207190990447998, Accuracy: 0.5947265625\n",
      "Batch: 112, Loss: 1.1350523233413696, Accuracy: 0.65625\n",
      "Batch: 113, Loss: 1.167468547821045, Accuracy: 0.64453125\n",
      "Batch: 114, Loss: 1.2876536846160889, Accuracy: 0.5947265625\n",
      "Batch: 115, Loss: 1.3003870248794556, Accuracy: 0.6044921875\n",
      "Batch: 116, Loss: 1.2122493982315063, Accuracy: 0.625\n",
      "Batch: 117, Loss: 1.2441719770431519, Accuracy: 0.619140625\n",
      "Batch: 118, Loss: 1.014595627784729, Accuracy: 0.673828125\n",
      "Batch: 119, Loss: 1.0445377826690674, Accuracy: 0.669921875\n",
      "Batch: 120, Loss: 1.2107621431350708, Accuracy: 0.611328125\n",
      "Batch: 121, Loss: 1.2402760982513428, Accuracy: 0.603515625\n",
      "Batch: 122, Loss: 1.0912847518920898, Accuracy: 0.6552734375\n",
      "Batch: 123, Loss: 1.117618441581726, Accuracy: 0.6572265625\n",
      "Batch: 124, Loss: 1.1730095148086548, Accuracy: 0.642578125\n",
      "Batch: 125, Loss: 1.2243976593017578, Accuracy: 0.619140625\n",
      "Batch: 126, Loss: 1.1918631792068481, Accuracy: 0.6103515625\n",
      "Batch: 127, Loss: 1.0541354417800903, Accuracy: 0.67578125\n",
      "Batch: 128, Loss: 1.3166930675506592, Accuracy: 0.6025390625\n",
      "Batch: 129, Loss: 1.0900797843933105, Accuracy: 0.662109375\n",
      "Batch: 130, Loss: 1.378253698348999, Accuracy: 0.5751953125\n",
      "Batch: 131, Loss: 1.2057173252105713, Accuracy: 0.6298828125\n",
      "Batch: 132, Loss: 1.2145795822143555, Accuracy: 0.62109375\n",
      "Batch: 133, Loss: 1.0688869953155518, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.1571331024169922, Accuracy: 0.6181640625\n",
      "Batch: 135, Loss: 1.0634793043136597, Accuracy: 0.6728515625\n",
      "Batch: 136, Loss: 1.1269261837005615, Accuracy: 0.6552734375\n",
      "Batch: 137, Loss: 1.0775723457336426, Accuracy: 0.6337890625\n",
      "Batch: 138, Loss: 0.9692884683609009, Accuracy: 0.6630859375\n",
      "Batch: 139, Loss: 1.0346735715866089, Accuracy: 0.6494140625\n",
      "Batch: 140, Loss: 1.137639045715332, Accuracy: 0.6162109375\n",
      "Batch: 141, Loss: 1.1730742454528809, Accuracy: 0.6171875\n",
      "Batch: 142, Loss: 1.2170202732086182, Accuracy: 0.6025390625\n",
      "Batch: 143, Loss: 1.159219741821289, Accuracy: 0.6279296875\n",
      "Batch: 144, Loss: 1.168426752090454, Accuracy: 0.6259765625\n",
      "Batch: 145, Loss: 1.099703073501587, Accuracy: 0.62890625\n",
      "Batch: 146, Loss: 1.2115873098373413, Accuracy: 0.6142578125\n",
      "Batch: 147, Loss: 1.1804871559143066, Accuracy: 0.6123046875\n",
      "Batch: 148, Loss: 1.288060188293457, Accuracy: 0.560546875\n",
      "Batch: 149, Loss: 1.1725926399230957, Accuracy: 0.6171875\n",
      "Batch: 150, Loss: 1.1031091213226318, Accuracy: 0.626953125\n",
      "Batch: 151, Loss: 1.0300419330596924, Accuracy: 0.6728515625\n",
      "Epoch 13/80\n",
      "Batch: 1, Loss: 1.389230489730835, Accuracy: 0.5537109375\n",
      "Batch: 2, Loss: 1.1959424018859863, Accuracy: 0.59765625\n",
      "Batch: 3, Loss: 1.0992645025253296, Accuracy: 0.626953125\n",
      "Batch: 4, Loss: 1.0469834804534912, Accuracy: 0.6611328125\n",
      "Batch: 5, Loss: 1.056365966796875, Accuracy: 0.6611328125\n",
      "Batch: 6, Loss: 1.1692092418670654, Accuracy: 0.6181640625\n",
      "Batch: 7, Loss: 1.1049284934997559, Accuracy: 0.6298828125\n",
      "Batch: 8, Loss: 1.0374021530151367, Accuracy: 0.6328125\n",
      "Batch: 9, Loss: 1.0211195945739746, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 1.0595216751098633, Accuracy: 0.6513671875\n",
      "Batch: 11, Loss: 1.2287766933441162, Accuracy: 0.5888671875\n",
      "Batch: 12, Loss: 1.2271931171417236, Accuracy: 0.6171875\n",
      "Batch: 13, Loss: 0.987184464931488, Accuracy: 0.6884765625\n",
      "Batch: 14, Loss: 1.2052826881408691, Accuracy: 0.6142578125\n",
      "Batch: 15, Loss: 1.0723987817764282, Accuracy: 0.671875\n",
      "Batch: 16, Loss: 1.0744223594665527, Accuracy: 0.6630859375\n",
      "Batch: 17, Loss: 1.187286615371704, Accuracy: 0.6376953125\n",
      "Batch: 18, Loss: 1.1550004482269287, Accuracy: 0.6318359375\n",
      "Batch: 19, Loss: 1.1997787952423096, Accuracy: 0.6328125\n",
      "Batch: 20, Loss: 1.0776394605636597, Accuracy: 0.6650390625\n",
      "Batch: 21, Loss: 1.0817961692810059, Accuracy: 0.650390625\n",
      "Batch: 22, Loss: 1.2094852924346924, Accuracy: 0.615234375\n",
      "Batch: 23, Loss: 1.1120563745498657, Accuracy: 0.640625\n",
      "Batch: 24, Loss: 1.1370099782943726, Accuracy: 0.6220703125\n",
      "Batch: 25, Loss: 1.1132996082305908, Accuracy: 0.6484375\n",
      "Batch: 26, Loss: 1.0240575075149536, Accuracy: 0.6728515625\n",
      "Batch: 27, Loss: 1.0731443166732788, Accuracy: 0.6533203125\n",
      "Batch: 28, Loss: 1.1908477544784546, Accuracy: 0.59765625\n",
      "Batch: 29, Loss: 1.1423227787017822, Accuracy: 0.6357421875\n",
      "Batch: 30, Loss: 1.0791497230529785, Accuracy: 0.662109375\n",
      "Batch: 31, Loss: 1.0664803981781006, Accuracy: 0.671875\n",
      "Batch: 32, Loss: 1.038112759590149, Accuracy: 0.6611328125\n",
      "Batch: 33, Loss: 1.2645063400268555, Accuracy: 0.6044921875\n",
      "Batch: 34, Loss: 1.2926521301269531, Accuracy: 0.595703125\n",
      "Batch: 35, Loss: 1.189780592918396, Accuracy: 0.62109375\n",
      "Batch: 36, Loss: 1.1873018741607666, Accuracy: 0.6259765625\n",
      "Batch: 37, Loss: 1.1591823101043701, Accuracy: 0.63671875\n",
      "Batch: 38, Loss: 1.171060562133789, Accuracy: 0.6171875\n",
      "Batch: 39, Loss: 1.1694625616073608, Accuracy: 0.6376953125\n",
      "Batch: 40, Loss: 1.180572748184204, Accuracy: 0.630859375\n",
      "Batch: 41, Loss: 1.1636509895324707, Accuracy: 0.634765625\n",
      "Batch: 42, Loss: 0.9500104188919067, Accuracy: 0.6845703125\n",
      "Batch: 43, Loss: 1.1335983276367188, Accuracy: 0.6220703125\n",
      "Batch: 44, Loss: 1.150587797164917, Accuracy: 0.6064453125\n",
      "Batch: 45, Loss: 1.0061780214309692, Accuracy: 0.66015625\n",
      "Batch: 46, Loss: 1.1425418853759766, Accuracy: 0.64453125\n",
      "Batch: 47, Loss: 1.134849190711975, Accuracy: 0.658203125\n",
      "Batch: 48, Loss: 1.0637065172195435, Accuracy: 0.65625\n",
      "Batch: 49, Loss: 1.2594306468963623, Accuracy: 0.59765625\n",
      "Batch: 50, Loss: 1.2184045314788818, Accuracy: 0.5966796875\n",
      "Batch: 51, Loss: 1.2820584774017334, Accuracy: 0.58203125\n",
      "Batch: 52, Loss: 1.2496963739395142, Accuracy: 0.619140625\n",
      "Batch: 53, Loss: 1.056856632232666, Accuracy: 0.6455078125\n",
      "Batch: 54, Loss: 1.1167540550231934, Accuracy: 0.65234375\n",
      "Batch: 55, Loss: 1.1937824487686157, Accuracy: 0.6083984375\n",
      "Batch: 56, Loss: 1.1896305084228516, Accuracy: 0.6220703125\n",
      "Batch: 57, Loss: 1.1420435905456543, Accuracy: 0.65234375\n",
      "Batch: 58, Loss: 1.2221450805664062, Accuracy: 0.6396484375\n",
      "Batch: 59, Loss: 1.0277719497680664, Accuracy: 0.6826171875\n",
      "Batch: 60, Loss: 1.051398515701294, Accuracy: 0.6728515625\n",
      "Batch: 61, Loss: 1.1713063716888428, Accuracy: 0.6240234375\n",
      "Batch: 62, Loss: 1.1104722023010254, Accuracy: 0.6455078125\n",
      "Batch: 63, Loss: 1.1571438312530518, Accuracy: 0.6328125\n",
      "Batch: 64, Loss: 1.1195294857025146, Accuracy: 0.6484375\n",
      "Batch: 65, Loss: 1.1767702102661133, Accuracy: 0.630859375\n",
      "Batch: 66, Loss: 1.100175380706787, Accuracy: 0.6611328125\n",
      "Batch: 67, Loss: 1.2316505908966064, Accuracy: 0.6279296875\n",
      "Batch: 68, Loss: 1.2308106422424316, Accuracy: 0.6279296875\n",
      "Batch: 69, Loss: 1.1430013179779053, Accuracy: 0.638671875\n",
      "Batch: 70, Loss: 1.130916714668274, Accuracy: 0.650390625\n",
      "Batch: 71, Loss: 1.1656489372253418, Accuracy: 0.6318359375\n",
      "Batch: 72, Loss: 1.0452392101287842, Accuracy: 0.666015625\n",
      "Batch: 73, Loss: 1.0993947982788086, Accuracy: 0.658203125\n",
      "Batch: 74, Loss: 1.081953525543213, Accuracy: 0.6630859375\n",
      "Batch: 75, Loss: 1.03141188621521, Accuracy: 0.6669921875\n",
      "Batch: 76, Loss: 1.1202694177627563, Accuracy: 0.6181640625\n",
      "Batch: 77, Loss: 1.1156139373779297, Accuracy: 0.6435546875\n",
      "Batch: 78, Loss: 1.0960358381271362, Accuracy: 0.6640625\n",
      "Batch: 79, Loss: 1.0117520093917847, Accuracy: 0.6953125\n",
      "Batch: 80, Loss: 1.0402830839157104, Accuracy: 0.6455078125\n",
      "Batch: 81, Loss: 1.2093782424926758, Accuracy: 0.59375\n",
      "Batch: 82, Loss: 1.1462204456329346, Accuracy: 0.634765625\n",
      "Batch: 83, Loss: 1.0001091957092285, Accuracy: 0.6845703125\n",
      "Batch: 84, Loss: 1.1009148359298706, Accuracy: 0.654296875\n",
      "Batch: 85, Loss: 1.031554937362671, Accuracy: 0.6748046875\n",
      "Batch: 86, Loss: 1.3042947053909302, Accuracy: 0.580078125\n",
      "Batch: 87, Loss: 1.0603325366973877, Accuracy: 0.68359375\n",
      "Batch: 88, Loss: 1.1675567626953125, Accuracy: 0.640625\n",
      "Batch: 89, Loss: 1.1660981178283691, Accuracy: 0.6298828125\n",
      "Batch: 90, Loss: 1.0443273782730103, Accuracy: 0.6630859375\n",
      "Batch: 91, Loss: 1.09698486328125, Accuracy: 0.65234375\n",
      "Batch: 92, Loss: 1.1384961605072021, Accuracy: 0.6474609375\n",
      "Batch: 93, Loss: 1.08659029006958, Accuracy: 0.6630859375\n",
      "Batch: 94, Loss: 1.0900382995605469, Accuracy: 0.6484375\n",
      "Batch: 95, Loss: 1.1386864185333252, Accuracy: 0.61328125\n",
      "Batch: 96, Loss: 1.0821423530578613, Accuracy: 0.65625\n",
      "Batch: 97, Loss: 0.9721189141273499, Accuracy: 0.6884765625\n",
      "Batch: 98, Loss: 1.0089198350906372, Accuracy: 0.68359375\n",
      "Batch: 99, Loss: 1.0611283779144287, Accuracy: 0.666015625\n",
      "Batch: 100, Loss: 1.0841023921966553, Accuracy: 0.6484375\n",
      "Batch: 101, Loss: 1.1576049327850342, Accuracy: 0.6318359375\n",
      "Batch: 102, Loss: 1.0575777292251587, Accuracy: 0.669921875\n",
      "Batch: 103, Loss: 1.1754599809646606, Accuracy: 0.6484375\n",
      "Batch: 104, Loss: 1.0385692119598389, Accuracy: 0.6650390625\n",
      "Batch: 105, Loss: 1.1392822265625, Accuracy: 0.63671875\n",
      "Batch: 106, Loss: 1.1277353763580322, Accuracy: 0.6474609375\n",
      "Batch: 107, Loss: 1.2405457496643066, Accuracy: 0.6220703125\n",
      "Batch: 108, Loss: 1.1797699928283691, Accuracy: 0.6259765625\n",
      "Batch: 109, Loss: 1.3167848587036133, Accuracy: 0.5751953125\n",
      "Batch: 110, Loss: 0.955801248550415, Accuracy: 0.6845703125\n",
      "Batch: 111, Loss: 1.1782854795455933, Accuracy: 0.603515625\n",
      "Batch: 114, Loss: 1.2602373361587524, Accuracy: 0.5986328125\n",
      "Batch: 115, Loss: 1.281812071800232, Accuracy: 0.615234375\n",
      "Batch: 116, Loss: 1.2143056392669678, Accuracy: 0.625\n",
      "Batch: 117, Loss: 1.2044018507003784, Accuracy: 0.619140625\n",
      "Batch: 118, Loss: 1.0022938251495361, Accuracy: 0.6806640625\n",
      "Batch: 119, Loss: 1.0196378231048584, Accuracy: 0.677734375\n",
      "Batch: 120, Loss: 1.181659460067749, Accuracy: 0.6162109375\n",
      "Batch: 121, Loss: 1.2366187572479248, Accuracy: 0.6123046875\n",
      "Batch: 122, Loss: 1.0787824392318726, Accuracy: 0.6552734375\n",
      "Batch: 123, Loss: 1.109107255935669, Accuracy: 0.66015625\n",
      "Batch: 124, Loss: 1.1617000102996826, Accuracy: 0.640625\n",
      "Batch: 125, Loss: 1.1770216226577759, Accuracy: 0.62109375\n",
      "Batch: 126, Loss: 1.1715831756591797, Accuracy: 0.619140625\n",
      "Batch: 127, Loss: 1.0355193614959717, Accuracy: 0.6806640625\n",
      "Batch: 128, Loss: 1.2666271924972534, Accuracy: 0.62890625\n",
      "Batch: 129, Loss: 1.0545666217803955, Accuracy: 0.669921875\n",
      "Batch: 130, Loss: 1.3296520709991455, Accuracy: 0.587890625\n",
      "Batch: 131, Loss: 1.1763604879379272, Accuracy: 0.6328125\n",
      "Batch: 132, Loss: 1.2106454372406006, Accuracy: 0.6103515625\n",
      "Batch: 133, Loss: 1.0623551607131958, Accuracy: 0.63671875\n",
      "Batch: 134, Loss: 1.1582326889038086, Accuracy: 0.623046875\n",
      "Batch: 135, Loss: 1.0502862930297852, Accuracy: 0.68359375\n",
      "Batch: 136, Loss: 1.146385908126831, Accuracy: 0.623046875\n",
      "Batch: 137, Loss: 1.0467233657836914, Accuracy: 0.6484375\n",
      "Batch: 138, Loss: 0.954937219619751, Accuracy: 0.6845703125\n",
      "Batch: 139, Loss: 1.0207180976867676, Accuracy: 0.662109375\n",
      "Batch: 140, Loss: 1.1330533027648926, Accuracy: 0.62890625\n",
      "Batch: 141, Loss: 1.1377787590026855, Accuracy: 0.6328125\n",
      "Batch: 142, Loss: 1.1746680736541748, Accuracy: 0.6240234375\n",
      "Batch: 143, Loss: 1.152284026145935, Accuracy: 0.63671875\n",
      "Batch: 144, Loss: 1.1230130195617676, Accuracy: 0.634765625\n",
      "Batch: 145, Loss: 1.0924806594848633, Accuracy: 0.6396484375\n",
      "Batch: 146, Loss: 1.184878945350647, Accuracy: 0.61328125\n",
      "Batch: 147, Loss: 1.182187795639038, Accuracy: 0.6240234375\n",
      "Batch: 148, Loss: 1.2977977991104126, Accuracy: 0.5654296875\n",
      "Batch: 149, Loss: 1.1430778503417969, Accuracy: 0.626953125\n",
      "Batch: 150, Loss: 1.0691930055618286, Accuracy: 0.65234375\n",
      "Batch: 151, Loss: 0.9969099760055542, Accuracy: 0.6875\n",
      "Epoch 14/80\n",
      "Batch: 1, Loss: 1.3703198432922363, Accuracy: 0.55859375\n",
      "Batch: 2, Loss: 1.141615867614746, Accuracy: 0.59765625\n",
      "Batch: 3, Loss: 1.0698225498199463, Accuracy: 0.63671875\n",
      "Batch: 4, Loss: 1.0120989084243774, Accuracy: 0.6767578125\n",
      "Batch: 5, Loss: 1.0398097038269043, Accuracy: 0.669921875\n",
      "Batch: 6, Loss: 1.1330747604370117, Accuracy: 0.6103515625\n",
      "Batch: 7, Loss: 1.072635293006897, Accuracy: 0.6455078125\n",
      "Batch: 8, Loss: 1.0168945789337158, Accuracy: 0.6591796875\n",
      "Batch: 9, Loss: 0.9928756356239319, Accuracy: 0.6845703125\n",
      "Batch: 10, Loss: 1.0293269157409668, Accuracy: 0.66015625\n",
      "Batch: 11, Loss: 1.2173449993133545, Accuracy: 0.587890625\n",
      "Batch: 12, Loss: 1.2139918804168701, Accuracy: 0.6142578125\n",
      "Batch: 13, Loss: 0.9740183353424072, Accuracy: 0.69140625\n",
      "Batch: 14, Loss: 1.213841199874878, Accuracy: 0.6005859375\n",
      "Batch: 15, Loss: 1.0847142934799194, Accuracy: 0.6640625\n",
      "Batch: 16, Loss: 1.0894547700881958, Accuracy: 0.6640625\n",
      "Batch: 17, Loss: 1.1530072689056396, Accuracy: 0.63671875\n",
      "Batch: 18, Loss: 1.1236920356750488, Accuracy: 0.6357421875\n",
      "Batch: 19, Loss: 1.1698832511901855, Accuracy: 0.6259765625\n",
      "Batch: 20, Loss: 1.0606310367584229, Accuracy: 0.666015625\n",
      "Batch: 21, Loss: 1.06528902053833, Accuracy: 0.65625\n",
      "Batch: 22, Loss: 1.2005972862243652, Accuracy: 0.6162109375\n",
      "Batch: 23, Loss: 1.0833256244659424, Accuracy: 0.642578125\n",
      "Batch: 24, Loss: 1.1358871459960938, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.1175932884216309, Accuracy: 0.646484375\n",
      "Batch: 26, Loss: 1.0201890468597412, Accuracy: 0.671875\n",
      "Batch: 27, Loss: 1.0685176849365234, Accuracy: 0.6494140625\n",
      "Batch: 28, Loss: 1.1525623798370361, Accuracy: 0.619140625\n",
      "Batch: 29, Loss: 1.1274644136428833, Accuracy: 0.64453125\n",
      "Batch: 30, Loss: 1.040534257888794, Accuracy: 0.681640625\n",
      "Batch: 31, Loss: 1.0489000082015991, Accuracy: 0.673828125\n",
      "Batch: 32, Loss: 1.0369330644607544, Accuracy: 0.6455078125\n",
      "Batch: 33, Loss: 1.2399213314056396, Accuracy: 0.60546875\n",
      "Batch: 34, Loss: 1.282273292541504, Accuracy: 0.5986328125\n",
      "Batch: 35, Loss: 1.1791788339614868, Accuracy: 0.6259765625\n",
      "Batch: 36, Loss: 1.1757822036743164, Accuracy: 0.6328125\n",
      "Batch: 37, Loss: 1.1377689838409424, Accuracy: 0.62890625\n",
      "Batch: 38, Loss: 1.1547231674194336, Accuracy: 0.6298828125\n",
      "Batch: 39, Loss: 1.1260513067245483, Accuracy: 0.6494140625\n",
      "Batch: 40, Loss: 1.1444053649902344, Accuracy: 0.638671875\n",
      "Batch: 41, Loss: 1.1185617446899414, Accuracy: 0.6611328125\n",
      "Batch: 42, Loss: 0.9206219911575317, Accuracy: 0.6943359375\n",
      "Batch: 43, Loss: 1.1262993812561035, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 1.1246916055679321, Accuracy: 0.61328125\n",
      "Batch: 45, Loss: 0.9634706974029541, Accuracy: 0.677734375\n",
      "Batch: 46, Loss: 1.095696210861206, Accuracy: 0.6552734375\n",
      "Batch: 47, Loss: 1.1182587146759033, Accuracy: 0.658203125\n",
      "Batch: 48, Loss: 1.0101796388626099, Accuracy: 0.6845703125\n",
      "Batch: 49, Loss: 1.2365515232086182, Accuracy: 0.59765625\n",
      "Batch: 50, Loss: 1.2128863334655762, Accuracy: 0.6083984375\n",
      "Batch: 51, Loss: 1.2410507202148438, Accuracy: 0.5908203125\n",
      "Batch: 52, Loss: 1.2449265718460083, Accuracy: 0.6142578125\n",
      "Batch: 53, Loss: 1.0366750955581665, Accuracy: 0.6572265625\n",
      "Batch: 54, Loss: 1.0807230472564697, Accuracy: 0.662109375\n",
      "Batch: 55, Loss: 1.1728676557540894, Accuracy: 0.6162109375\n",
      "Batch: 56, Loss: 1.1907317638397217, Accuracy: 0.6259765625\n",
      "Batch: 59, Loss: 1.009392499923706, Accuracy: 0.7021484375\n",
      "Batch: 60, Loss: 1.0019105672836304, Accuracy: 0.6806640625\n",
      "Batch: 61, Loss: 1.1413123607635498, Accuracy: 0.6376953125\n",
      "Batch: 62, Loss: 1.1155707836151123, Accuracy: 0.6494140625\n",
      "Batch: 63, Loss: 1.160861849784851, Accuracy: 0.638671875\n",
      "Batch: 64, Loss: 1.099278211593628, Accuracy: 0.6513671875\n",
      "Batch: 65, Loss: 1.149130940437317, Accuracy: 0.630859375\n",
      "Batch: 66, Loss: 1.0756711959838867, Accuracy: 0.6533203125\n",
      "Batch: 67, Loss: 1.1822576522827148, Accuracy: 0.630859375\n",
      "Batch: 68, Loss: 1.2088966369628906, Accuracy: 0.640625\n",
      "Batch: 69, Loss: 1.1595547199249268, Accuracy: 0.6318359375\n",
      "Batch: 70, Loss: 1.1057264804840088, Accuracy: 0.6728515625\n",
      "Batch: 71, Loss: 1.149630069732666, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.0214807987213135, Accuracy: 0.6787109375\n",
      "Batch: 73, Loss: 1.0977331399917603, Accuracy: 0.671875\n",
      "Batch: 74, Loss: 1.0490963459014893, Accuracy: 0.6728515625\n",
      "Batch: 75, Loss: 1.0386366844177246, Accuracy: 0.673828125\n",
      "Batch: 76, Loss: 1.114446759223938, Accuracy: 0.638671875\n",
      "Batch: 77, Loss: 1.1105645895004272, Accuracy: 0.6298828125\n",
      "Batch: 78, Loss: 1.0765635967254639, Accuracy: 0.6591796875\n",
      "Batch: 79, Loss: 0.9709764719009399, Accuracy: 0.7099609375\n",
      "Batch: 80, Loss: 1.0221327543258667, Accuracy: 0.658203125\n",
      "Batch: 81, Loss: 1.1761271953582764, Accuracy: 0.6083984375\n",
      "Batch: 82, Loss: 1.1445039510726929, Accuracy: 0.6318359375\n",
      "Batch: 83, Loss: 0.9645065069198608, Accuracy: 0.7060546875\n",
      "Batch: 84, Loss: 1.0705478191375732, Accuracy: 0.6748046875\n",
      "Batch: 85, Loss: 1.0195918083190918, Accuracy: 0.67578125\n",
      "Batch: 86, Loss: 1.2773720026016235, Accuracy: 0.6083984375\n",
      "Batch: 87, Loss: 1.0593816041946411, Accuracy: 0.6708984375\n",
      "Batch: 88, Loss: 1.1298072338104248, Accuracy: 0.658203125\n",
      "Batch: 89, Loss: 1.1587185859680176, Accuracy: 0.6474609375\n",
      "Batch: 90, Loss: 1.0615588426589966, Accuracy: 0.673828125\n",
      "Batch: 91, Loss: 1.0777487754821777, Accuracy: 0.662109375\n",
      "Batch: 92, Loss: 1.1217796802520752, Accuracy: 0.646484375\n",
      "Batch: 93, Loss: 1.0690863132476807, Accuracy: 0.6669921875\n",
      "Batch: 94, Loss: 1.0801258087158203, Accuracy: 0.6474609375\n",
      "Batch: 95, Loss: 1.1074124574661255, Accuracy: 0.6396484375\n",
      "Batch: 96, Loss: 1.0695232152938843, Accuracy: 0.66796875\n",
      "Batch: 97, Loss: 0.9523941278457642, Accuracy: 0.6953125\n",
      "Batch: 98, Loss: 1.0006084442138672, Accuracy: 0.697265625\n",
      "Batch: 99, Loss: 1.0119736194610596, Accuracy: 0.6767578125\n",
      "Batch: 100, Loss: 1.049838662147522, Accuracy: 0.6708984375\n",
      "Batch: 101, Loss: 1.1202268600463867, Accuracy: 0.6396484375\n",
      "Batch: 102, Loss: 1.0514352321624756, Accuracy: 0.6767578125\n",
      "Batch: 103, Loss: 1.1423532962799072, Accuracy: 0.646484375\n",
      "Batch: 104, Loss: 1.014280080795288, Accuracy: 0.662109375\n",
      "Batch: 105, Loss: 1.1195520162582397, Accuracy: 0.65234375\n",
      "Batch: 106, Loss: 1.1032763719558716, Accuracy: 0.6396484375\n",
      "Batch: 107, Loss: 1.2541115283966064, Accuracy: 0.62109375\n",
      "Batch: 108, Loss: 1.1863579750061035, Accuracy: 0.611328125\n",
      "Batch: 109, Loss: 1.2855318784713745, Accuracy: 0.580078125\n",
      "Batch: 110, Loss: 0.9403940439224243, Accuracy: 0.7080078125\n",
      "Batch: 111, Loss: 1.153091549873352, Accuracy: 0.6328125\n",
      "Batch: 112, Loss: 1.1022623777389526, Accuracy: 0.66015625\n",
      "Batch: 113, Loss: 1.1353983879089355, Accuracy: 0.6591796875\n",
      "Batch: 114, Loss: 1.2165768146514893, Accuracy: 0.615234375\n",
      "Batch: 115, Loss: 1.2796226739883423, Accuracy: 0.603515625\n",
      "Batch: 116, Loss: 1.1499829292297363, Accuracy: 0.6298828125\n",
      "Batch: 117, Loss: 1.191888451576233, Accuracy: 0.640625\n",
      "Batch: 118, Loss: 0.9703724384307861, Accuracy: 0.6953125\n",
      "Batch: 119, Loss: 0.9919707179069519, Accuracy: 0.6845703125\n",
      "Batch: 120, Loss: 1.1728953123092651, Accuracy: 0.6162109375\n",
      "Batch: 121, Loss: 1.193642020225525, Accuracy: 0.623046875\n",
      "Batch: 122, Loss: 1.0594842433929443, Accuracy: 0.6748046875\n",
      "Batch: 123, Loss: 1.0796478986740112, Accuracy: 0.6591796875\n",
      "Batch: 124, Loss: 1.1194050312042236, Accuracy: 0.6376953125\n",
      "Batch: 125, Loss: 1.1632630825042725, Accuracy: 0.6376953125\n",
      "Batch: 126, Loss: 1.1502017974853516, Accuracy: 0.6279296875\n",
      "Batch: 127, Loss: 0.9914124608039856, Accuracy: 0.69921875\n",
      "Batch: 128, Loss: 1.2608747482299805, Accuracy: 0.6259765625\n",
      "Batch: 129, Loss: 1.0508949756622314, Accuracy: 0.6630859375\n",
      "Batch: 130, Loss: 1.3291445970535278, Accuracy: 0.578125\n",
      "Batch: 131, Loss: 1.1503533124923706, Accuracy: 0.619140625\n",
      "Batch: 132, Loss: 1.1467938423156738, Accuracy: 0.642578125\n",
      "Batch: 133, Loss: 1.041686773300171, Accuracy: 0.6484375\n",
      "Batch: 134, Loss: 1.1346485614776611, Accuracy: 0.6123046875\n",
      "Batch: 135, Loss: 1.0050249099731445, Accuracy: 0.689453125\n",
      "Batch: 136, Loss: 1.095045566558838, Accuracy: 0.654296875\n",
      "Batch: 137, Loss: 1.0398318767547607, Accuracy: 0.640625\n",
      "Batch: 138, Loss: 0.9340792894363403, Accuracy: 0.6806640625\n",
      "Batch: 139, Loss: 1.0000903606414795, Accuracy: 0.673828125\n",
      "Batch: 140, Loss: 1.108303189277649, Accuracy: 0.6259765625\n",
      "Batch: 141, Loss: 1.1375393867492676, Accuracy: 0.6376953125\n",
      "Batch: 142, Loss: 1.1732585430145264, Accuracy: 0.6298828125\n",
      "Batch: 143, Loss: 1.1335010528564453, Accuracy: 0.6328125\n",
      "Batch: 144, Loss: 1.1014739274978638, Accuracy: 0.6572265625\n",
      "Batch: 145, Loss: 1.0686960220336914, Accuracy: 0.6435546875\n",
      "Batch: 146, Loss: 1.1745532751083374, Accuracy: 0.615234375\n",
      "Batch: 147, Loss: 1.1451747417449951, Accuracy: 0.6435546875\n",
      "Batch: 148, Loss: 1.2818636894226074, Accuracy: 0.5888671875\n",
      "Batch: 149, Loss: 1.1225028038024902, Accuracy: 0.626953125\n",
      "Batch: 150, Loss: 1.0601568222045898, Accuracy: 0.65234375\n",
      "Batch: 151, Loss: 0.9787909388542175, Accuracy: 0.6923828125\n",
      "Epoch 15/80\n",
      "Batch: 1, Loss: 1.3699170351028442, Accuracy: 0.560546875\n",
      "Batch: 2, Loss: 1.1561044454574585, Accuracy: 0.603515625\n",
      "Batch: 3, Loss: 1.0523570775985718, Accuracy: 0.6533203125\n",
      "Batch: 4, Loss: 0.977152943611145, Accuracy: 0.6982421875\n",
      "Batch: 5, Loss: 1.0110855102539062, Accuracy: 0.685546875\n",
      "Batch: 6, Loss: 1.1288931369781494, Accuracy: 0.6259765625\n",
      "Batch: 7, Loss: 1.0639705657958984, Accuracy: 0.6376953125\n",
      "Batch: 8, Loss: 0.9939364194869995, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 0.9663231372833252, Accuracy: 0.69140625\n",
      "Batch: 10, Loss: 1.003696322441101, Accuracy: 0.6748046875\n",
      "Batch: 11, Loss: 1.1798896789550781, Accuracy: 0.6044921875\n",
      "Batch: 12, Loss: 1.1807174682617188, Accuracy: 0.6240234375\n",
      "Batch: 13, Loss: 0.9331211447715759, Accuracy: 0.7001953125\n",
      "Batch: 14, Loss: 1.1962294578552246, Accuracy: 0.61328125\n",
      "Batch: 15, Loss: 1.023564338684082, Accuracy: 0.685546875\n",
      "Batch: 16, Loss: 1.0487391948699951, Accuracy: 0.6767578125\n",
      "Batch: 17, Loss: 1.1258422136306763, Accuracy: 0.6455078125\n",
      "Batch: 18, Loss: 1.1263535022735596, Accuracy: 0.640625\n",
      "Batch: 19, Loss: 1.135388731956482, Accuracy: 0.64453125\n",
      "Batch: 20, Loss: 1.0453131198883057, Accuracy: 0.6748046875\n",
      "Batch: 21, Loss: 1.0481511354446411, Accuracy: 0.6513671875\n",
      "Batch: 22, Loss: 1.1616454124450684, Accuracy: 0.62890625\n",
      "Batch: 23, Loss: 1.0790953636169434, Accuracy: 0.65234375\n",
      "Batch: 24, Loss: 1.0983245372772217, Accuracy: 0.646484375\n",
      "Batch: 25, Loss: 1.0860155820846558, Accuracy: 0.6513671875\n",
      "Batch: 26, Loss: 1.003539800643921, Accuracy: 0.689453125\n",
      "Batch: 27, Loss: 1.0245414972305298, Accuracy: 0.650390625\n",
      "Batch: 28, Loss: 1.1380000114440918, Accuracy: 0.615234375\n",
      "Batch: 29, Loss: 1.1080191135406494, Accuracy: 0.634765625\n",
      "Batch: 30, Loss: 1.0506010055541992, Accuracy: 0.6728515625\n",
      "Batch: 31, Loss: 1.0296170711517334, Accuracy: 0.6826171875\n",
      "Batch: 32, Loss: 1.000828742980957, Accuracy: 0.6767578125\n",
      "Batch: 33, Loss: 1.2120094299316406, Accuracy: 0.6259765625\n",
      "Batch: 34, Loss: 1.2387290000915527, Accuracy: 0.6015625\n",
      "Batch: 35, Loss: 1.1483473777770996, Accuracy: 0.619140625\n",
      "Batch: 36, Loss: 1.1476486921310425, Accuracy: 0.6416015625\n",
      "Batch: 37, Loss: 1.1248091459274292, Accuracy: 0.6220703125\n",
      "Batch: 38, Loss: 1.124308705329895, Accuracy: 0.6279296875\n",
      "Batch: 39, Loss: 1.1052687168121338, Accuracy: 0.658203125\n",
      "Batch: 40, Loss: 1.1068716049194336, Accuracy: 0.654296875\n",
      "Batch: 41, Loss: 1.1064453125, Accuracy: 0.6494140625\n",
      "Batch: 42, Loss: 0.9053122997283936, Accuracy: 0.69140625\n",
      "Batch: 43, Loss: 1.1041558980941772, Accuracy: 0.638671875\n",
      "Batch: 44, Loss: 1.090660572052002, Accuracy: 0.6396484375\n",
      "Batch: 45, Loss: 0.9504476189613342, Accuracy: 0.677734375\n",
      "Batch: 46, Loss: 1.0736932754516602, Accuracy: 0.66015625\n",
      "Batch: 47, Loss: 1.0955488681793213, Accuracy: 0.6611328125\n",
      "Batch: 48, Loss: 1.0013234615325928, Accuracy: 0.6865234375\n",
      "Batch: 49, Loss: 1.211891770362854, Accuracy: 0.599609375\n",
      "Batch: 50, Loss: 1.1905412673950195, Accuracy: 0.6083984375\n",
      "Batch: 51, Loss: 1.2197988033294678, Accuracy: 0.609375\n",
      "Batch: 52, Loss: 1.1897093057632446, Accuracy: 0.6298828125\n",
      "Batch: 53, Loss: 1.024989128112793, Accuracy: 0.6689453125\n",
      "Batch: 54, Loss: 1.0694580078125, Accuracy: 0.6572265625\n",
      "Batch: 55, Loss: 1.1385459899902344, Accuracy: 0.62890625\n",
      "Batch: 56, Loss: 1.1399158239364624, Accuracy: 0.6396484375\n",
      "Batch: 57, Loss: 1.089176058769226, Accuracy: 0.6552734375\n",
      "Batch: 58, Loss: 1.177629828453064, Accuracy: 0.6396484375\n",
      "Batch: 59, Loss: 0.9914070963859558, Accuracy: 0.697265625\n",
      "Batch: 60, Loss: 0.9975374341011047, Accuracy: 0.6884765625\n",
      "Batch: 61, Loss: 1.1194030046463013, Accuracy: 0.6484375\n",
      "Batch: 62, Loss: 1.099684715270996, Accuracy: 0.650390625\n",
      "Batch: 63, Loss: 1.127640962600708, Accuracy: 0.63671875\n",
      "Batch: 64, Loss: 1.0648047924041748, Accuracy: 0.66796875\n",
      "Batch: 65, Loss: 1.1088719367980957, Accuracy: 0.64453125\n",
      "Batch: 66, Loss: 1.056036114692688, Accuracy: 0.662109375\n",
      "Batch: 67, Loss: 1.172160029411316, Accuracy: 0.6279296875\n",
      "Batch: 68, Loss: 1.1954880952835083, Accuracy: 0.6474609375\n",
      "Batch: 69, Loss: 1.1275722980499268, Accuracy: 0.6455078125\n",
      "Batch: 70, Loss: 1.0823904275894165, Accuracy: 0.6640625\n",
      "Batch: 71, Loss: 1.1320536136627197, Accuracy: 0.6494140625\n",
      "Batch: 72, Loss: 0.9841272830963135, Accuracy: 0.685546875\n",
      "Batch: 73, Loss: 1.0579617023468018, Accuracy: 0.6787109375\n",
      "Batch: 74, Loss: 1.0196218490600586, Accuracy: 0.6865234375\n",
      "Batch: 75, Loss: 1.0006310939788818, Accuracy: 0.6689453125\n",
      "Batch: 76, Loss: 1.1151055097579956, Accuracy: 0.6318359375\n",
      "Batch: 77, Loss: 1.1048214435577393, Accuracy: 0.6357421875\n",
      "Batch: 78, Loss: 1.0726600885391235, Accuracy: 0.673828125\n",
      "Batch: 79, Loss: 0.980563759803772, Accuracy: 0.703125\n",
      "Batch: 80, Loss: 1.0050172805786133, Accuracy: 0.66015625\n",
      "Batch: 81, Loss: 1.159775972366333, Accuracy: 0.6044921875\n",
      "Batch: 82, Loss: 1.132169485092163, Accuracy: 0.6357421875\n",
      "Batch: 83, Loss: 0.9790760278701782, Accuracy: 0.7001953125\n",
      "Batch: 84, Loss: 1.0318007469177246, Accuracy: 0.6806640625\n",
      "Batch: 85, Loss: 0.991025447845459, Accuracy: 0.6923828125\n",
      "Batch: 86, Loss: 1.244675874710083, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.0235812664031982, Accuracy: 0.6865234375\n",
      "Batch: 88, Loss: 1.0954967737197876, Accuracy: 0.6572265625\n",
      "Batch: 89, Loss: 1.1289242506027222, Accuracy: 0.6611328125\n",
      "Batch: 90, Loss: 1.0344243049621582, Accuracy: 0.66796875\n",
      "Batch: 91, Loss: 1.0685473680496216, Accuracy: 0.650390625\n",
      "Batch: 92, Loss: 1.0925791263580322, Accuracy: 0.6533203125\n",
      "Batch: 95, Loss: 1.0815149545669556, Accuracy: 0.640625\n",
      "Batch: 96, Loss: 1.031374216079712, Accuracy: 0.6630859375\n",
      "Batch: 97, Loss: 0.9252345561981201, Accuracy: 0.6904296875\n",
      "Batch: 98, Loss: 0.9797301888465881, Accuracy: 0.6953125\n",
      "Batch: 99, Loss: 1.0037480592727661, Accuracy: 0.685546875\n",
      "Batch: 100, Loss: 1.0677648782730103, Accuracy: 0.6669921875\n",
      "Batch: 101, Loss: 1.146149754524231, Accuracy: 0.6396484375\n",
      "Batch: 102, Loss: 1.0420539379119873, Accuracy: 0.6787109375\n",
      "Batch: 103, Loss: 1.1170177459716797, Accuracy: 0.65625\n",
      "Batch: 104, Loss: 0.9981327056884766, Accuracy: 0.6640625\n",
      "Batch: 105, Loss: 1.1140716075897217, Accuracy: 0.64453125\n",
      "Batch: 106, Loss: 1.0788663625717163, Accuracy: 0.6689453125\n",
      "Batch: 107, Loss: 1.2016154527664185, Accuracy: 0.6201171875\n",
      "Batch: 108, Loss: 1.1435611248016357, Accuracy: 0.6162109375\n",
      "Batch: 109, Loss: 1.2664127349853516, Accuracy: 0.5869140625\n",
      "Batch: 110, Loss: 0.939507007598877, Accuracy: 0.6875\n",
      "Batch: 111, Loss: 1.1238207817077637, Accuracy: 0.6201171875\n",
      "Batch: 112, Loss: 1.0812287330627441, Accuracy: 0.6611328125\n",
      "Batch: 113, Loss: 1.0952845811843872, Accuracy: 0.669921875\n",
      "Batch: 114, Loss: 1.231487512588501, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.2426387071609497, Accuracy: 0.6259765625\n",
      "Batch: 116, Loss: 1.1532397270202637, Accuracy: 0.6494140625\n",
      "Batch: 117, Loss: 1.1640844345092773, Accuracy: 0.6376953125\n",
      "Batch: 118, Loss: 0.9685401320457458, Accuracy: 0.689453125\n",
      "Batch: 119, Loss: 0.993969738483429, Accuracy: 0.689453125\n",
      "Batch: 120, Loss: 1.1496857404708862, Accuracy: 0.6171875\n",
      "Batch: 121, Loss: 1.1735684871673584, Accuracy: 0.6220703125\n",
      "Batch: 122, Loss: 1.035347819328308, Accuracy: 0.65625\n",
      "Batch: 123, Loss: 1.0543930530548096, Accuracy: 0.6630859375\n",
      "Batch: 124, Loss: 1.1216832399368286, Accuracy: 0.6376953125\n",
      "Batch: 125, Loss: 1.1439783573150635, Accuracy: 0.6279296875\n",
      "Batch: 126, Loss: 1.1237950325012207, Accuracy: 0.634765625\n",
      "Batch: 127, Loss: 1.0036373138427734, Accuracy: 0.6943359375\n",
      "Batch: 128, Loss: 1.2174279689788818, Accuracy: 0.6455078125\n",
      "Batch: 129, Loss: 1.0209925174713135, Accuracy: 0.67578125\n",
      "Batch: 130, Loss: 1.274122953414917, Accuracy: 0.6064453125\n",
      "Batch: 131, Loss: 1.133118987083435, Accuracy: 0.6416015625\n",
      "Batch: 132, Loss: 1.1576367616653442, Accuracy: 0.630859375\n",
      "Batch: 133, Loss: 1.0278159379959106, Accuracy: 0.6455078125\n",
      "Batch: 134, Loss: 1.1085515022277832, Accuracy: 0.6318359375\n",
      "Batch: 135, Loss: 1.002465844154358, Accuracy: 0.693359375\n",
      "Batch: 136, Loss: 1.071603536605835, Accuracy: 0.66015625\n",
      "Batch: 137, Loss: 1.0280959606170654, Accuracy: 0.65625\n",
      "Batch: 138, Loss: 0.9249037504196167, Accuracy: 0.6875\n",
      "Batch: 139, Loss: 0.9834845066070557, Accuracy: 0.6806640625\n",
      "Batch: 140, Loss: 1.0867724418640137, Accuracy: 0.634765625\n",
      "Batch: 141, Loss: 1.123570203781128, Accuracy: 0.6513671875\n",
      "Batch: 142, Loss: 1.1596168279647827, Accuracy: 0.6318359375\n",
      "Batch: 143, Loss: 1.113958716392517, Accuracy: 0.6494140625\n",
      "Batch: 144, Loss: 1.0909712314605713, Accuracy: 0.6640625\n",
      "Batch: 145, Loss: 1.0436325073242188, Accuracy: 0.64453125\n",
      "Batch: 146, Loss: 1.1519533395767212, Accuracy: 0.6259765625\n",
      "Batch: 147, Loss: 1.136347770690918, Accuracy: 0.6474609375\n",
      "Batch: 148, Loss: 1.2430204153060913, Accuracy: 0.591796875\n",
      "Batch: 149, Loss: 1.1064822673797607, Accuracy: 0.650390625\n",
      "Batch: 150, Loss: 1.0436432361602783, Accuracy: 0.6650390625\n",
      "Batch: 151, Loss: 0.9432260394096375, Accuracy: 0.701171875\n",
      "Epoch 16/80\n",
      "Batch: 1, Loss: 1.3290231227874756, Accuracy: 0.5693359375\n",
      "Batch: 2, Loss: 1.1469042301177979, Accuracy: 0.6025390625\n",
      "Batch: 3, Loss: 1.0381965637207031, Accuracy: 0.6689453125\n",
      "Batch: 4, Loss: 0.9753785133361816, Accuracy: 0.69140625\n",
      "Batch: 5, Loss: 1.0195339918136597, Accuracy: 0.6865234375\n",
      "Batch: 6, Loss: 1.1253635883331299, Accuracy: 0.6318359375\n",
      "Batch: 7, Loss: 1.055422306060791, Accuracy: 0.6435546875\n",
      "Batch: 8, Loss: 0.988212525844574, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 0.9355099201202393, Accuracy: 0.716796875\n",
      "Batch: 10, Loss: 0.9731633067131042, Accuracy: 0.6875\n",
      "Batch: 11, Loss: 1.1605231761932373, Accuracy: 0.611328125\n",
      "Batch: 12, Loss: 1.155903935432434, Accuracy: 0.6201171875\n",
      "Batch: 13, Loss: 0.9299578666687012, Accuracy: 0.705078125\n",
      "Batch: 14, Loss: 1.1814711093902588, Accuracy: 0.6162109375\n",
      "Batch: 15, Loss: 1.0160610675811768, Accuracy: 0.689453125\n",
      "Batch: 16, Loss: 1.0338550806045532, Accuracy: 0.6796875\n",
      "Batch: 17, Loss: 1.1176583766937256, Accuracy: 0.6552734375\n",
      "Batch: 18, Loss: 1.109045386314392, Accuracy: 0.6494140625\n",
      "Batch: 19, Loss: 1.1135616302490234, Accuracy: 0.658203125\n",
      "Batch: 20, Loss: 1.0195125341415405, Accuracy: 0.67578125\n",
      "Batch: 21, Loss: 1.0234975814819336, Accuracy: 0.6689453125\n",
      "Batch: 22, Loss: 1.1493546962738037, Accuracy: 0.6416015625\n",
      "Batch: 23, Loss: 1.0671803951263428, Accuracy: 0.6533203125\n",
      "Batch: 24, Loss: 1.1107319593429565, Accuracy: 0.646484375\n",
      "Batch: 25, Loss: 1.0520654916763306, Accuracy: 0.65234375\n",
      "Batch: 26, Loss: 0.9891071319580078, Accuracy: 0.6875\n",
      "Batch: 27, Loss: 0.9841189980506897, Accuracy: 0.673828125\n",
      "Batch: 28, Loss: 1.118492841720581, Accuracy: 0.640625\n",
      "Batch: 29, Loss: 1.0795425176620483, Accuracy: 0.654296875\n",
      "Batch: 30, Loss: 1.0449528694152832, Accuracy: 0.677734375\n",
      "Batch: 31, Loss: 0.9970210194587708, Accuracy: 0.6796875\n",
      "Batch: 32, Loss: 0.9714367389678955, Accuracy: 0.689453125\n",
      "Batch: 33, Loss: 1.1739883422851562, Accuracy: 0.623046875\n",
      "Batch: 34, Loss: 1.227590560913086, Accuracy: 0.609375\n",
      "Batch: 37, Loss: 1.107833743095398, Accuracy: 0.640625\n",
      "Batch: 38, Loss: 1.1082946062088013, Accuracy: 0.642578125\n",
      "Batch: 39, Loss: 1.1081371307373047, Accuracy: 0.6416015625\n",
      "Batch: 40, Loss: 1.0844100713729858, Accuracy: 0.662109375\n",
      "Batch: 41, Loss: 1.0776546001434326, Accuracy: 0.6484375\n",
      "Batch: 42, Loss: 0.9066663384437561, Accuracy: 0.705078125\n",
      "Batch: 43, Loss: 1.087140679359436, Accuracy: 0.6416015625\n",
      "Batch: 44, Loss: 1.0857906341552734, Accuracy: 0.6357421875\n",
      "Batch: 45, Loss: 0.9424480199813843, Accuracy: 0.6884765625\n",
      "Batch: 46, Loss: 1.0380070209503174, Accuracy: 0.6982421875\n",
      "Batch: 47, Loss: 1.0796287059783936, Accuracy: 0.666015625\n",
      "Batch: 48, Loss: 0.992554247379303, Accuracy: 0.67578125\n",
      "Batch: 49, Loss: 1.183972716331482, Accuracy: 0.6162109375\n",
      "Batch: 50, Loss: 1.1793577671051025, Accuracy: 0.630859375\n",
      "Batch: 51, Loss: 1.1959245204925537, Accuracy: 0.619140625\n",
      "Batch: 52, Loss: 1.191652536392212, Accuracy: 0.630859375\n",
      "Batch: 53, Loss: 0.9987278580665588, Accuracy: 0.671875\n",
      "Batch: 54, Loss: 1.0561833381652832, Accuracy: 0.6591796875\n",
      "Batch: 55, Loss: 1.133455514907837, Accuracy: 0.6357421875\n",
      "Batch: 56, Loss: 1.147681713104248, Accuracy: 0.6474609375\n",
      "Batch: 57, Loss: 1.0867222547531128, Accuracy: 0.66796875\n",
      "Batch: 58, Loss: 1.164982557296753, Accuracy: 0.650390625\n",
      "Batch: 59, Loss: 0.9732332229614258, Accuracy: 0.7021484375\n",
      "Batch: 60, Loss: 0.981839656829834, Accuracy: 0.6845703125\n",
      "Batch: 61, Loss: 1.1525771617889404, Accuracy: 0.6328125\n",
      "Batch: 62, Loss: 1.0592138767242432, Accuracy: 0.671875\n",
      "Batch: 63, Loss: 1.109590768814087, Accuracy: 0.6474609375\n",
      "Batch: 64, Loss: 1.0543110370635986, Accuracy: 0.6708984375\n",
      "Batch: 65, Loss: 1.1018950939178467, Accuracy: 0.6533203125\n",
      "Batch: 66, Loss: 1.0338704586029053, Accuracy: 0.6787109375\n",
      "Batch: 67, Loss: 1.1407749652862549, Accuracy: 0.6416015625\n",
      "Batch: 68, Loss: 1.1657304763793945, Accuracy: 0.638671875\n",
      "Batch: 69, Loss: 1.111377239227295, Accuracy: 0.654296875\n",
      "Batch: 70, Loss: 1.0626189708709717, Accuracy: 0.681640625\n",
      "Batch: 71, Loss: 1.1035566329956055, Accuracy: 0.6484375\n",
      "Batch: 72, Loss: 0.9755525588989258, Accuracy: 0.6875\n",
      "Batch: 73, Loss: 1.0498161315917969, Accuracy: 0.68359375\n",
      "Batch: 74, Loss: 1.0204534530639648, Accuracy: 0.6767578125\n",
      "Batch: 75, Loss: 0.9935292601585388, Accuracy: 0.6796875\n",
      "Batch: 76, Loss: 1.0999958515167236, Accuracy: 0.63671875\n",
      "Batch: 77, Loss: 1.0810197591781616, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.0313770771026611, Accuracy: 0.6943359375\n",
      "Batch: 79, Loss: 0.9343215823173523, Accuracy: 0.71875\n",
      "Batch: 80, Loss: 0.9858742952346802, Accuracy: 0.6650390625\n",
      "Batch: 81, Loss: 1.1354472637176514, Accuracy: 0.6083984375\n",
      "Batch: 85, Loss: 0.976391613483429, Accuracy: 0.7001953125\n",
      "Batch: 86, Loss: 1.2324738502502441, Accuracy: 0.6171875\n",
      "Batch: 87, Loss: 1.0065425634384155, Accuracy: 0.6806640625\n",
      "Batch: 88, Loss: 1.1167815923690796, Accuracy: 0.65234375\n",
      "Batch: 89, Loss: 1.1213359832763672, Accuracy: 0.6533203125\n",
      "Batch: 90, Loss: 0.9874686598777771, Accuracy: 0.6826171875\n",
      "Batch: 91, Loss: 1.0423924922943115, Accuracy: 0.6640625\n",
      "Batch: 92, Loss: 1.0933082103729248, Accuracy: 0.6513671875\n",
      "Batch: 93, Loss: 1.0468811988830566, Accuracy: 0.658203125\n",
      "Batch: 94, Loss: 1.0362389087677002, Accuracy: 0.6533203125\n",
      "Batch: 95, Loss: 1.100235104560852, Accuracy: 0.630859375\n",
      "Batch: 96, Loss: 1.0215587615966797, Accuracy: 0.6806640625\n",
      "Batch: 97, Loss: 0.9003013372421265, Accuracy: 0.7119140625\n",
      "Batch: 98, Loss: 0.9537946581840515, Accuracy: 0.705078125\n",
      "Batch: 99, Loss: 0.9833778738975525, Accuracy: 0.693359375\n",
      "Batch: 100, Loss: 1.0401357412338257, Accuracy: 0.677734375\n",
      "Batch: 101, Loss: 1.136705994606018, Accuracy: 0.64453125\n",
      "Batch: 102, Loss: 1.0369524955749512, Accuracy: 0.6650390625\n",
      "Batch: 103, Loss: 1.1313068866729736, Accuracy: 0.66015625\n",
      "Batch: 104, Loss: 0.9892765283584595, Accuracy: 0.6728515625\n",
      "Batch: 105, Loss: 1.0963289737701416, Accuracy: 0.6572265625\n",
      "Batch: 106, Loss: 1.0800336599349976, Accuracy: 0.66015625\n",
      "Batch: 107, Loss: 1.1754497289657593, Accuracy: 0.6376953125\n",
      "Batch: 108, Loss: 1.1081104278564453, Accuracy: 0.6435546875\n",
      "Batch: 109, Loss: 1.225656509399414, Accuracy: 0.5947265625\n",
      "Batch: 110, Loss: 0.9060378670692444, Accuracy: 0.7158203125\n",
      "Batch: 111, Loss: 1.0789525508880615, Accuracy: 0.6474609375\n",
      "Batch: 112, Loss: 1.0585453510284424, Accuracy: 0.6796875\n",
      "Batch: 113, Loss: 1.0610308647155762, Accuracy: 0.66796875\n",
      "Batch: 114, Loss: 1.188328742980957, Accuracy: 0.615234375\n",
      "Batch: 115, Loss: 1.2211458683013916, Accuracy: 0.62890625\n",
      "Batch: 116, Loss: 1.1577296257019043, Accuracy: 0.642578125\n",
      "Batch: 117, Loss: 1.1627187728881836, Accuracy: 0.646484375\n",
      "Batch: 118, Loss: 0.938060462474823, Accuracy: 0.6943359375\n",
      "Batch: 119, Loss: 0.9661612510681152, Accuracy: 0.6904296875\n",
      "Batch: 120, Loss: 1.1164568662643433, Accuracy: 0.638671875\n",
      "Batch: 121, Loss: 1.1437218189239502, Accuracy: 0.64453125\n",
      "Batch: 122, Loss: 1.0077879428863525, Accuracy: 0.685546875\n",
      "Batch: 123, Loss: 1.0461394786834717, Accuracy: 0.662109375\n",
      "Batch: 124, Loss: 1.080367088317871, Accuracy: 0.646484375\n",
      "Batch: 125, Loss: 1.1192433834075928, Accuracy: 0.6416015625\n",
      "Batch: 126, Loss: 1.109865427017212, Accuracy: 0.6337890625\n",
      "Batch: 128, Loss: 1.1980042457580566, Accuracy: 0.6435546875\n",
      "Batch: 129, Loss: 1.0169800519943237, Accuracy: 0.6796875\n",
      "Batch: 130, Loss: 1.2961052656173706, Accuracy: 0.5849609375\n",
      "Batch: 131, Loss: 1.1261990070343018, Accuracy: 0.6298828125\n",
      "Batch: 132, Loss: 1.1608511209487915, Accuracy: 0.634765625\n",
      "Batch: 133, Loss: 1.0124506950378418, Accuracy: 0.6552734375\n",
      "Batch: 134, Loss: 1.1023098230361938, Accuracy: 0.6396484375\n",
      "Batch: 135, Loss: 0.9801640510559082, Accuracy: 0.7060546875\n",
      "Batch: 136, Loss: 1.0679500102996826, Accuracy: 0.6669921875\n",
      "Batch: 137, Loss: 0.998136579990387, Accuracy: 0.6669921875\n",
      "Batch: 138, Loss: 0.9176321625709534, Accuracy: 0.705078125\n",
      "Batch: 139, Loss: 0.9538495540618896, Accuracy: 0.6806640625\n",
      "Batch: 140, Loss: 1.0313479900360107, Accuracy: 0.6533203125\n",
      "Batch: 141, Loss: 1.0996158123016357, Accuracy: 0.6396484375\n",
      "Batch: 142, Loss: 1.130125641822815, Accuracy: 0.62890625\n",
      "Batch: 143, Loss: 1.080620288848877, Accuracy: 0.6630859375\n",
      "Batch: 144, Loss: 1.0795978307724, Accuracy: 0.662109375\n",
      "Batch: 145, Loss: 1.0222976207733154, Accuracy: 0.654296875\n",
      "Batch: 146, Loss: 1.1226478815078735, Accuracy: 0.6396484375\n",
      "Batch: 147, Loss: 1.1129895448684692, Accuracy: 0.6396484375\n",
      "Batch: 148, Loss: 1.2339506149291992, Accuracy: 0.6015625\n",
      "Batch: 149, Loss: 1.07703697681427, Accuracy: 0.6435546875\n",
      "Batch: 150, Loss: 1.0279998779296875, Accuracy: 0.6572265625\n",
      "Batch: 151, Loss: 0.9573043584823608, Accuracy: 0.689453125\n",
      "Epoch 17/80\n",
      "Batch: 1, Loss: 1.3217612504959106, Accuracy: 0.580078125\n",
      "Batch: 2, Loss: 1.1134557723999023, Accuracy: 0.623046875\n",
      "Batch: 3, Loss: 1.035355567932129, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 0.9651447534561157, Accuracy: 0.6845703125\n",
      "Batch: 5, Loss: 0.9895342588424683, Accuracy: 0.693359375\n",
      "Batch: 6, Loss: 1.0803442001342773, Accuracy: 0.6328125\n",
      "Batch: 7, Loss: 1.036570429801941, Accuracy: 0.658203125\n",
      "Batch: 8, Loss: 0.9634513854980469, Accuracy: 0.673828125\n",
      "Batch: 9, Loss: 0.9445610642433167, Accuracy: 0.7060546875\n",
      "Batch: 10, Loss: 0.9837926626205444, Accuracy: 0.6767578125\n",
      "Batch: 11, Loss: 1.1426475048065186, Accuracy: 0.6201171875\n",
      "Batch: 12, Loss: 1.146316409111023, Accuracy: 0.6240234375\n",
      "Batch: 13, Loss: 0.9123668074607849, Accuracy: 0.7138671875\n",
      "Batch: 14, Loss: 1.1488800048828125, Accuracy: 0.62109375\n",
      "Batch: 15, Loss: 0.9963564872741699, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 1.0135259628295898, Accuracy: 0.6826171875\n",
      "Batch: 17, Loss: 1.0963835716247559, Accuracy: 0.6494140625\n",
      "Batch: 18, Loss: 1.0760633945465088, Accuracy: 0.6513671875\n",
      "Batch: 19, Loss: 1.1070061922073364, Accuracy: 0.65234375\n",
      "Batch: 20, Loss: 0.989042341709137, Accuracy: 0.6953125\n",
      "Batch: 21, Loss: 0.9911485314369202, Accuracy: 0.6796875\n",
      "Batch: 22, Loss: 1.1176763772964478, Accuracy: 0.65625\n",
      "Batch: 23, Loss: 1.0476781129837036, Accuracy: 0.6572265625\n",
      "Batch: 24, Loss: 1.090387225151062, Accuracy: 0.6455078125\n",
      "Batch: 25, Loss: 1.0542356967926025, Accuracy: 0.6728515625\n",
      "Batch: 26, Loss: 0.9311453104019165, Accuracy: 0.703125\n",
      "Batch: 27, Loss: 1.0052032470703125, Accuracy: 0.6552734375\n",
      "Batch: 28, Loss: 1.1294474601745605, Accuracy: 0.62890625\n",
      "Batch: 29, Loss: 1.0661674737930298, Accuracy: 0.6552734375\n",
      "Batch: 30, Loss: 1.017756700515747, Accuracy: 0.6796875\n",
      "Batch: 31, Loss: 0.9590134620666504, Accuracy: 0.6923828125\n",
      "Batch: 32, Loss: 0.955926775932312, Accuracy: 0.693359375\n",
      "Batch: 33, Loss: 1.1687885522842407, Accuracy: 0.6279296875\n",
      "Batch: 34, Loss: 1.2132858037948608, Accuracy: 0.603515625\n",
      "Batch: 35, Loss: 1.151107668876648, Accuracy: 0.6357421875\n",
      "Batch: 36, Loss: 1.1172267198562622, Accuracy: 0.65625\n",
      "Batch: 37, Loss: 1.0758150815963745, Accuracy: 0.66015625\n",
      "Batch: 38, Loss: 1.0800813436508179, Accuracy: 0.66015625\n",
      "Batch: 39, Loss: 1.085557222366333, Accuracy: 0.65625\n",
      "Batch: 40, Loss: 1.0903995037078857, Accuracy: 0.669921875\n",
      "Batch: 41, Loss: 1.0536067485809326, Accuracy: 0.671875\n",
      "Batch: 42, Loss: 0.86031174659729, Accuracy: 0.7109375\n",
      "Batch: 43, Loss: 1.0564754009246826, Accuracy: 0.650390625\n",
      "Batch: 44, Loss: 1.0622837543487549, Accuracy: 0.65625\n",
      "Batch: 45, Loss: 0.9275195598602295, Accuracy: 0.6884765625\n",
      "Batch: 46, Loss: 1.0345854759216309, Accuracy: 0.669921875\n",
      "Batch: 47, Loss: 1.0690312385559082, Accuracy: 0.65625\n",
      "Batch: 48, Loss: 0.9584466218948364, Accuracy: 0.6923828125\n",
      "Batch: 49, Loss: 1.1459964513778687, Accuracy: 0.6220703125\n",
      "Batch: 50, Loss: 1.1388180255889893, Accuracy: 0.634765625\n",
      "Batch: 51, Loss: 1.180030107498169, Accuracy: 0.62109375\n",
      "Batch: 52, Loss: 1.1646488904953003, Accuracy: 0.638671875\n",
      "Batch: 53, Loss: 0.9734224081039429, Accuracy: 0.6708984375\n",
      "Batch: 54, Loss: 1.057788372039795, Accuracy: 0.6728515625\n",
      "Batch: 55, Loss: 1.123792290687561, Accuracy: 0.6328125\n",
      "Batch: 56, Loss: 1.124121069908142, Accuracy: 0.6533203125\n",
      "Batch: 57, Loss: 1.0606400966644287, Accuracy: 0.6552734375\n",
      "Batch: 58, Loss: 1.1588153839111328, Accuracy: 0.66015625\n",
      "Batch: 59, Loss: 0.95561283826828, Accuracy: 0.7119140625\n",
      "Batch: 60, Loss: 0.9694004058837891, Accuracy: 0.6826171875\n",
      "Batch: 61, Loss: 1.0987740755081177, Accuracy: 0.662109375\n",
      "Batch: 62, Loss: 1.0701894760131836, Accuracy: 0.662109375\n",
      "Batch: 63, Loss: 1.0945466756820679, Accuracy: 0.6474609375\n",
      "Batch: 64, Loss: 1.0450857877731323, Accuracy: 0.6708984375\n",
      "Batch: 65, Loss: 1.091594934463501, Accuracy: 0.6494140625\n",
      "Batch: 66, Loss: 1.0464106798171997, Accuracy: 0.669921875\n",
      "Batch: 67, Loss: 1.1297221183776855, Accuracy: 0.6494140625\n",
      "Batch: 68, Loss: 1.1262915134429932, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 1.0952401161193848, Accuracy: 0.6455078125\n",
      "Batch: 72, Loss: 0.9551745653152466, Accuracy: 0.689453125\n",
      "Batch: 73, Loss: 1.0107312202453613, Accuracy: 0.6787109375\n",
      "Batch: 74, Loss: 0.9714182615280151, Accuracy: 0.685546875\n",
      "Batch: 75, Loss: 0.9665066003799438, Accuracy: 0.689453125\n",
      "Batch: 76, Loss: 1.059220314025879, Accuracy: 0.6474609375\n",
      "Batch: 77, Loss: 1.067848801612854, Accuracy: 0.6630859375\n",
      "Batch: 78, Loss: 1.0325912237167358, Accuracy: 0.69140625\n",
      "Batch: 79, Loss: 0.9588042497634888, Accuracy: 0.716796875\n",
      "Batch: 80, Loss: 0.9798457622528076, Accuracy: 0.666015625\n",
      "Batch: 81, Loss: 1.1331830024719238, Accuracy: 0.6162109375\n",
      "Batch: 82, Loss: 1.1079177856445312, Accuracy: 0.6455078125\n",
      "Batch: 83, Loss: 0.934939980506897, Accuracy: 0.701171875\n",
      "Batch: 84, Loss: 1.043771505355835, Accuracy: 0.6904296875\n",
      "Batch: 85, Loss: 0.9592928886413574, Accuracy: 0.697265625\n",
      "Batch: 86, Loss: 1.2137706279754639, Accuracy: 0.6083984375\n",
      "Batch: 87, Loss: 0.9877811670303345, Accuracy: 0.693359375\n",
      "Batch: 88, Loss: 1.1006230115890503, Accuracy: 0.6474609375\n",
      "Batch: 89, Loss: 1.102933645248413, Accuracy: 0.6474609375\n",
      "Batch: 90, Loss: 0.9971987009048462, Accuracy: 0.677734375\n",
      "Batch: 91, Loss: 1.018617868423462, Accuracy: 0.6787109375\n",
      "Batch: 92, Loss: 1.0653513669967651, Accuracy: 0.6435546875\n",
      "Batch: 93, Loss: 1.0253288745880127, Accuracy: 0.6748046875\n",
      "Batch: 94, Loss: 1.0260075330734253, Accuracy: 0.66015625\n",
      "Batch: 95, Loss: 1.0536487102508545, Accuracy: 0.6533203125\n",
      "Batch: 96, Loss: 1.0136113166809082, Accuracy: 0.6728515625\n",
      "Batch: 97, Loss: 0.8926994204521179, Accuracy: 0.7021484375\n",
      "Batch: 98, Loss: 0.9344356656074524, Accuracy: 0.7138671875\n",
      "Batch: 99, Loss: 0.972432017326355, Accuracy: 0.6962890625\n",
      "Batch: 100, Loss: 1.0137428045272827, Accuracy: 0.6875\n",
      "Batch: 101, Loss: 1.121985673904419, Accuracy: 0.650390625\n",
      "Batch: 102, Loss: 1.019789457321167, Accuracy: 0.67578125\n",
      "Batch: 103, Loss: 1.0589711666107178, Accuracy: 0.6806640625\n",
      "Batch: 104, Loss: 0.9639894962310791, Accuracy: 0.681640625\n",
      "Batch: 105, Loss: 1.0626386404037476, Accuracy: 0.6630859375\n",
      "Batch: 106, Loss: 1.059929370880127, Accuracy: 0.66796875\n",
      "Batch: 107, Loss: 1.1280088424682617, Accuracy: 0.6435546875\n",
      "Batch: 108, Loss: 1.1011873483657837, Accuracy: 0.6298828125\n",
      "Batch: 109, Loss: 1.2288362979888916, Accuracy: 0.615234375\n",
      "Batch: 110, Loss: 0.8780053853988647, Accuracy: 0.708984375\n",
      "Batch: 111, Loss: 1.09092116355896, Accuracy: 0.642578125\n",
      "Batch: 112, Loss: 1.0627379417419434, Accuracy: 0.673828125\n",
      "Batch: 113, Loss: 1.0610300302505493, Accuracy: 0.67578125\n",
      "Batch: 114, Loss: 1.18813157081604, Accuracy: 0.634765625\n",
      "Batch: 115, Loss: 1.2154232263565063, Accuracy: 0.6220703125\n",
      "Batch: 116, Loss: 1.116994023323059, Accuracy: 0.6435546875\n",
      "Batch: 117, Loss: 1.1600984334945679, Accuracy: 0.63671875\n",
      "Batch: 118, Loss: 0.9248723983764648, Accuracy: 0.7021484375\n",
      "Batch: 119, Loss: 0.9389224648475647, Accuracy: 0.7109375\n",
      "Batch: 120, Loss: 1.1232213973999023, Accuracy: 0.6533203125\n",
      "Batch: 121, Loss: 1.1352264881134033, Accuracy: 0.66015625\n",
      "Batch: 122, Loss: 1.0222806930541992, Accuracy: 0.6787109375\n",
      "Batch: 123, Loss: 1.0323641300201416, Accuracy: 0.673828125\n",
      "Batch: 124, Loss: 1.0554020404815674, Accuracy: 0.6591796875\n",
      "Batch: 125, Loss: 1.1004951000213623, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.1149272918701172, Accuracy: 0.6513671875\n",
      "Batch: 127, Loss: 0.960484504699707, Accuracy: 0.7109375\n",
      "Batch: 128, Loss: 1.1739062070846558, Accuracy: 0.6533203125\n",
      "Batch: 129, Loss: 0.9693388342857361, Accuracy: 0.6884765625\n",
      "Batch: 130, Loss: 1.2279977798461914, Accuracy: 0.6083984375\n",
      "Batch: 131, Loss: 1.1088721752166748, Accuracy: 0.6376953125\n",
      "Batch: 132, Loss: 1.1294567584991455, Accuracy: 0.6455078125\n",
      "Batch: 133, Loss: 0.9783018827438354, Accuracy: 0.673828125\n",
      "Batch: 134, Loss: 1.0869710445404053, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 0.9762540459632874, Accuracy: 0.7041015625\n",
      "Batch: 136, Loss: 1.0377435684204102, Accuracy: 0.6748046875\n",
      "Batch: 137, Loss: 0.9904694557189941, Accuracy: 0.66796875\n",
      "Batch: 138, Loss: 0.887576699256897, Accuracy: 0.705078125\n",
      "Batch: 139, Loss: 0.9467864036560059, Accuracy: 0.67578125\n",
      "Batch: 140, Loss: 1.01841402053833, Accuracy: 0.66796875\n",
      "Batch: 141, Loss: 1.0788319110870361, Accuracy: 0.6640625\n",
      "Batch: 142, Loss: 1.1259799003601074, Accuracy: 0.640625\n",
      "Batch: 143, Loss: 1.0584571361541748, Accuracy: 0.65625\n",
      "Batch: 144, Loss: 1.0315074920654297, Accuracy: 0.671875\n",
      "Batch: 145, Loss: 0.9780691266059875, Accuracy: 0.673828125\n",
      "Batch: 146, Loss: 1.108931064605713, Accuracy: 0.6396484375\n",
      "Batch: 147, Loss: 1.0836024284362793, Accuracy: 0.64453125\n",
      "Batch: 148, Loss: 1.2114710807800293, Accuracy: 0.5859375\n",
      "Batch: 149, Loss: 1.0515092611312866, Accuracy: 0.66796875\n",
      "Batch: 150, Loss: 1.003391981124878, Accuracy: 0.673828125\n",
      "Batch: 151, Loss: 0.9278836846351624, Accuracy: 0.703125\n",
      "Epoch 18/80\n",
      "Batch: 1, Loss: 1.30873441696167, Accuracy: 0.564453125\n",
      "Batch: 2, Loss: 1.1127381324768066, Accuracy: 0.642578125\n",
      "Batch: 3, Loss: 0.9855684041976929, Accuracy: 0.6748046875\n",
      "Batch: 4, Loss: 0.939668595790863, Accuracy: 0.697265625\n",
      "Batch: 5, Loss: 0.9670968055725098, Accuracy: 0.6962890625\n",
      "Batch: 6, Loss: 1.0644042491912842, Accuracy: 0.6376953125\n",
      "Batch: 7, Loss: 1.0217647552490234, Accuracy: 0.65234375\n",
      "Batch: 10, Loss: 0.9596359729766846, Accuracy: 0.6787109375\n",
      "Batch: 11, Loss: 1.1313631534576416, Accuracy: 0.625\n",
      "Batch: 12, Loss: 1.1333916187286377, Accuracy: 0.6376953125\n",
      "Batch: 13, Loss: 0.8879284858703613, Accuracy: 0.716796875\n",
      "Batch: 14, Loss: 1.130438208580017, Accuracy: 0.638671875\n",
      "Batch: 15, Loss: 0.976703941822052, Accuracy: 0.6904296875\n",
      "Batch: 16, Loss: 0.9881761074066162, Accuracy: 0.6953125\n",
      "Batch: 17, Loss: 1.0975492000579834, Accuracy: 0.640625\n",
      "Batch: 18, Loss: 1.0686485767364502, Accuracy: 0.646484375\n",
      "Batch: 19, Loss: 1.0970022678375244, Accuracy: 0.662109375\n",
      "Batch: 20, Loss: 0.9702650904655457, Accuracy: 0.69140625\n",
      "Batch: 21, Loss: 0.9924579858779907, Accuracy: 0.6787109375\n",
      "Batch: 22, Loss: 1.1111328601837158, Accuracy: 0.64453125\n",
      "Batch: 23, Loss: 1.0107766389846802, Accuracy: 0.6640625\n",
      "Batch: 24, Loss: 1.0777958631515503, Accuracy: 0.6494140625\n",
      "Batch: 25, Loss: 1.0447261333465576, Accuracy: 0.646484375\n",
      "Batch: 26, Loss: 0.9176451563835144, Accuracy: 0.7041015625\n",
      "Batch: 27, Loss: 0.9886350631713867, Accuracy: 0.6708984375\n",
      "Batch: 28, Loss: 1.0621968507766724, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 1.0227339267730713, Accuracy: 0.6767578125\n",
      "Batch: 30, Loss: 0.9799787998199463, Accuracy: 0.6806640625\n",
      "Batch: 31, Loss: 0.9664772748947144, Accuracy: 0.69921875\n",
      "Batch: 32, Loss: 0.9528807401657104, Accuracy: 0.6748046875\n",
      "Batch: 33, Loss: 1.1267333030700684, Accuracy: 0.6494140625\n",
      "Batch: 34, Loss: 1.1825246810913086, Accuracy: 0.625\n",
      "Batch: 35, Loss: 1.1080354452133179, Accuracy: 0.6318359375\n",
      "Batch: 36, Loss: 1.1047366857528687, Accuracy: 0.658203125\n",
      "Batch: 37, Loss: 1.0440362691879272, Accuracy: 0.6630859375\n",
      "Batch: 38, Loss: 1.0592272281646729, Accuracy: 0.640625\n",
      "Batch: 39, Loss: 1.0866494178771973, Accuracy: 0.671875\n",
      "Batch: 40, Loss: 1.081533432006836, Accuracy: 0.6650390625\n",
      "Batch: 41, Loss: 1.028290033340454, Accuracy: 0.669921875\n",
      "Batch: 42, Loss: 0.8601027727127075, Accuracy: 0.7138671875\n",
      "Batch: 43, Loss: 1.0861670970916748, Accuracy: 0.6513671875\n",
      "Batch: 44, Loss: 1.0407016277313232, Accuracy: 0.6396484375\n",
      "Batch: 45, Loss: 0.9053418636322021, Accuracy: 0.6943359375\n",
      "Batch: 46, Loss: 1.0210598707199097, Accuracy: 0.6748046875\n",
      "Batch: 47, Loss: 1.0310242176055908, Accuracy: 0.689453125\n",
      "Batch: 48, Loss: 0.9443355798721313, Accuracy: 0.703125\n",
      "Batch: 49, Loss: 1.1433851718902588, Accuracy: 0.6279296875\n",
      "Batch: 50, Loss: 1.1132214069366455, Accuracy: 0.6484375\n",
      "Batch: 51, Loss: 1.1909480094909668, Accuracy: 0.623046875\n",
      "Batch: 52, Loss: 1.1237736940383911, Accuracy: 0.6494140625\n",
      "Batch: 53, Loss: 0.9915375113487244, Accuracy: 0.6630859375\n",
      "Batch: 54, Loss: 1.0282611846923828, Accuracy: 0.673828125\n",
      "Batch: 55, Loss: 1.1068023443222046, Accuracy: 0.6357421875\n",
      "Batch: 56, Loss: 1.1013174057006836, Accuracy: 0.650390625\n",
      "Batch: 59, Loss: 0.9553557634353638, Accuracy: 0.693359375\n",
      "Batch: 60, Loss: 0.9635745286941528, Accuracy: 0.693359375\n",
      "Batch: 61, Loss: 1.0637271404266357, Accuracy: 0.6455078125\n",
      "Batch: 62, Loss: 1.0399869680404663, Accuracy: 0.6572265625\n",
      "Batch: 63, Loss: 1.0779063701629639, Accuracy: 0.6494140625\n",
      "Batch: 64, Loss: 1.025752305984497, Accuracy: 0.6875\n",
      "Batch: 65, Loss: 1.0925335884094238, Accuracy: 0.6572265625\n",
      "Batch: 66, Loss: 1.0201746225357056, Accuracy: 0.6708984375\n",
      "Batch: 67, Loss: 1.093217372894287, Accuracy: 0.6552734375\n",
      "Batch: 68, Loss: 1.1200945377349854, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 1.0646042823791504, Accuracy: 0.6533203125\n",
      "Batch: 70, Loss: 1.0392403602600098, Accuracy: 0.69140625\n",
      "Batch: 71, Loss: 1.0790143013000488, Accuracy: 0.6591796875\n",
      "Batch: 72, Loss: 0.9534661769866943, Accuracy: 0.693359375\n",
      "Batch: 73, Loss: 0.9864711761474609, Accuracy: 0.697265625\n",
      "Batch: 74, Loss: 0.9826005697250366, Accuracy: 0.7001953125\n",
      "Batch: 75, Loss: 0.9493569135665894, Accuracy: 0.6953125\n",
      "Batch: 76, Loss: 1.0470678806304932, Accuracy: 0.654296875\n",
      "Batch: 77, Loss: 1.0421736240386963, Accuracy: 0.677734375\n",
      "Batch: 78, Loss: 0.999051034450531, Accuracy: 0.6904296875\n",
      "Batch: 79, Loss: 0.9280850887298584, Accuracy: 0.7177734375\n",
      "Batch: 80, Loss: 0.9782060384750366, Accuracy: 0.6650390625\n",
      "Batch: 81, Loss: 1.093362808227539, Accuracy: 0.6171875\n",
      "Batch: 82, Loss: 1.046454906463623, Accuracy: 0.65625\n",
      "Batch: 83, Loss: 0.9092154502868652, Accuracy: 0.7255859375\n",
      "Batch: 84, Loss: 0.9928122162818909, Accuracy: 0.6923828125\n",
      "Batch: 85, Loss: 0.9533655047416687, Accuracy: 0.712890625\n",
      "Batch: 86, Loss: 1.1904780864715576, Accuracy: 0.6201171875\n",
      "Batch: 87, Loss: 0.9779751896858215, Accuracy: 0.689453125\n",
      "Batch: 88, Loss: 1.0744136571884155, Accuracy: 0.673828125\n",
      "Batch: 89, Loss: 1.066115379333496, Accuracy: 0.6591796875\n",
      "Batch: 90, Loss: 0.9686861634254456, Accuracy: 0.689453125\n",
      "Batch: 91, Loss: 1.036688208580017, Accuracy: 0.666015625\n",
      "Batch: 92, Loss: 1.036856770515442, Accuracy: 0.6650390625\n",
      "Batch: 93, Loss: 1.013596534729004, Accuracy: 0.685546875\n",
      "Batch: 94, Loss: 1.02754807472229, Accuracy: 0.65625\n",
      "Batch: 95, Loss: 1.0524630546569824, Accuracy: 0.6416015625\n",
      "Batch: 96, Loss: 1.0106143951416016, Accuracy: 0.6728515625\n",
      "Batch: 97, Loss: 0.8745765089988708, Accuracy: 0.71484375\n",
      "Batch: 98, Loss: 0.925915002822876, Accuracy: 0.712890625\n",
      "Batch: 99, Loss: 0.9489150047302246, Accuracy: 0.697265625\n",
      "Batch: 100, Loss: 1.0076849460601807, Accuracy: 0.693359375\n",
      "Batch: 101, Loss: 1.0798625946044922, Accuracy: 0.6572265625\n",
      "Batch: 102, Loss: 0.9883209466934204, Accuracy: 0.68359375\n",
      "Batch: 103, Loss: 1.0811246633529663, Accuracy: 0.6650390625\n",
      "Batch: 104, Loss: 0.9590785503387451, Accuracy: 0.689453125\n",
      "Batch: 105, Loss: 1.0631978511810303, Accuracy: 0.65625\n",
      "Batch: 106, Loss: 1.0225038528442383, Accuracy: 0.6806640625\n",
      "Batch: 107, Loss: 1.1170432567596436, Accuracy: 0.6513671875\n",
      "Batch: 108, Loss: 1.0849151611328125, Accuracy: 0.640625\n",
      "Batch: 109, Loss: 1.1899381875991821, Accuracy: 0.6171875\n",
      "Batch: 110, Loss: 0.8898781538009644, Accuracy: 0.71484375\n",
      "Batch: 111, Loss: 1.049980878829956, Accuracy: 0.6484375\n",
      "Batch: 112, Loss: 1.0339462757110596, Accuracy: 0.6708984375\n",
      "Batch: 113, Loss: 1.0420100688934326, Accuracy: 0.6669921875\n",
      "Batch: 114, Loss: 1.1642472743988037, Accuracy: 0.6240234375\n",
      "Batch: 115, Loss: 1.1854286193847656, Accuracy: 0.6416015625\n",
      "Batch: 116, Loss: 1.1103583574295044, Accuracy: 0.6611328125\n",
      "Batch: 117, Loss: 1.1024138927459717, Accuracy: 0.6552734375\n",
      "Batch: 118, Loss: 0.9169434905052185, Accuracy: 0.705078125\n",
      "Batch: 119, Loss: 0.9280107021331787, Accuracy: 0.697265625\n",
      "Batch: 120, Loss: 1.1068410873413086, Accuracy: 0.6435546875\n",
      "Batch: 121, Loss: 1.1038322448730469, Accuracy: 0.646484375\n",
      "Batch: 122, Loss: 0.9999607801437378, Accuracy: 0.67578125\n",
      "Batch: 123, Loss: 0.9948179125785828, Accuracy: 0.6787109375\n",
      "Batch: 124, Loss: 1.0427064895629883, Accuracy: 0.65625\n",
      "Batch: 125, Loss: 1.107826590538025, Accuracy: 0.65234375\n",
      "Batch: 126, Loss: 1.065581202507019, Accuracy: 0.666015625\n",
      "Batch: 127, Loss: 0.9548429250717163, Accuracy: 0.70703125\n",
      "Batch: 128, Loss: 1.1848115921020508, Accuracy: 0.626953125\n",
      "Batch: 129, Loss: 0.981655478477478, Accuracy: 0.6943359375\n",
      "Batch: 130, Loss: 1.2100828886032104, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.0950042009353638, Accuracy: 0.6455078125\n",
      "Batch: 132, Loss: 1.0996365547180176, Accuracy: 0.650390625\n",
      "Batch: 133, Loss: 0.9954214096069336, Accuracy: 0.658203125\n",
      "Batch: 134, Loss: 1.0706143379211426, Accuracy: 0.6455078125\n",
      "Batch: 135, Loss: 0.9575853943824768, Accuracy: 0.6982421875\n",
      "Batch: 136, Loss: 1.0254088640213013, Accuracy: 0.677734375\n",
      "Batch: 137, Loss: 0.9890300035476685, Accuracy: 0.6611328125\n",
      "Batch: 138, Loss: 0.872309148311615, Accuracy: 0.71484375\n",
      "Batch: 139, Loss: 0.9658207893371582, Accuracy: 0.6708984375\n",
      "Batch: 140, Loss: 1.015406847000122, Accuracy: 0.6533203125\n",
      "Batch: 141, Loss: 1.0323615074157715, Accuracy: 0.666015625\n",
      "Batch: 142, Loss: 1.122929334640503, Accuracy: 0.6416015625\n",
      "Batch: 143, Loss: 1.0370022058486938, Accuracy: 0.6640625\n",
      "Batch: 144, Loss: 1.0581748485565186, Accuracy: 0.65625\n",
      "Batch: 145, Loss: 0.9796760678291321, Accuracy: 0.673828125\n",
      "Batch: 146, Loss: 1.104546308517456, Accuracy: 0.642578125\n",
      "Batch: 147, Loss: 1.070361614227295, Accuracy: 0.6494140625\n",
      "Batch: 148, Loss: 1.192293405532837, Accuracy: 0.6083984375\n",
      "Batch: 149, Loss: 1.042952060699463, Accuracy: 0.66015625\n",
      "Batch: 150, Loss: 1.0062592029571533, Accuracy: 0.681640625\n",
      "Batch: 151, Loss: 0.9175868034362793, Accuracy: 0.708984375\n",
      "Epoch 19/80\n",
      "Batch: 1, Loss: 1.2957379817962646, Accuracy: 0.580078125\n",
      "Batch: 2, Loss: 1.0748056173324585, Accuracy: 0.6455078125\n",
      "Batch: 3, Loss: 0.9886559247970581, Accuracy: 0.6708984375\n",
      "Batch: 4, Loss: 0.9400351643562317, Accuracy: 0.7158203125\n",
      "Batch: 5, Loss: 0.9715000987052917, Accuracy: 0.6904296875\n",
      "Batch: 6, Loss: 1.0655267238616943, Accuracy: 0.6435546875\n",
      "Batch: 7, Loss: 1.007983684539795, Accuracy: 0.6591796875\n",
      "Batch: 8, Loss: 0.9524672031402588, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 0.9205744862556458, Accuracy: 0.7080078125\n",
      "Batch: 10, Loss: 0.9450504779815674, Accuracy: 0.6904296875\n",
      "Batch: 11, Loss: 1.0988777875900269, Accuracy: 0.6337890625\n",
      "Batch: 12, Loss: 1.1059319972991943, Accuracy: 0.640625\n",
      "Batch: 13, Loss: 0.8901972770690918, Accuracy: 0.7138671875\n",
      "Batch: 14, Loss: 1.1148154735565186, Accuracy: 0.6318359375\n",
      "Batch: 15, Loss: 0.9747796058654785, Accuracy: 0.69921875\n",
      "Batch: 16, Loss: 0.9964958429336548, Accuracy: 0.7001953125\n",
      "Batch: 17, Loss: 1.0646417140960693, Accuracy: 0.6591796875\n",
      "Batch: 18, Loss: 1.056997537612915, Accuracy: 0.6533203125\n",
      "Batch: 19, Loss: 1.0850934982299805, Accuracy: 0.66015625\n",
      "Batch: 20, Loss: 0.949691891670227, Accuracy: 0.69921875\n",
      "Batch: 21, Loss: 0.9880760908126831, Accuracy: 0.6767578125\n",
      "Batch: 22, Loss: 1.1150456666946411, Accuracy: 0.6591796875\n",
      "Batch: 23, Loss: 1.008935570716858, Accuracy: 0.6591796875\n",
      "Batch: 24, Loss: 1.0542443990707397, Accuracy: 0.654296875\n",
      "Batch: 25, Loss: 1.0079526901245117, Accuracy: 0.673828125\n",
      "Batch: 26, Loss: 0.907611608505249, Accuracy: 0.7060546875\n",
      "Batch: 27, Loss: 0.9639836549758911, Accuracy: 0.6796875\n",
      "Batch: 28, Loss: 1.05355703830719, Accuracy: 0.6513671875\n",
      "Batch: 29, Loss: 0.9975916743278503, Accuracy: 0.6748046875\n",
      "Batch: 30, Loss: 0.9841635227203369, Accuracy: 0.693359375\n",
      "Batch: 31, Loss: 0.93061763048172, Accuracy: 0.6943359375\n",
      "Batch: 32, Loss: 0.9391285181045532, Accuracy: 0.685546875\n",
      "Batch: 33, Loss: 1.1304858922958374, Accuracy: 0.642578125\n",
      "Batch: 34, Loss: 1.192853569984436, Accuracy: 0.6279296875\n",
      "Batch: 35, Loss: 1.08751380443573, Accuracy: 0.64453125\n",
      "Batch: 36, Loss: 1.0998786687850952, Accuracy: 0.6513671875\n",
      "Batch: 37, Loss: 1.0341463088989258, Accuracy: 0.6650390625\n",
      "Batch: 38, Loss: 1.0659356117248535, Accuracy: 0.6416015625\n",
      "Batch: 39, Loss: 1.0320037603378296, Accuracy: 0.6767578125\n",
      "Batch: 40, Loss: 1.0428236722946167, Accuracy: 0.6640625\n",
      "Batch: 41, Loss: 1.00504732131958, Accuracy: 0.6748046875\n",
      "Batch: 42, Loss: 0.832772970199585, Accuracy: 0.728515625\n",
      "Batch: 43, Loss: 1.0428247451782227, Accuracy: 0.6416015625\n",
      "Batch: 44, Loss: 1.0422992706298828, Accuracy: 0.6494140625\n",
      "Batch: 45, Loss: 0.9144354462623596, Accuracy: 0.6962890625\n",
      "Batch: 46, Loss: 1.0083484649658203, Accuracy: 0.6796875\n",
      "Batch: 47, Loss: 1.0071308612823486, Accuracy: 0.6884765625\n",
      "Batch: 50, Loss: 1.1190650463104248, Accuracy: 0.625\n",
      "Batch: 51, Loss: 1.1568275690078735, Accuracy: 0.6240234375\n",
      "Batch: 52, Loss: 1.1183223724365234, Accuracy: 0.6416015625\n",
      "Batch: 53, Loss: 0.9845457077026367, Accuracy: 0.66796875\n",
      "Batch: 54, Loss: 0.9985679984092712, Accuracy: 0.6806640625\n",
      "Batch: 55, Loss: 1.0990641117095947, Accuracy: 0.634765625\n",
      "Batch: 56, Loss: 1.0910637378692627, Accuracy: 0.6611328125\n",
      "Batch: 57, Loss: 1.046038031578064, Accuracy: 0.66015625\n",
      "Batch: 58, Loss: 1.1194944381713867, Accuracy: 0.6572265625\n",
      "Batch: 59, Loss: 0.9221317172050476, Accuracy: 0.712890625\n",
      "Batch: 60, Loss: 0.9481009244918823, Accuracy: 0.697265625\n",
      "Batch: 61, Loss: 1.0716254711151123, Accuracy: 0.65234375\n",
      "Batch: 62, Loss: 1.0282683372497559, Accuracy: 0.6845703125\n",
      "Batch: 63, Loss: 1.0760436058044434, Accuracy: 0.6533203125\n",
      "Batch: 64, Loss: 1.029681921005249, Accuracy: 0.681640625\n",
      "Batch: 65, Loss: 1.057132601737976, Accuracy: 0.6806640625\n",
      "Batch: 66, Loss: 0.9910821914672852, Accuracy: 0.693359375\n",
      "Batch: 67, Loss: 1.0888301134109497, Accuracy: 0.6513671875\n",
      "Batch: 68, Loss: 1.0962259769439697, Accuracy: 0.65234375\n",
      "Batch: 69, Loss: 1.0490391254425049, Accuracy: 0.6748046875\n",
      "Batch: 70, Loss: 1.0361039638519287, Accuracy: 0.6875\n",
      "Batch: 71, Loss: 1.061501145362854, Accuracy: 0.669921875\n",
      "Batch: 72, Loss: 0.9356369972229004, Accuracy: 0.6904296875\n",
      "Batch: 73, Loss: 0.9792615175247192, Accuracy: 0.69921875\n",
      "Batch: 74, Loss: 0.958735466003418, Accuracy: 0.69921875\n",
      "Batch: 75, Loss: 0.9441468119621277, Accuracy: 0.6904296875\n",
      "Batch: 76, Loss: 1.037015676498413, Accuracy: 0.6669921875\n",
      "Batch: 77, Loss: 1.0402119159698486, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.0019625425338745, Accuracy: 0.6982421875\n",
      "Batch: 79, Loss: 0.9165571928024292, Accuracy: 0.720703125\n",
      "Batch: 80, Loss: 0.9714908003807068, Accuracy: 0.66796875\n",
      "Batch: 81, Loss: 1.0901362895965576, Accuracy: 0.6328125\n",
      "Batch: 82, Loss: 1.049473524093628, Accuracy: 0.6494140625\n",
      "Batch: 83, Loss: 0.9124526381492615, Accuracy: 0.71875\n",
      "Batch: 84, Loss: 0.9641208052635193, Accuracy: 0.705078125\n",
      "Batch: 85, Loss: 0.9176899194717407, Accuracy: 0.708984375\n",
      "Batch: 86, Loss: 1.1910614967346191, Accuracy: 0.625\n",
      "Batch: 87, Loss: 0.9567902684211731, Accuracy: 0.7119140625\n",
      "Batch: 88, Loss: 1.073972463607788, Accuracy: 0.6630859375\n",
      "Batch: 89, Loss: 1.069753885269165, Accuracy: 0.6728515625\n",
      "Batch: 90, Loss: 0.9587916135787964, Accuracy: 0.6904296875\n",
      "Batch: 91, Loss: 1.0240654945373535, Accuracy: 0.6650390625\n",
      "Batch: 92, Loss: 1.0562996864318848, Accuracy: 0.66015625\n",
      "Batch: 93, Loss: 0.9995545744895935, Accuracy: 0.677734375\n",
      "Batch: 94, Loss: 1.0062710046768188, Accuracy: 0.6640625\n",
      "Batch: 97, Loss: 0.8473073244094849, Accuracy: 0.7236328125\n",
      "Batch: 98, Loss: 0.926101565361023, Accuracy: 0.6962890625\n",
      "Batch: 99, Loss: 0.9418760538101196, Accuracy: 0.701171875\n",
      "Batch: 100, Loss: 0.999418318271637, Accuracy: 0.689453125\n",
      "Batch: 101, Loss: 1.0612539052963257, Accuracy: 0.6708984375\n",
      "Batch: 102, Loss: 0.9921546578407288, Accuracy: 0.6767578125\n",
      "Batch: 103, Loss: 1.074730396270752, Accuracy: 0.6787109375\n",
      "Batch: 104, Loss: 0.9425145387649536, Accuracy: 0.6962890625\n",
      "Batch: 105, Loss: 1.0546199083328247, Accuracy: 0.6572265625\n",
      "Batch: 106, Loss: 0.9881694316864014, Accuracy: 0.69140625\n",
      "Batch: 107, Loss: 1.1068048477172852, Accuracy: 0.6533203125\n",
      "Batch: 108, Loss: 1.0395724773406982, Accuracy: 0.6552734375\n",
      "Batch: 109, Loss: 1.1907119750976562, Accuracy: 0.6162109375\n",
      "Batch: 110, Loss: 0.8679831624031067, Accuracy: 0.716796875\n",
      "Batch: 111, Loss: 1.0414462089538574, Accuracy: 0.6494140625\n",
      "Batch: 112, Loss: 1.0410947799682617, Accuracy: 0.681640625\n",
      "Batch: 113, Loss: 1.0332396030426025, Accuracy: 0.673828125\n",
      "Batch: 114, Loss: 1.140207052230835, Accuracy: 0.6240234375\n",
      "Batch: 115, Loss: 1.1720647811889648, Accuracy: 0.6376953125\n",
      "Batch: 116, Loss: 1.08279550075531, Accuracy: 0.6630859375\n",
      "Batch: 117, Loss: 1.1387736797332764, Accuracy: 0.6357421875\n",
      "Batch: 118, Loss: 0.9044991731643677, Accuracy: 0.70703125\n",
      "Batch: 119, Loss: 0.9165854454040527, Accuracy: 0.7041015625\n",
      "Batch: 120, Loss: 1.0694420337677002, Accuracy: 0.666015625\n",
      "Batch: 121, Loss: 1.0960376262664795, Accuracy: 0.6455078125\n",
      "Batch: 122, Loss: 1.0070173740386963, Accuracy: 0.6640625\n",
      "Batch: 123, Loss: 0.9636802673339844, Accuracy: 0.6904296875\n",
      "Batch: 124, Loss: 1.082554817199707, Accuracy: 0.65625\n",
      "Batch: 125, Loss: 1.093396782875061, Accuracy: 0.646484375\n",
      "Batch: 126, Loss: 1.0943036079406738, Accuracy: 0.654296875\n",
      "Batch: 127, Loss: 0.9269574284553528, Accuracy: 0.7021484375\n",
      "Batch: 128, Loss: 1.1727583408355713, Accuracy: 0.6533203125\n",
      "Batch: 129, Loss: 0.9675436019897461, Accuracy: 0.6884765625\n",
      "Batch: 130, Loss: 1.2171435356140137, Accuracy: 0.623046875\n",
      "Batch: 131, Loss: 1.070603370666504, Accuracy: 0.6513671875\n",
      "Batch: 132, Loss: 1.0646096467971802, Accuracy: 0.66796875\n",
      "Batch: 133, Loss: 0.9654626846313477, Accuracy: 0.6611328125\n",
      "Batch: 134, Loss: 1.056135654449463, Accuracy: 0.6650390625\n",
      "Batch: 135, Loss: 0.9367550015449524, Accuracy: 0.703125\n",
      "Batch: 136, Loss: 1.0105921030044556, Accuracy: 0.689453125\n",
      "Batch: 137, Loss: 0.965854823589325, Accuracy: 0.6826171875\n",
      "Batch: 138, Loss: 0.8454350233078003, Accuracy: 0.71484375\n",
      "Batch: 139, Loss: 0.9132400751113892, Accuracy: 0.6904296875\n",
      "Batch: 140, Loss: 0.9909548759460449, Accuracy: 0.66796875\n",
      "Batch: 141, Loss: 1.0468088388442993, Accuracy: 0.6708984375\n",
      "Batch: 142, Loss: 1.0688632726669312, Accuracy: 0.662109375\n",
      "Batch: 143, Loss: 1.0585229396820068, Accuracy: 0.66796875\n",
      "Batch: 144, Loss: 1.0349938869476318, Accuracy: 0.6708984375\n",
      "Batch: 145, Loss: 0.9520622491836548, Accuracy: 0.6767578125\n",
      "Batch: 146, Loss: 1.069805383682251, Accuracy: 0.6494140625\n",
      "Batch: 147, Loss: 1.0456857681274414, Accuracy: 0.66015625\n",
      "Batch: 148, Loss: 1.1794352531433105, Accuracy: 0.6162109375\n",
      "Batch: 149, Loss: 1.0255661010742188, Accuracy: 0.65625\n",
      "Batch: 150, Loss: 0.9889202117919922, Accuracy: 0.6767578125\n",
      "Batch: 151, Loss: 0.8883472681045532, Accuracy: 0.716796875\n",
      "Epoch 20/80\n",
      "Batch: 1, Loss: 1.3292044401168823, Accuracy: 0.5849609375\n",
      "Batch: 2, Loss: 1.0693528652191162, Accuracy: 0.6357421875\n",
      "Batch: 3, Loss: 0.9699701070785522, Accuracy: 0.6806640625\n",
      "Batch: 4, Loss: 0.9241105914115906, Accuracy: 0.7197265625\n",
      "Batch: 5, Loss: 0.9425552487373352, Accuracy: 0.697265625\n",
      "Batch: 6, Loss: 1.0386171340942383, Accuracy: 0.6435546875\n",
      "Batch: 7, Loss: 1.017553448677063, Accuracy: 0.65234375\n",
      "Batch: 8, Loss: 0.9366875290870667, Accuracy: 0.6904296875\n",
      "Batch: 9, Loss: 0.8901083469390869, Accuracy: 0.712890625\n",
      "Batch: 10, Loss: 0.9154190421104431, Accuracy: 0.6923828125\n",
      "Batch: 11, Loss: 1.083648920059204, Accuracy: 0.6455078125\n",
      "Batch: 12, Loss: 1.080960750579834, Accuracy: 0.6552734375\n",
      "Batch: 13, Loss: 0.8506886959075928, Accuracy: 0.7294921875\n",
      "Batch: 14, Loss: 1.1238064765930176, Accuracy: 0.630859375\n",
      "Batch: 15, Loss: 0.9583634734153748, Accuracy: 0.70703125\n",
      "Batch: 16, Loss: 0.9642369747161865, Accuracy: 0.7041015625\n",
      "Batch: 17, Loss: 1.055336833000183, Accuracy: 0.65625\n",
      "Batch: 18, Loss: 1.0501612424850464, Accuracy: 0.65234375\n",
      "Batch: 19, Loss: 1.091309666633606, Accuracy: 0.6533203125\n",
      "Batch: 20, Loss: 0.955943763256073, Accuracy: 0.7041015625\n",
      "Batch: 21, Loss: 0.9814088940620422, Accuracy: 0.6689453125\n",
      "Batch: 22, Loss: 1.083504319190979, Accuracy: 0.669921875\n",
      "Batch: 23, Loss: 1.01935613155365, Accuracy: 0.6513671875\n",
      "Batch: 24, Loss: 1.0425963401794434, Accuracy: 0.658203125\n",
      "Batch: 25, Loss: 1.0016790628433228, Accuracy: 0.6796875\n",
      "Batch: 26, Loss: 0.9041491746902466, Accuracy: 0.716796875\n",
      "Batch: 27, Loss: 0.95099937915802, Accuracy: 0.689453125\n",
      "Batch: 28, Loss: 1.0333995819091797, Accuracy: 0.671875\n",
      "Batch: 29, Loss: 0.9958033561706543, Accuracy: 0.669921875\n",
      "Batch: 30, Loss: 0.9558437466621399, Accuracy: 0.69140625\n",
      "Batch: 31, Loss: 0.9121949672698975, Accuracy: 0.7060546875\n",
      "Batch: 32, Loss: 0.9270594120025635, Accuracy: 0.681640625\n",
      "Batch: 33, Loss: 1.0997285842895508, Accuracy: 0.6474609375\n",
      "Batch: 34, Loss: 1.1550099849700928, Accuracy: 0.634765625\n",
      "Batch: 35, Loss: 1.0582785606384277, Accuracy: 0.6533203125\n",
      "Batch: 36, Loss: 1.0729671716690063, Accuracy: 0.669921875\n",
      "Batch: 37, Loss: 1.0287652015686035, Accuracy: 0.6689453125\n",
      "Batch: 38, Loss: 1.0548722743988037, Accuracy: 0.6513671875\n",
      "Batch: 39, Loss: 1.0663994550704956, Accuracy: 0.6708984375\n",
      "Batch: 40, Loss: 1.0401010513305664, Accuracy: 0.6640625\n",
      "Batch: 42, Loss: 0.8263601660728455, Accuracy: 0.7177734375\n",
      "Batch: 43, Loss: 1.0200151205062866, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 1.0491435527801514, Accuracy: 0.6396484375\n",
      "Batch: 45, Loss: 0.8925424218177795, Accuracy: 0.693359375\n",
      "Batch: 46, Loss: 0.9787090420722961, Accuracy: 0.69140625\n",
      "Batch: 47, Loss: 1.0065306425094604, Accuracy: 0.685546875\n",
      "Batch: 48, Loss: 0.9376117587089539, Accuracy: 0.705078125\n",
      "Batch: 49, Loss: 1.1280016899108887, Accuracy: 0.6259765625\n",
      "Batch: 50, Loss: 1.1170867681503296, Accuracy: 0.63671875\n",
      "Batch: 51, Loss: 1.1427693367004395, Accuracy: 0.6337890625\n",
      "Batch: 52, Loss: 1.0921046733856201, Accuracy: 0.6572265625\n",
      "Batch: 53, Loss: 0.9498940110206604, Accuracy: 0.6865234375\n",
      "Batch: 54, Loss: 1.0226304531097412, Accuracy: 0.6669921875\n",
      "Batch: 55, Loss: 1.0844597816467285, Accuracy: 0.6376953125\n",
      "Batch: 56, Loss: 1.058867335319519, Accuracy: 0.6669921875\n",
      "Batch: 57, Loss: 1.0383720397949219, Accuracy: 0.6591796875\n",
      "Batch: 58, Loss: 1.103148102760315, Accuracy: 0.66796875\n",
      "Batch: 59, Loss: 0.9216455221176147, Accuracy: 0.712890625\n",
      "Batch: 60, Loss: 0.9196639657020569, Accuracy: 0.7080078125\n",
      "Batch: 61, Loss: 1.07273268699646, Accuracy: 0.662109375\n",
      "Batch: 62, Loss: 1.011641025543213, Accuracy: 0.6806640625\n",
      "Batch: 63, Loss: 1.0549430847167969, Accuracy: 0.6572265625\n",
      "Batch: 64, Loss: 1.0237067937850952, Accuracy: 0.6748046875\n",
      "Batch: 65, Loss: 1.072837471961975, Accuracy: 0.66015625\n",
      "Batch: 66, Loss: 0.9850610494613647, Accuracy: 0.6884765625\n",
      "Batch: 67, Loss: 1.0882282257080078, Accuracy: 0.6640625\n",
      "Batch: 68, Loss: 1.0763380527496338, Accuracy: 0.6787109375\n",
      "Batch: 69, Loss: 1.0427143573760986, Accuracy: 0.6630859375\n",
      "Batch: 70, Loss: 1.0110714435577393, Accuracy: 0.693359375\n",
      "Batch: 71, Loss: 1.0468640327453613, Accuracy: 0.6494140625\n",
      "Batch: 72, Loss: 0.9275837540626526, Accuracy: 0.7041015625\n",
      "Batch: 73, Loss: 0.9806326627731323, Accuracy: 0.6884765625\n",
      "Batch: 74, Loss: 0.9278572797775269, Accuracy: 0.7119140625\n",
      "Batch: 75, Loss: 0.9330044984817505, Accuracy: 0.70703125\n",
      "Batch: 76, Loss: 1.017479658126831, Accuracy: 0.6552734375\n",
      "Batch: 77, Loss: 0.9911924600601196, Accuracy: 0.6875\n",
      "Batch: 78, Loss: 0.9655783176422119, Accuracy: 0.703125\n",
      "Batch: 79, Loss: 0.8838027715682983, Accuracy: 0.73046875\n",
      "Batch: 80, Loss: 0.9390608072280884, Accuracy: 0.6708984375\n",
      "Batch: 81, Loss: 1.078961968421936, Accuracy: 0.6455078125\n",
      "Batch: 82, Loss: 1.0438934564590454, Accuracy: 0.6640625\n",
      "Batch: 83, Loss: 0.8982452154159546, Accuracy: 0.728515625\n",
      "Batch: 84, Loss: 0.9702188968658447, Accuracy: 0.703125\n",
      "Batch: 85, Loss: 0.9190858602523804, Accuracy: 0.7041015625\n",
      "Batch: 86, Loss: 1.155721664428711, Accuracy: 0.6357421875\n",
      "Batch: 87, Loss: 0.9442883729934692, Accuracy: 0.7138671875\n",
      "Batch: 88, Loss: 1.0373996496200562, Accuracy: 0.685546875\n",
      "Batch: 89, Loss: 1.0324602127075195, Accuracy: 0.6640625\n",
      "Batch: 90, Loss: 0.9329184889793396, Accuracy: 0.69140625\n",
      "Batch: 91, Loss: 1.010880470275879, Accuracy: 0.6669921875\n",
      "Batch: 92, Loss: 1.0305745601654053, Accuracy: 0.666015625\n",
      "Batch: 93, Loss: 0.956155002117157, Accuracy: 0.6962890625\n",
      "Batch: 94, Loss: 0.9680790901184082, Accuracy: 0.671875\n",
      "Batch: 95, Loss: 1.03902268409729, Accuracy: 0.64453125\n",
      "Batch: 96, Loss: 0.9815412759780884, Accuracy: 0.681640625\n",
      "Batch: 97, Loss: 0.8573776483535767, Accuracy: 0.7275390625\n",
      "Batch: 98, Loss: 0.8989834189414978, Accuracy: 0.720703125\n",
      "Batch: 99, Loss: 0.9221866130828857, Accuracy: 0.7060546875\n",
      "Batch: 100, Loss: 0.9692518711090088, Accuracy: 0.6982421875\n",
      "Batch: 101, Loss: 1.0384869575500488, Accuracy: 0.66796875\n",
      "Batch: 102, Loss: 0.9847657680511475, Accuracy: 0.677734375\n",
      "Batch: 103, Loss: 1.0437108278274536, Accuracy: 0.6884765625\n",
      "Batch: 104, Loss: 0.9439245462417603, Accuracy: 0.6796875\n",
      "Batch: 105, Loss: 1.0626220703125, Accuracy: 0.65625\n",
      "Batch: 106, Loss: 0.9807020425796509, Accuracy: 0.6953125\n",
      "Batch: 107, Loss: 1.0820342302322388, Accuracy: 0.6591796875\n",
      "Batch: 108, Loss: 1.017667293548584, Accuracy: 0.6650390625\n",
      "Batch: 109, Loss: 1.1600532531738281, Accuracy: 0.62109375\n",
      "Batch: 110, Loss: 0.8661637306213379, Accuracy: 0.72265625\n",
      "Batch: 111, Loss: 1.0373600721359253, Accuracy: 0.6689453125\n",
      "Batch: 112, Loss: 1.0101661682128906, Accuracy: 0.6884765625\n",
      "Batch: 113, Loss: 1.015068769454956, Accuracy: 0.6865234375\n",
      "Batch: 114, Loss: 1.1190769672393799, Accuracy: 0.6357421875\n",
      "Batch: 115, Loss: 1.1430294513702393, Accuracy: 0.6484375\n",
      "Batch: 116, Loss: 1.0589122772216797, Accuracy: 0.6669921875\n",
      "Batch: 117, Loss: 1.098787546157837, Accuracy: 0.6396484375\n",
      "Batch: 118, Loss: 0.8881316184997559, Accuracy: 0.701171875\n",
      "Batch: 119, Loss: 0.9145500659942627, Accuracy: 0.7060546875\n",
      "Batch: 120, Loss: 1.0594849586486816, Accuracy: 0.6650390625\n",
      "Batch: 121, Loss: 1.0767359733581543, Accuracy: 0.6552734375\n",
      "Batch: 122, Loss: 0.9889625906944275, Accuracy: 0.6796875\n",
      "Batch: 123, Loss: 0.9704033136367798, Accuracy: 0.7001953125\n",
      "Batch: 124, Loss: 1.0433354377746582, Accuracy: 0.6572265625\n",
      "Batch: 125, Loss: 1.0786545276641846, Accuracy: 0.662109375\n",
      "Batch: 126, Loss: 1.0408581495285034, Accuracy: 0.662109375\n",
      "Batch: 127, Loss: 0.9251663684844971, Accuracy: 0.71484375\n",
      "Batch: 128, Loss: 1.1491516828536987, Accuracy: 0.654296875\n",
      "Batch: 129, Loss: 0.9433057904243469, Accuracy: 0.7021484375\n",
      "Batch: 130, Loss: 1.1585946083068848, Accuracy: 0.625\n",
      "Batch: 131, Loss: 1.0360053777694702, Accuracy: 0.6728515625\n",
      "Batch: 132, Loss: 1.0723562240600586, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 0.9336654543876648, Accuracy: 0.6796875\n",
      "Batch: 134, Loss: 1.0471935272216797, Accuracy: 0.6630859375\n",
      "Batch: 135, Loss: 0.9296046495437622, Accuracy: 0.69921875\n",
      "Batch: 136, Loss: 0.9912991523742676, Accuracy: 0.6865234375\n",
      "Batch: 140, Loss: 0.9781923294067383, Accuracy: 0.681640625\n",
      "Batch: 141, Loss: 1.0562019348144531, Accuracy: 0.669921875\n",
      "Batch: 142, Loss: 1.089906096458435, Accuracy: 0.6484375\n",
      "Batch: 143, Loss: 1.0445351600646973, Accuracy: 0.6748046875\n",
      "Batch: 144, Loss: 1.0023945569992065, Accuracy: 0.6796875\n",
      "Batch: 145, Loss: 0.9880549907684326, Accuracy: 0.6474609375\n",
      "Batch: 146, Loss: 1.0464489459991455, Accuracy: 0.6513671875\n",
      "Batch: 147, Loss: 1.0583205223083496, Accuracy: 0.6474609375\n",
      "Batch: 148, Loss: 1.1525537967681885, Accuracy: 0.611328125\n",
      "Batch: 149, Loss: 1.0176981687545776, Accuracy: 0.673828125\n",
      "Batch: 150, Loss: 0.9832215905189514, Accuracy: 0.6826171875\n",
      "Batch: 151, Loss: 0.8996988534927368, Accuracy: 0.7177734375\n",
      "Saved Weights at epoch 20 to file Weights_20.h5\n",
      "Epoch 21/80\n",
      "Batch: 1, Loss: 1.2602767944335938, Accuracy: 0.599609375\n",
      "Batch: 2, Loss: 1.0715059041976929, Accuracy: 0.6298828125\n",
      "Batch: 3, Loss: 0.9954797029495239, Accuracy: 0.6796875\n",
      "Batch: 4, Loss: 0.8852515816688538, Accuracy: 0.7216796875\n",
      "Batch: 5, Loss: 0.917434573173523, Accuracy: 0.7021484375\n",
      "Batch: 6, Loss: 1.0193191766738892, Accuracy: 0.6572265625\n",
      "Batch: 7, Loss: 0.9914919137954712, Accuracy: 0.6533203125\n",
      "Batch: 8, Loss: 0.9326928853988647, Accuracy: 0.693359375\n",
      "Batch: 9, Loss: 0.8888399600982666, Accuracy: 0.7216796875\n",
      "Batch: 10, Loss: 0.9080196619033813, Accuracy: 0.703125\n",
      "Batch: 11, Loss: 1.0804035663604736, Accuracy: 0.6396484375\n",
      "Batch: 12, Loss: 1.0670742988586426, Accuracy: 0.662109375\n",
      "Batch: 13, Loss: 0.8471869826316833, Accuracy: 0.73828125\n",
      "Batch: 14, Loss: 1.1140835285186768, Accuracy: 0.6455078125\n",
      "Batch: 15, Loss: 0.9278405904769897, Accuracy: 0.7080078125\n",
      "Batch: 16, Loss: 0.968657910823822, Accuracy: 0.70703125\n",
      "Batch: 17, Loss: 1.0353598594665527, Accuracy: 0.6611328125\n",
      "Batch: 18, Loss: 1.0298304557800293, Accuracy: 0.6640625\n",
      "Batch: 19, Loss: 1.0383739471435547, Accuracy: 0.6806640625\n",
      "Batch: 20, Loss: 0.9324019551277161, Accuracy: 0.705078125\n",
      "Batch: 21, Loss: 0.9597572088241577, Accuracy: 0.6806640625\n",
      "Batch: 22, Loss: 1.0833995342254639, Accuracy: 0.66015625\n",
      "Batch: 23, Loss: 0.9793483018875122, Accuracy: 0.67578125\n",
      "Batch: 24, Loss: 1.0289031267166138, Accuracy: 0.6552734375\n",
      "Batch: 25, Loss: 0.9824785590171814, Accuracy: 0.6826171875\n",
      "Batch: 26, Loss: 0.8813664317131042, Accuracy: 0.703125\n",
      "Batch: 27, Loss: 0.913611650466919, Accuracy: 0.6826171875\n",
      "Batch: 28, Loss: 1.017899751663208, Accuracy: 0.6611328125\n",
      "Batch: 29, Loss: 0.9616168737411499, Accuracy: 0.6865234375\n",
      "Batch: 30, Loss: 0.941034734249115, Accuracy: 0.712890625\n",
      "Batch: 33, Loss: 1.090386152267456, Accuracy: 0.6533203125\n",
      "Batch: 34, Loss: 1.145494818687439, Accuracy: 0.6484375\n",
      "Batch: 35, Loss: 1.0435750484466553, Accuracy: 0.650390625\n",
      "Batch: 36, Loss: 1.0770207643508911, Accuracy: 0.6611328125\n",
      "Batch: 37, Loss: 1.000825047492981, Accuracy: 0.6748046875\n",
      "Batch: 38, Loss: 1.0542068481445312, Accuracy: 0.6640625\n",
      "Batch: 39, Loss: 1.020667552947998, Accuracy: 0.6748046875\n",
      "Batch: 40, Loss: 1.0403436422348022, Accuracy: 0.673828125\n",
      "Batch: 41, Loss: 0.9760266542434692, Accuracy: 0.6943359375\n",
      "Batch: 42, Loss: 0.8055353164672852, Accuracy: 0.732421875\n",
      "Batch: 43, Loss: 1.0351347923278809, Accuracy: 0.662109375\n",
      "Batch: 44, Loss: 1.0182979106903076, Accuracy: 0.6640625\n",
      "Batch: 45, Loss: 0.8905758261680603, Accuracy: 0.712890625\n",
      "Batch: 46, Loss: 0.9656323194503784, Accuracy: 0.6943359375\n",
      "Batch: 47, Loss: 1.0033444166183472, Accuracy: 0.69921875\n",
      "Batch: 48, Loss: 0.8993615508079529, Accuracy: 0.7080078125\n",
      "Batch: 49, Loss: 1.1069469451904297, Accuracy: 0.64453125\n",
      "Batch: 50, Loss: 1.0744235515594482, Accuracy: 0.662109375\n",
      "Batch: 51, Loss: 1.1200553178787231, Accuracy: 0.642578125\n",
      "Batch: 52, Loss: 1.0864832401275635, Accuracy: 0.64453125\n",
      "Batch: 53, Loss: 0.9313889145851135, Accuracy: 0.6923828125\n",
      "Batch: 54, Loss: 0.9866339564323425, Accuracy: 0.677734375\n",
      "Batch: 55, Loss: 1.0626697540283203, Accuracy: 0.654296875\n",
      "Batch: 56, Loss: 1.057112455368042, Accuracy: 0.65625\n",
      "Batch: 57, Loss: 1.0056942701339722, Accuracy: 0.6796875\n",
      "Batch: 58, Loss: 1.114309310913086, Accuracy: 0.666015625\n",
      "Batch: 59, Loss: 0.9272388219833374, Accuracy: 0.7021484375\n",
      "Batch: 60, Loss: 0.9057389497756958, Accuracy: 0.712890625\n",
      "Batch: 61, Loss: 1.0177178382873535, Accuracy: 0.6650390625\n",
      "Batch: 62, Loss: 0.9718059301376343, Accuracy: 0.693359375\n",
      "Batch: 63, Loss: 1.0456329584121704, Accuracy: 0.669921875\n",
      "Batch: 64, Loss: 1.0000309944152832, Accuracy: 0.673828125\n",
      "Batch: 65, Loss: 1.0440332889556885, Accuracy: 0.66015625\n",
      "Batch: 66, Loss: 0.9757639169692993, Accuracy: 0.681640625\n",
      "Batch: 67, Loss: 1.0567560195922852, Accuracy: 0.6630859375\n",
      "Batch: 68, Loss: 1.0993843078613281, Accuracy: 0.6748046875\n",
      "Batch: 69, Loss: 0.9965036511421204, Accuracy: 0.681640625\n",
      "Batch: 70, Loss: 0.97889244556427, Accuracy: 0.7001953125\n",
      "Batch: 71, Loss: 1.0328137874603271, Accuracy: 0.67578125\n",
      "Batch: 72, Loss: 0.8874245882034302, Accuracy: 0.708984375\n",
      "Batch: 73, Loss: 0.9369428753852844, Accuracy: 0.708984375\n",
      "Batch: 74, Loss: 0.8988348245620728, Accuracy: 0.7197265625\n",
      "Batch: 75, Loss: 0.919272243976593, Accuracy: 0.716796875\n",
      "Batch: 76, Loss: 1.0185658931732178, Accuracy: 0.671875\n",
      "Batch: 77, Loss: 0.9932053089141846, Accuracy: 0.69140625\n",
      "Batch: 78, Loss: 0.9608352780342102, Accuracy: 0.6953125\n",
      "Batch: 79, Loss: 0.9139066934585571, Accuracy: 0.71484375\n",
      "Batch: 80, Loss: 0.9392430782318115, Accuracy: 0.6845703125\n",
      "Batch: 81, Loss: 1.066763162612915, Accuracy: 0.6328125\n",
      "Batch: 82, Loss: 1.0215256214141846, Accuracy: 0.654296875\n",
      "Batch: 83, Loss: 0.895919144153595, Accuracy: 0.740234375\n",
      "Batch: 84, Loss: 0.9392568469047546, Accuracy: 0.712890625\n",
      "Batch: 85, Loss: 0.8911765813827515, Accuracy: 0.7197265625\n",
      "Batch: 86, Loss: 1.1510403156280518, Accuracy: 0.6279296875\n",
      "Batch: 87, Loss: 0.9321175813674927, Accuracy: 0.7119140625\n",
      "Batch: 88, Loss: 1.0409079790115356, Accuracy: 0.6787109375\n",
      "Batch: 89, Loss: 1.0198500156402588, Accuracy: 0.681640625\n",
      "Batch: 90, Loss: 0.9393355846405029, Accuracy: 0.6982421875\n",
      "Batch: 91, Loss: 1.001683235168457, Accuracy: 0.6806640625\n",
      "Batch: 92, Loss: 1.003186583518982, Accuracy: 0.677734375\n",
      "Batch: 93, Loss: 0.9501147866249084, Accuracy: 0.685546875\n",
      "Batch: 94, Loss: 0.956742525100708, Accuracy: 0.67578125\n",
      "Batch: 95, Loss: 1.0244582891464233, Accuracy: 0.66015625\n",
      "Batch: 96, Loss: 0.9551469087600708, Accuracy: 0.693359375\n",
      "Batch: 97, Loss: 0.8161658048629761, Accuracy: 0.734375\n",
      "Batch: 98, Loss: 0.895673394203186, Accuracy: 0.7177734375\n",
      "Batch: 99, Loss: 0.9200976490974426, Accuracy: 0.7119140625\n",
      "Batch: 100, Loss: 0.954153299331665, Accuracy: 0.6982421875\n",
      "Batch: 101, Loss: 1.0389474630355835, Accuracy: 0.66015625\n",
      "Batch: 102, Loss: 0.9707690477371216, Accuracy: 0.7001953125\n",
      "Batch: 103, Loss: 1.03739333152771, Accuracy: 0.67578125\n",
      "Batch: 104, Loss: 0.920988917350769, Accuracy: 0.6845703125\n",
      "Batch: 105, Loss: 1.0217074155807495, Accuracy: 0.6728515625\n",
      "Batch: 106, Loss: 0.9676042795181274, Accuracy: 0.703125\n",
      "Batch: 107, Loss: 1.057932734489441, Accuracy: 0.66015625\n",
      "Batch: 108, Loss: 0.9915351271629333, Accuracy: 0.6826171875\n",
      "Batch: 109, Loss: 1.1218531131744385, Accuracy: 0.6279296875\n",
      "Batch: 110, Loss: 0.8582818508148193, Accuracy: 0.71484375\n",
      "Batch: 111, Loss: 1.0221222639083862, Accuracy: 0.6533203125\n",
      "Batch: 112, Loss: 1.0071147680282593, Accuracy: 0.6962890625\n",
      "Batch: 113, Loss: 1.0186277627944946, Accuracy: 0.6787109375\n",
      "Batch: 114, Loss: 1.0976908206939697, Accuracy: 0.65234375\n",
      "Batch: 115, Loss: 1.1521713733673096, Accuracy: 0.640625\n",
      "Batch: 116, Loss: 1.0804917812347412, Accuracy: 0.666015625\n",
      "Batch: 117, Loss: 1.0561130046844482, Accuracy: 0.6630859375\n",
      "Batch: 118, Loss: 0.8873715996742249, Accuracy: 0.7060546875\n",
      "Batch: 119, Loss: 0.8482292890548706, Accuracy: 0.7333984375\n",
      "Batch: 120, Loss: 1.0337128639221191, Accuracy: 0.6630859375\n",
      "Batch: 121, Loss: 1.0682504177093506, Accuracy: 0.638671875\n",
      "Batch: 124, Loss: 1.0003634691238403, Accuracy: 0.6796875\n",
      "Batch: 125, Loss: 1.0756644010543823, Accuracy: 0.6572265625\n",
      "Batch: 126, Loss: 1.0453200340270996, Accuracy: 0.6650390625\n",
      "Batch: 127, Loss: 0.9250032901763916, Accuracy: 0.720703125\n",
      "Batch: 128, Loss: 1.1050727367401123, Accuracy: 0.658203125\n",
      "Batch: 129, Loss: 0.9496439695358276, Accuracy: 0.701171875\n",
      "Batch: 130, Loss: 1.188248634338379, Accuracy: 0.64453125\n",
      "Batch: 131, Loss: 1.050226092338562, Accuracy: 0.6494140625\n",
      "Batch: 132, Loss: 1.0801260471343994, Accuracy: 0.6572265625\n",
      "Batch: 133, Loss: 0.9371711611747742, Accuracy: 0.6904296875\n",
      "Batch: 134, Loss: 1.017012119293213, Accuracy: 0.666015625\n",
      "Batch: 135, Loss: 0.9044649004936218, Accuracy: 0.71875\n",
      "Batch: 136, Loss: 0.9845566153526306, Accuracy: 0.685546875\n",
      "Batch: 137, Loss: 0.9552687406539917, Accuracy: 0.669921875\n",
      "Batch: 138, Loss: 0.8313796520233154, Accuracy: 0.73046875\n",
      "Batch: 139, Loss: 0.8934130668640137, Accuracy: 0.7041015625\n",
      "Batch: 140, Loss: 0.9904543161392212, Accuracy: 0.6728515625\n",
      "Batch: 141, Loss: 1.0271986722946167, Accuracy: 0.681640625\n",
      "Batch: 142, Loss: 1.0876399278640747, Accuracy: 0.6494140625\n",
      "Batch: 143, Loss: 1.010652780532837, Accuracy: 0.669921875\n",
      "Batch: 144, Loss: 1.0101522207260132, Accuracy: 0.681640625\n",
      "Batch: 145, Loss: 0.9651229381561279, Accuracy: 0.671875\n",
      "Batch: 146, Loss: 1.046400785446167, Accuracy: 0.6484375\n",
      "Batch: 147, Loss: 1.021683931350708, Accuracy: 0.650390625\n",
      "Batch: 148, Loss: 1.1508609056472778, Accuracy: 0.619140625\n",
      "Batch: 149, Loss: 1.003709077835083, Accuracy: 0.669921875\n",
      "Batch: 150, Loss: 0.9630869030952454, Accuracy: 0.6953125\n",
      "Batch: 151, Loss: 0.875613808631897, Accuracy: 0.7275390625\n",
      "Epoch 22/80\n",
      "Batch: 1, Loss: 1.2598555088043213, Accuracy: 0.583984375\n",
      "Batch: 2, Loss: 1.040236234664917, Accuracy: 0.66015625\n",
      "Batch: 3, Loss: 0.9745842218399048, Accuracy: 0.681640625\n",
      "Batch: 4, Loss: 0.8907995820045471, Accuracy: 0.7119140625\n",
      "Batch: 5, Loss: 0.9465553760528564, Accuracy: 0.697265625\n",
      "Batch: 6, Loss: 1.000073790550232, Accuracy: 0.66796875\n",
      "Batch: 7, Loss: 0.9746019244194031, Accuracy: 0.662109375\n",
      "Batch: 8, Loss: 0.9294503331184387, Accuracy: 0.6875\n",
      "Batch: 9, Loss: 0.8943402767181396, Accuracy: 0.7158203125\n",
      "Batch: 10, Loss: 0.884308397769928, Accuracy: 0.701171875\n",
      "Batch: 11, Loss: 1.0590524673461914, Accuracy: 0.6396484375\n",
      "Batch: 12, Loss: 1.0699762105941772, Accuracy: 0.658203125\n",
      "Batch: 13, Loss: 0.8298070430755615, Accuracy: 0.728515625\n",
      "Batch: 14, Loss: 1.0956099033355713, Accuracy: 0.6611328125\n",
      "Batch: 15, Loss: 0.9301526546478271, Accuracy: 0.7109375\n",
      "Batch: 16, Loss: 0.9324839115142822, Accuracy: 0.72265625\n",
      "Batch: 18, Loss: 1.0103662014007568, Accuracy: 0.6689453125\n",
      "Batch: 19, Loss: 1.035954475402832, Accuracy: 0.6748046875\n",
      "Batch: 20, Loss: 0.91230309009552, Accuracy: 0.7158203125\n",
      "Batch: 21, Loss: 0.9513871073722839, Accuracy: 0.7001953125\n",
      "Batch: 22, Loss: 1.061373233795166, Accuracy: 0.6865234375\n",
      "Batch: 23, Loss: 0.9910290837287903, Accuracy: 0.6728515625\n",
      "Batch: 24, Loss: 1.0149877071380615, Accuracy: 0.6640625\n",
      "Batch: 25, Loss: 0.9880671501159668, Accuracy: 0.68359375\n",
      "Batch: 26, Loss: 0.8621171712875366, Accuracy: 0.73828125\n",
      "Batch: 27, Loss: 0.9221533536911011, Accuracy: 0.6875\n",
      "Batch: 28, Loss: 1.0175719261169434, Accuracy: 0.66796875\n",
      "Batch: 29, Loss: 0.9609326124191284, Accuracy: 0.689453125\n",
      "Batch: 30, Loss: 0.9083269834518433, Accuracy: 0.7197265625\n",
      "Batch: 31, Loss: 0.8963715434074402, Accuracy: 0.7197265625\n",
      "Batch: 32, Loss: 0.8803662061691284, Accuracy: 0.6982421875\n",
      "Batch: 33, Loss: 1.0888466835021973, Accuracy: 0.6630859375\n",
      "Batch: 34, Loss: 1.1196030378341675, Accuracy: 0.634765625\n",
      "Batch: 35, Loss: 1.052355408668518, Accuracy: 0.6630859375\n",
      "Batch: 36, Loss: 1.0545852184295654, Accuracy: 0.67578125\n",
      "Batch: 37, Loss: 1.004537582397461, Accuracy: 0.6787109375\n",
      "Batch: 38, Loss: 1.0281099081039429, Accuracy: 0.673828125\n",
      "Batch: 39, Loss: 1.0184223651885986, Accuracy: 0.6650390625\n",
      "Batch: 40, Loss: 1.015751600265503, Accuracy: 0.6904296875\n",
      "Batch: 41, Loss: 0.9606989026069641, Accuracy: 0.7021484375\n",
      "Batch: 42, Loss: 0.8048461675643921, Accuracy: 0.732421875\n",
      "Batch: 43, Loss: 1.0130503177642822, Accuracy: 0.6669921875\n",
      "Batch: 44, Loss: 0.9830914735794067, Accuracy: 0.666015625\n",
      "Batch: 45, Loss: 0.863353967666626, Accuracy: 0.69921875\n",
      "Batch: 46, Loss: 0.946260392665863, Accuracy: 0.7138671875\n",
      "Batch: 47, Loss: 0.9989287257194519, Accuracy: 0.69140625\n",
      "Batch: 48, Loss: 0.8993940353393555, Accuracy: 0.716796875\n",
      "Batch: 49, Loss: 1.0690672397613525, Accuracy: 0.65625\n",
      "Batch: 50, Loss: 1.0623363256454468, Accuracy: 0.654296875\n",
      "Batch: 51, Loss: 1.1225130558013916, Accuracy: 0.6298828125\n",
      "Batch: 52, Loss: 1.079601526260376, Accuracy: 0.662109375\n",
      "Batch: 53, Loss: 0.937195360660553, Accuracy: 0.6875\n",
      "Batch: 54, Loss: 0.9729458689689636, Accuracy: 0.6787109375\n",
      "Batch: 55, Loss: 1.0635485649108887, Accuracy: 0.654296875\n",
      "Batch: 56, Loss: 1.0366487503051758, Accuracy: 0.6689453125\n",
      "Batch: 57, Loss: 1.0175931453704834, Accuracy: 0.6787109375\n",
      "Batch: 58, Loss: 1.0901904106140137, Accuracy: 0.669921875\n",
      "Batch: 59, Loss: 0.9291987419128418, Accuracy: 0.7158203125\n",
      "Batch: 60, Loss: 0.9021933674812317, Accuracy: 0.712890625\n",
      "Batch: 61, Loss: 1.0284008979797363, Accuracy: 0.6611328125\n",
      "Batch: 64, Loss: 0.9867885708808899, Accuracy: 0.685546875\n",
      "Batch: 65, Loss: 1.0148820877075195, Accuracy: 0.669921875\n",
      "Batch: 66, Loss: 0.960010290145874, Accuracy: 0.693359375\n",
      "Batch: 67, Loss: 1.0880727767944336, Accuracy: 0.65234375\n",
      "Batch: 68, Loss: 1.064827561378479, Accuracy: 0.666015625\n",
      "Batch: 69, Loss: 1.0141998529434204, Accuracy: 0.6640625\n",
      "Batch: 70, Loss: 0.989018440246582, Accuracy: 0.6923828125\n",
      "Batch: 71, Loss: 1.015416145324707, Accuracy: 0.671875\n",
      "Batch: 72, Loss: 0.8577907085418701, Accuracy: 0.7138671875\n",
      "Batch: 73, Loss: 0.9361395835876465, Accuracy: 0.708984375\n",
      "Batch: 74, Loss: 0.8985523581504822, Accuracy: 0.7255859375\n",
      "Batch: 75, Loss: 0.9105426073074341, Accuracy: 0.703125\n",
      "Batch: 76, Loss: 0.9985519647598267, Accuracy: 0.6767578125\n",
      "Batch: 77, Loss: 0.9620707035064697, Accuracy: 0.673828125\n",
      "Batch: 78, Loss: 0.9497288465499878, Accuracy: 0.7099609375\n",
      "Batch: 79, Loss: 0.908757746219635, Accuracy: 0.7294921875\n",
      "Batch: 80, Loss: 0.9459019899368286, Accuracy: 0.6923828125\n",
      "Batch: 81, Loss: 1.0533274412155151, Accuracy: 0.638671875\n",
      "Batch: 82, Loss: 1.0208656787872314, Accuracy: 0.669921875\n",
      "Batch: 83, Loss: 0.883708119392395, Accuracy: 0.732421875\n",
      "Batch: 84, Loss: 0.9694077968597412, Accuracy: 0.7041015625\n",
      "Batch: 85, Loss: 0.888807475566864, Accuracy: 0.7255859375\n",
      "Batch: 86, Loss: 1.131648063659668, Accuracy: 0.6396484375\n",
      "Batch: 87, Loss: 0.9195845723152161, Accuracy: 0.712890625\n",
      "Batch: 88, Loss: 1.0317658185958862, Accuracy: 0.681640625\n",
      "Batch: 89, Loss: 1.0182523727416992, Accuracy: 0.693359375\n",
      "Batch: 90, Loss: 0.92758709192276, Accuracy: 0.7001953125\n",
      "Batch: 91, Loss: 0.9604587554931641, Accuracy: 0.68359375\n",
      "Batch: 92, Loss: 0.9954129457473755, Accuracy: 0.6767578125\n",
      "Batch: 93, Loss: 0.950942873954773, Accuracy: 0.697265625\n",
      "Batch: 94, Loss: 0.9627037048339844, Accuracy: 0.689453125\n",
      "Batch: 95, Loss: 1.0113837718963623, Accuracy: 0.654296875\n",
      "Batch: 96, Loss: 0.9416823387145996, Accuracy: 0.6962890625\n",
      "Batch: 97, Loss: 0.8149002194404602, Accuracy: 0.7177734375\n",
      "Batch: 98, Loss: 0.8775469064712524, Accuracy: 0.72265625\n",
      "Batch: 99, Loss: 0.9024680852890015, Accuracy: 0.7177734375\n",
      "Batch: 100, Loss: 0.9365170001983643, Accuracy: 0.7099609375\n",
      "Batch: 101, Loss: 1.0397744178771973, Accuracy: 0.6767578125\n",
      "Batch: 102, Loss: 0.9351335763931274, Accuracy: 0.69140625\n",
      "Batch: 103, Loss: 1.029689908027649, Accuracy: 0.6865234375\n",
      "Batch: 104, Loss: 0.8870331048965454, Accuracy: 0.7060546875\n",
      "Batch: 105, Loss: 1.0229902267456055, Accuracy: 0.6767578125\n",
      "Batch: 108, Loss: 1.0298856496810913, Accuracy: 0.669921875\n",
      "Batch: 109, Loss: 1.1319457292556763, Accuracy: 0.6337890625\n",
      "Batch: 110, Loss: 0.8269175887107849, Accuracy: 0.73046875\n",
      "Batch: 111, Loss: 0.9872690439224243, Accuracy: 0.6689453125\n",
      "Batch: 112, Loss: 0.9982263445854187, Accuracy: 0.6923828125\n",
      "Batch: 113, Loss: 0.9739058017730713, Accuracy: 0.701171875\n",
      "Batch: 114, Loss: 1.0930116176605225, Accuracy: 0.6337890625\n",
      "Batch: 115, Loss: 1.1425375938415527, Accuracy: 0.6416015625\n",
      "Batch: 116, Loss: 1.0271480083465576, Accuracy: 0.6708984375\n",
      "Batch: 117, Loss: 1.0616893768310547, Accuracy: 0.6630859375\n",
      "Batch: 118, Loss: 0.8719914555549622, Accuracy: 0.7265625\n",
      "Batch: 119, Loss: 0.8882962465286255, Accuracy: 0.7197265625\n",
      "Batch: 120, Loss: 1.0386805534362793, Accuracy: 0.658203125\n",
      "Batch: 121, Loss: 1.0613412857055664, Accuracy: 0.6650390625\n",
      "Batch: 122, Loss: 0.96876060962677, Accuracy: 0.677734375\n",
      "Batch: 123, Loss: 0.9488269686698914, Accuracy: 0.6923828125\n",
      "Batch: 124, Loss: 1.0028890371322632, Accuracy: 0.6669921875\n",
      "Batch: 125, Loss: 1.0679705142974854, Accuracy: 0.6572265625\n",
      "Batch: 126, Loss: 1.0331881046295166, Accuracy: 0.66015625\n",
      "Batch: 127, Loss: 0.9130352735519409, Accuracy: 0.734375\n",
      "Batch: 128, Loss: 1.1314935684204102, Accuracy: 0.6630859375\n",
      "Batch: 129, Loss: 0.9163030385971069, Accuracy: 0.71484375\n",
      "Batch: 130, Loss: 1.1636817455291748, Accuracy: 0.6064453125\n",
      "Batch: 131, Loss: 1.0405651330947876, Accuracy: 0.66015625\n",
      "Batch: 132, Loss: 1.0643264055252075, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 0.9383580684661865, Accuracy: 0.6953125\n",
      "Batch: 134, Loss: 1.0137628316879272, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 0.9075175523757935, Accuracy: 0.7080078125\n",
      "Batch: 136, Loss: 0.9631149768829346, Accuracy: 0.6943359375\n",
      "Batch: 137, Loss: 0.9200274348258972, Accuracy: 0.6923828125\n",
      "Batch: 138, Loss: 0.8338735103607178, Accuracy: 0.7294921875\n",
      "Batch: 139, Loss: 0.8937597274780273, Accuracy: 0.701171875\n",
      "Batch: 140, Loss: 0.9383649826049805, Accuracy: 0.6962890625\n",
      "Batch: 141, Loss: 1.0152177810668945, Accuracy: 0.6806640625\n",
      "Batch: 142, Loss: 1.0773475170135498, Accuracy: 0.6650390625\n",
      "Batch: 143, Loss: 0.9922376871109009, Accuracy: 0.6865234375\n",
      "Batch: 144, Loss: 0.9757683873176575, Accuracy: 0.69140625\n",
      "Batch: 145, Loss: 0.9290821552276611, Accuracy: 0.689453125\n",
      "Batch: 146, Loss: 1.0459222793579102, Accuracy: 0.666015625\n",
      "Batch: 147, Loss: 1.022883415222168, Accuracy: 0.6533203125\n",
      "Batch: 148, Loss: 1.1141743659973145, Accuracy: 0.6416015625\n",
      "Batch: 149, Loss: 0.995307981967926, Accuracy: 0.673828125\n",
      "Batch: 150, Loss: 0.9546712636947632, Accuracy: 0.6845703125\n",
      "Batch: 151, Loss: 0.8647469282150269, Accuracy: 0.7255859375\n",
      "Epoch 23/80\n",
      "Batch: 3, Loss: 0.9566126465797424, Accuracy: 0.673828125\n",
      "Batch: 4, Loss: 0.8879605531692505, Accuracy: 0.720703125\n",
      "Batch: 5, Loss: 0.9123873114585876, Accuracy: 0.7060546875\n",
      "Batch: 6, Loss: 1.02553391456604, Accuracy: 0.6611328125\n",
      "Batch: 7, Loss: 0.9628280997276306, Accuracy: 0.677734375\n",
      "Batch: 8, Loss: 0.9165456295013428, Accuracy: 0.69921875\n",
      "Batch: 9, Loss: 0.890087366104126, Accuracy: 0.7119140625\n",
      "Batch: 10, Loss: 0.9068071842193604, Accuracy: 0.7001953125\n",
      "Batch: 11, Loss: 1.0691965818405151, Accuracy: 0.642578125\n",
      "Batch: 12, Loss: 1.0565296411514282, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 0.8238235712051392, Accuracy: 0.7265625\n",
      "Batch: 14, Loss: 1.08586847782135, Accuracy: 0.6552734375\n",
      "Batch: 15, Loss: 0.9199829697608948, Accuracy: 0.7099609375\n",
      "Batch: 16, Loss: 0.9581961035728455, Accuracy: 0.7021484375\n",
      "Batch: 17, Loss: 1.0176531076431274, Accuracy: 0.6708984375\n",
      "Batch: 18, Loss: 0.9922940731048584, Accuracy: 0.6748046875\n",
      "Batch: 19, Loss: 1.0306512117385864, Accuracy: 0.681640625\n",
      "Batch: 20, Loss: 0.8967578411102295, Accuracy: 0.7158203125\n",
      "Batch: 21, Loss: 0.9268599152565002, Accuracy: 0.7109375\n",
      "Batch: 22, Loss: 1.0538618564605713, Accuracy: 0.6630859375\n",
      "Batch: 23, Loss: 1.0010120868682861, Accuracy: 0.6640625\n",
      "Batch: 24, Loss: 0.9956093430519104, Accuracy: 0.6728515625\n",
      "Batch: 25, Loss: 0.9656016230583191, Accuracy: 0.6884765625\n",
      "Batch: 26, Loss: 0.8433417081832886, Accuracy: 0.7255859375\n",
      "Batch: 27, Loss: 0.9207499027252197, Accuracy: 0.6826171875\n",
      "Batch: 28, Loss: 0.9995021820068359, Accuracy: 0.6845703125\n",
      "Batch: 29, Loss: 0.9751086235046387, Accuracy: 0.685546875\n",
      "Batch: 30, Loss: 0.9062117338180542, Accuracy: 0.7158203125\n",
      "Batch: 31, Loss: 0.8768609166145325, Accuracy: 0.7177734375\n",
      "Batch: 32, Loss: 0.8846868276596069, Accuracy: 0.70703125\n",
      "Batch: 33, Loss: 1.0819728374481201, Accuracy: 0.6474609375\n",
      "Batch: 34, Loss: 1.1081562042236328, Accuracy: 0.646484375\n",
      "Batch: 35, Loss: 1.0286147594451904, Accuracy: 0.6572265625\n",
      "Batch: 36, Loss: 1.0429365634918213, Accuracy: 0.6669921875\n",
      "Batch: 37, Loss: 0.9781444072723389, Accuracy: 0.6787109375\n",
      "Batch: 38, Loss: 0.9788053035736084, Accuracy: 0.677734375\n",
      "Batch: 39, Loss: 0.9960763454437256, Accuracy: 0.6845703125\n",
      "Batch: 40, Loss: 0.995712399482727, Accuracy: 0.6796875\n",
      "Batch: 41, Loss: 0.9300121068954468, Accuracy: 0.7109375\n",
      "Batch: 42, Loss: 0.7872912883758545, Accuracy: 0.732421875\n",
      "Batch: 43, Loss: 1.0017410516738892, Accuracy: 0.662109375\n",
      "Batch: 44, Loss: 0.9757957458496094, Accuracy: 0.6806640625\n",
      "Batch: 45, Loss: 0.8639516830444336, Accuracy: 0.7021484375\n",
      "Batch: 46, Loss: 0.9299061298370361, Accuracy: 0.708984375\n",
      "Batch: 48, Loss: 0.9015097618103027, Accuracy: 0.6982421875\n",
      "Batch: 49, Loss: 1.0567824840545654, Accuracy: 0.6611328125\n",
      "Batch: 50, Loss: 1.0311168432235718, Accuracy: 0.6708984375\n",
      "Batch: 51, Loss: 1.0875470638275146, Accuracy: 0.650390625\n",
      "Batch: 52, Loss: 1.0694189071655273, Accuracy: 0.65625\n",
      "Batch: 53, Loss: 0.9052920341491699, Accuracy: 0.7060546875\n",
      "Batch: 54, Loss: 0.9812697768211365, Accuracy: 0.693359375\n",
      "Batch: 55, Loss: 1.069832444190979, Accuracy: 0.6494140625\n",
      "Batch: 56, Loss: 1.0278624296188354, Accuracy: 0.6689453125\n",
      "Batch: 57, Loss: 0.9834001660346985, Accuracy: 0.681640625\n",
      "Batch: 58, Loss: 1.0610665082931519, Accuracy: 0.68359375\n",
      "Batch: 59, Loss: 0.8968020081520081, Accuracy: 0.712890625\n",
      "Batch: 60, Loss: 0.8836539387702942, Accuracy: 0.716796875\n",
      "Batch: 61, Loss: 1.039609670639038, Accuracy: 0.6591796875\n",
      "Batch: 62, Loss: 0.9674656391143799, Accuracy: 0.697265625\n",
      "Batch: 63, Loss: 1.0204312801361084, Accuracy: 0.673828125\n",
      "Batch: 64, Loss: 0.9837512969970703, Accuracy: 0.6806640625\n",
      "Batch: 65, Loss: 0.9970725774765015, Accuracy: 0.68359375\n",
      "Batch: 66, Loss: 0.9286953210830688, Accuracy: 0.6982421875\n",
      "Batch: 67, Loss: 1.0564570426940918, Accuracy: 0.65625\n",
      "Batch: 68, Loss: 1.076765775680542, Accuracy: 0.66796875\n",
      "Batch: 69, Loss: 0.9782659411430359, Accuracy: 0.681640625\n",
      "Batch: 70, Loss: 0.9609483480453491, Accuracy: 0.7060546875\n",
      "Batch: 71, Loss: 1.003321647644043, Accuracy: 0.673828125\n",
      "Batch: 72, Loss: 0.8593467473983765, Accuracy: 0.712890625\n",
      "Batch: 73, Loss: 0.9169053435325623, Accuracy: 0.703125\n",
      "Batch: 74, Loss: 0.8659349679946899, Accuracy: 0.7392578125\n",
      "Batch: 75, Loss: 0.9121929407119751, Accuracy: 0.7041015625\n",
      "Batch: 76, Loss: 0.9858034253120422, Accuracy: 0.6787109375\n",
      "Batch: 77, Loss: 0.9411571025848389, Accuracy: 0.7119140625\n",
      "Batch: 78, Loss: 0.9405002593994141, Accuracy: 0.7138671875\n",
      "Batch: 79, Loss: 0.8592109680175781, Accuracy: 0.7421875\n",
      "Batch: 80, Loss: 0.9291038513183594, Accuracy: 0.6767578125\n",
      "Batch: 81, Loss: 1.0468218326568604, Accuracy: 0.63671875\n",
      "Batch: 82, Loss: 1.020573377609253, Accuracy: 0.6708984375\n",
      "Batch: 83, Loss: 0.8589879274368286, Accuracy: 0.744140625\n",
      "Batch: 84, Loss: 0.9254087209701538, Accuracy: 0.7060546875\n",
      "Batch: 85, Loss: 0.8649088144302368, Accuracy: 0.7294921875\n",
      "Batch: 86, Loss: 1.0895814895629883, Accuracy: 0.666015625\n",
      "Batch: 87, Loss: 0.891507089138031, Accuracy: 0.7138671875\n",
      "Batch: 88, Loss: 0.9973952174186707, Accuracy: 0.6845703125\n",
      "Batch: 89, Loss: 1.009221076965332, Accuracy: 0.6796875\n",
      "Batch: 90, Loss: 0.915511965751648, Accuracy: 0.6962890625\n",
      "Batch: 93, Loss: 0.9410800933837891, Accuracy: 0.6923828125\n",
      "Batch: 94, Loss: 0.9483373165130615, Accuracy: 0.6796875\n",
      "Batch: 95, Loss: 0.9864367246627808, Accuracy: 0.6650390625\n",
      "Batch: 96, Loss: 0.9391319155693054, Accuracy: 0.693359375\n",
      "Batch: 97, Loss: 0.8254621028900146, Accuracy: 0.72265625\n",
      "Batch: 98, Loss: 0.8738616704940796, Accuracy: 0.7294921875\n",
      "Batch: 99, Loss: 0.9068185687065125, Accuracy: 0.7021484375\n",
      "Batch: 100, Loss: 0.9276477098464966, Accuracy: 0.7255859375\n",
      "Batch: 101, Loss: 1.0299091339111328, Accuracy: 0.67578125\n",
      "Batch: 102, Loss: 0.9258357286453247, Accuracy: 0.701171875\n",
      "Batch: 103, Loss: 1.005720615386963, Accuracy: 0.693359375\n",
      "Batch: 104, Loss: 0.9002389907836914, Accuracy: 0.69921875\n",
      "Batch: 105, Loss: 0.991127610206604, Accuracy: 0.685546875\n",
      "Batch: 106, Loss: 0.9423927068710327, Accuracy: 0.697265625\n",
      "Batch: 107, Loss: 1.0432026386260986, Accuracy: 0.677734375\n",
      "Batch: 108, Loss: 0.9786158204078674, Accuracy: 0.6875\n",
      "Batch: 109, Loss: 1.0916857719421387, Accuracy: 0.6337890625\n",
      "Batch: 110, Loss: 0.8480968475341797, Accuracy: 0.7236328125\n",
      "Batch: 111, Loss: 0.9890589714050293, Accuracy: 0.6728515625\n",
      "Batch: 112, Loss: 0.9596364498138428, Accuracy: 0.69921875\n",
      "Batch: 113, Loss: 0.9649626016616821, Accuracy: 0.6865234375\n",
      "Batch: 114, Loss: 1.0863630771636963, Accuracy: 0.638671875\n",
      "Batch: 115, Loss: 1.1404563188552856, Accuracy: 0.65625\n",
      "Batch: 116, Loss: 1.046708106994629, Accuracy: 0.6708984375\n",
      "Batch: 117, Loss: 1.0561587810516357, Accuracy: 0.6640625\n",
      "Batch: 118, Loss: 0.852780282497406, Accuracy: 0.7177734375\n",
      "Batch: 119, Loss: 0.8561053276062012, Accuracy: 0.724609375\n",
      "Batch: 120, Loss: 1.0091066360473633, Accuracy: 0.6650390625\n",
      "Batch: 121, Loss: 1.0468976497650146, Accuracy: 0.6591796875\n",
      "Batch: 122, Loss: 0.9239728450775146, Accuracy: 0.7060546875\n",
      "Batch: 123, Loss: 0.9399446249008179, Accuracy: 0.7138671875\n",
      "Batch: 124, Loss: 1.0005183219909668, Accuracy: 0.67578125\n",
      "Batch: 125, Loss: 1.0468237400054932, Accuracy: 0.6591796875\n",
      "Batch: 126, Loss: 1.0231754779815674, Accuracy: 0.669921875\n",
      "Batch: 127, Loss: 0.8999922871589661, Accuracy: 0.7177734375\n",
      "Batch: 128, Loss: 1.0980818271636963, Accuracy: 0.6708984375\n",
      "Batch: 129, Loss: 0.8792611956596375, Accuracy: 0.7314453125\n",
      "Batch: 130, Loss: 1.1599998474121094, Accuracy: 0.6357421875\n",
      "Batch: 131, Loss: 1.0230216979980469, Accuracy: 0.6708984375\n",
      "Batch: 132, Loss: 1.0479388236999512, Accuracy: 0.6650390625\n",
      "Batch: 133, Loss: 0.9231598973274231, Accuracy: 0.6865234375\n",
      "Batch: 134, Loss: 1.0085148811340332, Accuracy: 0.6611328125\n",
      "Batch: 137, Loss: 0.933448076248169, Accuracy: 0.693359375\n",
      "Batch: 138, Loss: 0.8152148723602295, Accuracy: 0.7431640625\n",
      "Batch: 139, Loss: 0.8964548110961914, Accuracy: 0.6884765625\n",
      "Batch: 140, Loss: 0.978469967842102, Accuracy: 0.6796875\n",
      "Batch: 141, Loss: 1.0010185241699219, Accuracy: 0.6748046875\n",
      "Batch: 142, Loss: 1.0452980995178223, Accuracy: 0.6689453125\n",
      "Batch: 143, Loss: 0.9918471574783325, Accuracy: 0.6826171875\n",
      "Batch: 144, Loss: 0.962337076663971, Accuracy: 0.685546875\n",
      "Batch: 145, Loss: 0.9196581840515137, Accuracy: 0.6806640625\n",
      "Batch: 146, Loss: 1.0415499210357666, Accuracy: 0.6640625\n",
      "Batch: 147, Loss: 0.9936679005622864, Accuracy: 0.67578125\n",
      "Batch: 148, Loss: 1.1046744585037231, Accuracy: 0.6337890625\n",
      "Batch: 149, Loss: 0.9563590288162231, Accuracy: 0.6787109375\n",
      "Batch: 150, Loss: 0.936835527420044, Accuracy: 0.7041015625\n",
      "Batch: 151, Loss: 0.8399092555046082, Accuracy: 0.736328125\n",
      "Epoch 24/80\n",
      "Batch: 1, Loss: 1.2314754724502563, Accuracy: 0.6015625\n",
      "Batch: 2, Loss: 1.026784062385559, Accuracy: 0.6591796875\n",
      "Batch: 3, Loss: 0.9253302812576294, Accuracy: 0.708984375\n",
      "Batch: 4, Loss: 0.8579856157302856, Accuracy: 0.7265625\n",
      "Batch: 5, Loss: 0.9087381362915039, Accuracy: 0.7265625\n",
      "Batch: 6, Loss: 0.9904993176460266, Accuracy: 0.671875\n",
      "Batch: 7, Loss: 0.97479248046875, Accuracy: 0.6669921875\n",
      "Batch: 8, Loss: 0.9112030267715454, Accuracy: 0.693359375\n",
      "Batch: 9, Loss: 0.8773295879364014, Accuracy: 0.7197265625\n",
      "Batch: 10, Loss: 0.8825165033340454, Accuracy: 0.7021484375\n",
      "Batch: 11, Loss: 1.0406075716018677, Accuracy: 0.638671875\n",
      "Batch: 12, Loss: 1.0418087244033813, Accuracy: 0.6533203125\n",
      "Batch: 13, Loss: 0.7959755063056946, Accuracy: 0.7451171875\n",
      "Batch: 14, Loss: 1.0708835124969482, Accuracy: 0.6552734375\n",
      "Batch: 15, Loss: 0.905623197555542, Accuracy: 0.7314453125\n",
      "Batch: 16, Loss: 0.9478582143783569, Accuracy: 0.7109375\n",
      "Batch: 17, Loss: 0.9947938919067383, Accuracy: 0.6787109375\n",
      "Batch: 18, Loss: 0.9763937592506409, Accuracy: 0.6796875\n",
      "Batch: 19, Loss: 1.01003098487854, Accuracy: 0.6865234375\n",
      "Batch: 20, Loss: 0.8905515670776367, Accuracy: 0.7158203125\n",
      "Batch: 21, Loss: 0.940841019153595, Accuracy: 0.69140625\n",
      "Batch: 22, Loss: 1.0434942245483398, Accuracy: 0.662109375\n",
      "Batch: 23, Loss: 0.9703679084777832, Accuracy: 0.6787109375\n",
      "Batch: 24, Loss: 0.9702206254005432, Accuracy: 0.67578125\n",
      "Batch: 25, Loss: 0.9655169248580933, Accuracy: 0.6923828125\n",
      "Batch: 26, Loss: 0.8324460983276367, Accuracy: 0.7294921875\n",
      "Batch: 27, Loss: 0.8881131410598755, Accuracy: 0.705078125\n",
      "Batch: 28, Loss: 0.9786425828933716, Accuracy: 0.6767578125\n",
      "Batch: 29, Loss: 0.9467781782150269, Accuracy: 0.697265625\n",
      "Batch: 30, Loss: 0.8678348660469055, Accuracy: 0.7275390625\n",
      "Batch: 32, Loss: 0.8848221302032471, Accuracy: 0.70703125\n",
      "Batch: 33, Loss: 1.051649570465088, Accuracy: 0.6591796875\n",
      "Batch: 34, Loss: 1.0948975086212158, Accuracy: 0.642578125\n",
      "Batch: 35, Loss: 1.0371477603912354, Accuracy: 0.673828125\n",
      "Batch: 36, Loss: 1.037937879562378, Accuracy: 0.6865234375\n",
      "Batch: 37, Loss: 0.964299201965332, Accuracy: 0.6884765625\n",
      "Batch: 38, Loss: 0.9911882281303406, Accuracy: 0.6767578125\n",
      "Batch: 39, Loss: 1.007940649986267, Accuracy: 0.67578125\n",
      "Batch: 40, Loss: 0.9723011255264282, Accuracy: 0.6884765625\n",
      "Batch: 41, Loss: 0.9307934641838074, Accuracy: 0.712890625\n",
      "Batch: 42, Loss: 0.7777671217918396, Accuracy: 0.732421875\n",
      "Batch: 43, Loss: 0.9847235679626465, Accuracy: 0.673828125\n",
      "Batch: 44, Loss: 0.9575121402740479, Accuracy: 0.6806640625\n",
      "Batch: 45, Loss: 0.8636722564697266, Accuracy: 0.7001953125\n",
      "Batch: 46, Loss: 0.9326590299606323, Accuracy: 0.7021484375\n",
      "Batch: 47, Loss: 0.9628297090530396, Accuracy: 0.6923828125\n",
      "Batch: 48, Loss: 0.8864803314208984, Accuracy: 0.7119140625\n",
      "Batch: 49, Loss: 1.065407633781433, Accuracy: 0.662109375\n",
      "Batch: 50, Loss: 1.0300313234329224, Accuracy: 0.673828125\n",
      "Batch: 51, Loss: 1.049928903579712, Accuracy: 0.65234375\n",
      "Batch: 52, Loss: 1.0596542358398438, Accuracy: 0.6650390625\n",
      "Batch: 53, Loss: 0.8973533511161804, Accuracy: 0.697265625\n",
      "Batch: 54, Loss: 0.9407854080200195, Accuracy: 0.69921875\n",
      "Batch: 55, Loss: 1.0335021018981934, Accuracy: 0.6640625\n",
      "Batch: 56, Loss: 1.0045803785324097, Accuracy: 0.6787109375\n",
      "Batch: 57, Loss: 0.9703518152236938, Accuracy: 0.6865234375\n",
      "Batch: 58, Loss: 1.0810080766677856, Accuracy: 0.6767578125\n",
      "Batch: 59, Loss: 0.888158917427063, Accuracy: 0.716796875\n",
      "Batch: 60, Loss: 0.8738589286804199, Accuracy: 0.7197265625\n",
      "Batch: 61, Loss: 0.9926941394805908, Accuracy: 0.6845703125\n",
      "Batch: 62, Loss: 0.9253445267677307, Accuracy: 0.7021484375\n",
      "Batch: 63, Loss: 1.0196317434310913, Accuracy: 0.681640625\n",
      "Batch: 64, Loss: 0.977275013923645, Accuracy: 0.6884765625\n",
      "Batch: 65, Loss: 0.9942451119422913, Accuracy: 0.685546875\n",
      "Batch: 66, Loss: 0.9349374771118164, Accuracy: 0.70703125\n",
      "Batch: 67, Loss: 1.0046024322509766, Accuracy: 0.685546875\n",
      "Batch: 68, Loss: 1.0834290981292725, Accuracy: 0.666015625\n",
      "Batch: 69, Loss: 0.9625656604766846, Accuracy: 0.6845703125\n",
      "Batch: 70, Loss: 0.9517649412155151, Accuracy: 0.70703125\n",
      "Batch: 71, Loss: 0.9881510734558105, Accuracy: 0.673828125\n",
      "Batch: 72, Loss: 0.8632659912109375, Accuracy: 0.7158203125\n",
      "Batch: 73, Loss: 0.8942833542823792, Accuracy: 0.7041015625\n",
      "Batch: 74, Loss: 0.8651111721992493, Accuracy: 0.740234375\n",
      "Batch: 75, Loss: 0.8753211498260498, Accuracy: 0.71484375\n",
      "Batch: 76, Loss: 0.9834461808204651, Accuracy: 0.669921875\n",
      "Batch: 77, Loss: 0.9358830451965332, Accuracy: 0.6953125\n",
      "Batch: 78, Loss: 0.9111818671226501, Accuracy: 0.720703125\n",
      "Batch: 79, Loss: 0.8579226732254028, Accuracy: 0.73828125\n",
      "Batch: 80, Loss: 0.884445071220398, Accuracy: 0.6904296875\n",
      "Batch: 81, Loss: 1.013753056526184, Accuracy: 0.6396484375\n",
      "Batch: 82, Loss: 0.9952659010887146, Accuracy: 0.6826171875\n",
      "Batch: 83, Loss: 0.8323659896850586, Accuracy: 0.7421875\n",
      "Batch: 84, Loss: 0.9260295629501343, Accuracy: 0.703125\n",
      "Batch: 85, Loss: 0.8617477416992188, Accuracy: 0.720703125\n",
      "Batch: 86, Loss: 1.097001075744629, Accuracy: 0.634765625\n",
      "Batch: 87, Loss: 0.8758194446563721, Accuracy: 0.728515625\n",
      "Batch: 88, Loss: 1.0092957019805908, Accuracy: 0.697265625\n",
      "Batch: 89, Loss: 1.0072426795959473, Accuracy: 0.6865234375\n",
      "Batch: 90, Loss: 0.8958231210708618, Accuracy: 0.7158203125\n",
      "Batch: 91, Loss: 0.9386807084083557, Accuracy: 0.6982421875\n",
      "Batch: 92, Loss: 0.9669748544692993, Accuracy: 0.703125\n",
      "Batch: 93, Loss: 0.9284913539886475, Accuracy: 0.7021484375\n",
      "Batch: 94, Loss: 0.9354442358016968, Accuracy: 0.689453125\n",
      "Batch: 95, Loss: 0.9695691466331482, Accuracy: 0.6630859375\n",
      "Batch: 96, Loss: 0.9333793520927429, Accuracy: 0.6884765625\n",
      "Batch: 97, Loss: 0.7932173013687134, Accuracy: 0.7412109375\n",
      "Batch: 98, Loss: 0.8601765632629395, Accuracy: 0.7275390625\n",
      "Batch: 99, Loss: 0.9024711847305298, Accuracy: 0.7080078125\n",
      "Batch: 100, Loss: 0.9086461663246155, Accuracy: 0.7119140625\n",
      "Batch: 101, Loss: 1.0026898384094238, Accuracy: 0.6787109375\n",
      "Batch: 102, Loss: 0.9425279498100281, Accuracy: 0.6962890625\n",
      "Batch: 103, Loss: 1.0121902227401733, Accuracy: 0.701171875\n",
      "Batch: 104, Loss: 0.8941377401351929, Accuracy: 0.697265625\n",
      "Batch: 105, Loss: 0.9696565866470337, Accuracy: 0.703125\n",
      "Batch: 106, Loss: 0.9258867502212524, Accuracy: 0.7041015625\n",
      "Batch: 107, Loss: 1.0125641822814941, Accuracy: 0.677734375\n",
      "Batch: 108, Loss: 0.9738444089889526, Accuracy: 0.6650390625\n",
      "Batch: 109, Loss: 1.0948572158813477, Accuracy: 0.6552734375\n",
      "Batch: 110, Loss: 0.8353824019432068, Accuracy: 0.734375\n",
      "Batch: 111, Loss: 0.9919891953468323, Accuracy: 0.6826171875\n",
      "Batch: 112, Loss: 0.9358511567115784, Accuracy: 0.6953125\n",
      "Batch: 113, Loss: 0.9692087769508362, Accuracy: 0.6962890625\n",
      "Batch: 114, Loss: 1.052494764328003, Accuracy: 0.65625\n",
      "Batch: 115, Loss: 1.1063523292541504, Accuracy: 0.6552734375\n",
      "Batch: 116, Loss: 1.0164740085601807, Accuracy: 0.681640625\n",
      "Batch: 117, Loss: 1.042342185974121, Accuracy: 0.671875\n",
      "Batch: 120, Loss: 0.9953952431678772, Accuracy: 0.669921875\n",
      "Batch: 121, Loss: 1.0378968715667725, Accuracy: 0.6640625\n",
      "Batch: 122, Loss: 0.9090976119041443, Accuracy: 0.71484375\n",
      "Batch: 123, Loss: 0.9219018220901489, Accuracy: 0.7177734375\n",
      "Batch: 124, Loss: 0.979946494102478, Accuracy: 0.6796875\n",
      "Batch: 125, Loss: 1.032884955406189, Accuracy: 0.6611328125\n",
      "Batch: 126, Loss: 0.9985394477844238, Accuracy: 0.6728515625\n",
      "Batch: 127, Loss: 0.8542072772979736, Accuracy: 0.73828125\n",
      "Batch: 128, Loss: 1.1114614009857178, Accuracy: 0.666015625\n",
      "Batch: 129, Loss: 0.8936899900436401, Accuracy: 0.7109375\n",
      "Batch: 130, Loss: 1.1341582536697388, Accuracy: 0.6474609375\n",
      "Batch: 131, Loss: 1.003791332244873, Accuracy: 0.68359375\n",
      "Batch: 132, Loss: 1.01848566532135, Accuracy: 0.6845703125\n",
      "Batch: 133, Loss: 0.911335289478302, Accuracy: 0.689453125\n",
      "Batch: 134, Loss: 0.9854624271392822, Accuracy: 0.671875\n",
      "Batch: 135, Loss: 0.8860387802124023, Accuracy: 0.716796875\n",
      "Batch: 136, Loss: 0.9561914205551147, Accuracy: 0.6962890625\n",
      "Batch: 137, Loss: 0.8975467681884766, Accuracy: 0.6943359375\n",
      "Batch: 138, Loss: 0.8133509159088135, Accuracy: 0.732421875\n",
      "Batch: 139, Loss: 0.8777444362640381, Accuracy: 0.7119140625\n",
      "Batch: 140, Loss: 0.946384072303772, Accuracy: 0.69140625\n",
      "Batch: 141, Loss: 0.9903305768966675, Accuracy: 0.6904296875\n",
      "Batch: 142, Loss: 1.0224144458770752, Accuracy: 0.671875\n",
      "Batch: 143, Loss: 0.9833403825759888, Accuracy: 0.6904296875\n",
      "Batch: 144, Loss: 0.9548490047454834, Accuracy: 0.6923828125\n",
      "Batch: 145, Loss: 0.9154297113418579, Accuracy: 0.6953125\n",
      "Batch: 146, Loss: 1.018090009689331, Accuracy: 0.677734375\n",
      "Batch: 147, Loss: 0.9769685864448547, Accuracy: 0.6650390625\n",
      "Batch: 148, Loss: 1.0716195106506348, Accuracy: 0.6396484375\n",
      "Batch: 149, Loss: 0.948628306388855, Accuracy: 0.69140625\n",
      "Batch: 150, Loss: 0.9268448948860168, Accuracy: 0.6904296875\n",
      "Batch: 151, Loss: 0.8481496572494507, Accuracy: 0.732421875\n",
      "Epoch 25/80\n",
      "Batch: 1, Loss: 1.2123950719833374, Accuracy: 0.6328125\n",
      "Batch: 2, Loss: 1.0340300798416138, Accuracy: 0.65234375\n",
      "Batch: 3, Loss: 0.9203848838806152, Accuracy: 0.6875\n",
      "Batch: 4, Loss: 0.8630698919296265, Accuracy: 0.7138671875\n",
      "Batch: 5, Loss: 0.9054088592529297, Accuracy: 0.7197265625\n",
      "Batch: 6, Loss: 0.9744105935096741, Accuracy: 0.6748046875\n",
      "Batch: 7, Loss: 0.9277374744415283, Accuracy: 0.69140625\n",
      "Batch: 8, Loss: 0.8882443904876709, Accuracy: 0.705078125\n",
      "Batch: 10, Loss: 0.8850419521331787, Accuracy: 0.703125\n",
      "Batch: 11, Loss: 1.019482135772705, Accuracy: 0.6396484375\n",
      "Batch: 12, Loss: 1.0374422073364258, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 0.7898465394973755, Accuracy: 0.748046875\n",
      "Batch: 14, Loss: 1.0509757995605469, Accuracy: 0.6630859375\n",
      "Batch: 15, Loss: 0.9167171120643616, Accuracy: 0.7109375\n",
      "Batch: 16, Loss: 0.9120423197746277, Accuracy: 0.7099609375\n",
      "Batch: 17, Loss: 0.9654157757759094, Accuracy: 0.6875\n",
      "Batch: 18, Loss: 0.9685689210891724, Accuracy: 0.6748046875\n",
      "Batch: 19, Loss: 1.003535509109497, Accuracy: 0.689453125\n",
      "Batch: 20, Loss: 0.89307701587677, Accuracy: 0.720703125\n",
      "Batch: 21, Loss: 0.9227059483528137, Accuracy: 0.69921875\n",
      "Batch: 22, Loss: 1.019336223602295, Accuracy: 0.677734375\n",
      "Batch: 23, Loss: 0.9546236395835876, Accuracy: 0.677734375\n",
      "Batch: 24, Loss: 0.9555227756500244, Accuracy: 0.6845703125\n",
      "Batch: 25, Loss: 0.9392672777175903, Accuracy: 0.693359375\n",
      "Batch: 26, Loss: 0.8430287837982178, Accuracy: 0.7333984375\n",
      "Batch: 27, Loss: 0.8677794933319092, Accuracy: 0.7109375\n",
      "Batch: 28, Loss: 0.9737122654914856, Accuracy: 0.6796875\n",
      "Batch: 29, Loss: 0.9234582185745239, Accuracy: 0.7001953125\n",
      "Batch: 30, Loss: 0.8923962712287903, Accuracy: 0.7236328125\n",
      "Batch: 31, Loss: 0.8526784777641296, Accuracy: 0.7109375\n",
      "Batch: 32, Loss: 0.863447904586792, Accuracy: 0.716796875\n",
      "Batch: 33, Loss: 1.0530338287353516, Accuracy: 0.66796875\n",
      "Batch: 34, Loss: 1.0932193994522095, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.018357276916504, Accuracy: 0.66796875\n",
      "Batch: 36, Loss: 1.0249311923980713, Accuracy: 0.6806640625\n",
      "Batch: 37, Loss: 0.9509299397468567, Accuracy: 0.69140625\n",
      "Batch: 38, Loss: 0.9834424257278442, Accuracy: 0.654296875\n",
      "Batch: 39, Loss: 0.9521479606628418, Accuracy: 0.697265625\n",
      "Batch: 40, Loss: 0.9641575813293457, Accuracy: 0.6982421875\n",
      "Batch: 41, Loss: 0.9177813529968262, Accuracy: 0.7158203125\n",
      "Batch: 42, Loss: 0.7567498683929443, Accuracy: 0.74609375\n",
      "Batch: 43, Loss: 0.9812082648277283, Accuracy: 0.6796875\n",
      "Batch: 44, Loss: 0.9557032585144043, Accuracy: 0.677734375\n",
      "Batch: 45, Loss: 0.8472377061843872, Accuracy: 0.716796875\n",
      "Batch: 46, Loss: 0.9088022708892822, Accuracy: 0.70703125\n",
      "Batch: 47, Loss: 0.9453955888748169, Accuracy: 0.7041015625\n",
      "Batch: 48, Loss: 0.8524052500724792, Accuracy: 0.72265625\n",
      "Batch: 49, Loss: 1.041917085647583, Accuracy: 0.67578125\n",
      "Batch: 50, Loss: 1.0242246389389038, Accuracy: 0.671875\n",
      "Batch: 51, Loss: 1.050229549407959, Accuracy: 0.6572265625\n",
      "Batch: 52, Loss: 1.046029806137085, Accuracy: 0.6640625\n",
      "Batch: 55, Loss: 1.0298147201538086, Accuracy: 0.6630859375\n",
      "Batch: 56, Loss: 1.0156841278076172, Accuracy: 0.6826171875\n",
      "Batch: 57, Loss: 0.9571936130523682, Accuracy: 0.6982421875\n",
      "Batch: 58, Loss: 1.0368034839630127, Accuracy: 0.6923828125\n",
      "Batch: 59, Loss: 0.890531063079834, Accuracy: 0.71484375\n",
      "Batch: 60, Loss: 0.8747950792312622, Accuracy: 0.7197265625\n",
      "Batch: 61, Loss: 1.0085103511810303, Accuracy: 0.6669921875\n",
      "Batch: 62, Loss: 0.9498752951622009, Accuracy: 0.705078125\n",
      "Batch: 63, Loss: 1.0044752359390259, Accuracy: 0.6767578125\n",
      "Batch: 64, Loss: 0.9482861757278442, Accuracy: 0.69921875\n",
      "Batch: 65, Loss: 0.9655455350875854, Accuracy: 0.6923828125\n",
      "Batch: 66, Loss: 0.9403582811355591, Accuracy: 0.69921875\n",
      "Batch: 67, Loss: 1.0183885097503662, Accuracy: 0.677734375\n",
      "Batch: 68, Loss: 1.0609796047210693, Accuracy: 0.677734375\n",
      "Batch: 69, Loss: 0.9372633695602417, Accuracy: 0.70703125\n",
      "Batch: 70, Loss: 0.9419298768043518, Accuracy: 0.7080078125\n",
      "Batch: 71, Loss: 0.977566123008728, Accuracy: 0.6689453125\n",
      "Batch: 72, Loss: 0.8395063281059265, Accuracy: 0.7158203125\n",
      "Batch: 73, Loss: 0.8895466923713684, Accuracy: 0.71875\n",
      "Batch: 74, Loss: 0.8605809211730957, Accuracy: 0.7158203125\n",
      "Batch: 75, Loss: 0.8791273236274719, Accuracy: 0.7265625\n",
      "Batch: 76, Loss: 0.9597962498664856, Accuracy: 0.6865234375\n",
      "Batch: 77, Loss: 0.9184709191322327, Accuracy: 0.7060546875\n",
      "Batch: 78, Loss: 0.9149829149246216, Accuracy: 0.7080078125\n",
      "Batch: 79, Loss: 0.8654170036315918, Accuracy: 0.7265625\n",
      "Batch: 80, Loss: 0.8899728655815125, Accuracy: 0.689453125\n",
      "Batch: 81, Loss: 1.051500916481018, Accuracy: 0.6494140625\n",
      "Batch: 82, Loss: 0.986791729927063, Accuracy: 0.6796875\n",
      "Batch: 83, Loss: 0.846686840057373, Accuracy: 0.7314453125\n",
      "Batch: 84, Loss: 0.9323463439941406, Accuracy: 0.705078125\n",
      "Batch: 85, Loss: 0.8583320379257202, Accuracy: 0.72265625\n",
      "Batch: 86, Loss: 1.0885834693908691, Accuracy: 0.6552734375\n",
      "Batch: 87, Loss: 0.8775844573974609, Accuracy: 0.72265625\n",
      "Batch: 88, Loss: 0.9878503084182739, Accuracy: 0.6982421875\n",
      "Batch: 89, Loss: 0.9731446504592896, Accuracy: 0.7001953125\n",
      "Batch: 90, Loss: 0.8864071369171143, Accuracy: 0.7158203125\n",
      "Batch: 91, Loss: 0.934376060962677, Accuracy: 0.6875\n",
      "Batch: 92, Loss: 0.9518424868583679, Accuracy: 0.6923828125\n",
      "Batch: 93, Loss: 0.8945200443267822, Accuracy: 0.716796875\n",
      "Batch: 94, Loss: 0.927783727645874, Accuracy: 0.69140625\n",
      "Batch: 95, Loss: 0.9773997664451599, Accuracy: 0.6767578125\n",
      "Batch: 96, Loss: 0.9149539470672607, Accuracy: 0.705078125\n",
      "Batch: 97, Loss: 0.7853761911392212, Accuracy: 0.7421875\n",
      "Batch: 98, Loss: 0.8521103262901306, Accuracy: 0.734375\n",
      "Batch: 99, Loss: 0.869025707244873, Accuracy: 0.712890625\n",
      "Batch: 100, Loss: 0.8898463249206543, Accuracy: 0.71875\n",
      "Batch: 101, Loss: 0.998214840888977, Accuracy: 0.6796875\n",
      "Batch: 102, Loss: 0.9211220741271973, Accuracy: 0.7080078125\n",
      "Batch: 103, Loss: 0.9668506383895874, Accuracy: 0.7119140625\n",
      "Batch: 104, Loss: 0.8582342863082886, Accuracy: 0.712890625\n",
      "Batch: 105, Loss: 0.9767266511917114, Accuracy: 0.69140625\n",
      "Batch: 106, Loss: 0.9261273741722107, Accuracy: 0.7001953125\n",
      "Batch: 107, Loss: 0.9790753722190857, Accuracy: 0.6875\n",
      "Batch: 108, Loss: 0.9595426321029663, Accuracy: 0.681640625\n",
      "Batch: 109, Loss: 1.050092339515686, Accuracy: 0.6494140625\n",
      "Batch: 110, Loss: 0.8182133436203003, Accuracy: 0.7373046875\n",
      "Batch: 111, Loss: 0.9625018239021301, Accuracy: 0.689453125\n",
      "Batch: 112, Loss: 0.9669585824012756, Accuracy: 0.703125\n",
      "Batch: 113, Loss: 0.9558436870574951, Accuracy: 0.693359375\n",
      "Batch: 114, Loss: 1.0387637615203857, Accuracy: 0.6591796875\n",
      "Batch: 115, Loss: 1.0895283222198486, Accuracy: 0.6611328125\n",
      "Batch: 116, Loss: 1.0225467681884766, Accuracy: 0.69140625\n",
      "Batch: 117, Loss: 1.012850046157837, Accuracy: 0.6689453125\n",
      "Batch: 118, Loss: 0.8552244901657104, Accuracy: 0.7294921875\n",
      "Batch: 119, Loss: 0.8210582733154297, Accuracy: 0.7431640625\n",
      "Batch: 120, Loss: 0.9793332815170288, Accuracy: 0.6826171875\n",
      "Batch: 121, Loss: 1.015481948852539, Accuracy: 0.6640625\n",
      "Batch: 122, Loss: 0.92894446849823, Accuracy: 0.7001953125\n",
      "Batch: 123, Loss: 0.8862866759300232, Accuracy: 0.7119140625\n",
      "Batch: 124, Loss: 0.9750734567642212, Accuracy: 0.67578125\n",
      "Batch: 125, Loss: 1.0228910446166992, Accuracy: 0.6728515625\n",
      "Batch: 126, Loss: 1.0079100131988525, Accuracy: 0.6767578125\n",
      "Batch: 127, Loss: 0.8779492974281311, Accuracy: 0.7236328125\n",
      "Batch: 128, Loss: 1.0578036308288574, Accuracy: 0.6826171875\n",
      "Batch: 129, Loss: 0.8980953693389893, Accuracy: 0.7080078125\n",
      "Batch: 130, Loss: 1.082440972328186, Accuracy: 0.640625\n",
      "Batch: 131, Loss: 1.0054277181625366, Accuracy: 0.6708984375\n",
      "Batch: 132, Loss: 0.9928061962127686, Accuracy: 0.6953125\n",
      "Batch: 133, Loss: 0.901898980140686, Accuracy: 0.69921875\n",
      "Batch: 134, Loss: 0.9963657855987549, Accuracy: 0.669921875\n",
      "Batch: 135, Loss: 0.8866122364997864, Accuracy: 0.7216796875\n",
      "Batch: 136, Loss: 0.9196565747261047, Accuracy: 0.7001953125\n",
      "Batch: 137, Loss: 0.9235234260559082, Accuracy: 0.6953125\n",
      "Batch: 138, Loss: 0.8165194392204285, Accuracy: 0.7431640625\n",
      "Batch: 139, Loss: 0.870444655418396, Accuracy: 0.7138671875\n",
      "Batch: 140, Loss: 0.922874927520752, Accuracy: 0.6953125\n",
      "Batch: 141, Loss: 0.9679016470909119, Accuracy: 0.6953125\n",
      "Batch: 142, Loss: 1.020808219909668, Accuracy: 0.6572265625\n",
      "Batch: 143, Loss: 0.9621832966804504, Accuracy: 0.685546875\n",
      "Batch: 144, Loss: 0.9449754953384399, Accuracy: 0.703125\n",
      "Batch: 145, Loss: 0.9189893007278442, Accuracy: 0.6953125\n",
      "Batch: 146, Loss: 0.9769404530525208, Accuracy: 0.6865234375\n",
      "Batch: 149, Loss: 0.93131023645401, Accuracy: 0.6884765625\n",
      "Batch: 150, Loss: 0.9184836149215698, Accuracy: 0.712890625\n",
      "Batch: 151, Loss: 0.8286479711532593, Accuracy: 0.73828125\n",
      "Epoch 26/80\n",
      "Batch: 1, Loss: 1.2190520763397217, Accuracy: 0.626953125\n",
      "Batch: 2, Loss: 1.0007431507110596, Accuracy: 0.6533203125\n",
      "Batch: 3, Loss: 0.8764408230781555, Accuracy: 0.712890625\n",
      "Batch: 4, Loss: 0.8480355739593506, Accuracy: 0.73046875\n",
      "Batch: 5, Loss: 0.8824225664138794, Accuracy: 0.72265625\n",
      "Batch: 6, Loss: 0.9675626754760742, Accuracy: 0.6865234375\n",
      "Batch: 7, Loss: 0.9334144592285156, Accuracy: 0.6787109375\n",
      "Batch: 8, Loss: 0.8744316101074219, Accuracy: 0.703125\n",
      "Batch: 9, Loss: 0.859645426273346, Accuracy: 0.71875\n",
      "Batch: 10, Loss: 0.8592128753662109, Accuracy: 0.7060546875\n",
      "Batch: 11, Loss: 1.0037354230880737, Accuracy: 0.6650390625\n",
      "Batch: 12, Loss: 1.01899254322052, Accuracy: 0.6796875\n",
      "Batch: 13, Loss: 0.7924813032150269, Accuracy: 0.744140625\n",
      "Batch: 14, Loss: 1.0263575315475464, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 0.9006015062332153, Accuracy: 0.7177734375\n",
      "Batch: 16, Loss: 0.9090633392333984, Accuracy: 0.7265625\n",
      "Batch: 17, Loss: 0.9658318758010864, Accuracy: 0.689453125\n",
      "Batch: 18, Loss: 0.950111985206604, Accuracy: 0.6865234375\n",
      "Batch: 19, Loss: 0.9880918264389038, Accuracy: 0.6826171875\n",
      "Batch: 20, Loss: 0.8790605068206787, Accuracy: 0.724609375\n",
      "Batch: 21, Loss: 0.9027991890907288, Accuracy: 0.701171875\n",
      "Batch: 22, Loss: 1.0046775341033936, Accuracy: 0.6904296875\n",
      "Batch: 23, Loss: 0.9413629770278931, Accuracy: 0.6708984375\n",
      "Batch: 24, Loss: 0.956613302230835, Accuracy: 0.6796875\n",
      "Batch: 25, Loss: 0.9421459436416626, Accuracy: 0.7060546875\n",
      "Batch: 26, Loss: 0.81512451171875, Accuracy: 0.7529296875\n",
      "Batch: 27, Loss: 0.8600731492042542, Accuracy: 0.7041015625\n",
      "Batch: 28, Loss: 0.9472073316574097, Accuracy: 0.6923828125\n",
      "Batch: 29, Loss: 0.9238411784172058, Accuracy: 0.7041015625\n",
      "Batch: 30, Loss: 0.8780713081359863, Accuracy: 0.7236328125\n",
      "Batch: 31, Loss: 0.8424049615859985, Accuracy: 0.7333984375\n",
      "Batch: 32, Loss: 0.8382787704467773, Accuracy: 0.7177734375\n",
      "Batch: 33, Loss: 1.0375505685806274, Accuracy: 0.6708984375\n",
      "Batch: 34, Loss: 1.0566455125808716, Accuracy: 0.6669921875\n",
      "Batch: 35, Loss: 0.9926480054855347, Accuracy: 0.671875\n",
      "Batch: 36, Loss: 0.9992114305496216, Accuracy: 0.693359375\n",
      "Batch: 37, Loss: 0.933617353439331, Accuracy: 0.697265625\n",
      "Batch: 38, Loss: 0.9746661186218262, Accuracy: 0.6845703125\n",
      "Batch: 42, Loss: 0.7544701099395752, Accuracy: 0.7587890625\n",
      "Batch: 43, Loss: 0.9713478088378906, Accuracy: 0.6787109375\n",
      "Batch: 44, Loss: 0.9754335880279541, Accuracy: 0.6875\n",
      "Batch: 45, Loss: 0.8513680100440979, Accuracy: 0.7041015625\n",
      "Batch: 46, Loss: 0.9011520147323608, Accuracy: 0.7099609375\n",
      "Batch: 47, Loss: 0.9145943522453308, Accuracy: 0.7119140625\n",
      "Batch: 48, Loss: 0.8510980606079102, Accuracy: 0.71875\n",
      "Batch: 49, Loss: 1.0134549140930176, Accuracy: 0.666015625\n",
      "Batch: 50, Loss: 1.015866756439209, Accuracy: 0.6748046875\n",
      "Batch: 51, Loss: 1.0456604957580566, Accuracy: 0.65234375\n",
      "Batch: 52, Loss: 1.026491641998291, Accuracy: 0.6630859375\n",
      "Batch: 53, Loss: 0.8567372560501099, Accuracy: 0.7197265625\n",
      "Batch: 54, Loss: 0.9295189380645752, Accuracy: 0.6943359375\n",
      "Batch: 55, Loss: 1.0325393676757812, Accuracy: 0.658203125\n",
      "Batch: 56, Loss: 1.0190776586532593, Accuracy: 0.6748046875\n",
      "Batch: 57, Loss: 0.9418634176254272, Accuracy: 0.6982421875\n",
      "Batch: 58, Loss: 1.0359532833099365, Accuracy: 0.69921875\n",
      "Batch: 59, Loss: 0.8749860525131226, Accuracy: 0.71875\n",
      "Batch: 60, Loss: 0.8693376779556274, Accuracy: 0.7109375\n",
      "Batch: 61, Loss: 0.9681432247161865, Accuracy: 0.6787109375\n",
      "Batch: 62, Loss: 0.9227971434593201, Accuracy: 0.705078125\n",
      "Batch: 63, Loss: 1.001217246055603, Accuracy: 0.67578125\n",
      "Batch: 64, Loss: 0.925775408744812, Accuracy: 0.6953125\n",
      "Batch: 65, Loss: 0.9762980937957764, Accuracy: 0.69921875\n",
      "Batch: 66, Loss: 0.894025444984436, Accuracy: 0.7080078125\n",
      "Batch: 67, Loss: 1.0184080600738525, Accuracy: 0.6806640625\n",
      "Batch: 68, Loss: 1.051692247390747, Accuracy: 0.6708984375\n",
      "Batch: 69, Loss: 0.9772727489471436, Accuracy: 0.7001953125\n",
      "Batch: 70, Loss: 0.9446337819099426, Accuracy: 0.712890625\n",
      "Batch: 71, Loss: 0.9691792726516724, Accuracy: 0.6806640625\n",
      "Batch: 72, Loss: 0.838241457939148, Accuracy: 0.724609375\n",
      "Batch: 73, Loss: 0.8864953517913818, Accuracy: 0.71484375\n",
      "Batch: 74, Loss: 0.8448750972747803, Accuracy: 0.74609375\n",
      "Batch: 75, Loss: 0.8566839098930359, Accuracy: 0.7236328125\n",
      "Batch: 76, Loss: 0.9618653059005737, Accuracy: 0.6904296875\n",
      "Batch: 77, Loss: 0.922661304473877, Accuracy: 0.697265625\n",
      "Batch: 78, Loss: 0.910272479057312, Accuracy: 0.712890625\n",
      "Batch: 79, Loss: 0.839439868927002, Accuracy: 0.7490234375\n",
      "Batch: 80, Loss: 0.9106024503707886, Accuracy: 0.69921875\n",
      "Batch: 81, Loss: 1.0135939121246338, Accuracy: 0.650390625\n",
      "Batch: 82, Loss: 0.9899932146072388, Accuracy: 0.669921875\n",
      "Batch: 83, Loss: 0.8185775279998779, Accuracy: 0.7509765625\n",
      "Batch: 84, Loss: 0.8801746368408203, Accuracy: 0.7314453125\n",
      "Batch: 87, Loss: 0.8638592958450317, Accuracy: 0.73046875\n",
      "Batch: 88, Loss: 1.0045020580291748, Accuracy: 0.7080078125\n",
      "Batch: 89, Loss: 0.9640724062919617, Accuracy: 0.7041015625\n",
      "Batch: 90, Loss: 0.895773708820343, Accuracy: 0.7236328125\n",
      "Batch: 91, Loss: 0.9229394197463989, Accuracy: 0.6943359375\n",
      "Batch: 92, Loss: 0.9301191568374634, Accuracy: 0.6845703125\n",
      "Batch: 93, Loss: 0.9291932582855225, Accuracy: 0.7001953125\n",
      "Batch: 94, Loss: 0.9329445362091064, Accuracy: 0.6943359375\n",
      "Batch: 95, Loss: 0.9754170179367065, Accuracy: 0.662109375\n",
      "Batch: 96, Loss: 0.9110714793205261, Accuracy: 0.7158203125\n",
      "Batch: 97, Loss: 0.7905164361000061, Accuracy: 0.7255859375\n",
      "Batch: 98, Loss: 0.8286632299423218, Accuracy: 0.7275390625\n",
      "Batch: 99, Loss: 0.8804563879966736, Accuracy: 0.7236328125\n",
      "Batch: 100, Loss: 0.8976258039474487, Accuracy: 0.7119140625\n",
      "Batch: 101, Loss: 0.972731351852417, Accuracy: 0.6962890625\n",
      "Batch: 102, Loss: 0.8961722254753113, Accuracy: 0.6953125\n",
      "Batch: 103, Loss: 0.9927739500999451, Accuracy: 0.6845703125\n",
      "Batch: 104, Loss: 0.8598397970199585, Accuracy: 0.7216796875\n",
      "Batch: 105, Loss: 0.9522966146469116, Accuracy: 0.69140625\n",
      "Batch: 106, Loss: 0.9059730768203735, Accuracy: 0.7236328125\n",
      "Batch: 107, Loss: 0.9709821343421936, Accuracy: 0.6962890625\n",
      "Batch: 108, Loss: 0.927882194519043, Accuracy: 0.697265625\n",
      "Batch: 109, Loss: 1.054717779159546, Accuracy: 0.6611328125\n",
      "Batch: 110, Loss: 0.8032121658325195, Accuracy: 0.7431640625\n",
      "Batch: 111, Loss: 0.9443553686141968, Accuracy: 0.7041015625\n",
      "Batch: 112, Loss: 0.9335314035415649, Accuracy: 0.7021484375\n",
      "Batch: 113, Loss: 0.920673131942749, Accuracy: 0.7001953125\n",
      "Batch: 114, Loss: 1.0197155475616455, Accuracy: 0.6650390625\n",
      "Batch: 115, Loss: 1.0929135084152222, Accuracy: 0.6796875\n",
      "Batch: 116, Loss: 1.0005172491073608, Accuracy: 0.68359375\n",
      "Batch: 117, Loss: 0.989776074886322, Accuracy: 0.6767578125\n",
      "Batch: 118, Loss: 0.8276321291923523, Accuracy: 0.7373046875\n",
      "Batch: 119, Loss: 0.8154729604721069, Accuracy: 0.73046875\n",
      "Batch: 120, Loss: 0.9768027067184448, Accuracy: 0.6806640625\n",
      "Batch: 121, Loss: 1.0087989568710327, Accuracy: 0.6630859375\n",
      "Batch: 122, Loss: 0.8730458617210388, Accuracy: 0.7197265625\n",
      "Batch: 123, Loss: 0.9001253247261047, Accuracy: 0.716796875\n",
      "Batch: 124, Loss: 0.9655653238296509, Accuracy: 0.689453125\n",
      "Batch: 125, Loss: 0.9973222613334656, Accuracy: 0.681640625\n",
      "Batch: 126, Loss: 0.9710221290588379, Accuracy: 0.6875\n",
      "Batch: 127, Loss: 0.868241012096405, Accuracy: 0.724609375\n",
      "Batch: 128, Loss: 1.0456475019454956, Accuracy: 0.6875\n",
      "Batch: 129, Loss: 0.8725742101669312, Accuracy: 0.7099609375\n",
      "Batch: 132, Loss: 0.9727897644042969, Accuracy: 0.6962890625\n",
      "Batch: 133, Loss: 0.8986985683441162, Accuracy: 0.6943359375\n",
      "Batch: 134, Loss: 0.9572382569313049, Accuracy: 0.6865234375\n",
      "Batch: 135, Loss: 0.866482675075531, Accuracy: 0.7333984375\n",
      "Batch: 136, Loss: 0.9219259023666382, Accuracy: 0.701171875\n",
      "Batch: 137, Loss: 0.8757001757621765, Accuracy: 0.7099609375\n",
      "Batch: 138, Loss: 0.8158543109893799, Accuracy: 0.736328125\n",
      "Batch: 139, Loss: 0.8573148250579834, Accuracy: 0.703125\n",
      "Batch: 140, Loss: 0.9037816524505615, Accuracy: 0.697265625\n",
      "Batch: 141, Loss: 0.9468767046928406, Accuracy: 0.6865234375\n",
      "Batch: 142, Loss: 1.0015456676483154, Accuracy: 0.685546875\n",
      "Batch: 143, Loss: 0.9581686854362488, Accuracy: 0.6865234375\n",
      "Batch: 144, Loss: 0.9581378698348999, Accuracy: 0.6923828125\n",
      "Batch: 145, Loss: 0.895343542098999, Accuracy: 0.6923828125\n",
      "Batch: 146, Loss: 0.976781964302063, Accuracy: 0.6826171875\n",
      "Batch: 147, Loss: 0.9716297388076782, Accuracy: 0.669921875\n",
      "Batch: 148, Loss: 1.064559817314148, Accuracy: 0.6572265625\n",
      "Batch: 149, Loss: 0.9231740236282349, Accuracy: 0.6923828125\n",
      "Batch: 150, Loss: 0.8971269130706787, Accuracy: 0.6953125\n",
      "Batch: 151, Loss: 0.8311187624931335, Accuracy: 0.7255859375\n",
      "Epoch 27/80\n",
      "Batch: 1, Loss: 1.2486318349838257, Accuracy: 0.607421875\n",
      "Batch: 2, Loss: 1.0234003067016602, Accuracy: 0.6552734375\n",
      "Batch: 3, Loss: 0.9144206047058105, Accuracy: 0.6943359375\n",
      "Batch: 4, Loss: 0.8408470153808594, Accuracy: 0.734375\n",
      "Batch: 5, Loss: 0.8775793313980103, Accuracy: 0.7314453125\n",
      "Batch: 6, Loss: 0.9502100944519043, Accuracy: 0.6953125\n",
      "Batch: 7, Loss: 0.9437296390533447, Accuracy: 0.6591796875\n",
      "Batch: 8, Loss: 0.8560510277748108, Accuracy: 0.71875\n",
      "Batch: 9, Loss: 0.8293304443359375, Accuracy: 0.7421875\n",
      "Batch: 10, Loss: 0.8569579124450684, Accuracy: 0.720703125\n",
      "Batch: 11, Loss: 1.0112653970718384, Accuracy: 0.6435546875\n",
      "Batch: 12, Loss: 1.0177162885665894, Accuracy: 0.66796875\n",
      "Batch: 13, Loss: 0.776370644569397, Accuracy: 0.736328125\n",
      "Batch: 14, Loss: 1.0465909242630005, Accuracy: 0.6611328125\n",
      "Batch: 15, Loss: 0.8832384943962097, Accuracy: 0.728515625\n",
      "Batch: 16, Loss: 0.8881602883338928, Accuracy: 0.7265625\n",
      "Batch: 17, Loss: 0.9496853351593018, Accuracy: 0.6982421875\n",
      "Batch: 18, Loss: 0.9519469141960144, Accuracy: 0.6796875\n",
      "Batch: 19, Loss: 0.9606399536132812, Accuracy: 0.6904296875\n",
      "Batch: 20, Loss: 0.8451420068740845, Accuracy: 0.7431640625\n",
      "Batch: 21, Loss: 0.8885465860366821, Accuracy: 0.693359375\n",
      "Batch: 22, Loss: 0.9769434332847595, Accuracy: 0.6923828125\n",
      "Batch: 23, Loss: 0.9356374740600586, Accuracy: 0.6845703125\n",
      "Batch: 24, Loss: 0.9580091834068298, Accuracy: 0.68359375\n",
      "Batch: 25, Loss: 0.9122626781463623, Accuracy: 0.70703125\n",
      "Batch: 26, Loss: 0.8191264867782593, Accuracy: 0.736328125\n",
      "Batch: 27, Loss: 0.8604694604873657, Accuracy: 0.7041015625\n",
      "Batch: 28, Loss: 0.942645251750946, Accuracy: 0.6865234375\n",
      "Batch: 29, Loss: 0.9208640456199646, Accuracy: 0.708984375\n",
      "Batch: 30, Loss: 0.8761005401611328, Accuracy: 0.7314453125\n",
      "Batch: 31, Loss: 0.8522011041641235, Accuracy: 0.724609375\n",
      "Batch: 32, Loss: 0.8393901586532593, Accuracy: 0.7177734375\n",
      "Batch: 33, Loss: 0.9868565797805786, Accuracy: 0.673828125\n",
      "Batch: 34, Loss: 1.0542463064193726, Accuracy: 0.662109375\n",
      "Batch: 35, Loss: 0.980103075504303, Accuracy: 0.6796875\n",
      "Batch: 36, Loss: 1.0012807846069336, Accuracy: 0.6826171875\n",
      "Batch: 37, Loss: 0.8992853760719299, Accuracy: 0.7177734375\n",
      "Batch: 38, Loss: 0.9533045887947083, Accuracy: 0.6953125\n",
      "Batch: 39, Loss: 0.9784854054450989, Accuracy: 0.6923828125\n",
      "Batch: 40, Loss: 0.9348344802856445, Accuracy: 0.7119140625\n",
      "Batch: 41, Loss: 0.8717343807220459, Accuracy: 0.728515625\n",
      "Batch: 42, Loss: 0.7321566343307495, Accuracy: 0.7568359375\n",
      "Batch: 43, Loss: 0.9444226026535034, Accuracy: 0.6962890625\n",
      "Batch: 44, Loss: 0.9393365979194641, Accuracy: 0.689453125\n",
      "Batch: 45, Loss: 0.8432192206382751, Accuracy: 0.7236328125\n",
      "Batch: 46, Loss: 0.9030289649963379, Accuracy: 0.708984375\n",
      "Batch: 47, Loss: 0.9310795664787292, Accuracy: 0.70703125\n",
      "Batch: 48, Loss: 0.8236453533172607, Accuracy: 0.7255859375\n",
      "Batch: 49, Loss: 1.0009713172912598, Accuracy: 0.6708984375\n",
      "Batch: 50, Loss: 1.0001929998397827, Accuracy: 0.6806640625\n",
      "Batch: 51, Loss: 1.0155723094940186, Accuracy: 0.6630859375\n",
      "Batch: 52, Loss: 1.0047043561935425, Accuracy: 0.6884765625\n",
      "Batch: 53, Loss: 0.8694949746131897, Accuracy: 0.71484375\n",
      "Batch: 54, Loss: 0.9255605936050415, Accuracy: 0.689453125\n",
      "Batch: 55, Loss: 1.0122780799865723, Accuracy: 0.6650390625\n",
      "Batch: 56, Loss: 0.970366895198822, Accuracy: 0.6845703125\n",
      "Batch: 57, Loss: 0.94469153881073, Accuracy: 0.7021484375\n",
      "Batch: 58, Loss: 1.0071237087249756, Accuracy: 0.6904296875\n",
      "Batch: 59, Loss: 0.8618005514144897, Accuracy: 0.7255859375\n",
      "Batch: 60, Loss: 0.8487691283226013, Accuracy: 0.7275390625\n",
      "Batch: 61, Loss: 0.9667460918426514, Accuracy: 0.6875\n",
      "Batch: 62, Loss: 0.920629620552063, Accuracy: 0.703125\n",
      "Batch: 63, Loss: 0.9685750007629395, Accuracy: 0.6806640625\n",
      "Batch: 64, Loss: 0.9169301986694336, Accuracy: 0.7060546875\n",
      "Batch: 65, Loss: 0.9443881511688232, Accuracy: 0.71484375\n",
      "Batch: 66, Loss: 0.8943061828613281, Accuracy: 0.708984375\n",
      "Batch: 67, Loss: 1.011583685874939, Accuracy: 0.671875\n",
      "Batch: 68, Loss: 1.0449260473251343, Accuracy: 0.66796875\n",
      "Batch: 69, Loss: 0.9520555734634399, Accuracy: 0.6923828125\n",
      "Batch: 70, Loss: 0.9170610308647156, Accuracy: 0.720703125\n",
      "Batch: 71, Loss: 0.9525579214096069, Accuracy: 0.6884765625\n",
      "Batch: 72, Loss: 0.8306946754455566, Accuracy: 0.732421875\n",
      "Batch: 73, Loss: 0.8789406418800354, Accuracy: 0.720703125\n",
      "Batch: 74, Loss: 0.846758246421814, Accuracy: 0.7275390625\n",
      "Batch: 75, Loss: 0.8451250791549683, Accuracy: 0.728515625\n",
      "Batch: 76, Loss: 0.939160168170929, Accuracy: 0.681640625\n",
      "Batch: 77, Loss: 0.8773550987243652, Accuracy: 0.71484375\n",
      "Batch: 78, Loss: 0.8842476606369019, Accuracy: 0.720703125\n",
      "Batch: 79, Loss: 0.8400267362594604, Accuracy: 0.732421875\n",
      "Batch: 80, Loss: 0.8916536569595337, Accuracy: 0.693359375\n",
      "Batch: 81, Loss: 0.9666675329208374, Accuracy: 0.67578125\n",
      "Batch: 82, Loss: 0.9642374515533447, Accuracy: 0.677734375\n",
      "Batch: 83, Loss: 0.8282352685928345, Accuracy: 0.7529296875\n",
      "Batch: 84, Loss: 0.8773928880691528, Accuracy: 0.7177734375\n",
      "Batch: 85, Loss: 0.8345510363578796, Accuracy: 0.73046875\n",
      "Batch: 86, Loss: 1.0752145051956177, Accuracy: 0.6455078125\n",
      "Batch: 87, Loss: 0.8603603839874268, Accuracy: 0.7197265625\n",
      "Batch: 88, Loss: 0.9826552867889404, Accuracy: 0.6962890625\n",
      "Batch: 89, Loss: 0.968341052532196, Accuracy: 0.7109375\n",
      "Batch: 90, Loss: 0.878446638584137, Accuracy: 0.7177734375\n",
      "Batch: 91, Loss: 0.8924692869186401, Accuracy: 0.7099609375\n",
      "Batch: 92, Loss: 0.9263907670974731, Accuracy: 0.6904296875\n",
      "Batch: 93, Loss: 0.8952776193618774, Accuracy: 0.7099609375\n",
      "Batch: 94, Loss: 0.9072924256324768, Accuracy: 0.6953125\n",
      "Batch: 95, Loss: 0.9804979562759399, Accuracy: 0.666015625\n",
      "Batch: 96, Loss: 0.889843761920929, Accuracy: 0.7060546875\n",
      "Batch: 97, Loss: 0.7572798728942871, Accuracy: 0.73828125\n",
      "Batch: 98, Loss: 0.8298155069351196, Accuracy: 0.7353515625\n",
      "Batch: 99, Loss: 0.8511667847633362, Accuracy: 0.7373046875\n",
      "Batch: 100, Loss: 0.86161208152771, Accuracy: 0.7392578125\n",
      "Batch: 101, Loss: 0.9752167463302612, Accuracy: 0.69921875\n",
      "Batch: 102, Loss: 0.8970513939857483, Accuracy: 0.7138671875\n",
      "Batch: 103, Loss: 0.9476211667060852, Accuracy: 0.712890625\n",
      "Batch: 104, Loss: 0.8356932997703552, Accuracy: 0.7197265625\n",
      "Batch: 105, Loss: 0.9302371740341187, Accuracy: 0.70703125\n",
      "Batch: 106, Loss: 0.8821132183074951, Accuracy: 0.724609375\n",
      "Batch: 107, Loss: 0.9699597358703613, Accuracy: 0.693359375\n",
      "Batch: 108, Loss: 0.9306650161743164, Accuracy: 0.68359375\n",
      "Batch: 109, Loss: 1.0487382411956787, Accuracy: 0.654296875\n",
      "Batch: 110, Loss: 0.7836573719978333, Accuracy: 0.736328125\n",
      "Batch: 111, Loss: 0.9386745691299438, Accuracy: 0.6943359375\n",
      "Batch: 114, Loss: 1.0075714588165283, Accuracy: 0.6728515625\n",
      "Batch: 115, Loss: 1.0723776817321777, Accuracy: 0.6826171875\n",
      "Batch: 116, Loss: 0.985543966293335, Accuracy: 0.67578125\n",
      "Batch: 117, Loss: 0.9906197786331177, Accuracy: 0.6875\n",
      "Batch: 118, Loss: 0.8067556619644165, Accuracy: 0.7412109375\n",
      "Batch: 119, Loss: 0.8103985786437988, Accuracy: 0.736328125\n",
      "Batch: 120, Loss: 0.9656518697738647, Accuracy: 0.6884765625\n",
      "Batch: 121, Loss: 0.993805468082428, Accuracy: 0.6689453125\n",
      "Batch: 122, Loss: 0.8994615077972412, Accuracy: 0.7099609375\n",
      "Batch: 123, Loss: 0.8732411861419678, Accuracy: 0.72265625\n",
      "Batch: 124, Loss: 0.9424589276313782, Accuracy: 0.701171875\n",
      "Batch: 125, Loss: 1.020730972290039, Accuracy: 0.67578125\n",
      "Batch: 126, Loss: 0.96784907579422, Accuracy: 0.6826171875\n",
      "Batch: 127, Loss: 0.833898663520813, Accuracy: 0.7451171875\n",
      "Batch: 128, Loss: 1.0490543842315674, Accuracy: 0.6904296875\n",
      "Batch: 129, Loss: 0.8693950772285461, Accuracy: 0.7197265625\n",
      "Batch: 130, Loss: 1.074284553527832, Accuracy: 0.6611328125\n",
      "Batch: 131, Loss: 0.9754456877708435, Accuracy: 0.6826171875\n",
      "Batch: 132, Loss: 1.0037164688110352, Accuracy: 0.6806640625\n",
      "Batch: 133, Loss: 0.868834912776947, Accuracy: 0.7041015625\n",
      "Batch: 134, Loss: 0.9734976291656494, Accuracy: 0.6787109375\n",
      "Batch: 135, Loss: 0.8418315649032593, Accuracy: 0.736328125\n",
      "Batch: 136, Loss: 0.9151109457015991, Accuracy: 0.7041015625\n",
      "Batch: 137, Loss: 0.8739462494850159, Accuracy: 0.712890625\n",
      "Batch: 138, Loss: 0.8071280717849731, Accuracy: 0.73046875\n",
      "Batch: 139, Loss: 0.839293897151947, Accuracy: 0.7119140625\n",
      "Batch: 140, Loss: 0.9094463586807251, Accuracy: 0.69921875\n",
      "Batch: 141, Loss: 0.955828845500946, Accuracy: 0.685546875\n",
      "Batch: 142, Loss: 1.0163518190383911, Accuracy: 0.6728515625\n",
      "Batch: 143, Loss: 0.9570651054382324, Accuracy: 0.6884765625\n",
      "Batch: 144, Loss: 0.9304392337799072, Accuracy: 0.705078125\n",
      "Batch: 145, Loss: 0.8648704290390015, Accuracy: 0.705078125\n",
      "Batch: 146, Loss: 0.9836238622665405, Accuracy: 0.673828125\n",
      "Batch: 147, Loss: 0.962704598903656, Accuracy: 0.6875\n",
      "Batch: 148, Loss: 1.044384479522705, Accuracy: 0.654296875\n",
      "Batch: 149, Loss: 0.9195318222045898, Accuracy: 0.7109375\n",
      "Batch: 150, Loss: 0.8959288001060486, Accuracy: 0.705078125\n",
      "Batch: 151, Loss: 0.817901074886322, Accuracy: 0.73828125\n",
      "Epoch 28/80\n",
      "Batch: 1, Loss: 1.1696016788482666, Accuracy: 0.6240234375\n",
      "Batch: 2, Loss: 0.9674094319343567, Accuracy: 0.669921875\n",
      "Batch: 3, Loss: 0.8933466672897339, Accuracy: 0.701171875\n",
      "Batch: 4, Loss: 0.8018887042999268, Accuracy: 0.748046875\n",
      "Batch: 5, Loss: 0.8897808790206909, Accuracy: 0.720703125\n",
      "Batch: 6, Loss: 0.9651163220405579, Accuracy: 0.68359375\n",
      "Batch: 10, Loss: 0.8464757204055786, Accuracy: 0.71875\n",
      "Batch: 11, Loss: 0.9851604700088501, Accuracy: 0.6708984375\n",
      "Batch: 12, Loss: 0.9785789847373962, Accuracy: 0.6865234375\n",
      "Batch: 13, Loss: 0.7545920610427856, Accuracy: 0.7529296875\n",
      "Batch: 14, Loss: 1.0228992700576782, Accuracy: 0.6591796875\n",
      "Batch: 15, Loss: 0.868966281414032, Accuracy: 0.7236328125\n",
      "Batch: 16, Loss: 0.8745442032814026, Accuracy: 0.7265625\n",
      "Batch: 17, Loss: 0.9384192228317261, Accuracy: 0.703125\n",
      "Batch: 18, Loss: 0.9127089977264404, Accuracy: 0.69921875\n",
      "Batch: 19, Loss: 0.9364644885063171, Accuracy: 0.7060546875\n",
      "Batch: 20, Loss: 0.8637275099754333, Accuracy: 0.732421875\n",
      "Batch: 21, Loss: 0.8684701919555664, Accuracy: 0.7177734375\n",
      "Batch: 22, Loss: 1.0237832069396973, Accuracy: 0.6787109375\n",
      "Batch: 23, Loss: 0.9363775253295898, Accuracy: 0.69140625\n",
      "Batch: 24, Loss: 0.9268474578857422, Accuracy: 0.7060546875\n",
      "Batch: 25, Loss: 0.9128925800323486, Accuracy: 0.7109375\n",
      "Batch: 26, Loss: 0.798530101776123, Accuracy: 0.7509765625\n",
      "Batch: 27, Loss: 0.8549371957778931, Accuracy: 0.71875\n",
      "Batch: 28, Loss: 0.9195974469184875, Accuracy: 0.708984375\n",
      "Batch: 29, Loss: 0.8860628604888916, Accuracy: 0.7119140625\n",
      "Batch: 30, Loss: 0.8619839549064636, Accuracy: 0.7294921875\n",
      "Batch: 31, Loss: 0.831539511680603, Accuracy: 0.734375\n",
      "Batch: 32, Loss: 0.8191088438034058, Accuracy: 0.71875\n",
      "Batch: 33, Loss: 0.9978567361831665, Accuracy: 0.6884765625\n",
      "Batch: 34, Loss: 1.0467989444732666, Accuracy: 0.6611328125\n",
      "Batch: 35, Loss: 0.9795621633529663, Accuracy: 0.6796875\n",
      "Batch: 36, Loss: 0.9976357817649841, Accuracy: 0.681640625\n",
      "Batch: 37, Loss: 0.9293898344039917, Accuracy: 0.6953125\n",
      "Batch: 38, Loss: 0.9790565967559814, Accuracy: 0.67578125\n",
      "Batch: 39, Loss: 0.9190835356712341, Accuracy: 0.697265625\n",
      "Batch: 40, Loss: 0.9208356142044067, Accuracy: 0.708984375\n",
      "Batch: 41, Loss: 0.8735884428024292, Accuracy: 0.7265625\n",
      "Batch: 42, Loss: 0.7441989183425903, Accuracy: 0.7548828125\n",
      "Batch: 43, Loss: 0.9287286996841431, Accuracy: 0.6826171875\n",
      "Batch: 44, Loss: 0.9208564162254333, Accuracy: 0.685546875\n",
      "Batch: 45, Loss: 0.8166654706001282, Accuracy: 0.724609375\n",
      "Batch: 46, Loss: 0.8681128025054932, Accuracy: 0.71875\n",
      "Batch: 47, Loss: 0.9109610915184021, Accuracy: 0.720703125\n",
      "Batch: 48, Loss: 0.8247576951980591, Accuracy: 0.736328125\n",
      "Batch: 49, Loss: 1.009946584701538, Accuracy: 0.669921875\n",
      "Batch: 52, Loss: 0.9822881817817688, Accuracy: 0.6875\n",
      "Batch: 53, Loss: 0.8503561019897461, Accuracy: 0.708984375\n",
      "Batch: 54, Loss: 0.9375870823860168, Accuracy: 0.689453125\n",
      "Batch: 55, Loss: 1.0072219371795654, Accuracy: 0.6640625\n",
      "Batch: 56, Loss: 0.96230548620224, Accuracy: 0.6923828125\n",
      "Batch: 57, Loss: 0.9103000164031982, Accuracy: 0.7060546875\n",
      "Batch: 58, Loss: 1.0080466270446777, Accuracy: 0.6953125\n",
      "Batch: 59, Loss: 0.8715296983718872, Accuracy: 0.728515625\n",
      "Batch: 60, Loss: 0.8326472043991089, Accuracy: 0.7353515625\n",
      "Batch: 61, Loss: 0.9822241067886353, Accuracy: 0.681640625\n",
      "Batch: 62, Loss: 0.9078280925750732, Accuracy: 0.7138671875\n",
      "Batch: 63, Loss: 0.9792263507843018, Accuracy: 0.685546875\n",
      "Batch: 64, Loss: 0.9229081273078918, Accuracy: 0.701171875\n",
      "Batch: 65, Loss: 0.9270485043525696, Accuracy: 0.7080078125\n",
      "Batch: 66, Loss: 0.8748729228973389, Accuracy: 0.7197265625\n",
      "Batch: 67, Loss: 1.00575852394104, Accuracy: 0.669921875\n",
      "Batch: 68, Loss: 1.0374596118927002, Accuracy: 0.6826171875\n",
      "Batch: 69, Loss: 0.9282513856887817, Accuracy: 0.7021484375\n",
      "Batch: 70, Loss: 0.9001296758651733, Accuracy: 0.73046875\n",
      "Batch: 71, Loss: 0.9423694610595703, Accuracy: 0.6904296875\n",
      "Batch: 72, Loss: 0.8211008310317993, Accuracy: 0.7216796875\n",
      "Batch: 73, Loss: 0.8774576187133789, Accuracy: 0.724609375\n",
      "Batch: 74, Loss: 0.8209086656570435, Accuracy: 0.7509765625\n",
      "Batch: 75, Loss: 0.8307331800460815, Accuracy: 0.716796875\n",
      "Batch: 76, Loss: 0.9061208963394165, Accuracy: 0.6943359375\n",
      "Batch: 77, Loss: 0.8578026294708252, Accuracy: 0.71484375\n",
      "Batch: 78, Loss: 0.8778963685035706, Accuracy: 0.7255859375\n",
      "Batch: 79, Loss: 0.8165501356124878, Accuracy: 0.740234375\n",
      "Batch: 80, Loss: 0.8627352714538574, Accuracy: 0.720703125\n",
      "Batch: 81, Loss: 0.9857283234596252, Accuracy: 0.66796875\n",
      "Batch: 82, Loss: 0.9455868601799011, Accuracy: 0.701171875\n",
      "Batch: 83, Loss: 0.8171617388725281, Accuracy: 0.7529296875\n",
      "Batch: 84, Loss: 0.8649942278862, Accuracy: 0.7265625\n",
      "Batch: 85, Loss: 0.8483729362487793, Accuracy: 0.740234375\n",
      "Batch: 86, Loss: 1.0481982231140137, Accuracy: 0.6728515625\n",
      "Batch: 87, Loss: 0.8433605432510376, Accuracy: 0.7392578125\n",
      "Batch: 88, Loss: 0.9624382257461548, Accuracy: 0.7216796875\n",
      "Batch: 89, Loss: 0.9489856958389282, Accuracy: 0.7060546875\n",
      "Batch: 90, Loss: 0.8518353700637817, Accuracy: 0.7314453125\n",
      "Batch: 91, Loss: 0.9119786024093628, Accuracy: 0.6943359375\n",
      "Batch: 92, Loss: 0.9336775541305542, Accuracy: 0.6865234375\n",
      "Batch: 93, Loss: 0.9076570272445679, Accuracy: 0.7109375\n",
      "Batch: 94, Loss: 0.9103608727455139, Accuracy: 0.6953125\n",
      "Batch: 95, Loss: 0.9462323188781738, Accuracy: 0.67578125\n",
      "Batch: 97, Loss: 0.7836571335792542, Accuracy: 0.728515625\n",
      "Batch: 98, Loss: 0.8261616826057434, Accuracy: 0.732421875\n",
      "Batch: 99, Loss: 0.8588227033615112, Accuracy: 0.7255859375\n",
      "Batch: 100, Loss: 0.8814526796340942, Accuracy: 0.7275390625\n",
      "Batch: 101, Loss: 0.9844133257865906, Accuracy: 0.6806640625\n",
      "Batch: 102, Loss: 0.8907161951065063, Accuracy: 0.708984375\n",
      "Batch: 103, Loss: 0.9294031858444214, Accuracy: 0.7158203125\n",
      "Batch: 104, Loss: 0.8340725898742676, Accuracy: 0.7197265625\n",
      "Batch: 105, Loss: 0.9534533023834229, Accuracy: 0.7001953125\n",
      "Batch: 106, Loss: 0.8746386766433716, Accuracy: 0.7314453125\n",
      "Batch: 107, Loss: 0.9375020265579224, Accuracy: 0.7099609375\n",
      "Batch: 108, Loss: 0.9358497858047485, Accuracy: 0.6904296875\n",
      "Batch: 109, Loss: 1.0215814113616943, Accuracy: 0.6630859375\n",
      "Batch: 110, Loss: 0.8183715343475342, Accuracy: 0.7373046875\n",
      "Batch: 111, Loss: 0.9269985556602478, Accuracy: 0.69140625\n",
      "Batch: 112, Loss: 0.9088993668556213, Accuracy: 0.7216796875\n",
      "Batch: 113, Loss: 0.9068739414215088, Accuracy: 0.7138671875\n",
      "Batch: 114, Loss: 1.0023832321166992, Accuracy: 0.6748046875\n",
      "Batch: 115, Loss: 1.0765397548675537, Accuracy: 0.66015625\n",
      "Batch: 116, Loss: 0.987096905708313, Accuracy: 0.7021484375\n",
      "Batch: 117, Loss: 0.9994029998779297, Accuracy: 0.6767578125\n",
      "Batch: 118, Loss: 0.801091194152832, Accuracy: 0.744140625\n",
      "Batch: 119, Loss: 0.8120589256286621, Accuracy: 0.74609375\n",
      "Batch: 120, Loss: 0.9553447961807251, Accuracy: 0.6806640625\n",
      "Batch: 121, Loss: 0.9708455801010132, Accuracy: 0.6845703125\n",
      "Batch: 122, Loss: 0.8772366046905518, Accuracy: 0.708984375\n",
      "Batch: 123, Loss: 0.8972623944282532, Accuracy: 0.732421875\n",
      "Batch: 124, Loss: 0.9287350177764893, Accuracy: 0.701171875\n",
      "Batch: 125, Loss: 0.9939670562744141, Accuracy: 0.6748046875\n",
      "Batch: 126, Loss: 0.9785866737365723, Accuracy: 0.6748046875\n",
      "Batch: 127, Loss: 0.8595564365386963, Accuracy: 0.7412109375\n",
      "Batch: 128, Loss: 1.0500080585479736, Accuracy: 0.6943359375\n",
      "Batch: 129, Loss: 0.8438203930854797, Accuracy: 0.7333984375\n",
      "Batch: 130, Loss: 1.0229761600494385, Accuracy: 0.677734375\n",
      "Batch: 131, Loss: 0.9401771426200867, Accuracy: 0.6923828125\n",
      "Batch: 132, Loss: 0.9632903933525085, Accuracy: 0.681640625\n",
      "Batch: 133, Loss: 0.8900278210639954, Accuracy: 0.6943359375\n",
      "Batch: 134, Loss: 0.9561060667037964, Accuracy: 0.6904296875\n",
      "Batch: 135, Loss: 0.8638064861297607, Accuracy: 0.7099609375\n",
      "Batch: 136, Loss: 0.9186030626296997, Accuracy: 0.705078125\n",
      "Batch: 137, Loss: 0.8823307752609253, Accuracy: 0.70703125\n",
      "Batch: 138, Loss: 0.7687861919403076, Accuracy: 0.740234375\n",
      "Batch: 139, Loss: 0.8315712809562683, Accuracy: 0.728515625\n",
      "Batch: 142, Loss: 0.9778163433074951, Accuracy: 0.6865234375\n",
      "Batch: 143, Loss: 0.911320149898529, Accuracy: 0.705078125\n",
      "Batch: 144, Loss: 0.9116575717926025, Accuracy: 0.701171875\n",
      "Batch: 145, Loss: 0.8533945083618164, Accuracy: 0.7177734375\n",
      "Batch: 146, Loss: 0.956555187702179, Accuracy: 0.6865234375\n",
      "Batch: 147, Loss: 0.9650404453277588, Accuracy: 0.6943359375\n",
      "Batch: 148, Loss: 1.0544835329055786, Accuracy: 0.65625\n",
      "Batch: 149, Loss: 0.9191000461578369, Accuracy: 0.71484375\n",
      "Batch: 150, Loss: 0.8582459688186646, Accuracy: 0.7138671875\n",
      "Batch: 151, Loss: 0.8201733231544495, Accuracy: 0.7392578125\n",
      "Epoch 29/80\n",
      "Batch: 1, Loss: 1.167961597442627, Accuracy: 0.6435546875\n",
      "Batch: 2, Loss: 0.9650079011917114, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 0.8805824518203735, Accuracy: 0.7109375\n",
      "Batch: 4, Loss: 0.8353761434555054, Accuracy: 0.7529296875\n",
      "Batch: 5, Loss: 0.849227786064148, Accuracy: 0.7275390625\n",
      "Batch: 6, Loss: 0.9332286715507507, Accuracy: 0.701171875\n",
      "Batch: 7, Loss: 0.9206935167312622, Accuracy: 0.6865234375\n",
      "Batch: 8, Loss: 0.8463020920753479, Accuracy: 0.716796875\n",
      "Batch: 9, Loss: 0.8036361932754517, Accuracy: 0.75390625\n",
      "Batch: 10, Loss: 0.8600582480430603, Accuracy: 0.7109375\n",
      "Batch: 11, Loss: 0.9744389057159424, Accuracy: 0.6630859375\n",
      "Batch: 12, Loss: 0.9873573184013367, Accuracy: 0.68359375\n",
      "Batch: 13, Loss: 0.7624287605285645, Accuracy: 0.7412109375\n",
      "Batch: 14, Loss: 1.0054564476013184, Accuracy: 0.677734375\n",
      "Batch: 15, Loss: 0.8522974252700806, Accuracy: 0.728515625\n",
      "Batch: 16, Loss: 0.871151328086853, Accuracy: 0.7314453125\n",
      "Batch: 17, Loss: 0.9541468620300293, Accuracy: 0.6845703125\n",
      "Batch: 18, Loss: 0.9169270992279053, Accuracy: 0.693359375\n",
      "Batch: 19, Loss: 0.9466209411621094, Accuracy: 0.7001953125\n",
      "Batch: 20, Loss: 0.8115577697753906, Accuracy: 0.7373046875\n",
      "Batch: 21, Loss: 0.8840733766555786, Accuracy: 0.7138671875\n",
      "Batch: 22, Loss: 0.9998466968536377, Accuracy: 0.6806640625\n",
      "Batch: 23, Loss: 0.909623384475708, Accuracy: 0.689453125\n",
      "Batch: 24, Loss: 0.932227611541748, Accuracy: 0.677734375\n",
      "Batch: 25, Loss: 0.9030026793479919, Accuracy: 0.7099609375\n",
      "Batch: 26, Loss: 0.7977072596549988, Accuracy: 0.73046875\n",
      "Batch: 27, Loss: 0.8603839874267578, Accuracy: 0.6982421875\n",
      "Batch: 28, Loss: 0.9314091205596924, Accuracy: 0.689453125\n",
      "Batch: 29, Loss: 0.8994258046150208, Accuracy: 0.7060546875\n",
      "Batch: 30, Loss: 0.8510993719100952, Accuracy: 0.73046875\n",
      "Batch: 31, Loss: 0.8095800876617432, Accuracy: 0.7470703125\n",
      "Batch: 32, Loss: 0.8220807313919067, Accuracy: 0.724609375\n",
      "Batch: 33, Loss: 0.9939463138580322, Accuracy: 0.6826171875\n",
      "Batch: 34, Loss: 1.047161340713501, Accuracy: 0.6611328125\n",
      "Batch: 35, Loss: 0.9811595678329468, Accuracy: 0.6875\n",
      "Batch: 36, Loss: 0.9760081768035889, Accuracy: 0.701171875\n",
      "Batch: 37, Loss: 0.9297816753387451, Accuracy: 0.703125\n",
      "Batch: 38, Loss: 0.9440186619758606, Accuracy: 0.685546875\n",
      "Batch: 39, Loss: 0.93985915184021, Accuracy: 0.69921875\n",
      "Batch: 40, Loss: 0.9305911660194397, Accuracy: 0.701171875\n",
      "Batch: 41, Loss: 0.8492612838745117, Accuracy: 0.724609375\n",
      "Batch: 42, Loss: 0.7217072248458862, Accuracy: 0.74609375\n",
      "Batch: 43, Loss: 0.9337443709373474, Accuracy: 0.6923828125\n",
      "Batch: 44, Loss: 0.9061502814292908, Accuracy: 0.69921875\n",
      "Batch: 45, Loss: 0.8159538507461548, Accuracy: 0.7138671875\n",
      "Batch: 46, Loss: 0.8448619246482849, Accuracy: 0.734375\n",
      "Batch: 47, Loss: 0.9079484939575195, Accuracy: 0.7275390625\n",
      "Batch: 48, Loss: 0.8371678590774536, Accuracy: 0.73046875\n",
      "Batch: 49, Loss: 0.9735356569290161, Accuracy: 0.689453125\n",
      "Batch: 50, Loss: 0.9711442589759827, Accuracy: 0.681640625\n",
      "Batch: 51, Loss: 0.9908269047737122, Accuracy: 0.6787109375\n",
      "Batch: 52, Loss: 0.9615479111671448, Accuracy: 0.673828125\n",
      "Batch: 53, Loss: 0.8336576819419861, Accuracy: 0.7255859375\n",
      "Batch: 54, Loss: 0.8961949348449707, Accuracy: 0.697265625\n",
      "Batch: 55, Loss: 1.0165131092071533, Accuracy: 0.6630859375\n",
      "Batch: 56, Loss: 0.9976503849029541, Accuracy: 0.6787109375\n",
      "Batch: 57, Loss: 0.9280327558517456, Accuracy: 0.703125\n",
      "Batch: 58, Loss: 0.9961931109428406, Accuracy: 0.6923828125\n",
      "Batch: 59, Loss: 0.8617589473724365, Accuracy: 0.734375\n",
      "Batch: 60, Loss: 0.8424418568611145, Accuracy: 0.7353515625\n",
      "Batch: 61, Loss: 0.9407831430435181, Accuracy: 0.697265625\n",
      "Batch: 62, Loss: 0.9135189056396484, Accuracy: 0.6884765625\n",
      "Batch: 63, Loss: 0.9493236541748047, Accuracy: 0.701171875\n",
      "Batch: 64, Loss: 0.9265486001968384, Accuracy: 0.6953125\n",
      "Batch: 65, Loss: 0.9246876239776611, Accuracy: 0.7216796875\n",
      "Batch: 66, Loss: 0.8862848877906799, Accuracy: 0.7275390625\n",
      "Batch: 67, Loss: 0.9926470518112183, Accuracy: 0.689453125\n",
      "Batch: 68, Loss: 1.0251367092132568, Accuracy: 0.6787109375\n",
      "Batch: 69, Loss: 0.8951292037963867, Accuracy: 0.708984375\n",
      "Batch: 70, Loss: 0.9002689123153687, Accuracy: 0.716796875\n",
      "Batch: 71, Loss: 0.9441689848899841, Accuracy: 0.6865234375\n",
      "Batch: 72, Loss: 0.7992486357688904, Accuracy: 0.740234375\n",
      "Batch: 73, Loss: 0.8838492035865784, Accuracy: 0.7216796875\n",
      "Batch: 74, Loss: 0.8095500469207764, Accuracy: 0.748046875\n",
      "Batch: 75, Loss: 0.8541427850723267, Accuracy: 0.7294921875\n",
      "Batch: 76, Loss: 0.9037862420082092, Accuracy: 0.6962890625\n",
      "Batch: 77, Loss: 0.8558399081230164, Accuracy: 0.724609375\n",
      "Batch: 78, Loss: 0.8553731441497803, Accuracy: 0.728515625\n",
      "Batch: 79, Loss: 0.804288923740387, Accuracy: 0.7509765625\n",
      "Batch: 80, Loss: 0.8419013023376465, Accuracy: 0.708984375\n",
      "Batch: 81, Loss: 0.9555110931396484, Accuracy: 0.6796875\n",
      "Batch: 82, Loss: 0.9376211166381836, Accuracy: 0.7080078125\n",
      "Batch: 83, Loss: 0.8167469501495361, Accuracy: 0.73828125\n",
      "Batch: 84, Loss: 0.8553138971328735, Accuracy: 0.720703125\n",
      "Batch: 85, Loss: 0.8139243721961975, Accuracy: 0.728515625\n",
      "Batch: 86, Loss: 1.054659128189087, Accuracy: 0.6669921875\n",
      "Batch: 87, Loss: 0.8338598012924194, Accuracy: 0.7373046875\n",
      "Batch: 88, Loss: 0.940802812576294, Accuracy: 0.7080078125\n",
      "Batch: 89, Loss: 0.933201014995575, Accuracy: 0.7158203125\n",
      "Batch: 90, Loss: 0.8720927834510803, Accuracy: 0.71875\n",
      "Batch: 91, Loss: 0.9045052528381348, Accuracy: 0.701171875\n",
      "Batch: 92, Loss: 0.9020884037017822, Accuracy: 0.6982421875\n",
      "Batch: 93, Loss: 0.8939834833145142, Accuracy: 0.708984375\n",
      "Batch: 94, Loss: 0.8935396075248718, Accuracy: 0.7021484375\n",
      "Batch: 95, Loss: 0.955524742603302, Accuracy: 0.6787109375\n",
      "Batch: 96, Loss: 0.8750180006027222, Accuracy: 0.7109375\n",
      "Batch: 97, Loss: 0.7413389086723328, Accuracy: 0.7509765625\n",
      "Batch: 98, Loss: 0.8089590668678284, Accuracy: 0.7392578125\n",
      "Batch: 99, Loss: 0.8430782556533813, Accuracy: 0.71875\n",
      "Batch: 100, Loss: 0.8576666116714478, Accuracy: 0.724609375\n",
      "Batch: 101, Loss: 0.9511092901229858, Accuracy: 0.7060546875\n",
      "Batch: 102, Loss: 0.8988614082336426, Accuracy: 0.7138671875\n",
      "Batch: 103, Loss: 0.9304205179214478, Accuracy: 0.7197265625\n",
      "Batch: 104, Loss: 0.8293269872665405, Accuracy: 0.71484375\n",
      "Batch: 105, Loss: 0.9342310428619385, Accuracy: 0.705078125\n",
      "Batch: 106, Loss: 0.861930787563324, Accuracy: 0.732421875\n",
      "Batch: 107, Loss: 0.9281397461891174, Accuracy: 0.7138671875\n",
      "Batch: 108, Loss: 0.8905930519104004, Accuracy: 0.712890625\n",
      "Batch: 109, Loss: 1.0037915706634521, Accuracy: 0.6787109375\n",
      "Batch: 110, Loss: 0.7866541147232056, Accuracy: 0.75\n",
      "Batch: 111, Loss: 0.9262781143188477, Accuracy: 0.7060546875\n",
      "Batch: 112, Loss: 0.8968822956085205, Accuracy: 0.7353515625\n",
      "Batch: 113, Loss: 0.8998563289642334, Accuracy: 0.708984375\n",
      "Batch: 114, Loss: 1.003333330154419, Accuracy: 0.6728515625\n",
      "Batch: 115, Loss: 1.0492324829101562, Accuracy: 0.6796875\n",
      "Batch: 116, Loss: 1.0064191818237305, Accuracy: 0.7041015625\n",
      "Batch: 117, Loss: 0.9677066802978516, Accuracy: 0.681640625\n",
      "Batch: 118, Loss: 0.8080690503120422, Accuracy: 0.7412109375\n",
      "Batch: 119, Loss: 0.8014814853668213, Accuracy: 0.7431640625\n",
      "Batch: 120, Loss: 0.9509372711181641, Accuracy: 0.701171875\n",
      "Batch: 121, Loss: 0.9742419719696045, Accuracy: 0.6865234375\n",
      "Batch: 122, Loss: 0.8744422793388367, Accuracy: 0.732421875\n",
      "Batch: 123, Loss: 0.8425648212432861, Accuracy: 0.7373046875\n",
      "Batch: 125, Loss: 0.9797766804695129, Accuracy: 0.671875\n",
      "Batch: 126, Loss: 0.9491117000579834, Accuracy: 0.685546875\n",
      "Batch: 127, Loss: 0.8195047974586487, Accuracy: 0.744140625\n",
      "Batch: 128, Loss: 1.0360825061798096, Accuracy: 0.6943359375\n",
      "Batch: 129, Loss: 0.8482679724693298, Accuracy: 0.7421875\n",
      "Batch: 130, Loss: 1.0489356517791748, Accuracy: 0.677734375\n",
      "Batch: 131, Loss: 0.9510736465454102, Accuracy: 0.68359375\n",
      "Batch: 132, Loss: 0.976975679397583, Accuracy: 0.69140625\n",
      "Batch: 133, Loss: 0.8680571913719177, Accuracy: 0.720703125\n",
      "Batch: 134, Loss: 0.9565105438232422, Accuracy: 0.68359375\n",
      "Batch: 135, Loss: 0.8436232805252075, Accuracy: 0.732421875\n",
      "Batch: 136, Loss: 0.9270352125167847, Accuracy: 0.701171875\n",
      "Batch: 137, Loss: 0.876636803150177, Accuracy: 0.7099609375\n",
      "Batch: 138, Loss: 0.7521234750747681, Accuracy: 0.7685546875\n",
      "Batch: 139, Loss: 0.8316595554351807, Accuracy: 0.720703125\n",
      "Batch: 140, Loss: 0.8880374431610107, Accuracy: 0.708984375\n",
      "Batch: 141, Loss: 0.9342575073242188, Accuracy: 0.69140625\n",
      "Batch: 142, Loss: 0.9606115818023682, Accuracy: 0.6904296875\n",
      "Batch: 143, Loss: 0.9276965856552124, Accuracy: 0.7041015625\n",
      "Batch: 144, Loss: 0.8956646919250488, Accuracy: 0.705078125\n",
      "Batch: 145, Loss: 0.8853154182434082, Accuracy: 0.697265625\n",
      "Batch: 146, Loss: 0.9421747922897339, Accuracy: 0.705078125\n",
      "Batch: 147, Loss: 0.9545658826828003, Accuracy: 0.6982421875\n",
      "Batch: 148, Loss: 1.041282296180725, Accuracy: 0.6572265625\n",
      "Batch: 149, Loss: 0.8916515111923218, Accuracy: 0.7158203125\n",
      "Batch: 150, Loss: 0.8812698125839233, Accuracy: 0.708984375\n",
      "Batch: 151, Loss: 0.8100070953369141, Accuracy: 0.734375\n",
      "Epoch 30/80\n",
      "Batch: 1, Loss: 1.1565001010894775, Accuracy: 0.634765625\n",
      "Batch: 2, Loss: 0.9789718389511108, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 0.894768476486206, Accuracy: 0.703125\n",
      "Batch: 4, Loss: 0.8151543140411377, Accuracy: 0.7392578125\n",
      "Batch: 5, Loss: 0.8616992831230164, Accuracy: 0.7236328125\n",
      "Batch: 6, Loss: 0.9109247922897339, Accuracy: 0.6875\n",
      "Batch: 7, Loss: 0.9050875902175903, Accuracy: 0.6865234375\n",
      "Batch: 8, Loss: 0.853138267993927, Accuracy: 0.720703125\n",
      "Batch: 9, Loss: 0.8113658428192139, Accuracy: 0.736328125\n",
      "Batch: 10, Loss: 0.8386530876159668, Accuracy: 0.7275390625\n",
      "Batch: 11, Loss: 1.0081841945648193, Accuracy: 0.6552734375\n",
      "Batch: 12, Loss: 0.9873115420341492, Accuracy: 0.677734375\n",
      "Batch: 13, Loss: 0.7766276597976685, Accuracy: 0.7451171875\n",
      "Batch: 14, Loss: 1.013599157333374, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.8293555974960327, Accuracy: 0.7392578125\n",
      "Batch: 16, Loss: 0.8721956610679626, Accuracy: 0.728515625\n",
      "Batch: 17, Loss: 0.9291633367538452, Accuracy: 0.6943359375\n",
      "Batch: 18, Loss: 0.9137994050979614, Accuracy: 0.6962890625\n",
      "Batch: 19, Loss: 0.9541470408439636, Accuracy: 0.701171875\n",
      "Batch: 20, Loss: 0.8414775133132935, Accuracy: 0.7421875\n",
      "Batch: 22, Loss: 0.9429240226745605, Accuracy: 0.7041015625\n",
      "Batch: 23, Loss: 0.8942879438400269, Accuracy: 0.7080078125\n",
      "Batch: 24, Loss: 0.9197589159011841, Accuracy: 0.6884765625\n",
      "Batch: 25, Loss: 0.8984183669090271, Accuracy: 0.7080078125\n",
      "Batch: 26, Loss: 0.7916427254676819, Accuracy: 0.7275390625\n",
      "Batch: 27, Loss: 0.8530139923095703, Accuracy: 0.708984375\n",
      "Batch: 28, Loss: 0.9254108667373657, Accuracy: 0.689453125\n",
      "Batch: 29, Loss: 0.8665269613265991, Accuracy: 0.720703125\n",
      "Batch: 30, Loss: 0.838595986366272, Accuracy: 0.744140625\n",
      "Batch: 31, Loss: 0.8081027865409851, Accuracy: 0.748046875\n",
      "Batch: 32, Loss: 0.8327163457870483, Accuracy: 0.7255859375\n",
      "Batch: 33, Loss: 0.9731613397598267, Accuracy: 0.6923828125\n",
      "Batch: 34, Loss: 1.0475211143493652, Accuracy: 0.6591796875\n",
      "Batch: 35, Loss: 0.9502378702163696, Accuracy: 0.703125\n",
      "Batch: 36, Loss: 0.9637902975082397, Accuracy: 0.7080078125\n",
      "Batch: 37, Loss: 0.8971845507621765, Accuracy: 0.705078125\n",
      "Batch: 38, Loss: 0.9370974898338318, Accuracy: 0.6953125\n",
      "Batch: 39, Loss: 0.9165325164794922, Accuracy: 0.701171875\n",
      "Batch: 40, Loss: 0.9200494885444641, Accuracy: 0.7080078125\n",
      "Batch: 41, Loss: 0.8515809178352356, Accuracy: 0.7236328125\n",
      "Batch: 42, Loss: 0.7326693534851074, Accuracy: 0.7587890625\n",
      "Batch: 43, Loss: 0.9301992654800415, Accuracy: 0.6806640625\n",
      "Batch: 44, Loss: 0.9229534864425659, Accuracy: 0.6962890625\n",
      "Batch: 45, Loss: 0.823931097984314, Accuracy: 0.7177734375\n",
      "Batch: 46, Loss: 0.879920482635498, Accuracy: 0.7138671875\n",
      "Batch: 47, Loss: 0.8717880249023438, Accuracy: 0.734375\n",
      "Batch: 48, Loss: 0.8331347107887268, Accuracy: 0.7216796875\n",
      "Batch: 49, Loss: 1.0086395740509033, Accuracy: 0.66796875\n",
      "Batch: 50, Loss: 0.9535906314849854, Accuracy: 0.6806640625\n",
      "Batch: 51, Loss: 0.9903367757797241, Accuracy: 0.673828125\n",
      "Batch: 52, Loss: 0.9406120777130127, Accuracy: 0.685546875\n",
      "Batch: 53, Loss: 0.8478931188583374, Accuracy: 0.7177734375\n",
      "Batch: 54, Loss: 0.8847634792327881, Accuracy: 0.703125\n",
      "Batch: 55, Loss: 0.9888576865196228, Accuracy: 0.666015625\n",
      "Batch: 56, Loss: 0.9704270362854004, Accuracy: 0.6708984375\n",
      "Batch: 57, Loss: 0.9274291396141052, Accuracy: 0.7138671875\n",
      "Batch: 58, Loss: 0.9943786859512329, Accuracy: 0.68359375\n",
      "Batch: 59, Loss: 0.840313732624054, Accuracy: 0.73046875\n",
      "Batch: 60, Loss: 0.8526027202606201, Accuracy: 0.7294921875\n",
      "Batch: 61, Loss: 0.946415364742279, Accuracy: 0.6953125\n",
      "Batch: 62, Loss: 0.8860849142074585, Accuracy: 0.703125\n",
      "Batch: 63, Loss: 0.9348975419998169, Accuracy: 0.7001953125\n",
      "Batch: 64, Loss: 0.8918405771255493, Accuracy: 0.70703125\n",
      "Batch: 67, Loss: 0.9884833097457886, Accuracy: 0.69140625\n",
      "Batch: 68, Loss: 1.005787968635559, Accuracy: 0.6982421875\n",
      "Batch: 69, Loss: 0.9254494309425354, Accuracy: 0.7109375\n",
      "Batch: 70, Loss: 0.8757621645927429, Accuracy: 0.732421875\n",
      "Batch: 71, Loss: 0.9377359747886658, Accuracy: 0.6865234375\n",
      "Batch: 72, Loss: 0.7996816635131836, Accuracy: 0.7314453125\n",
      "Batch: 73, Loss: 0.843029260635376, Accuracy: 0.7373046875\n",
      "Batch: 74, Loss: 0.8055393695831299, Accuracy: 0.73828125\n",
      "Batch: 75, Loss: 0.8268457055091858, Accuracy: 0.7333984375\n",
      "Batch: 76, Loss: 0.9209793210029602, Accuracy: 0.697265625\n",
      "Batch: 77, Loss: 0.847405195236206, Accuracy: 0.7109375\n",
      "Batch: 78, Loss: 0.8816571831703186, Accuracy: 0.7275390625\n",
      "Batch: 79, Loss: 0.7857571840286255, Accuracy: 0.748046875\n",
      "Batch: 80, Loss: 0.8477573394775391, Accuracy: 0.71875\n",
      "Batch: 81, Loss: 0.9576394557952881, Accuracy: 0.66796875\n",
      "Batch: 82, Loss: 0.9295070767402649, Accuracy: 0.7158203125\n",
      "Batch: 83, Loss: 0.7751914858818054, Accuracy: 0.7587890625\n",
      "Batch: 84, Loss: 0.8631117343902588, Accuracy: 0.720703125\n",
      "Batch: 85, Loss: 0.8232896327972412, Accuracy: 0.7314453125\n",
      "Batch: 86, Loss: 1.0292422771453857, Accuracy: 0.6748046875\n",
      "Batch: 87, Loss: 0.8269215822219849, Accuracy: 0.74609375\n",
      "Batch: 88, Loss: 0.9654704332351685, Accuracy: 0.6962890625\n",
      "Batch: 89, Loss: 0.9054558873176575, Accuracy: 0.7080078125\n",
      "Batch: 90, Loss: 0.8615531921386719, Accuracy: 0.7255859375\n",
      "Batch: 91, Loss: 0.8704432249069214, Accuracy: 0.712890625\n",
      "Batch: 92, Loss: 0.9092251062393188, Accuracy: 0.7001953125\n",
      "Batch: 93, Loss: 0.8713937997817993, Accuracy: 0.7255859375\n",
      "Batch: 94, Loss: 0.8852501511573792, Accuracy: 0.703125\n",
      "Batch: 95, Loss: 0.9393892288208008, Accuracy: 0.6796875\n",
      "Batch: 96, Loss: 0.8715716600418091, Accuracy: 0.6962890625\n",
      "Batch: 97, Loss: 0.7453534603118896, Accuracy: 0.755859375\n",
      "Batch: 98, Loss: 0.7967824339866638, Accuracy: 0.7509765625\n",
      "Batch: 99, Loss: 0.8195685148239136, Accuracy: 0.7421875\n",
      "Batch: 100, Loss: 0.8645864129066467, Accuracy: 0.7314453125\n",
      "Batch: 101, Loss: 0.9308931827545166, Accuracy: 0.701171875\n",
      "Batch: 102, Loss: 0.8669736385345459, Accuracy: 0.712890625\n",
      "Batch: 103, Loss: 0.9050906896591187, Accuracy: 0.72265625\n",
      "Batch: 104, Loss: 0.8089905977249146, Accuracy: 0.7255859375\n",
      "Batch: 105, Loss: 0.9275615215301514, Accuracy: 0.7119140625\n",
      "Batch: 106, Loss: 0.848732054233551, Accuracy: 0.7353515625\n",
      "Batch: 107, Loss: 0.9127280116081238, Accuracy: 0.7041015625\n",
      "Batch: 108, Loss: 0.8866126537322998, Accuracy: 0.6982421875\n",
      "Batch: 109, Loss: 1.01706063747406, Accuracy: 0.6728515625\n",
      "Batch: 110, Loss: 0.7597320079803467, Accuracy: 0.7626953125\n",
      "Batch: 111, Loss: 0.9102928638458252, Accuracy: 0.7001953125\n",
      "Batch: 112, Loss: 0.8892920017242432, Accuracy: 0.7314453125\n",
      "Batch: 113, Loss: 0.8948453068733215, Accuracy: 0.712890625\n",
      "Batch: 115, Loss: 1.045180082321167, Accuracy: 0.6796875\n",
      "Batch: 116, Loss: 0.9571179747581482, Accuracy: 0.7080078125\n",
      "Batch: 117, Loss: 0.9649324417114258, Accuracy: 0.6826171875\n",
      "Batch: 118, Loss: 0.7973759174346924, Accuracy: 0.7431640625\n",
      "Batch: 119, Loss: 0.769662082195282, Accuracy: 0.75390625\n",
      "Batch: 120, Loss: 0.9257012605667114, Accuracy: 0.6962890625\n",
      "Batch: 121, Loss: 0.9390604496002197, Accuracy: 0.7001953125\n",
      "Batch: 122, Loss: 0.885936975479126, Accuracy: 0.7041015625\n",
      "Batch: 123, Loss: 0.8500847816467285, Accuracy: 0.7294921875\n",
      "Batch: 124, Loss: 0.9132477045059204, Accuracy: 0.6962890625\n",
      "Batch: 125, Loss: 0.9677332043647766, Accuracy: 0.6884765625\n",
      "Batch: 126, Loss: 0.9083074331283569, Accuracy: 0.7138671875\n",
      "Batch: 127, Loss: 0.8220601081848145, Accuracy: 0.75390625\n",
      "Batch: 128, Loss: 1.0148530006408691, Accuracy: 0.701171875\n",
      "Batch: 129, Loss: 0.8293321132659912, Accuracy: 0.7373046875\n",
      "Batch: 130, Loss: 1.026827335357666, Accuracy: 0.6708984375\n",
      "Batch: 131, Loss: 0.9241753816604614, Accuracy: 0.69921875\n",
      "Batch: 132, Loss: 0.9348393082618713, Accuracy: 0.7041015625\n",
      "Batch: 133, Loss: 0.8371886610984802, Accuracy: 0.7099609375\n",
      "Batch: 134, Loss: 0.9333037734031677, Accuracy: 0.6904296875\n",
      "Batch: 135, Loss: 0.8338751196861267, Accuracy: 0.7265625\n",
      "Batch: 136, Loss: 0.908470094203949, Accuracy: 0.720703125\n",
      "Batch: 137, Loss: 0.8693708181381226, Accuracy: 0.7216796875\n",
      "Batch: 138, Loss: 0.7545185089111328, Accuracy: 0.755859375\n",
      "Batch: 139, Loss: 0.827782392501831, Accuracy: 0.728515625\n",
      "Batch: 140, Loss: 0.8685710430145264, Accuracy: 0.716796875\n",
      "Batch: 141, Loss: 0.9210197329521179, Accuracy: 0.6962890625\n",
      "Batch: 142, Loss: 0.973052978515625, Accuracy: 0.6904296875\n",
      "Batch: 143, Loss: 0.9069526791572571, Accuracy: 0.69921875\n",
      "Batch: 144, Loss: 0.9120283126831055, Accuracy: 0.7119140625\n",
      "Batch: 145, Loss: 0.8408463001251221, Accuracy: 0.7119140625\n",
      "Batch: 146, Loss: 0.9344798922538757, Accuracy: 0.69140625\n",
      "Batch: 147, Loss: 0.9296703338623047, Accuracy: 0.6943359375\n",
      "Batch: 148, Loss: 1.03311288356781, Accuracy: 0.6640625\n",
      "Batch: 149, Loss: 0.8850265741348267, Accuracy: 0.7158203125\n",
      "Batch: 150, Loss: 0.8733276128768921, Accuracy: 0.7177734375\n",
      "Batch: 151, Loss: 0.7919739484786987, Accuracy: 0.74609375\n",
      "Saved Weights at epoch 30 to file Weights_30.h5\n",
      "Epoch 31/80\n",
      "Batch: 1, Loss: 1.1408323049545288, Accuracy: 0.63671875\n",
      "Batch: 2, Loss: 0.9529324769973755, Accuracy: 0.6689453125\n",
      "Batch: 3, Loss: 0.8743420839309692, Accuracy: 0.708984375\n",
      "Batch: 4, Loss: 0.8170403242111206, Accuracy: 0.7470703125\n",
      "Batch: 5, Loss: 0.8390721082687378, Accuracy: 0.73828125\n",
      "Batch: 6, Loss: 0.914878249168396, Accuracy: 0.6953125\n",
      "Batch: 7, Loss: 0.9059914350509644, Accuracy: 0.6845703125\n",
      "Batch: 9, Loss: 0.810192346572876, Accuracy: 0.7568359375\n",
      "Batch: 10, Loss: 0.8181098103523254, Accuracy: 0.7177734375\n",
      "Batch: 11, Loss: 0.9693834781646729, Accuracy: 0.6806640625\n",
      "Batch: 12, Loss: 0.9479899406433105, Accuracy: 0.6884765625\n",
      "Batch: 13, Loss: 0.7520960569381714, Accuracy: 0.7509765625\n",
      "Batch: 14, Loss: 1.0136798620224, Accuracy: 0.6904296875\n",
      "Batch: 15, Loss: 0.8337450623512268, Accuracy: 0.7431640625\n",
      "Batch: 16, Loss: 0.8518807888031006, Accuracy: 0.7275390625\n",
      "Batch: 17, Loss: 0.9256516695022583, Accuracy: 0.7080078125\n",
      "Batch: 18, Loss: 0.9061839580535889, Accuracy: 0.7041015625\n",
      "Batch: 19, Loss: 0.9389244318008423, Accuracy: 0.71875\n",
      "Batch: 20, Loss: 0.807873547077179, Accuracy: 0.7470703125\n",
      "Batch: 21, Loss: 0.8399998545646667, Accuracy: 0.724609375\n",
      "Batch: 22, Loss: 0.9686092138290405, Accuracy: 0.708984375\n",
      "Batch: 23, Loss: 0.9070479869842529, Accuracy: 0.6865234375\n",
      "Batch: 24, Loss: 0.9075747132301331, Accuracy: 0.701171875\n",
      "Batch: 25, Loss: 0.8921962380409241, Accuracy: 0.7099609375\n",
      "Batch: 26, Loss: 0.772913932800293, Accuracy: 0.7578125\n",
      "Batch: 27, Loss: 0.8258951306343079, Accuracy: 0.7255859375\n",
      "Batch: 28, Loss: 0.8955482244491577, Accuracy: 0.7099609375\n",
      "Batch: 29, Loss: 0.8798019886016846, Accuracy: 0.716796875\n",
      "Batch: 30, Loss: 0.8156108260154724, Accuracy: 0.73828125\n",
      "Batch: 31, Loss: 0.7898392081260681, Accuracy: 0.7470703125\n",
      "Batch: 32, Loss: 0.8021701574325562, Accuracy: 0.724609375\n",
      "Batch: 33, Loss: 0.9570484161376953, Accuracy: 0.6923828125\n",
      "Batch: 34, Loss: 1.021714448928833, Accuracy: 0.6796875\n",
      "Batch: 35, Loss: 0.9591590166091919, Accuracy: 0.685546875\n",
      "Batch: 36, Loss: 0.9697418212890625, Accuracy: 0.705078125\n",
      "Batch: 37, Loss: 0.8998934030532837, Accuracy: 0.7158203125\n",
      "Batch: 38, Loss: 0.9105144739151001, Accuracy: 0.685546875\n",
      "Batch: 39, Loss: 0.8988509774208069, Accuracy: 0.7001953125\n",
      "Batch: 40, Loss: 0.9011043310165405, Accuracy: 0.712890625\n",
      "Batch: 41, Loss: 0.8350816369056702, Accuracy: 0.7333984375\n",
      "Batch: 42, Loss: 0.6863455772399902, Accuracy: 0.767578125\n",
      "Batch: 43, Loss: 0.9048546552658081, Accuracy: 0.697265625\n",
      "Batch: 44, Loss: 0.9188156127929688, Accuracy: 0.6923828125\n",
      "Batch: 45, Loss: 0.8078509569168091, Accuracy: 0.724609375\n",
      "Batch: 46, Loss: 0.8446727991104126, Accuracy: 0.73046875\n",
      "Batch: 47, Loss: 0.8715482950210571, Accuracy: 0.7314453125\n",
      "Batch: 48, Loss: 0.7912466526031494, Accuracy: 0.740234375\n",
      "Batch: 49, Loss: 0.9765223264694214, Accuracy: 0.6826171875\n",
      "Batch: 50, Loss: 0.9495806694030762, Accuracy: 0.693359375\n",
      "Batch: 51, Loss: 0.9577374458312988, Accuracy: 0.6826171875\n",
      "Batch: 52, Loss: 0.9492047429084778, Accuracy: 0.6943359375\n",
      "Batch: 53, Loss: 0.8138598203659058, Accuracy: 0.7314453125\n",
      "Batch: 54, Loss: 0.8880075216293335, Accuracy: 0.7001953125\n",
      "Batch: 55, Loss: 0.9948215484619141, Accuracy: 0.6708984375\n",
      "Batch: 56, Loss: 0.9524238705635071, Accuracy: 0.689453125\n",
      "Batch: 57, Loss: 0.9146904945373535, Accuracy: 0.7041015625\n",
      "Batch: 58, Loss: 0.9611828327178955, Accuracy: 0.7109375\n",
      "Batch: 59, Loss: 0.8401443362236023, Accuracy: 0.7275390625\n",
      "Batch: 60, Loss: 0.8253971338272095, Accuracy: 0.732421875\n",
      "Batch: 61, Loss: 0.9373136162757874, Accuracy: 0.7001953125\n",
      "Batch: 62, Loss: 0.8667681217193604, Accuracy: 0.71875\n",
      "Batch: 63, Loss: 0.9409068822860718, Accuracy: 0.697265625\n",
      "Batch: 64, Loss: 0.8978815078735352, Accuracy: 0.7099609375\n",
      "Batch: 65, Loss: 0.918637752532959, Accuracy: 0.7099609375\n",
      "Batch: 66, Loss: 0.8954812288284302, Accuracy: 0.7177734375\n",
      "Batch: 67, Loss: 0.9720774292945862, Accuracy: 0.69921875\n",
      "Batch: 68, Loss: 1.007522463798523, Accuracy: 0.69140625\n",
      "Batch: 69, Loss: 0.891909122467041, Accuracy: 0.716796875\n",
      "Batch: 70, Loss: 0.8910125494003296, Accuracy: 0.728515625\n",
      "Batch: 71, Loss: 0.8912346363067627, Accuracy: 0.7099609375\n",
      "Batch: 72, Loss: 0.7997450232505798, Accuracy: 0.7236328125\n",
      "Batch: 73, Loss: 0.8326540589332581, Accuracy: 0.7529296875\n",
      "Batch: 74, Loss: 0.7765308618545532, Accuracy: 0.755859375\n",
      "Batch: 75, Loss: 0.8228991627693176, Accuracy: 0.7353515625\n",
      "Batch: 76, Loss: 0.8955919146537781, Accuracy: 0.7119140625\n",
      "Batch: 77, Loss: 0.8455170392990112, Accuracy: 0.724609375\n",
      "Batch: 78, Loss: 0.8562908172607422, Accuracy: 0.7255859375\n",
      "Batch: 79, Loss: 0.7767765522003174, Accuracy: 0.75\n",
      "Batch: 80, Loss: 0.8551811575889587, Accuracy: 0.70703125\n",
      "Batch: 81, Loss: 0.9408739805221558, Accuracy: 0.6845703125\n",
      "Batch: 82, Loss: 0.9423787593841553, Accuracy: 0.6875\n",
      "Batch: 83, Loss: 0.8104894161224365, Accuracy: 0.7529296875\n",
      "Batch: 84, Loss: 0.8713051080703735, Accuracy: 0.7177734375\n",
      "Batch: 85, Loss: 0.8255202770233154, Accuracy: 0.736328125\n",
      "Batch: 86, Loss: 1.0243637561798096, Accuracy: 0.67578125\n",
      "Batch: 87, Loss: 0.7991329431533813, Accuracy: 0.7568359375\n",
      "Batch: 88, Loss: 0.9269886612892151, Accuracy: 0.71484375\n",
      "Batch: 89, Loss: 0.9199318885803223, Accuracy: 0.7109375\n",
      "Batch: 90, Loss: 0.8479836583137512, Accuracy: 0.7333984375\n",
      "Batch: 91, Loss: 0.8843474388122559, Accuracy: 0.7158203125\n",
      "Batch: 92, Loss: 0.8995366096496582, Accuracy: 0.7119140625\n",
      "Batch: 93, Loss: 0.867971658706665, Accuracy: 0.7177734375\n",
      "Batch: 94, Loss: 0.9008299112319946, Accuracy: 0.69921875\n",
      "Batch: 95, Loss: 0.9392480850219727, Accuracy: 0.673828125\n",
      "Batch: 96, Loss: 0.8489999771118164, Accuracy: 0.7216796875\n",
      "Batch: 97, Loss: 0.7411191463470459, Accuracy: 0.755859375\n",
      "Batch: 98, Loss: 0.8017594218254089, Accuracy: 0.7275390625\n",
      "Batch: 99, Loss: 0.8493232727050781, Accuracy: 0.71875\n",
      "Batch: 100, Loss: 0.8555668592453003, Accuracy: 0.7158203125\n",
      "Batch: 101, Loss: 0.9465972781181335, Accuracy: 0.703125\n",
      "Batch: 102, Loss: 0.8722479343414307, Accuracy: 0.7119140625\n",
      "Batch: 104, Loss: 0.8079480528831482, Accuracy: 0.7255859375\n",
      "Batch: 105, Loss: 0.9009732007980347, Accuracy: 0.720703125\n",
      "Batch: 106, Loss: 0.8400096893310547, Accuracy: 0.7373046875\n",
      "Batch: 107, Loss: 0.9157791137695312, Accuracy: 0.7119140625\n",
      "Batch: 108, Loss: 0.9035529494285583, Accuracy: 0.708984375\n",
      "Batch: 109, Loss: 0.9888487458229065, Accuracy: 0.6875\n",
      "Batch: 110, Loss: 0.7765864729881287, Accuracy: 0.744140625\n",
      "Batch: 111, Loss: 0.9083448648452759, Accuracy: 0.701171875\n",
      "Batch: 112, Loss: 0.8728346824645996, Accuracy: 0.7373046875\n",
      "Batch: 113, Loss: 0.8810805082321167, Accuracy: 0.7197265625\n",
      "Batch: 114, Loss: 0.9780106544494629, Accuracy: 0.6953125\n",
      "Batch: 115, Loss: 1.0138438940048218, Accuracy: 0.6904296875\n",
      "Batch: 116, Loss: 0.9310554265975952, Accuracy: 0.7138671875\n",
      "Batch: 117, Loss: 0.9381413459777832, Accuracy: 0.685546875\n",
      "Batch: 118, Loss: 0.7793826460838318, Accuracy: 0.748046875\n",
      "Batch: 119, Loss: 0.7618104219436646, Accuracy: 0.75390625\n",
      "Batch: 120, Loss: 0.9367584586143494, Accuracy: 0.7021484375\n",
      "Batch: 121, Loss: 0.9462153911590576, Accuracy: 0.6884765625\n",
      "Batch: 122, Loss: 0.8514652252197266, Accuracy: 0.734375\n",
      "Batch: 123, Loss: 0.8240708112716675, Accuracy: 0.7509765625\n",
      "Batch: 124, Loss: 0.8696521520614624, Accuracy: 0.7216796875\n",
      "Batch: 125, Loss: 0.9556974768638611, Accuracy: 0.6982421875\n",
      "Batch: 126, Loss: 0.9267840385437012, Accuracy: 0.6923828125\n",
      "Batch: 127, Loss: 0.813053548336029, Accuracy: 0.755859375\n",
      "Batch: 128, Loss: 1.01112961769104, Accuracy: 0.705078125\n",
      "Batch: 129, Loss: 0.8151637315750122, Accuracy: 0.734375\n",
      "Batch: 130, Loss: 1.0205450057983398, Accuracy: 0.67578125\n",
      "Batch: 131, Loss: 0.9233361482620239, Accuracy: 0.6845703125\n",
      "Batch: 132, Loss: 0.9469720125198364, Accuracy: 0.693359375\n",
      "Batch: 133, Loss: 0.8268923163414001, Accuracy: 0.7197265625\n",
      "Batch: 134, Loss: 0.9097248315811157, Accuracy: 0.6865234375\n",
      "Batch: 135, Loss: 0.8271350860595703, Accuracy: 0.724609375\n",
      "Batch: 136, Loss: 0.8774462938308716, Accuracy: 0.7119140625\n",
      "Batch: 137, Loss: 0.8651474118232727, Accuracy: 0.7080078125\n",
      "Batch: 138, Loss: 0.7576079368591309, Accuracy: 0.75\n",
      "Batch: 139, Loss: 0.8006939888000488, Accuracy: 0.73046875\n",
      "Batch: 140, Loss: 0.8650991916656494, Accuracy: 0.71484375\n",
      "Batch: 141, Loss: 0.8904364705085754, Accuracy: 0.7041015625\n",
      "Batch: 142, Loss: 0.9607599973678589, Accuracy: 0.6796875\n",
      "Batch: 143, Loss: 0.9322580695152283, Accuracy: 0.6953125\n",
      "Batch: 144, Loss: 0.881578803062439, Accuracy: 0.712890625\n",
      "Batch: 145, Loss: 0.8358556032180786, Accuracy: 0.7158203125\n",
      "Batch: 146, Loss: 0.9220507740974426, Accuracy: 0.6806640625\n",
      "Batch: 147, Loss: 0.9273760318756104, Accuracy: 0.703125\n",
      "Batch: 148, Loss: 1.0116063356399536, Accuracy: 0.6650390625\n",
      "Batch: 150, Loss: 0.8412654399871826, Accuracy: 0.73046875\n",
      "Batch: 151, Loss: 0.7791317105293274, Accuracy: 0.7490234375\n",
      "Epoch 32/80\n",
      "Batch: 1, Loss: 1.1339808702468872, Accuracy: 0.6328125\n",
      "Batch: 2, Loss: 0.9575655460357666, Accuracy: 0.66796875\n",
      "Batch: 3, Loss: 0.8611421585083008, Accuracy: 0.705078125\n",
      "Batch: 4, Loss: 0.8054048418998718, Accuracy: 0.740234375\n",
      "Batch: 5, Loss: 0.8610538244247437, Accuracy: 0.72265625\n",
      "Batch: 6, Loss: 0.9220919013023376, Accuracy: 0.6962890625\n",
      "Batch: 7, Loss: 0.9250955581665039, Accuracy: 0.6953125\n",
      "Batch: 8, Loss: 0.8260084986686707, Accuracy: 0.7275390625\n",
      "Batch: 9, Loss: 0.8033692836761475, Accuracy: 0.7470703125\n",
      "Batch: 10, Loss: 0.8315714597702026, Accuracy: 0.7197265625\n",
      "Batch: 11, Loss: 0.9771993160247803, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 0.9471514821052551, Accuracy: 0.6904296875\n",
      "Batch: 13, Loss: 0.7398242950439453, Accuracy: 0.7548828125\n",
      "Batch: 14, Loss: 0.9820945262908936, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 0.8210307955741882, Accuracy: 0.734375\n",
      "Batch: 16, Loss: 0.852946400642395, Accuracy: 0.7294921875\n",
      "Batch: 17, Loss: 0.8860598206520081, Accuracy: 0.7138671875\n",
      "Batch: 18, Loss: 0.8753020763397217, Accuracy: 0.7177734375\n",
      "Batch: 19, Loss: 0.9087189435958862, Accuracy: 0.7099609375\n",
      "Batch: 20, Loss: 0.8088469505310059, Accuracy: 0.732421875\n",
      "Batch: 21, Loss: 0.8400401473045349, Accuracy: 0.7255859375\n",
      "Batch: 22, Loss: 0.9427868127822876, Accuracy: 0.7109375\n",
      "Batch: 23, Loss: 0.9062027931213379, Accuracy: 0.6943359375\n",
      "Batch: 24, Loss: 0.8947070240974426, Accuracy: 0.712890625\n",
      "Batch: 25, Loss: 0.8699740171432495, Accuracy: 0.732421875\n",
      "Batch: 26, Loss: 0.7640203237533569, Accuracy: 0.7548828125\n",
      "Batch: 27, Loss: 0.7914608716964722, Accuracy: 0.748046875\n",
      "Batch: 28, Loss: 0.8846660256385803, Accuracy: 0.705078125\n",
      "Batch: 29, Loss: 0.8678205013275146, Accuracy: 0.7255859375\n",
      "Batch: 30, Loss: 0.8296546339988708, Accuracy: 0.736328125\n",
      "Batch: 31, Loss: 0.7921500205993652, Accuracy: 0.740234375\n",
      "Batch: 32, Loss: 0.8062829971313477, Accuracy: 0.728515625\n",
      "Batch: 33, Loss: 0.959330677986145, Accuracy: 0.6923828125\n",
      "Batch: 34, Loss: 0.9904171824455261, Accuracy: 0.685546875\n",
      "Batch: 35, Loss: 0.9518351554870605, Accuracy: 0.6982421875\n",
      "Batch: 36, Loss: 0.9454511404037476, Accuracy: 0.70703125\n",
      "Batch: 37, Loss: 0.8578699827194214, Accuracy: 0.71484375\n",
      "Batch: 38, Loss: 0.9266260862350464, Accuracy: 0.6904296875\n",
      "Batch: 39, Loss: 0.924801230430603, Accuracy: 0.7060546875\n",
      "Batch: 40, Loss: 0.8714282512664795, Accuracy: 0.7197265625\n",
      "Batch: 41, Loss: 0.842854380607605, Accuracy: 0.7236328125\n",
      "Batch: 42, Loss: 0.6875941157341003, Accuracy: 0.763671875\n",
      "Batch: 43, Loss: 0.9011040925979614, Accuracy: 0.701171875\n",
      "Batch: 44, Loss: 0.8971003890037537, Accuracy: 0.70703125\n",
      "Batch: 45, Loss: 0.7933386564254761, Accuracy: 0.732421875\n",
      "Batch: 46, Loss: 0.8300370573997498, Accuracy: 0.7421875\n",
      "Batch: 50, Loss: 0.9467260837554932, Accuracy: 0.69140625\n",
      "Batch: 51, Loss: 0.9674987196922302, Accuracy: 0.685546875\n",
      "Batch: 52, Loss: 0.9392132759094238, Accuracy: 0.7041015625\n",
      "Batch: 53, Loss: 0.8233096599578857, Accuracy: 0.734375\n",
      "Batch: 54, Loss: 0.8580847978591919, Accuracy: 0.716796875\n",
      "Batch: 55, Loss: 0.9758418798446655, Accuracy: 0.6728515625\n",
      "Batch: 56, Loss: 0.9681569337844849, Accuracy: 0.6923828125\n",
      "Batch: 57, Loss: 0.9077329635620117, Accuracy: 0.7021484375\n",
      "Batch: 58, Loss: 0.9826127290725708, Accuracy: 0.6875\n",
      "Batch: 59, Loss: 0.8503434062004089, Accuracy: 0.7275390625\n",
      "Batch: 60, Loss: 0.827788770198822, Accuracy: 0.7333984375\n",
      "Batch: 61, Loss: 0.9165298938751221, Accuracy: 0.701171875\n",
      "Batch: 62, Loss: 0.8871464729309082, Accuracy: 0.71875\n",
      "Batch: 63, Loss: 0.9081358909606934, Accuracy: 0.70703125\n",
      "Batch: 64, Loss: 0.8825818300247192, Accuracy: 0.69140625\n",
      "Batch: 65, Loss: 0.9186559915542603, Accuracy: 0.7158203125\n",
      "Batch: 66, Loss: 0.86932373046875, Accuracy: 0.724609375\n",
      "Batch: 67, Loss: 0.9810783863067627, Accuracy: 0.685546875\n",
      "Batch: 68, Loss: 0.9974464178085327, Accuracy: 0.7021484375\n",
      "Batch: 69, Loss: 0.8911164999008179, Accuracy: 0.7109375\n",
      "Batch: 70, Loss: 0.8863001465797424, Accuracy: 0.728515625\n",
      "Batch: 71, Loss: 0.9000585079193115, Accuracy: 0.7099609375\n",
      "Batch: 72, Loss: 0.7681564688682556, Accuracy: 0.7548828125\n",
      "Batch: 73, Loss: 0.8383817076683044, Accuracy: 0.728515625\n",
      "Batch: 74, Loss: 0.7983415126800537, Accuracy: 0.75390625\n",
      "Batch: 75, Loss: 0.7795506119728088, Accuracy: 0.748046875\n",
      "Batch: 76, Loss: 0.8798811435699463, Accuracy: 0.7138671875\n",
      "Batch: 77, Loss: 0.8277875185012817, Accuracy: 0.73828125\n",
      "Batch: 78, Loss: 0.8310681581497192, Accuracy: 0.7265625\n",
      "Batch: 79, Loss: 0.7852113246917725, Accuracy: 0.748046875\n",
      "Batch: 80, Loss: 0.8259202837944031, Accuracy: 0.7275390625\n",
      "Batch: 81, Loss: 0.9243643283843994, Accuracy: 0.69140625\n",
      "Batch: 82, Loss: 0.9224293231964111, Accuracy: 0.7099609375\n",
      "Batch: 83, Loss: 0.780523955821991, Accuracy: 0.76171875\n",
      "Batch: 84, Loss: 0.8326996564865112, Accuracy: 0.7314453125\n",
      "Batch: 85, Loss: 0.810725212097168, Accuracy: 0.7431640625\n",
      "Batch: 86, Loss: 1.0214283466339111, Accuracy: 0.6611328125\n",
      "Batch: 87, Loss: 0.8025786876678467, Accuracy: 0.748046875\n",
      "Batch: 88, Loss: 0.9117758274078369, Accuracy: 0.716796875\n",
      "Batch: 89, Loss: 0.9230659008026123, Accuracy: 0.716796875\n",
      "Batch: 92, Loss: 0.8870588541030884, Accuracy: 0.7041015625\n",
      "Batch: 93, Loss: 0.859247088432312, Accuracy: 0.71484375\n",
      "Batch: 94, Loss: 0.8703835606575012, Accuracy: 0.7109375\n",
      "Batch: 95, Loss: 0.9392849802970886, Accuracy: 0.6708984375\n",
      "Batch: 96, Loss: 0.8609365224838257, Accuracy: 0.720703125\n",
      "Batch: 97, Loss: 0.7241857647895813, Accuracy: 0.763671875\n",
      "Batch: 98, Loss: 0.7976059913635254, Accuracy: 0.7412109375\n",
      "Batch: 99, Loss: 0.8248539566993713, Accuracy: 0.7373046875\n",
      "Batch: 100, Loss: 0.8352746963500977, Accuracy: 0.73046875\n",
      "Batch: 101, Loss: 0.9622389674186707, Accuracy: 0.697265625\n",
      "Batch: 102, Loss: 0.8704327940940857, Accuracy: 0.7138671875\n",
      "Batch: 103, Loss: 0.888051450252533, Accuracy: 0.7255859375\n",
      "Batch: 104, Loss: 0.7840516567230225, Accuracy: 0.7265625\n",
      "Batch: 105, Loss: 0.8718204498291016, Accuracy: 0.7275390625\n",
      "Batch: 106, Loss: 0.8474747538566589, Accuracy: 0.7265625\n",
      "Batch: 107, Loss: 0.9149424433708191, Accuracy: 0.7119140625\n",
      "Batch: 108, Loss: 0.8598687648773193, Accuracy: 0.716796875\n",
      "Batch: 109, Loss: 0.9960744380950928, Accuracy: 0.6728515625\n",
      "Batch: 110, Loss: 0.778156578540802, Accuracy: 0.7421875\n",
      "Batch: 111, Loss: 0.8964685201644897, Accuracy: 0.708984375\n",
      "Batch: 112, Loss: 0.8817316293716431, Accuracy: 0.7265625\n",
      "Batch: 113, Loss: 0.8885080814361572, Accuracy: 0.708984375\n",
      "Batch: 114, Loss: 0.9867552518844604, Accuracy: 0.6865234375\n",
      "Batch: 115, Loss: 1.008652687072754, Accuracy: 0.6865234375\n",
      "Batch: 116, Loss: 0.9454008340835571, Accuracy: 0.7001953125\n",
      "Batch: 117, Loss: 0.9353221654891968, Accuracy: 0.7109375\n",
      "Batch: 118, Loss: 0.7687385082244873, Accuracy: 0.751953125\n",
      "Batch: 119, Loss: 0.7502081394195557, Accuracy: 0.755859375\n",
      "Batch: 120, Loss: 0.9104778170585632, Accuracy: 0.6962890625\n",
      "Batch: 121, Loss: 0.9216692447662354, Accuracy: 0.6923828125\n",
      "Batch: 122, Loss: 0.8550790548324585, Accuracy: 0.728515625\n",
      "Batch: 123, Loss: 0.8389307260513306, Accuracy: 0.7353515625\n",
      "Batch: 124, Loss: 0.8831145763397217, Accuracy: 0.7080078125\n",
      "Batch: 125, Loss: 0.9269325733184814, Accuracy: 0.6943359375\n",
      "Batch: 126, Loss: 0.9368504285812378, Accuracy: 0.693359375\n",
      "Batch: 127, Loss: 0.8005383610725403, Accuracy: 0.748046875\n",
      "Batch: 128, Loss: 0.9895546436309814, Accuracy: 0.7109375\n",
      "Batch: 129, Loss: 0.8242086172103882, Accuracy: 0.7275390625\n",
      "Batch: 130, Loss: 1.024938941001892, Accuracy: 0.67578125\n",
      "Batch: 131, Loss: 0.9129105806350708, Accuracy: 0.70703125\n",
      "Batch: 132, Loss: 0.9212359189987183, Accuracy: 0.71484375\n",
      "Batch: 133, Loss: 0.837020754814148, Accuracy: 0.716796875\n",
      "Batch: 134, Loss: 0.9290879964828491, Accuracy: 0.6806640625\n",
      "Batch: 135, Loss: 0.7987537384033203, Accuracy: 0.7451171875\n",
      "Batch: 136, Loss: 0.8863413333892822, Accuracy: 0.724609375\n",
      "Batch: 137, Loss: 0.830795168876648, Accuracy: 0.7080078125\n",
      "Batch: 138, Loss: 0.7538920640945435, Accuracy: 0.75390625\n",
      "Batch: 139, Loss: 0.8142447471618652, Accuracy: 0.7294921875\n",
      "Batch: 140, Loss: 0.849219560623169, Accuracy: 0.7177734375\n",
      "Batch: 142, Loss: 0.9356980919837952, Accuracy: 0.7001953125\n",
      "Batch: 143, Loss: 0.8956599235534668, Accuracy: 0.70703125\n",
      "Batch: 144, Loss: 0.8788796663284302, Accuracy: 0.7158203125\n",
      "Batch: 145, Loss: 0.8369786143302917, Accuracy: 0.7158203125\n",
      "Batch: 146, Loss: 0.9181042313575745, Accuracy: 0.7021484375\n",
      "Batch: 147, Loss: 0.9300690293312073, Accuracy: 0.7099609375\n",
      "Batch: 148, Loss: 1.0025153160095215, Accuracy: 0.6689453125\n",
      "Batch: 149, Loss: 0.8808068037033081, Accuracy: 0.7001953125\n",
      "Batch: 150, Loss: 0.8255689740180969, Accuracy: 0.728515625\n",
      "Batch: 151, Loss: 0.7759369611740112, Accuracy: 0.7451171875\n",
      "Epoch 33/80\n",
      "Batch: 1, Loss: 1.145058035850525, Accuracy: 0.662109375\n",
      "Batch: 2, Loss: 0.9188541173934937, Accuracy: 0.677734375\n",
      "Batch: 3, Loss: 0.8754093647003174, Accuracy: 0.7099609375\n",
      "Batch: 4, Loss: 0.7980239391326904, Accuracy: 0.744140625\n",
      "Batch: 5, Loss: 0.823960542678833, Accuracy: 0.734375\n",
      "Batch: 6, Loss: 0.9239858388900757, Accuracy: 0.6875\n",
      "Batch: 7, Loss: 0.894468367099762, Accuracy: 0.6875\n",
      "Batch: 8, Loss: 0.8283933401107788, Accuracy: 0.734375\n",
      "Batch: 9, Loss: 0.8038060665130615, Accuracy: 0.7431640625\n",
      "Batch: 10, Loss: 0.8225481510162354, Accuracy: 0.712890625\n",
      "Batch: 11, Loss: 0.9269121885299683, Accuracy: 0.6845703125\n",
      "Batch: 12, Loss: 0.9643139243125916, Accuracy: 0.67578125\n",
      "Batch: 13, Loss: 0.720853328704834, Accuracy: 0.763671875\n",
      "Batch: 14, Loss: 1.000985860824585, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.8320858478546143, Accuracy: 0.744140625\n",
      "Batch: 16, Loss: 0.8633677363395691, Accuracy: 0.7216796875\n",
      "Batch: 17, Loss: 0.9162355661392212, Accuracy: 0.7060546875\n",
      "Batch: 18, Loss: 0.8935688138008118, Accuracy: 0.703125\n",
      "Batch: 19, Loss: 0.9151999354362488, Accuracy: 0.712890625\n",
      "Batch: 20, Loss: 0.8063843846321106, Accuracy: 0.751953125\n",
      "Batch: 21, Loss: 0.8427616357803345, Accuracy: 0.708984375\n",
      "Batch: 22, Loss: 0.9565762281417847, Accuracy: 0.69921875\n",
      "Batch: 23, Loss: 0.8964599370956421, Accuracy: 0.6982421875\n",
      "Batch: 24, Loss: 0.8877004384994507, Accuracy: 0.716796875\n",
      "Batch: 25, Loss: 0.8649899959564209, Accuracy: 0.7138671875\n",
      "Batch: 26, Loss: 0.7724534273147583, Accuracy: 0.734375\n",
      "Batch: 27, Loss: 0.8032267093658447, Accuracy: 0.7353515625\n",
      "Batch: 28, Loss: 0.8850839138031006, Accuracy: 0.705078125\n",
      "Batch: 29, Loss: 0.8415327072143555, Accuracy: 0.7333984375\n",
      "Batch: 30, Loss: 0.8043023943901062, Accuracy: 0.7548828125\n",
      "Batch: 31, Loss: 0.7991573810577393, Accuracy: 0.7421875\n",
      "Batch: 32, Loss: 0.7788938283920288, Accuracy: 0.7333984375\n",
      "Batch: 33, Loss: 0.9387526512145996, Accuracy: 0.6962890625\n",
      "Batch: 34, Loss: 0.9878862500190735, Accuracy: 0.671875\n",
      "Batch: 36, Loss: 0.938132107257843, Accuracy: 0.7041015625\n",
      "Batch: 37, Loss: 0.8355134725570679, Accuracy: 0.73828125\n",
      "Batch: 38, Loss: 0.9062749147415161, Accuracy: 0.6923828125\n",
      "Batch: 39, Loss: 0.8980941772460938, Accuracy: 0.7197265625\n",
      "Batch: 40, Loss: 0.8743711709976196, Accuracy: 0.708984375\n",
      "Batch: 41, Loss: 0.8163076043128967, Accuracy: 0.7421875\n",
      "Batch: 42, Loss: 0.6844854354858398, Accuracy: 0.7685546875\n",
      "Batch: 43, Loss: 0.884207010269165, Accuracy: 0.697265625\n",
      "Batch: 44, Loss: 0.8877712488174438, Accuracy: 0.7109375\n",
      "Batch: 45, Loss: 0.7689805030822754, Accuracy: 0.7392578125\n",
      "Batch: 46, Loss: 0.8170762658119202, Accuracy: 0.7431640625\n",
      "Batch: 47, Loss: 0.8502546548843384, Accuracy: 0.73046875\n",
      "Batch: 48, Loss: 0.7783759236335754, Accuracy: 0.7421875\n",
      "Batch: 49, Loss: 0.9501464366912842, Accuracy: 0.703125\n",
      "Batch: 50, Loss: 0.9430462121963501, Accuracy: 0.6904296875\n",
      "Batch: 51, Loss: 0.9246070384979248, Accuracy: 0.69921875\n",
      "Batch: 52, Loss: 0.9386160969734192, Accuracy: 0.708984375\n",
      "Batch: 53, Loss: 0.801979660987854, Accuracy: 0.734375\n",
      "Batch: 54, Loss: 0.8783308267593384, Accuracy: 0.701171875\n",
      "Batch: 55, Loss: 0.972669243812561, Accuracy: 0.681640625\n",
      "Batch: 56, Loss: 0.9388254880905151, Accuracy: 0.689453125\n",
      "Batch: 57, Loss: 0.8924060463905334, Accuracy: 0.720703125\n",
      "Batch: 58, Loss: 0.9403133392333984, Accuracy: 0.7041015625\n",
      "Batch: 59, Loss: 0.823842465877533, Accuracy: 0.732421875\n",
      "Batch: 60, Loss: 0.8215125203132629, Accuracy: 0.7353515625\n",
      "Batch: 61, Loss: 0.929108738899231, Accuracy: 0.70703125\n",
      "Batch: 62, Loss: 0.8462090492248535, Accuracy: 0.7158203125\n",
      "Batch: 63, Loss: 0.9103502035140991, Accuracy: 0.7177734375\n",
      "Batch: 64, Loss: 0.8671035170555115, Accuracy: 0.712890625\n",
      "Batch: 65, Loss: 0.9129339456558228, Accuracy: 0.697265625\n",
      "Batch: 66, Loss: 0.8557063937187195, Accuracy: 0.7216796875\n",
      "Batch: 67, Loss: 0.9334602355957031, Accuracy: 0.6953125\n",
      "Batch: 68, Loss: 0.9752358198165894, Accuracy: 0.6953125\n",
      "Batch: 69, Loss: 0.8818792104721069, Accuracy: 0.712890625\n",
      "Batch: 70, Loss: 0.8511462807655334, Accuracy: 0.7373046875\n",
      "Batch: 71, Loss: 0.9064548015594482, Accuracy: 0.705078125\n",
      "Batch: 72, Loss: 0.7914972305297852, Accuracy: 0.7392578125\n",
      "Batch: 73, Loss: 0.8143883943557739, Accuracy: 0.7265625\n",
      "Batch: 74, Loss: 0.7970244884490967, Accuracy: 0.75\n",
      "Batch: 75, Loss: 0.8015056252479553, Accuracy: 0.7373046875\n",
      "Batch: 76, Loss: 0.8703318238258362, Accuracy: 0.7080078125\n",
      "Batch: 77, Loss: 0.8030489087104797, Accuracy: 0.73046875\n",
      "Batch: 78, Loss: 0.8263561725616455, Accuracy: 0.7392578125\n",
      "Batch: 79, Loss: 0.7742317914962769, Accuracy: 0.76171875\n",
      "Batch: 80, Loss: 0.8218603134155273, Accuracy: 0.724609375\n",
      "Batch: 81, Loss: 0.937794029712677, Accuracy: 0.6748046875\n",
      "Batch: 82, Loss: 0.9032161831855774, Accuracy: 0.7119140625\n",
      "Batch: 85, Loss: 0.8028668165206909, Accuracy: 0.73828125\n",
      "Batch: 86, Loss: 1.0300302505493164, Accuracy: 0.6630859375\n",
      "Batch: 87, Loss: 0.8074250221252441, Accuracy: 0.7392578125\n",
      "Batch: 88, Loss: 0.9229947924613953, Accuracy: 0.7177734375\n",
      "Batch: 89, Loss: 0.8978338241577148, Accuracy: 0.720703125\n",
      "Batch: 90, Loss: 0.8298156261444092, Accuracy: 0.7392578125\n",
      "Batch: 91, Loss: 0.8504577875137329, Accuracy: 0.71875\n",
      "Batch: 92, Loss: 0.8771759271621704, Accuracy: 0.712890625\n",
      "Batch: 93, Loss: 0.8534113764762878, Accuracy: 0.7275390625\n",
      "Batch: 94, Loss: 0.8881345391273499, Accuracy: 0.708984375\n",
      "Batch: 95, Loss: 0.8964557647705078, Accuracy: 0.6884765625\n",
      "Batch: 96, Loss: 0.8626397848129272, Accuracy: 0.7255859375\n",
      "Batch: 97, Loss: 0.7126491069793701, Accuracy: 0.7666015625\n",
      "Batch: 98, Loss: 0.8020721673965454, Accuracy: 0.744140625\n",
      "Batch: 99, Loss: 0.8293205499649048, Accuracy: 0.7314453125\n",
      "Batch: 100, Loss: 0.851594090461731, Accuracy: 0.7314453125\n",
      "Batch: 101, Loss: 0.9141278266906738, Accuracy: 0.7080078125\n",
      "Batch: 102, Loss: 0.8396550416946411, Accuracy: 0.7275390625\n",
      "Batch: 103, Loss: 0.8993803858757019, Accuracy: 0.7216796875\n",
      "Batch: 104, Loss: 0.7762373685836792, Accuracy: 0.740234375\n",
      "Batch: 105, Loss: 0.8917233347892761, Accuracy: 0.7265625\n",
      "Batch: 106, Loss: 0.8295438289642334, Accuracy: 0.7294921875\n",
      "Batch: 107, Loss: 0.8924647569656372, Accuracy: 0.716796875\n",
      "Batch: 108, Loss: 0.8522424101829529, Accuracy: 0.712890625\n",
      "Batch: 109, Loss: 0.9601055383682251, Accuracy: 0.689453125\n",
      "Batch: 110, Loss: 0.7698455452919006, Accuracy: 0.7509765625\n",
      "Batch: 111, Loss: 0.8849588632583618, Accuracy: 0.7099609375\n",
      "Batch: 112, Loss: 0.8885222673416138, Accuracy: 0.72265625\n",
      "Batch: 113, Loss: 0.8793745636940002, Accuracy: 0.7119140625\n",
      "Batch: 114, Loss: 0.9522308111190796, Accuracy: 0.6904296875\n",
      "Batch: 115, Loss: 1.0071531534194946, Accuracy: 0.6943359375\n",
      "Batch: 116, Loss: 0.9203580021858215, Accuracy: 0.70703125\n",
      "Batch: 117, Loss: 0.9148721694946289, Accuracy: 0.71875\n",
      "Batch: 118, Loss: 0.7678755521774292, Accuracy: 0.75390625\n",
      "Batch: 119, Loss: 0.7639451622962952, Accuracy: 0.7529296875\n",
      "Batch: 120, Loss: 0.9054177403450012, Accuracy: 0.7109375\n",
      "Batch: 121, Loss: 0.9164770841598511, Accuracy: 0.7001953125\n",
      "Batch: 122, Loss: 0.8326362371444702, Accuracy: 0.728515625\n",
      "Batch: 123, Loss: 0.8393373489379883, Accuracy: 0.74609375\n",
      "Batch: 124, Loss: 0.8734201192855835, Accuracy: 0.71484375\n",
      "Batch: 125, Loss: 0.9494118690490723, Accuracy: 0.6943359375\n",
      "Batch: 126, Loss: 0.9192060232162476, Accuracy: 0.6923828125\n",
      "Batch: 127, Loss: 0.7656984329223633, Accuracy: 0.7685546875\n",
      "Batch: 128, Loss: 0.9723315834999084, Accuracy: 0.7197265625\n",
      "Batch: 129, Loss: 0.7941466569900513, Accuracy: 0.7431640625\n",
      "Batch: 130, Loss: 1.008974313735962, Accuracy: 0.6845703125\n",
      "Batch: 131, Loss: 0.8982421159744263, Accuracy: 0.705078125\n",
      "Batch: 132, Loss: 0.9358984231948853, Accuracy: 0.69140625\n",
      "Batch: 135, Loss: 0.8018494248390198, Accuracy: 0.740234375\n",
      "Batch: 136, Loss: 0.8754322528839111, Accuracy: 0.7255859375\n",
      "Batch: 137, Loss: 0.8444421291351318, Accuracy: 0.7197265625\n",
      "Batch: 138, Loss: 0.7536193132400513, Accuracy: 0.75390625\n",
      "Batch: 139, Loss: 0.8089411854743958, Accuracy: 0.728515625\n",
      "Batch: 140, Loss: 0.8668721914291382, Accuracy: 0.7080078125\n",
      "Batch: 141, Loss: 0.8747090101242065, Accuracy: 0.7080078125\n",
      "Batch: 142, Loss: 0.9434360861778259, Accuracy: 0.697265625\n",
      "Batch: 143, Loss: 0.8616935014724731, Accuracy: 0.71875\n",
      "Batch: 144, Loss: 0.8651463389396667, Accuracy: 0.7216796875\n",
      "Batch: 145, Loss: 0.8203022480010986, Accuracy: 0.720703125\n",
      "Batch: 146, Loss: 0.8810631036758423, Accuracy: 0.716796875\n",
      "Batch: 147, Loss: 0.9115161299705505, Accuracy: 0.6953125\n",
      "Batch: 148, Loss: 0.9887321591377258, Accuracy: 0.6787109375\n",
      "Batch: 149, Loss: 0.8789793848991394, Accuracy: 0.716796875\n",
      "Batch: 150, Loss: 0.808893084526062, Accuracy: 0.7373046875\n",
      "Batch: 151, Loss: 0.7643628716468811, Accuracy: 0.7578125\n",
      "Epoch 34/80\n",
      "Batch: 1, Loss: 1.1585242748260498, Accuracy: 0.6513671875\n",
      "Batch: 2, Loss: 0.9665195941925049, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 0.8692708611488342, Accuracy: 0.7080078125\n",
      "Batch: 4, Loss: 0.7703154683113098, Accuracy: 0.7529296875\n",
      "Batch: 5, Loss: 0.8198909759521484, Accuracy: 0.7353515625\n",
      "Batch: 6, Loss: 0.8986575603485107, Accuracy: 0.703125\n",
      "Batch: 7, Loss: 0.8840876817703247, Accuracy: 0.693359375\n",
      "Batch: 8, Loss: 0.8170875906944275, Accuracy: 0.7255859375\n",
      "Batch: 9, Loss: 0.8022171258926392, Accuracy: 0.7529296875\n",
      "Batch: 10, Loss: 0.8020403385162354, Accuracy: 0.732421875\n",
      "Batch: 11, Loss: 0.9700698852539062, Accuracy: 0.666015625\n",
      "Batch: 12, Loss: 0.9331291913986206, Accuracy: 0.68359375\n",
      "Batch: 13, Loss: 0.7188927531242371, Accuracy: 0.7734375\n",
      "Batch: 14, Loss: 0.9530071020126343, Accuracy: 0.6962890625\n",
      "Batch: 15, Loss: 0.8089674711227417, Accuracy: 0.740234375\n",
      "Batch: 16, Loss: 0.8318209648132324, Accuracy: 0.744140625\n",
      "Batch: 17, Loss: 0.905226469039917, Accuracy: 0.701171875\n",
      "Batch: 18, Loss: 0.8636667728424072, Accuracy: 0.7158203125\n",
      "Batch: 19, Loss: 0.9082472920417786, Accuracy: 0.71484375\n",
      "Batch: 20, Loss: 0.7953473329544067, Accuracy: 0.75\n",
      "Batch: 21, Loss: 0.8029050230979919, Accuracy: 0.7431640625\n",
      "Batch: 22, Loss: 0.931577205657959, Accuracy: 0.7060546875\n",
      "Batch: 23, Loss: 0.8661785125732422, Accuracy: 0.7099609375\n",
      "Batch: 24, Loss: 0.9034445285797119, Accuracy: 0.708984375\n",
      "Batch: 25, Loss: 0.8606184720993042, Accuracy: 0.712890625\n",
      "Batch: 26, Loss: 0.7616365551948547, Accuracy: 0.73828125\n",
      "Batch: 27, Loss: 0.7918026447296143, Accuracy: 0.7412109375\n",
      "Batch: 28, Loss: 0.8987568616867065, Accuracy: 0.708984375\n",
      "Batch: 29, Loss: 0.8278650641441345, Accuracy: 0.7333984375\n",
      "Batch: 30, Loss: 0.7914413213729858, Accuracy: 0.7587890625\n",
      "Batch: 31, Loss: 0.783930778503418, Accuracy: 0.7431640625\n",
      "Batch: 32, Loss: 0.7820189595222473, Accuracy: 0.7373046875\n",
      "Batch: 33, Loss: 0.9417168498039246, Accuracy: 0.7001953125\n",
      "Batch: 34, Loss: 0.9889376163482666, Accuracy: 0.6787109375\n",
      "Batch: 35, Loss: 0.926811933517456, Accuracy: 0.7060546875\n",
      "Batch: 36, Loss: 0.9266139268875122, Accuracy: 0.7197265625\n",
      "Batch: 37, Loss: 0.8624685406684875, Accuracy: 0.7216796875\n",
      "Batch: 38, Loss: 0.8800680041313171, Accuracy: 0.708984375\n",
      "Batch: 39, Loss: 0.8816807866096497, Accuracy: 0.72265625\n",
      "Batch: 40, Loss: 0.855398952960968, Accuracy: 0.7275390625\n",
      "Batch: 41, Loss: 0.8350079655647278, Accuracy: 0.732421875\n",
      "Batch: 42, Loss: 0.6810463666915894, Accuracy: 0.76171875\n",
      "Batch: 43, Loss: 0.875781774520874, Accuracy: 0.703125\n",
      "Batch: 44, Loss: 0.8801584243774414, Accuracy: 0.720703125\n",
      "Batch: 45, Loss: 0.772281289100647, Accuracy: 0.7421875\n",
      "Batch: 46, Loss: 0.8334293365478516, Accuracy: 0.72265625\n",
      "Batch: 47, Loss: 0.8488091230392456, Accuracy: 0.732421875\n",
      "Batch: 48, Loss: 0.7854012250900269, Accuracy: 0.74609375\n",
      "Batch: 49, Loss: 0.91680908203125, Accuracy: 0.703125\n",
      "Batch: 50, Loss: 0.9180479049682617, Accuracy: 0.69921875\n",
      "Batch: 51, Loss: 0.9495023488998413, Accuracy: 0.6767578125\n",
      "Batch: 52, Loss: 0.9120839834213257, Accuracy: 0.7041015625\n",
      "Batch: 53, Loss: 0.7837655544281006, Accuracy: 0.7373046875\n",
      "Batch: 54, Loss: 0.8485350012779236, Accuracy: 0.720703125\n",
      "Batch: 55, Loss: 0.9755818247795105, Accuracy: 0.6708984375\n",
      "Batch: 56, Loss: 0.9367008209228516, Accuracy: 0.7041015625\n",
      "Batch: 57, Loss: 0.8961489796638489, Accuracy: 0.71484375\n",
      "Batch: 58, Loss: 0.9613695740699768, Accuracy: 0.7021484375\n",
      "Batch: 59, Loss: 0.8499535322189331, Accuracy: 0.7275390625\n",
      "Batch: 60, Loss: 0.8139475584030151, Accuracy: 0.7265625\n",
      "Batch: 61, Loss: 0.9053710103034973, Accuracy: 0.7001953125\n",
      "Batch: 62, Loss: 0.8306386470794678, Accuracy: 0.724609375\n",
      "Batch: 63, Loss: 0.9182817339897156, Accuracy: 0.701171875\n",
      "Batch: 64, Loss: 0.8899580240249634, Accuracy: 0.7001953125\n",
      "Batch: 65, Loss: 0.8720771670341492, Accuracy: 0.724609375\n",
      "Batch: 66, Loss: 0.8377926349639893, Accuracy: 0.7353515625\n",
      "Batch: 67, Loss: 0.9374018311500549, Accuracy: 0.7119140625\n",
      "Batch: 68, Loss: 0.978958010673523, Accuracy: 0.69140625\n",
      "Batch: 69, Loss: 0.8825057744979858, Accuracy: 0.7197265625\n",
      "Batch: 70, Loss: 0.8568780422210693, Accuracy: 0.7314453125\n",
      "Batch: 71, Loss: 0.8847760558128357, Accuracy: 0.6962890625\n",
      "Batch: 72, Loss: 0.7754088044166565, Accuracy: 0.734375\n",
      "Batch: 73, Loss: 0.8038190603256226, Accuracy: 0.73828125\n",
      "Batch: 74, Loss: 0.7574247121810913, Accuracy: 0.7548828125\n",
      "Batch: 75, Loss: 0.7881711721420288, Accuracy: 0.748046875\n",
      "Batch: 76, Loss: 0.8609766364097595, Accuracy: 0.724609375\n",
      "Batch: 77, Loss: 0.8135155439376831, Accuracy: 0.7333984375\n",
      "Batch: 78, Loss: 0.8084686994552612, Accuracy: 0.7431640625\n",
      "Batch: 79, Loss: 0.7739138603210449, Accuracy: 0.7578125\n",
      "Batch: 80, Loss: 0.8186048269271851, Accuracy: 0.716796875\n",
      "Batch: 81, Loss: 0.9335852861404419, Accuracy: 0.6796875\n",
      "Batch: 82, Loss: 0.8834450840950012, Accuracy: 0.7216796875\n",
      "Batch: 83, Loss: 0.7693027257919312, Accuracy: 0.7431640625\n",
      "Batch: 84, Loss: 0.8286122679710388, Accuracy: 0.7275390625\n",
      "Batch: 85, Loss: 0.7841793298721313, Accuracy: 0.7509765625\n",
      "Batch: 86, Loss: 0.9930382966995239, Accuracy: 0.6875\n",
      "Batch: 87, Loss: 0.7940927743911743, Accuracy: 0.7509765625\n",
      "Batch: 88, Loss: 0.9002276062965393, Accuracy: 0.7294921875\n",
      "Batch: 89, Loss: 0.9039930701255798, Accuracy: 0.72265625\n",
      "Batch: 90, Loss: 0.8237482905387878, Accuracy: 0.724609375\n",
      "Batch: 91, Loss: 0.8425865173339844, Accuracy: 0.724609375\n",
      "Batch: 92, Loss: 0.8908343315124512, Accuracy: 0.701171875\n",
      "Batch: 93, Loss: 0.8530008792877197, Accuracy: 0.7109375\n",
      "Batch: 94, Loss: 0.8582139015197754, Accuracy: 0.7158203125\n",
      "Batch: 95, Loss: 0.9130468368530273, Accuracy: 0.69140625\n",
      "Batch: 96, Loss: 0.821392297744751, Accuracy: 0.720703125\n",
      "Batch: 97, Loss: 0.7321853637695312, Accuracy: 0.7607421875\n",
      "Batch: 98, Loss: 0.7877478003501892, Accuracy: 0.755859375\n",
      "Batch: 99, Loss: 0.807099461555481, Accuracy: 0.7373046875\n",
      "Batch: 100, Loss: 0.8531355857849121, Accuracy: 0.7236328125\n",
      "Batch: 101, Loss: 0.9202037453651428, Accuracy: 0.6982421875\n",
      "Batch: 102, Loss: 0.8461548089981079, Accuracy: 0.7333984375\n",
      "Batch: 103, Loss: 0.8673502206802368, Accuracy: 0.7490234375\n",
      "Batch: 104, Loss: 0.8068066835403442, Accuracy: 0.71484375\n",
      "Batch: 105, Loss: 0.8842071890830994, Accuracy: 0.7158203125\n",
      "Batch: 106, Loss: 0.7950724363327026, Accuracy: 0.7421875\n",
      "Batch: 107, Loss: 0.8960232138633728, Accuracy: 0.716796875\n",
      "Batch: 108, Loss: 0.8708703517913818, Accuracy: 0.7099609375\n",
      "Batch: 109, Loss: 0.9756974577903748, Accuracy: 0.671875\n",
      "Batch: 110, Loss: 0.7684546709060669, Accuracy: 0.75\n",
      "Batch: 111, Loss: 0.884048581123352, Accuracy: 0.716796875\n",
      "Batch: 112, Loss: 0.8653243184089661, Accuracy: 0.734375\n",
      "Batch: 113, Loss: 0.8540830612182617, Accuracy: 0.716796875\n",
      "Batch: 114, Loss: 0.9475115537643433, Accuracy: 0.6826171875\n",
      "Batch: 115, Loss: 0.9883525371551514, Accuracy: 0.6884765625\n",
      "Batch: 116, Loss: 0.8928543925285339, Accuracy: 0.7275390625\n",
      "Batch: 117, Loss: 0.9304248094558716, Accuracy: 0.693359375\n",
      "Batch: 118, Loss: 0.742029070854187, Accuracy: 0.7646484375\n",
      "Batch: 119, Loss: 0.7394125461578369, Accuracy: 0.7587890625\n",
      "Batch: 120, Loss: 0.8820675611495972, Accuracy: 0.7119140625\n",
      "Batch: 121, Loss: 0.9037309885025024, Accuracy: 0.7001953125\n",
      "Batch: 122, Loss: 0.8160847425460815, Accuracy: 0.73046875\n",
      "Batch: 123, Loss: 0.8207281827926636, Accuracy: 0.734375\n",
      "Batch: 124, Loss: 0.8826038837432861, Accuracy: 0.71875\n",
      "Batch: 125, Loss: 0.930964469909668, Accuracy: 0.7021484375\n",
      "Batch: 126, Loss: 0.8930745124816895, Accuracy: 0.708984375\n",
      "Batch: 127, Loss: 0.7635867595672607, Accuracy: 0.76171875\n",
      "Batch: 128, Loss: 0.9711945056915283, Accuracy: 0.71484375\n",
      "Batch: 129, Loss: 0.7983341813087463, Accuracy: 0.736328125\n",
      "Batch: 130, Loss: 0.9610058069229126, Accuracy: 0.69921875\n",
      "Batch: 131, Loss: 0.9033520221710205, Accuracy: 0.701171875\n",
      "Batch: 132, Loss: 0.9001444578170776, Accuracy: 0.7119140625\n",
      "Batch: 133, Loss: 0.7986319065093994, Accuracy: 0.7333984375\n",
      "Batch: 134, Loss: 0.9007778763771057, Accuracy: 0.6953125\n",
      "Batch: 135, Loss: 0.7773114442825317, Accuracy: 0.7470703125\n",
      "Batch: 136, Loss: 0.872673749923706, Accuracy: 0.7275390625\n",
      "Batch: 137, Loss: 0.8339042663574219, Accuracy: 0.7119140625\n",
      "Batch: 138, Loss: 0.7426764965057373, Accuracy: 0.755859375\n",
      "Batch: 139, Loss: 0.7783589363098145, Accuracy: 0.7470703125\n",
      "Batch: 140, Loss: 0.8393180966377258, Accuracy: 0.7177734375\n",
      "Batch: 141, Loss: 0.8857479095458984, Accuracy: 0.7236328125\n",
      "Batch: 142, Loss: 0.8978358507156372, Accuracy: 0.69921875\n",
      "Batch: 143, Loss: 0.8933249711990356, Accuracy: 0.7119140625\n",
      "Batch: 144, Loss: 0.8597496747970581, Accuracy: 0.724609375\n",
      "Batch: 145, Loss: 0.8198349475860596, Accuracy: 0.7119140625\n",
      "Batch: 146, Loss: 0.9095081090927124, Accuracy: 0.701171875\n",
      "Batch: 147, Loss: 0.891625165939331, Accuracy: 0.70703125\n",
      "Batch: 148, Loss: 0.9702704548835754, Accuracy: 0.6845703125\n",
      "Batch: 149, Loss: 0.8328016996383667, Accuracy: 0.7294921875\n",
      "Batch: 150, Loss: 0.8319966793060303, Accuracy: 0.7333984375\n",
      "Batch: 151, Loss: 0.7525800466537476, Accuracy: 0.75390625\n",
      "Epoch 35/80\n",
      "Batch: 1, Loss: 1.1105667352676392, Accuracy: 0.6328125\n",
      "Batch: 2, Loss: 0.9415920972824097, Accuracy: 0.6796875\n",
      "Batch: 3, Loss: 0.8466615676879883, Accuracy: 0.7138671875\n",
      "Batch: 4, Loss: 0.766951322555542, Accuracy: 0.748046875\n",
      "Batch: 5, Loss: 0.8188493251800537, Accuracy: 0.740234375\n",
      "Batch: 6, Loss: 0.8900290727615356, Accuracy: 0.6875\n",
      "Batch: 7, Loss: 0.8733090162277222, Accuracy: 0.705078125\n",
      "Batch: 8, Loss: 0.8076863288879395, Accuracy: 0.7265625\n",
      "Batch: 9, Loss: 0.7853306531906128, Accuracy: 0.74609375\n",
      "Batch: 10, Loss: 0.7931861877441406, Accuracy: 0.732421875\n",
      "Batch: 11, Loss: 0.9364174604415894, Accuracy: 0.6669921875\n",
      "Batch: 12, Loss: 0.919355034828186, Accuracy: 0.6982421875\n",
      "Batch: 13, Loss: 0.7032135725021362, Accuracy: 0.7666015625\n",
      "Batch: 14, Loss: 0.9584641456604004, Accuracy: 0.6875\n",
      "Batch: 15, Loss: 0.8086633682250977, Accuracy: 0.751953125\n",
      "Batch: 16, Loss: 0.8367429971694946, Accuracy: 0.7314453125\n",
      "Batch: 17, Loss: 0.8983962535858154, Accuracy: 0.7041015625\n",
      "Batch: 18, Loss: 0.8652467727661133, Accuracy: 0.71875\n",
      "Batch: 19, Loss: 0.8812137246131897, Accuracy: 0.7177734375\n",
      "Batch: 20, Loss: 0.7733632326126099, Accuracy: 0.765625\n",
      "Batch: 21, Loss: 0.8194943070411682, Accuracy: 0.7314453125\n",
      "Batch: 22, Loss: 0.9404991269111633, Accuracy: 0.7119140625\n",
      "Batch: 23, Loss: 0.882553219795227, Accuracy: 0.7197265625\n",
      "Batch: 24, Loss: 0.8965277075767517, Accuracy: 0.7138671875\n",
      "Batch: 25, Loss: 0.8512356281280518, Accuracy: 0.7216796875\n",
      "Batch: 26, Loss: 0.7557374835014343, Accuracy: 0.7490234375\n",
      "Batch: 27, Loss: 0.7957693338394165, Accuracy: 0.7265625\n",
      "Batch: 28, Loss: 0.8866478204727173, Accuracy: 0.7041015625\n",
      "Batch: 29, Loss: 0.8221461772918701, Accuracy: 0.7265625\n",
      "Batch: 30, Loss: 0.801012396812439, Accuracy: 0.748046875\n",
      "Batch: 31, Loss: 0.779863715171814, Accuracy: 0.74609375\n",
      "Batch: 32, Loss: 0.7802059054374695, Accuracy: 0.7431640625\n",
      "Batch: 33, Loss: 0.9084126949310303, Accuracy: 0.716796875\n",
      "Batch: 34, Loss: 0.9779955148696899, Accuracy: 0.6865234375\n",
      "Batch: 35, Loss: 0.9259124994277954, Accuracy: 0.6865234375\n",
      "Batch: 36, Loss: 0.9201686978340149, Accuracy: 0.7099609375\n",
      "Batch: 37, Loss: 0.8379158973693848, Accuracy: 0.7333984375\n",
      "Batch: 38, Loss: 0.8817880749702454, Accuracy: 0.7021484375\n",
      "Batch: 39, Loss: 0.8634358048439026, Accuracy: 0.712890625\n",
      "Batch: 40, Loss: 0.8449832201004028, Accuracy: 0.712890625\n",
      "Batch: 41, Loss: 0.8106876611709595, Accuracy: 0.734375\n",
      "Batch: 42, Loss: 0.6677709221839905, Accuracy: 0.783203125\n",
      "Batch: 43, Loss: 0.8896151781082153, Accuracy: 0.7119140625\n",
      "Batch: 44, Loss: 0.8719015121459961, Accuracy: 0.7119140625\n",
      "Batch: 45, Loss: 0.7808787822723389, Accuracy: 0.7265625\n",
      "Batch: 46, Loss: 0.8057824373245239, Accuracy: 0.7275390625\n",
      "Batch: 47, Loss: 0.8469659090042114, Accuracy: 0.740234375\n",
      "Batch: 48, Loss: 0.7712749242782593, Accuracy: 0.755859375\n",
      "Batch: 49, Loss: 0.9022790193557739, Accuracy: 0.7138671875\n",
      "Batch: 50, Loss: 0.8968605995178223, Accuracy: 0.70703125\n",
      "Batch: 51, Loss: 0.9302999377250671, Accuracy: 0.69140625\n",
      "Batch: 52, Loss: 0.9132033586502075, Accuracy: 0.6982421875\n",
      "Batch: 53, Loss: 0.7901681661605835, Accuracy: 0.740234375\n",
      "Batch: 54, Loss: 0.8461618423461914, Accuracy: 0.7236328125\n",
      "Batch: 55, Loss: 0.9371113181114197, Accuracy: 0.6806640625\n",
      "Batch: 56, Loss: 0.9172931909561157, Accuracy: 0.712890625\n",
      "Batch: 57, Loss: 0.8647671937942505, Accuracy: 0.7158203125\n",
      "Batch: 58, Loss: 0.9792304635047913, Accuracy: 0.703125\n",
      "Batch: 59, Loss: 0.8191268444061279, Accuracy: 0.734375\n",
      "Batch: 60, Loss: 0.8131980299949646, Accuracy: 0.7412109375\n",
      "Batch: 61, Loss: 0.9055732488632202, Accuracy: 0.716796875\n",
      "Batch: 62, Loss: 0.853100061416626, Accuracy: 0.720703125\n",
      "Batch: 63, Loss: 0.8880473971366882, Accuracy: 0.7158203125\n",
      "Batch: 64, Loss: 0.8629319667816162, Accuracy: 0.716796875\n",
      "Batch: 65, Loss: 0.8975786566734314, Accuracy: 0.71875\n",
      "Batch: 66, Loss: 0.8127532005310059, Accuracy: 0.7353515625\n",
      "Batch: 68, Loss: 0.9813634753227234, Accuracy: 0.7119140625\n",
      "Batch: 69, Loss: 0.8696677684783936, Accuracy: 0.7197265625\n",
      "Batch: 70, Loss: 0.8508080244064331, Accuracy: 0.728515625\n",
      "Batch: 71, Loss: 0.8926563262939453, Accuracy: 0.693359375\n",
      "Batch: 72, Loss: 0.7634894847869873, Accuracy: 0.73828125\n",
      "Batch: 73, Loss: 0.7965909242630005, Accuracy: 0.7529296875\n",
      "Batch: 74, Loss: 0.7550563216209412, Accuracy: 0.7607421875\n",
      "Batch: 75, Loss: 0.7775974273681641, Accuracy: 0.748046875\n",
      "Batch: 76, Loss: 0.868515133857727, Accuracy: 0.71875\n",
      "Batch: 77, Loss: 0.7993112802505493, Accuracy: 0.7255859375\n",
      "Batch: 78, Loss: 0.798310399055481, Accuracy: 0.7509765625\n",
      "Batch: 79, Loss: 0.7890914678573608, Accuracy: 0.74609375\n",
      "Batch: 80, Loss: 0.8233083486557007, Accuracy: 0.73046875\n",
      "Batch: 81, Loss: 0.9114628434181213, Accuracy: 0.6748046875\n",
      "Batch: 82, Loss: 0.8953168392181396, Accuracy: 0.7099609375\n",
      "Batch: 83, Loss: 0.7508935928344727, Accuracy: 0.763671875\n",
      "Batch: 84, Loss: 0.8389731645584106, Accuracy: 0.7265625\n",
      "Batch: 85, Loss: 0.7674705386161804, Accuracy: 0.748046875\n",
      "Batch: 86, Loss: 0.9725508689880371, Accuracy: 0.6943359375\n",
      "Batch: 87, Loss: 0.7982546091079712, Accuracy: 0.7470703125\n",
      "Batch: 88, Loss: 0.8958084583282471, Accuracy: 0.728515625\n",
      "Batch: 89, Loss: 0.881820797920227, Accuracy: 0.7275390625\n",
      "Batch: 90, Loss: 0.8227077126502991, Accuracy: 0.7333984375\n",
      "Batch: 91, Loss: 0.8494359254837036, Accuracy: 0.7197265625\n",
      "Batch: 92, Loss: 0.8594400882720947, Accuracy: 0.70703125\n",
      "Batch: 93, Loss: 0.8341420888900757, Accuracy: 0.724609375\n",
      "Batch: 94, Loss: 0.8630434274673462, Accuracy: 0.7099609375\n",
      "Batch: 95, Loss: 0.902920663356781, Accuracy: 0.703125\n",
      "Batch: 96, Loss: 0.8164963722229004, Accuracy: 0.7294921875\n",
      "Batch: 97, Loss: 0.7214004397392273, Accuracy: 0.75390625\n",
      "Batch: 98, Loss: 0.7901832461357117, Accuracy: 0.7529296875\n",
      "Batch: 99, Loss: 0.8107593655586243, Accuracy: 0.734375\n",
      "Batch: 100, Loss: 0.8570758104324341, Accuracy: 0.720703125\n",
      "Batch: 101, Loss: 0.9317864179611206, Accuracy: 0.6943359375\n",
      "Batch: 102, Loss: 0.8291345238685608, Accuracy: 0.7392578125\n",
      "Batch: 103, Loss: 0.8662997484207153, Accuracy: 0.7314453125\n",
      "Batch: 104, Loss: 0.7791208624839783, Accuracy: 0.736328125\n",
      "Batch: 105, Loss: 0.8585143089294434, Accuracy: 0.732421875\n",
      "Batch: 106, Loss: 0.7911685109138489, Accuracy: 0.7353515625\n",
      "Batch: 107, Loss: 0.8741986751556396, Accuracy: 0.7099609375\n",
      "Batch: 108, Loss: 0.843031108379364, Accuracy: 0.7265625\n",
      "Batch: 109, Loss: 0.9638922214508057, Accuracy: 0.693359375\n",
      "Batch: 110, Loss: 0.7761842012405396, Accuracy: 0.75\n",
      "Batch: 111, Loss: 0.8954895734786987, Accuracy: 0.7138671875\n",
      "Batch: 112, Loss: 0.8387284874916077, Accuracy: 0.7451171875\n",
      "Batch: 113, Loss: 0.8689436316490173, Accuracy: 0.7138671875\n",
      "Batch: 114, Loss: 0.9423305988311768, Accuracy: 0.6943359375\n",
      "Batch: 115, Loss: 0.9746142625808716, Accuracy: 0.693359375\n",
      "Batch: 116, Loss: 0.8982391357421875, Accuracy: 0.7333984375\n",
      "Batch: 117, Loss: 0.9032114744186401, Accuracy: 0.7080078125\n",
      "Batch: 118, Loss: 0.7571225166320801, Accuracy: 0.75390625\n",
      "Batch: 119, Loss: 0.7453364133834839, Accuracy: 0.767578125\n",
      "Batch: 120, Loss: 0.885392427444458, Accuracy: 0.708984375\n",
      "Batch: 121, Loss: 0.9229006171226501, Accuracy: 0.6953125\n",
      "Batch: 122, Loss: 0.8136934041976929, Accuracy: 0.7412109375\n",
      "Batch: 123, Loss: 0.8112167119979858, Accuracy: 0.7333984375\n",
      "Batch: 124, Loss: 0.8828070163726807, Accuracy: 0.7021484375\n",
      "Batch: 125, Loss: 0.9256256818771362, Accuracy: 0.7021484375\n",
      "Batch: 126, Loss: 0.8676447868347168, Accuracy: 0.7216796875\n",
      "Batch: 127, Loss: 0.7812854647636414, Accuracy: 0.7646484375\n",
      "Batch: 128, Loss: 0.9511820077896118, Accuracy: 0.7158203125\n",
      "Batch: 129, Loss: 0.7809584140777588, Accuracy: 0.7451171875\n",
      "Batch: 130, Loss: 0.9921075105667114, Accuracy: 0.685546875\n",
      "Batch: 131, Loss: 0.8986554741859436, Accuracy: 0.7021484375\n",
      "Batch: 132, Loss: 0.9140728712081909, Accuracy: 0.703125\n",
      "Batch: 133, Loss: 0.8019599914550781, Accuracy: 0.734375\n",
      "Batch: 134, Loss: 0.9077891111373901, Accuracy: 0.6962890625\n",
      "Batch: 135, Loss: 0.7686435580253601, Accuracy: 0.75\n",
      "Batch: 136, Loss: 0.8511143922805786, Accuracy: 0.7177734375\n",
      "Batch: 137, Loss: 0.8018720149993896, Accuracy: 0.7275390625\n",
      "Batch: 138, Loss: 0.7204468846321106, Accuracy: 0.7578125\n",
      "Batch: 139, Loss: 0.7952128648757935, Accuracy: 0.7353515625\n",
      "Batch: 140, Loss: 0.813454270362854, Accuracy: 0.7275390625\n",
      "Batch: 141, Loss: 0.8840022683143616, Accuracy: 0.712890625\n",
      "Batch: 142, Loss: 0.9124684929847717, Accuracy: 0.705078125\n",
      "Batch: 143, Loss: 0.8390219211578369, Accuracy: 0.7197265625\n",
      "Batch: 144, Loss: 0.8625190258026123, Accuracy: 0.716796875\n",
      "Batch: 145, Loss: 0.8055034875869751, Accuracy: 0.7294921875\n",
      "Batch: 146, Loss: 0.9144643545150757, Accuracy: 0.7041015625\n",
      "Batch: 147, Loss: 0.8807418346405029, Accuracy: 0.7314453125\n",
      "Batch: 148, Loss: 0.9667160511016846, Accuracy: 0.681640625\n",
      "Batch: 149, Loss: 0.8516132831573486, Accuracy: 0.712890625\n",
      "Batch: 150, Loss: 0.8251292705535889, Accuracy: 0.732421875\n",
      "Batch: 151, Loss: 0.7594407796859741, Accuracy: 0.74609375\n",
      "Epoch 36/80\n",
      "Batch: 1, Loss: 1.1222859621047974, Accuracy: 0.6474609375\n",
      "Batch: 2, Loss: 0.8922505974769592, Accuracy: 0.69140625\n",
      "Batch: 3, Loss: 0.817833423614502, Accuracy: 0.73828125\n",
      "Batch: 4, Loss: 0.763458251953125, Accuracy: 0.7529296875\n",
      "Batch: 5, Loss: 0.805255651473999, Accuracy: 0.74609375\n",
      "Batch: 6, Loss: 0.8874917030334473, Accuracy: 0.697265625\n",
      "Batch: 7, Loss: 0.8798968195915222, Accuracy: 0.69921875\n",
      "Batch: 8, Loss: 0.8153840899467468, Accuracy: 0.724609375\n",
      "Batch: 9, Loss: 0.7894203662872314, Accuracy: 0.7568359375\n",
      "Batch: 10, Loss: 0.782224178314209, Accuracy: 0.7421875\n",
      "Batch: 11, Loss: 0.9423211216926575, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 0.9545711874961853, Accuracy: 0.697265625\n",
      "Batch: 13, Loss: 0.7125304341316223, Accuracy: 0.7744140625\n",
      "Batch: 14, Loss: 0.9439625144004822, Accuracy: 0.697265625\n",
      "Batch: 15, Loss: 0.7849377989768982, Accuracy: 0.759765625\n",
      "Batch: 18, Loss: 0.8607247471809387, Accuracy: 0.7119140625\n",
      "Batch: 19, Loss: 0.881153404712677, Accuracy: 0.7314453125\n",
      "Batch: 20, Loss: 0.7947887778282166, Accuracy: 0.75\n",
      "Batch: 21, Loss: 0.8118895888328552, Accuracy: 0.7451171875\n",
      "Batch: 22, Loss: 0.9366753697395325, Accuracy: 0.703125\n",
      "Batch: 23, Loss: 0.872443675994873, Accuracy: 0.7177734375\n",
      "Batch: 24, Loss: 0.9070805907249451, Accuracy: 0.69921875\n",
      "Batch: 25, Loss: 0.8683878183364868, Accuracy: 0.734375\n",
      "Batch: 26, Loss: 0.7352986335754395, Accuracy: 0.763671875\n",
      "Batch: 27, Loss: 0.7391599416732788, Accuracy: 0.75390625\n",
      "Batch: 28, Loss: 0.8495000004768372, Accuracy: 0.724609375\n",
      "Batch: 29, Loss: 0.8295562863349915, Accuracy: 0.7314453125\n",
      "Batch: 30, Loss: 0.7666323184967041, Accuracy: 0.759765625\n",
      "Batch: 31, Loss: 0.7593775987625122, Accuracy: 0.759765625\n",
      "Batch: 32, Loss: 0.7646134495735168, Accuracy: 0.7421875\n",
      "Batch: 33, Loss: 0.910434901714325, Accuracy: 0.7158203125\n",
      "Batch: 34, Loss: 0.9487520456314087, Accuracy: 0.6826171875\n",
      "Batch: 35, Loss: 0.923598051071167, Accuracy: 0.6923828125\n",
      "Batch: 36, Loss: 0.9107333421707153, Accuracy: 0.7138671875\n",
      "Batch: 37, Loss: 0.8567652702331543, Accuracy: 0.7177734375\n",
      "Batch: 38, Loss: 0.8771977424621582, Accuracy: 0.703125\n",
      "Batch: 39, Loss: 0.8904595375061035, Accuracy: 0.7060546875\n",
      "Batch: 40, Loss: 0.8410559296607971, Accuracy: 0.7255859375\n",
      "Batch: 41, Loss: 0.8197490572929382, Accuracy: 0.7392578125\n",
      "Batch: 42, Loss: 0.6831907033920288, Accuracy: 0.7626953125\n",
      "Batch: 43, Loss: 0.8769936561584473, Accuracy: 0.69140625\n",
      "Batch: 44, Loss: 0.8593905568122864, Accuracy: 0.712890625\n",
      "Batch: 45, Loss: 0.7641098499298096, Accuracy: 0.7392578125\n",
      "Batch: 46, Loss: 0.7987335324287415, Accuracy: 0.740234375\n",
      "Batch: 47, Loss: 0.8339554667472839, Accuracy: 0.734375\n",
      "Batch: 48, Loss: 0.7991397380828857, Accuracy: 0.7529296875\n",
      "Batch: 49, Loss: 0.9269224405288696, Accuracy: 0.7041015625\n",
      "Batch: 50, Loss: 0.8998578786849976, Accuracy: 0.7080078125\n",
      "Batch: 51, Loss: 0.8949573040008545, Accuracy: 0.7138671875\n",
      "Batch: 52, Loss: 0.9157533049583435, Accuracy: 0.7041015625\n",
      "Batch: 53, Loss: 0.7947040796279907, Accuracy: 0.7431640625\n",
      "Batch: 54, Loss: 0.8161435127258301, Accuracy: 0.7265625\n",
      "Batch: 55, Loss: 0.9163604974746704, Accuracy: 0.6875\n",
      "Batch: 56, Loss: 0.9271872043609619, Accuracy: 0.701171875\n",
      "Batch: 57, Loss: 0.8453202247619629, Accuracy: 0.7177734375\n",
      "Batch: 58, Loss: 0.9580700397491455, Accuracy: 0.6962890625\n",
      "Batch: 59, Loss: 0.8088074922561646, Accuracy: 0.7373046875\n",
      "Batch: 60, Loss: 0.7770039439201355, Accuracy: 0.7490234375\n",
      "Batch: 61, Loss: 0.8820347189903259, Accuracy: 0.712890625\n",
      "Batch: 62, Loss: 0.8223682045936584, Accuracy: 0.73046875\n",
      "Batch: 63, Loss: 0.8901991844177246, Accuracy: 0.7197265625\n",
      "Batch: 64, Loss: 0.8281766176223755, Accuracy: 0.724609375\n",
      "Batch: 65, Loss: 0.8792582750320435, Accuracy: 0.7216796875\n",
      "Batch: 66, Loss: 0.8601596355438232, Accuracy: 0.7333984375\n",
      "Batch: 67, Loss: 0.9316502809524536, Accuracy: 0.708984375\n",
      "Batch: 68, Loss: 0.9619930982589722, Accuracy: 0.69921875\n",
      "Batch: 69, Loss: 0.8605300188064575, Accuracy: 0.71484375\n",
      "Batch: 70, Loss: 0.8335320949554443, Accuracy: 0.7490234375\n",
      "Batch: 71, Loss: 0.8837705254554749, Accuracy: 0.7099609375\n",
      "Batch: 72, Loss: 0.7535474300384521, Accuracy: 0.73828125\n",
      "Batch: 73, Loss: 0.7735121250152588, Accuracy: 0.7568359375\n",
      "Batch: 74, Loss: 0.7255373001098633, Accuracy: 0.7666015625\n",
      "Batch: 75, Loss: 0.7759150862693787, Accuracy: 0.740234375\n",
      "Batch: 76, Loss: 0.8704619407653809, Accuracy: 0.716796875\n",
      "Batch: 77, Loss: 0.7908676862716675, Accuracy: 0.7412109375\n",
      "Batch: 78, Loss: 0.7804299592971802, Accuracy: 0.75390625\n",
      "Batch: 79, Loss: 0.7523394823074341, Accuracy: 0.7626953125\n",
      "Batch: 80, Loss: 0.7878252863883972, Accuracy: 0.7353515625\n",
      "Batch: 81, Loss: 0.920692503452301, Accuracy: 0.69140625\n",
      "Batch: 82, Loss: 0.8946088552474976, Accuracy: 0.708984375\n",
      "Batch: 83, Loss: 0.7465111017227173, Accuracy: 0.765625\n",
      "Batch: 84, Loss: 0.8014317750930786, Accuracy: 0.7412109375\n",
      "Batch: 85, Loss: 0.7635430097579956, Accuracy: 0.7578125\n",
      "Batch: 86, Loss: 0.9783867597579956, Accuracy: 0.697265625\n",
      "Batch: 87, Loss: 0.7691627144813538, Accuracy: 0.7470703125\n",
      "Batch: 88, Loss: 0.8838778734207153, Accuracy: 0.734375\n",
      "Batch: 89, Loss: 0.856343686580658, Accuracy: 0.7265625\n",
      "Batch: 90, Loss: 0.7918761968612671, Accuracy: 0.75\n",
      "Batch: 91, Loss: 0.7995367050170898, Accuracy: 0.7197265625\n",
      "Batch: 92, Loss: 0.8654205799102783, Accuracy: 0.720703125\n",
      "Batch: 93, Loss: 0.8465187549591064, Accuracy: 0.7236328125\n",
      "Batch: 94, Loss: 0.8744733929634094, Accuracy: 0.6953125\n",
      "Batch: 95, Loss: 0.8903101682662964, Accuracy: 0.6982421875\n",
      "Batch: 96, Loss: 0.8227272033691406, Accuracy: 0.7333984375\n",
      "Batch: 97, Loss: 0.6997110843658447, Accuracy: 0.765625\n",
      "Batch: 98, Loss: 0.7621568441390991, Accuracy: 0.755859375\n",
      "Batch: 99, Loss: 0.7936901450157166, Accuracy: 0.7421875\n",
      "Batch: 100, Loss: 0.8306443691253662, Accuracy: 0.7275390625\n",
      "Batch: 101, Loss: 0.9051715135574341, Accuracy: 0.7099609375\n",
      "Batch: 102, Loss: 0.8267697095870972, Accuracy: 0.732421875\n",
      "Batch: 103, Loss: 0.8722437620162964, Accuracy: 0.7373046875\n",
      "Batch: 104, Loss: 0.7619497776031494, Accuracy: 0.74609375\n",
      "Batch: 105, Loss: 0.8808609247207642, Accuracy: 0.7265625\n",
      "Batch: 106, Loss: 0.7940175533294678, Accuracy: 0.740234375\n",
      "Batch: 107, Loss: 0.853343665599823, Accuracy: 0.7314453125\n",
      "Batch: 108, Loss: 0.8263559341430664, Accuracy: 0.7158203125\n",
      "Batch: 109, Loss: 0.9099937081336975, Accuracy: 0.7041015625\n",
      "Batch: 110, Loss: 0.757768988609314, Accuracy: 0.7529296875\n",
      "Batch: 111, Loss: 0.8836075663566589, Accuracy: 0.7177734375\n",
      "Batch: 112, Loss: 0.8430643081665039, Accuracy: 0.7373046875\n",
      "Batch: 114, Loss: 0.9552013874053955, Accuracy: 0.6953125\n",
      "Batch: 115, Loss: 0.9743768572807312, Accuracy: 0.693359375\n",
      "Batch: 116, Loss: 0.9057334661483765, Accuracy: 0.724609375\n",
      "Batch: 117, Loss: 0.9024936556816101, Accuracy: 0.7099609375\n",
      "Batch: 118, Loss: 0.7173517942428589, Accuracy: 0.77734375\n",
      "Batch: 119, Loss: 0.71989905834198, Accuracy: 0.767578125\n",
      "Batch: 120, Loss: 0.8748584985733032, Accuracy: 0.72265625\n",
      "Batch: 121, Loss: 0.9132993817329407, Accuracy: 0.70703125\n",
      "Batch: 122, Loss: 0.8066600561141968, Accuracy: 0.7431640625\n",
      "Batch: 123, Loss: 0.8023290634155273, Accuracy: 0.7490234375\n",
      "Batch: 124, Loss: 0.8631945252418518, Accuracy: 0.7119140625\n",
      "Batch: 125, Loss: 0.9084183573722839, Accuracy: 0.697265625\n",
      "Batch: 126, Loss: 0.8768686056137085, Accuracy: 0.7177734375\n",
      "Batch: 127, Loss: 0.7805395126342773, Accuracy: 0.7626953125\n",
      "Batch: 128, Loss: 0.971929669380188, Accuracy: 0.703125\n",
      "Batch: 129, Loss: 0.7876003980636597, Accuracy: 0.7470703125\n",
      "Batch: 130, Loss: 0.9320443272590637, Accuracy: 0.7060546875\n",
      "Batch: 131, Loss: 0.8431597352027893, Accuracy: 0.71484375\n",
      "Batch: 132, Loss: 0.9005897045135498, Accuracy: 0.7080078125\n",
      "Batch: 133, Loss: 0.8025857210159302, Accuracy: 0.728515625\n",
      "Batch: 134, Loss: 0.8640037775039673, Accuracy: 0.7119140625\n",
      "Batch: 135, Loss: 0.7701935768127441, Accuracy: 0.7451171875\n",
      "Batch: 136, Loss: 0.8478193283081055, Accuracy: 0.7255859375\n",
      "Batch: 137, Loss: 0.8243322372436523, Accuracy: 0.72265625\n",
      "Batch: 138, Loss: 0.7113029360771179, Accuracy: 0.7646484375\n",
      "Batch: 139, Loss: 0.7704036235809326, Accuracy: 0.748046875\n",
      "Batch: 140, Loss: 0.8199928402900696, Accuracy: 0.7333984375\n",
      "Batch: 141, Loss: 0.8826056718826294, Accuracy: 0.6943359375\n",
      "Batch: 142, Loss: 0.8862909078598022, Accuracy: 0.69921875\n",
      "Batch: 143, Loss: 0.8823227286338806, Accuracy: 0.7236328125\n",
      "Batch: 144, Loss: 0.8484463691711426, Accuracy: 0.7197265625\n",
      "Batch: 145, Loss: 0.8131041526794434, Accuracy: 0.73046875\n",
      "Batch: 146, Loss: 0.8772081732749939, Accuracy: 0.7236328125\n",
      "Batch: 147, Loss: 0.885044515132904, Accuracy: 0.705078125\n",
      "Batch: 148, Loss: 0.9609309434890747, Accuracy: 0.6630859375\n",
      "Batch: 149, Loss: 0.849922239780426, Accuracy: 0.720703125\n",
      "Batch: 150, Loss: 0.8126937747001648, Accuracy: 0.7431640625\n",
      "Batch: 151, Loss: 0.7251655459403992, Accuracy: 0.76953125\n",
      "Epoch 37/80\n",
      "Batch: 1, Loss: 1.1250636577606201, Accuracy: 0.634765625\n",
      "Batch: 2, Loss: 0.9020164012908936, Accuracy: 0.6962890625\n",
      "Batch: 3, Loss: 0.8263269662857056, Accuracy: 0.732421875\n",
      "Batch: 4, Loss: 0.7387433052062988, Accuracy: 0.751953125\n",
      "Batch: 5, Loss: 0.8089485168457031, Accuracy: 0.74609375\n",
      "Batch: 6, Loss: 0.8566604256629944, Accuracy: 0.712890625\n",
      "Batch: 7, Loss: 0.8432199954986572, Accuracy: 0.716796875\n",
      "Batch: 8, Loss: 0.8039949536323547, Accuracy: 0.7265625\n",
      "Batch: 10, Loss: 0.7738115787506104, Accuracy: 0.7373046875\n",
      "Batch: 11, Loss: 0.9170097708702087, Accuracy: 0.6953125\n",
      "Batch: 12, Loss: 0.896928071975708, Accuracy: 0.716796875\n",
      "Batch: 13, Loss: 0.6961809992790222, Accuracy: 0.767578125\n",
      "Batch: 14, Loss: 0.9379187822341919, Accuracy: 0.6943359375\n",
      "Batch: 15, Loss: 0.7768291234970093, Accuracy: 0.7587890625\n",
      "Batch: 16, Loss: 0.8448506593704224, Accuracy: 0.7314453125\n",
      "Batch: 17, Loss: 0.8294346332550049, Accuracy: 0.7392578125\n",
      "Batch: 18, Loss: 0.8451218605041504, Accuracy: 0.7216796875\n",
      "Batch: 19, Loss: 0.8559181690216064, Accuracy: 0.732421875\n",
      "Batch: 20, Loss: 0.7620421051979065, Accuracy: 0.763671875\n",
      "Batch: 21, Loss: 0.7905739545822144, Accuracy: 0.7421875\n",
      "Batch: 22, Loss: 0.9167897701263428, Accuracy: 0.7119140625\n",
      "Batch: 23, Loss: 0.8574720025062561, Accuracy: 0.7138671875\n",
      "Batch: 24, Loss: 0.8919277787208557, Accuracy: 0.7197265625\n",
      "Batch: 25, Loss: 0.8313005566596985, Accuracy: 0.7333984375\n",
      "Batch: 26, Loss: 0.7640621066093445, Accuracy: 0.7451171875\n",
      "Batch: 27, Loss: 0.7488692998886108, Accuracy: 0.7431640625\n",
      "Batch: 28, Loss: 0.8566141724586487, Accuracy: 0.72265625\n",
      "Batch: 29, Loss: 0.8173211812973022, Accuracy: 0.7373046875\n",
      "Batch: 30, Loss: 0.8037055730819702, Accuracy: 0.7431640625\n",
      "Batch: 31, Loss: 0.7480570673942566, Accuracy: 0.76171875\n",
      "Batch: 32, Loss: 0.7797566056251526, Accuracy: 0.7236328125\n",
      "Batch: 33, Loss: 0.897855281829834, Accuracy: 0.708984375\n",
      "Batch: 34, Loss: 0.9587156176567078, Accuracy: 0.697265625\n",
      "Batch: 35, Loss: 0.8878793716430664, Accuracy: 0.703125\n",
      "Batch: 36, Loss: 0.9287151098251343, Accuracy: 0.708984375\n",
      "Batch: 37, Loss: 0.85267174243927, Accuracy: 0.7353515625\n",
      "Batch: 38, Loss: 0.8556207418441772, Accuracy: 0.7080078125\n",
      "Batch: 39, Loss: 0.860945463180542, Accuracy: 0.71875\n",
      "Batch: 40, Loss: 0.8322283625602722, Accuracy: 0.728515625\n",
      "Batch: 41, Loss: 0.7761838436126709, Accuracy: 0.7568359375\n",
      "Batch: 42, Loss: 0.6478348970413208, Accuracy: 0.779296875\n",
      "Batch: 43, Loss: 0.8530128598213196, Accuracy: 0.7177734375\n",
      "Batch: 44, Loss: 0.8740909099578857, Accuracy: 0.7060546875\n",
      "Batch: 45, Loss: 0.7402334809303284, Accuracy: 0.7529296875\n",
      "Batch: 46, Loss: 0.7937713861465454, Accuracy: 0.7353515625\n",
      "Batch: 47, Loss: 0.8091784715652466, Accuracy: 0.7529296875\n",
      "Batch: 48, Loss: 0.759306013584137, Accuracy: 0.75\n",
      "Batch: 49, Loss: 0.9066625833511353, Accuracy: 0.701171875\n",
      "Batch: 50, Loss: 0.8863670229911804, Accuracy: 0.7138671875\n",
      "Batch: 51, Loss: 0.9262961149215698, Accuracy: 0.703125\n",
      "Batch: 52, Loss: 0.871276319026947, Accuracy: 0.7109375\n",
      "Batch: 53, Loss: 0.7688701152801514, Accuracy: 0.755859375\n",
      "Batch: 54, Loss: 0.8335616588592529, Accuracy: 0.71875\n",
      "Batch: 55, Loss: 0.920151948928833, Accuracy: 0.677734375\n",
      "Batch: 56, Loss: 0.8961070775985718, Accuracy: 0.7060546875\n",
      "Batch: 57, Loss: 0.8491994142532349, Accuracy: 0.7119140625\n",
      "Batch: 60, Loss: 0.7763388156890869, Accuracy: 0.74609375\n",
      "Batch: 61, Loss: 0.8592660427093506, Accuracy: 0.7197265625\n",
      "Batch: 62, Loss: 0.8169469833374023, Accuracy: 0.740234375\n",
      "Batch: 63, Loss: 0.8636525869369507, Accuracy: 0.732421875\n",
      "Batch: 64, Loss: 0.8402930498123169, Accuracy: 0.736328125\n",
      "Batch: 65, Loss: 0.8634081482887268, Accuracy: 0.7236328125\n",
      "Batch: 66, Loss: 0.8160460591316223, Accuracy: 0.7392578125\n",
      "Batch: 67, Loss: 0.9302148818969727, Accuracy: 0.6953125\n",
      "Batch: 68, Loss: 0.9498550891876221, Accuracy: 0.720703125\n",
      "Batch: 69, Loss: 0.8379899859428406, Accuracy: 0.73046875\n",
      "Batch: 70, Loss: 0.8373563885688782, Accuracy: 0.7490234375\n",
      "Batch: 71, Loss: 0.8618936538696289, Accuracy: 0.7109375\n",
      "Batch: 72, Loss: 0.7586540579795837, Accuracy: 0.73828125\n",
      "Batch: 73, Loss: 0.7860114574432373, Accuracy: 0.7529296875\n",
      "Batch: 74, Loss: 0.7203035950660706, Accuracy: 0.783203125\n",
      "Batch: 75, Loss: 0.7654971480369568, Accuracy: 0.75\n",
      "Batch: 76, Loss: 0.8617373108863831, Accuracy: 0.720703125\n",
      "Batch: 77, Loss: 0.8079118132591248, Accuracy: 0.732421875\n",
      "Batch: 78, Loss: 0.7916686534881592, Accuracy: 0.7607421875\n",
      "Batch: 79, Loss: 0.7282800674438477, Accuracy: 0.767578125\n",
      "Batch: 80, Loss: 0.7817197442054749, Accuracy: 0.7412109375\n",
      "Batch: 81, Loss: 0.8942795991897583, Accuracy: 0.6982421875\n",
      "Batch: 82, Loss: 0.863265335559845, Accuracy: 0.71484375\n",
      "Batch: 83, Loss: 0.7211000919342041, Accuracy: 0.759765625\n",
      "Batch: 84, Loss: 0.7891017198562622, Accuracy: 0.744140625\n",
      "Batch: 85, Loss: 0.7733462452888489, Accuracy: 0.7529296875\n",
      "Batch: 86, Loss: 0.9465275406837463, Accuracy: 0.708984375\n",
      "Batch: 87, Loss: 0.7623833417892456, Accuracy: 0.7529296875\n",
      "Batch: 88, Loss: 0.8873000144958496, Accuracy: 0.7265625\n",
      "Batch: 89, Loss: 0.8364373445510864, Accuracy: 0.736328125\n",
      "Batch: 90, Loss: 0.795319676399231, Accuracy: 0.75390625\n",
      "Batch: 91, Loss: 0.8310242891311646, Accuracy: 0.7119140625\n",
      "Batch: 92, Loss: 0.8459584712982178, Accuracy: 0.7109375\n",
      "Batch: 93, Loss: 0.8559466004371643, Accuracy: 0.71484375\n",
      "Batch: 94, Loss: 0.8655454516410828, Accuracy: 0.71484375\n",
      "Batch: 95, Loss: 0.884435772895813, Accuracy: 0.705078125\n",
      "Batch: 96, Loss: 0.838653564453125, Accuracy: 0.72265625\n",
      "Batch: 97, Loss: 0.7093546390533447, Accuracy: 0.763671875\n",
      "Batch: 98, Loss: 0.7569831013679504, Accuracy: 0.7666015625\n",
      "Batch: 99, Loss: 0.7846964597702026, Accuracy: 0.7607421875\n",
      "Batch: 100, Loss: 0.8346246480941772, Accuracy: 0.7275390625\n",
      "Batch: 101, Loss: 0.8752015829086304, Accuracy: 0.73046875\n",
      "Batch: 102, Loss: 0.8182048797607422, Accuracy: 0.7412109375\n",
      "Batch: 103, Loss: 0.8373560309410095, Accuracy: 0.7353515625\n",
      "Batch: 104, Loss: 0.763087272644043, Accuracy: 0.7509765625\n",
      "Batch: 105, Loss: 0.8571334481239319, Accuracy: 0.73046875\n",
      "Batch: 106, Loss: 0.8062280416488647, Accuracy: 0.740234375\n",
      "Batch: 107, Loss: 0.8334705829620361, Accuracy: 0.740234375\n",
      "Batch: 108, Loss: 0.8092802166938782, Accuracy: 0.71875\n",
      "Batch: 109, Loss: 0.9059517979621887, Accuracy: 0.701171875\n",
      "Batch: 110, Loss: 0.7624149322509766, Accuracy: 0.7412109375\n",
      "Batch: 111, Loss: 0.8572722673416138, Accuracy: 0.7255859375\n",
      "Batch: 112, Loss: 0.834831714630127, Accuracy: 0.7333984375\n",
      "Batch: 113, Loss: 0.8624038696289062, Accuracy: 0.7216796875\n",
      "Batch: 114, Loss: 0.955048680305481, Accuracy: 0.6923828125\n",
      "Batch: 115, Loss: 0.9715677499771118, Accuracy: 0.697265625\n",
      "Batch: 116, Loss: 0.8723980188369751, Accuracy: 0.73828125\n",
      "Batch: 117, Loss: 0.9022308588027954, Accuracy: 0.697265625\n",
      "Batch: 118, Loss: 0.7325588464736938, Accuracy: 0.771484375\n",
      "Batch: 119, Loss: 0.7295389175415039, Accuracy: 0.7578125\n",
      "Batch: 120, Loss: 0.8883099555969238, Accuracy: 0.720703125\n",
      "Batch: 121, Loss: 0.8956809043884277, Accuracy: 0.712890625\n",
      "Batch: 122, Loss: 0.8003632426261902, Accuracy: 0.744140625\n",
      "Batch: 123, Loss: 0.7956128120422363, Accuracy: 0.751953125\n",
      "Batch: 124, Loss: 0.8364206552505493, Accuracy: 0.7138671875\n",
      "Batch: 125, Loss: 0.9008885622024536, Accuracy: 0.69921875\n",
      "Batch: 126, Loss: 0.8740576505661011, Accuracy: 0.7177734375\n",
      "Batch: 127, Loss: 0.7757909297943115, Accuracy: 0.7587890625\n",
      "Batch: 128, Loss: 0.9493190050125122, Accuracy: 0.71875\n",
      "Batch: 129, Loss: 0.7983769774436951, Accuracy: 0.732421875\n",
      "Batch: 130, Loss: 0.970287024974823, Accuracy: 0.6865234375\n",
      "Batch: 131, Loss: 0.8539460897445679, Accuracy: 0.7158203125\n",
      "Batch: 132, Loss: 0.8796951770782471, Accuracy: 0.74609375\n",
      "Batch: 133, Loss: 0.7860937714576721, Accuracy: 0.7451171875\n",
      "Batch: 134, Loss: 0.8767372369766235, Accuracy: 0.7080078125\n",
      "Batch: 135, Loss: 0.7847380638122559, Accuracy: 0.7431640625\n",
      "Batch: 136, Loss: 0.8560267686843872, Accuracy: 0.71875\n",
      "Batch: 137, Loss: 0.8243697881698608, Accuracy: 0.740234375\n",
      "Batch: 138, Loss: 0.7328052520751953, Accuracy: 0.75390625\n",
      "Batch: 139, Loss: 0.7658026218414307, Accuracy: 0.740234375\n",
      "Batch: 140, Loss: 0.8144267201423645, Accuracy: 0.7265625\n",
      "Batch: 141, Loss: 0.8693647384643555, Accuracy: 0.7294921875\n",
      "Batch: 142, Loss: 0.9010845422744751, Accuracy: 0.6962890625\n",
      "Batch: 143, Loss: 0.8652136325836182, Accuracy: 0.7119140625\n",
      "Batch: 144, Loss: 0.8343015313148499, Accuracy: 0.7236328125\n",
      "Batch: 145, Loss: 0.7932115793228149, Accuracy: 0.7265625\n",
      "Batch: 146, Loss: 0.8752885460853577, Accuracy: 0.720703125\n",
      "Batch: 147, Loss: 0.870445966720581, Accuracy: 0.7236328125\n",
      "Batch: 148, Loss: 0.9402074217796326, Accuracy: 0.6826171875\n",
      "Batch: 149, Loss: 0.8545765280723572, Accuracy: 0.7294921875\n",
      "Batch: 150, Loss: 0.8058114647865295, Accuracy: 0.7392578125\n",
      "Batch: 151, Loss: 0.733108401298523, Accuracy: 0.7587890625\n",
      "Epoch 38/80\n",
      "Batch: 1, Loss: 1.0715299844741821, Accuracy: 0.66796875\n",
      "Batch: 2, Loss: 0.9044846296310425, Accuracy: 0.6904296875\n",
      "Batch: 5, Loss: 0.7855675220489502, Accuracy: 0.75\n",
      "Batch: 6, Loss: 0.8759454488754272, Accuracy: 0.69921875\n",
      "Batch: 7, Loss: 0.8192201256752014, Accuracy: 0.7138671875\n",
      "Batch: 8, Loss: 0.783552885055542, Accuracy: 0.734375\n",
      "Batch: 9, Loss: 0.7937281131744385, Accuracy: 0.767578125\n",
      "Batch: 10, Loss: 0.7702274322509766, Accuracy: 0.7275390625\n",
      "Batch: 11, Loss: 0.9070594310760498, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 0.8770017623901367, Accuracy: 0.712890625\n",
      "Batch: 13, Loss: 0.7022634148597717, Accuracy: 0.76171875\n",
      "Batch: 14, Loss: 0.9346162676811218, Accuracy: 0.6982421875\n",
      "Batch: 15, Loss: 0.7944231033325195, Accuracy: 0.75390625\n",
      "Batch: 16, Loss: 0.8260177969932556, Accuracy: 0.73828125\n",
      "Batch: 17, Loss: 0.8478071689605713, Accuracy: 0.720703125\n",
      "Batch: 18, Loss: 0.8519454598426819, Accuracy: 0.71875\n",
      "Batch: 19, Loss: 0.8650304079055786, Accuracy: 0.7333984375\n",
      "Batch: 20, Loss: 0.7520574927330017, Accuracy: 0.763671875\n",
      "Batch: 21, Loss: 0.7954061031341553, Accuracy: 0.7412109375\n",
      "Batch: 22, Loss: 0.9339471459388733, Accuracy: 0.7216796875\n",
      "Batch: 23, Loss: 0.8443689346313477, Accuracy: 0.7158203125\n",
      "Batch: 24, Loss: 0.8629523515701294, Accuracy: 0.71484375\n",
      "Batch: 25, Loss: 0.8180735111236572, Accuracy: 0.7353515625\n",
      "Batch: 26, Loss: 0.7254759669303894, Accuracy: 0.7607421875\n",
      "Batch: 27, Loss: 0.7771470546722412, Accuracy: 0.7294921875\n",
      "Batch: 28, Loss: 0.8553695678710938, Accuracy: 0.7177734375\n",
      "Batch: 29, Loss: 0.8130508065223694, Accuracy: 0.7431640625\n",
      "Batch: 30, Loss: 0.7745691537857056, Accuracy: 0.7470703125\n",
      "Batch: 31, Loss: 0.7406447529792786, Accuracy: 0.7666015625\n",
      "Batch: 32, Loss: 0.7675421237945557, Accuracy: 0.751953125\n",
      "Batch: 33, Loss: 0.8964099884033203, Accuracy: 0.7099609375\n",
      "Batch: 34, Loss: 0.9379119873046875, Accuracy: 0.6982421875\n",
      "Batch: 35, Loss: 0.8610208034515381, Accuracy: 0.7021484375\n",
      "Batch: 36, Loss: 0.8959594964981079, Accuracy: 0.7099609375\n",
      "Batch: 37, Loss: 0.8284000754356384, Accuracy: 0.7353515625\n",
      "Batch: 38, Loss: 0.8602502942085266, Accuracy: 0.7177734375\n",
      "Batch: 39, Loss: 0.8509771227836609, Accuracy: 0.73046875\n",
      "Batch: 40, Loss: 0.8394230604171753, Accuracy: 0.724609375\n",
      "Batch: 41, Loss: 0.7797507047653198, Accuracy: 0.7529296875\n",
      "Batch: 42, Loss: 0.6568002104759216, Accuracy: 0.7734375\n",
      "Batch: 43, Loss: 0.8203762173652649, Accuracy: 0.7265625\n",
      "Batch: 44, Loss: 0.8550302982330322, Accuracy: 0.7119140625\n",
      "Batch: 45, Loss: 0.7365863919258118, Accuracy: 0.744140625\n",
      "Batch: 46, Loss: 0.7536609172821045, Accuracy: 0.76953125\n",
      "Batch: 47, Loss: 0.7873797416687012, Accuracy: 0.76171875\n",
      "Batch: 48, Loss: 0.760549783706665, Accuracy: 0.75\n",
      "Batch: 49, Loss: 0.8781360983848572, Accuracy: 0.71484375\n",
      "Batch: 50, Loss: 0.8745744228363037, Accuracy: 0.7333984375\n",
      "Batch: 51, Loss: 0.9029203057289124, Accuracy: 0.7099609375\n",
      "Batch: 53, Loss: 0.7762964963912964, Accuracy: 0.7255859375\n",
      "Batch: 54, Loss: 0.8214854001998901, Accuracy: 0.7294921875\n",
      "Batch: 55, Loss: 0.939495325088501, Accuracy: 0.6875\n",
      "Batch: 56, Loss: 0.8807764053344727, Accuracy: 0.7177734375\n",
      "Batch: 57, Loss: 0.8681490421295166, Accuracy: 0.71875\n",
      "Batch: 58, Loss: 0.913738489151001, Accuracy: 0.701171875\n",
      "Batch: 59, Loss: 0.8017221689224243, Accuracy: 0.7470703125\n",
      "Batch: 60, Loss: 0.7717447876930237, Accuracy: 0.7578125\n",
      "Batch: 61, Loss: 0.8572263717651367, Accuracy: 0.73046875\n",
      "Batch: 62, Loss: 0.8235220909118652, Accuracy: 0.7275390625\n",
      "Batch: 63, Loss: 0.862301766872406, Accuracy: 0.7177734375\n",
      "Batch: 64, Loss: 0.8472700119018555, Accuracy: 0.7421875\n",
      "Batch: 65, Loss: 0.840062141418457, Accuracy: 0.720703125\n",
      "Batch: 66, Loss: 0.8152704834938049, Accuracy: 0.736328125\n",
      "Batch: 67, Loss: 0.9146206974983215, Accuracy: 0.71875\n",
      "Batch: 68, Loss: 0.9371429085731506, Accuracy: 0.71484375\n",
      "Batch: 69, Loss: 0.8676532506942749, Accuracy: 0.7177734375\n",
      "Batch: 70, Loss: 0.8109272718429565, Accuracy: 0.7578125\n",
      "Batch: 71, Loss: 0.8712565898895264, Accuracy: 0.7119140625\n",
      "Batch: 72, Loss: 0.7359360456466675, Accuracy: 0.7490234375\n",
      "Batch: 73, Loss: 0.7841699123382568, Accuracy: 0.751953125\n",
      "Batch: 74, Loss: 0.7438702583312988, Accuracy: 0.7587890625\n",
      "Batch: 75, Loss: 0.746785044670105, Accuracy: 0.7490234375\n",
      "Batch: 76, Loss: 0.8416123390197754, Accuracy: 0.7255859375\n",
      "Batch: 77, Loss: 0.7907647490501404, Accuracy: 0.740234375\n",
      "Batch: 78, Loss: 0.7707031965255737, Accuracy: 0.7548828125\n",
      "Batch: 79, Loss: 0.7288753390312195, Accuracy: 0.7724609375\n",
      "Batch: 80, Loss: 0.7726184129714966, Accuracy: 0.7333984375\n",
      "Batch: 81, Loss: 0.871408224105835, Accuracy: 0.6962890625\n",
      "Batch: 82, Loss: 0.8728065490722656, Accuracy: 0.7099609375\n",
      "Batch: 83, Loss: 0.7302684783935547, Accuracy: 0.765625\n",
      "Batch: 84, Loss: 0.7875179648399353, Accuracy: 0.740234375\n",
      "Batch: 85, Loss: 0.7615063786506653, Accuracy: 0.7607421875\n",
      "Batch: 86, Loss: 0.944492518901825, Accuracy: 0.7109375\n",
      "Batch: 87, Loss: 0.7611675262451172, Accuracy: 0.751953125\n",
      "Batch: 88, Loss: 0.8708613514900208, Accuracy: 0.7275390625\n",
      "Batch: 89, Loss: 0.8805340528488159, Accuracy: 0.73828125\n",
      "Batch: 90, Loss: 0.7913708686828613, Accuracy: 0.744140625\n",
      "Batch: 91, Loss: 0.8025943040847778, Accuracy: 0.73828125\n",
      "Batch: 92, Loss: 0.8246565461158752, Accuracy: 0.7294921875\n",
      "Batch: 93, Loss: 0.7915979027748108, Accuracy: 0.7353515625\n",
      "Batch: 94, Loss: 0.8446485996246338, Accuracy: 0.7138671875\n",
      "Batch: 95, Loss: 0.8722645044326782, Accuracy: 0.70703125\n",
      "Batch: 96, Loss: 0.8074678778648376, Accuracy: 0.7333984375\n",
      "Batch: 97, Loss: 0.6898586750030518, Accuracy: 0.765625\n",
      "Batch: 98, Loss: 0.7543681859970093, Accuracy: 0.76953125\n",
      "Batch: 101, Loss: 0.8577414751052856, Accuracy: 0.7138671875\n",
      "Batch: 102, Loss: 0.8334928750991821, Accuracy: 0.7275390625\n",
      "Batch: 103, Loss: 0.8369139432907104, Accuracy: 0.7314453125\n",
      "Batch: 104, Loss: 0.7661884427070618, Accuracy: 0.7451171875\n",
      "Batch: 105, Loss: 0.8778030872344971, Accuracy: 0.7265625\n",
      "Batch: 106, Loss: 0.7719254493713379, Accuracy: 0.7470703125\n",
      "Batch: 107, Loss: 0.8537708520889282, Accuracy: 0.7265625\n",
      "Batch: 108, Loss: 0.8049806356430054, Accuracy: 0.7265625\n",
      "Batch: 109, Loss: 0.915237545967102, Accuracy: 0.7041015625\n",
      "Batch: 110, Loss: 0.7543627619743347, Accuracy: 0.755859375\n",
      "Batch: 111, Loss: 0.8677135705947876, Accuracy: 0.7255859375\n",
      "Batch: 112, Loss: 0.8442744016647339, Accuracy: 0.73046875\n",
      "Batch: 113, Loss: 0.8435196280479431, Accuracy: 0.7197265625\n",
      "Batch: 114, Loss: 0.9215455055236816, Accuracy: 0.6953125\n",
      "Batch: 115, Loss: 0.980029821395874, Accuracy: 0.7041015625\n",
      "Batch: 116, Loss: 0.855887770652771, Accuracy: 0.7421875\n",
      "Batch: 117, Loss: 0.8757787346839905, Accuracy: 0.72265625\n",
      "Batch: 118, Loss: 0.6969723701477051, Accuracy: 0.7685546875\n",
      "Batch: 119, Loss: 0.7231846451759338, Accuracy: 0.767578125\n",
      "Batch: 120, Loss: 0.8753582239151001, Accuracy: 0.69921875\n",
      "Batch: 121, Loss: 0.9004383683204651, Accuracy: 0.705078125\n",
      "Batch: 122, Loss: 0.7878549098968506, Accuracy: 0.751953125\n",
      "Batch: 123, Loss: 0.7875233888626099, Accuracy: 0.75390625\n",
      "Batch: 124, Loss: 0.8518479466438293, Accuracy: 0.71875\n",
      "Batch: 125, Loss: 0.90042644739151, Accuracy: 0.716796875\n",
      "Batch: 126, Loss: 0.8632078170776367, Accuracy: 0.7138671875\n",
      "Batch: 127, Loss: 0.7499672174453735, Accuracy: 0.765625\n",
      "Batch: 128, Loss: 0.9336036443710327, Accuracy: 0.71875\n",
      "Batch: 129, Loss: 0.7849521636962891, Accuracy: 0.734375\n",
      "Batch: 130, Loss: 0.9628961086273193, Accuracy: 0.6923828125\n",
      "Batch: 131, Loss: 0.8363820910453796, Accuracy: 0.7255859375\n",
      "Batch: 132, Loss: 0.8689490556716919, Accuracy: 0.7265625\n",
      "Batch: 133, Loss: 0.7917791604995728, Accuracy: 0.732421875\n",
      "Batch: 134, Loss: 0.856075644493103, Accuracy: 0.7041015625\n",
      "Batch: 135, Loss: 0.7622409462928772, Accuracy: 0.755859375\n",
      "Batch: 136, Loss: 0.8434165716171265, Accuracy: 0.732421875\n",
      "Batch: 137, Loss: 0.8003391027450562, Accuracy: 0.72265625\n",
      "Batch: 138, Loss: 0.722342312335968, Accuracy: 0.76171875\n",
      "Batch: 139, Loss: 0.768172025680542, Accuracy: 0.7490234375\n",
      "Batch: 140, Loss: 0.8088171482086182, Accuracy: 0.724609375\n",
      "Batch: 141, Loss: 0.859844982624054, Accuracy: 0.71875\n",
      "Batch: 142, Loss: 0.8772866725921631, Accuracy: 0.7138671875\n",
      "Batch: 143, Loss: 0.8460711240768433, Accuracy: 0.7265625\n",
      "Batch: 144, Loss: 0.8530308604240417, Accuracy: 0.7158203125\n",
      "Batch: 145, Loss: 0.8064099550247192, Accuracy: 0.724609375\n",
      "Batch: 146, Loss: 0.8808928728103638, Accuracy: 0.71484375\n",
      "Batch: 147, Loss: 0.8860518336296082, Accuracy: 0.712890625\n",
      "Batch: 148, Loss: 0.9563935995101929, Accuracy: 0.6748046875\n",
      "Batch: 149, Loss: 0.8247876167297363, Accuracy: 0.732421875\n",
      "Batch: 150, Loss: 0.7966916561126709, Accuracy: 0.736328125\n",
      "Batch: 151, Loss: 0.7602378129959106, Accuracy: 0.7529296875\n",
      "Epoch 39/80\n",
      "Batch: 1, Loss: 1.0600731372833252, Accuracy: 0.6708984375\n",
      "Batch: 2, Loss: 0.8912508487701416, Accuracy: 0.6982421875\n",
      "Batch: 3, Loss: 0.8218789100646973, Accuracy: 0.71875\n",
      "Batch: 4, Loss: 0.7137216329574585, Accuracy: 0.7666015625\n",
      "Batch: 5, Loss: 0.776389479637146, Accuracy: 0.7509765625\n",
      "Batch: 6, Loss: 0.8651040196418762, Accuracy: 0.701171875\n",
      "Batch: 7, Loss: 0.8566126823425293, Accuracy: 0.7265625\n",
      "Batch: 8, Loss: 0.8045713901519775, Accuracy: 0.7294921875\n",
      "Batch: 9, Loss: 0.7596238851547241, Accuracy: 0.765625\n",
      "Batch: 10, Loss: 0.7801863551139832, Accuracy: 0.744140625\n",
      "Batch: 11, Loss: 0.9137920141220093, Accuracy: 0.69140625\n",
      "Batch: 12, Loss: 0.8915807008743286, Accuracy: 0.712890625\n",
      "Batch: 13, Loss: 0.6661642789840698, Accuracy: 0.7744140625\n",
      "Batch: 14, Loss: 0.9029945135116577, Accuracy: 0.693359375\n",
      "Batch: 15, Loss: 0.7600176930427551, Accuracy: 0.76171875\n",
      "Batch: 16, Loss: 0.806481122970581, Accuracy: 0.7451171875\n",
      "Batch: 17, Loss: 0.8602410554885864, Accuracy: 0.712890625\n",
      "Batch: 18, Loss: 0.8464711904525757, Accuracy: 0.732421875\n",
      "Batch: 19, Loss: 0.8785412311553955, Accuracy: 0.7294921875\n",
      "Batch: 20, Loss: 0.7552847862243652, Accuracy: 0.763671875\n",
      "Batch: 21, Loss: 0.7771556377410889, Accuracy: 0.7421875\n",
      "Batch: 22, Loss: 0.9141403436660767, Accuracy: 0.71875\n",
      "Batch: 23, Loss: 0.8556392192840576, Accuracy: 0.7001953125\n",
      "Batch: 24, Loss: 0.8480333089828491, Accuracy: 0.71875\n",
      "Batch: 25, Loss: 0.8140939474105835, Accuracy: 0.7392578125\n",
      "Batch: 26, Loss: 0.7216382622718811, Accuracy: 0.7705078125\n",
      "Batch: 27, Loss: 0.7573227286338806, Accuracy: 0.7421875\n",
      "Batch: 28, Loss: 0.836356520652771, Accuracy: 0.7275390625\n",
      "Batch: 29, Loss: 0.8031713366508484, Accuracy: 0.736328125\n",
      "Batch: 30, Loss: 0.7611857056617737, Accuracy: 0.7607421875\n",
      "Batch: 31, Loss: 0.7672343850135803, Accuracy: 0.7431640625\n",
      "Batch: 32, Loss: 0.7559194564819336, Accuracy: 0.748046875\n",
      "Batch: 33, Loss: 0.8899434804916382, Accuracy: 0.7119140625\n",
      "Batch: 34, Loss: 0.9275938868522644, Accuracy: 0.703125\n",
      "Batch: 35, Loss: 0.9004677534103394, Accuracy: 0.7021484375\n",
      "Batch: 36, Loss: 0.9078516960144043, Accuracy: 0.7275390625\n",
      "Batch: 37, Loss: 0.8254936933517456, Accuracy: 0.728515625\n",
      "Batch: 38, Loss: 0.8413946628570557, Accuracy: 0.7138671875\n",
      "Batch: 39, Loss: 0.8268803358078003, Accuracy: 0.736328125\n",
      "Batch: 40, Loss: 0.7973983287811279, Accuracy: 0.748046875\n",
      "Batch: 41, Loss: 0.7905321717262268, Accuracy: 0.73828125\n",
      "Batch: 42, Loss: 0.6360525488853455, Accuracy: 0.7783203125\n",
      "Batch: 43, Loss: 0.833257257938385, Accuracy: 0.7177734375\n",
      "Batch: 44, Loss: 0.8590694665908813, Accuracy: 0.7119140625\n",
      "Batch: 45, Loss: 0.7462356090545654, Accuracy: 0.7509765625\n",
      "Batch: 46, Loss: 0.790158748626709, Accuracy: 0.7373046875\n",
      "Batch: 47, Loss: 0.8094813823699951, Accuracy: 0.7451171875\n",
      "Batch: 48, Loss: 0.7433028221130371, Accuracy: 0.7548828125\n",
      "Batch: 51, Loss: 0.8872712254524231, Accuracy: 0.7119140625\n",
      "Batch: 52, Loss: 0.8588837385177612, Accuracy: 0.7216796875\n",
      "Batch: 53, Loss: 0.7439476847648621, Accuracy: 0.7626953125\n",
      "Batch: 54, Loss: 0.7958498001098633, Accuracy: 0.728515625\n",
      "Batch: 55, Loss: 0.9172114133834839, Accuracy: 0.6884765625\n",
      "Batch: 56, Loss: 0.8645005822181702, Accuracy: 0.7080078125\n",
      "Batch: 57, Loss: 0.8244075775146484, Accuracy: 0.7275390625\n",
      "Batch: 58, Loss: 0.9170607328414917, Accuracy: 0.7138671875\n",
      "Batch: 59, Loss: 0.7725398540496826, Accuracy: 0.748046875\n",
      "Batch: 60, Loss: 0.7607064247131348, Accuracy: 0.7529296875\n",
      "Batch: 61, Loss: 0.8527102470397949, Accuracy: 0.7216796875\n",
      "Batch: 62, Loss: 0.7849866151809692, Accuracy: 0.748046875\n",
      "Batch: 63, Loss: 0.8575546741485596, Accuracy: 0.724609375\n",
      "Batch: 64, Loss: 0.821293830871582, Accuracy: 0.734375\n",
      "Batch: 65, Loss: 0.8478988409042358, Accuracy: 0.736328125\n",
      "Batch: 66, Loss: 0.8218196630477905, Accuracy: 0.7314453125\n",
      "Batch: 67, Loss: 0.918953537940979, Accuracy: 0.71875\n",
      "Batch: 68, Loss: 0.9453705549240112, Accuracy: 0.7099609375\n",
      "Batch: 69, Loss: 0.839633047580719, Accuracy: 0.7294921875\n",
      "Batch: 70, Loss: 0.8196868896484375, Accuracy: 0.73828125\n",
      "Batch: 71, Loss: 0.8527212142944336, Accuracy: 0.7109375\n",
      "Batch: 72, Loss: 0.7335286736488342, Accuracy: 0.7587890625\n",
      "Batch: 73, Loss: 0.7288758158683777, Accuracy: 0.765625\n",
      "Batch: 74, Loss: 0.7187584638595581, Accuracy: 0.7783203125\n",
      "Batch: 75, Loss: 0.7550003528594971, Accuracy: 0.74609375\n",
      "Batch: 76, Loss: 0.8430526256561279, Accuracy: 0.7294921875\n",
      "Batch: 77, Loss: 0.7967464327812195, Accuracy: 0.751953125\n",
      "Batch: 78, Loss: 0.7729406952857971, Accuracy: 0.7529296875\n",
      "Batch: 79, Loss: 0.727302074432373, Accuracy: 0.7822265625\n",
      "Batch: 80, Loss: 0.7781515121459961, Accuracy: 0.73046875\n",
      "Batch: 81, Loss: 0.892777681350708, Accuracy: 0.6953125\n",
      "Batch: 82, Loss: 0.876744270324707, Accuracy: 0.73046875\n",
      "Batch: 83, Loss: 0.7278883457183838, Accuracy: 0.767578125\n",
      "Batch: 84, Loss: 0.8019753694534302, Accuracy: 0.744140625\n",
      "Batch: 85, Loss: 0.755291223526001, Accuracy: 0.7578125\n",
      "Batch: 86, Loss: 0.9026913046836853, Accuracy: 0.71484375\n",
      "Batch: 87, Loss: 0.7617409825325012, Accuracy: 0.7548828125\n",
      "Batch: 88, Loss: 0.8583961725234985, Accuracy: 0.7275390625\n",
      "Batch: 89, Loss: 0.8342066407203674, Accuracy: 0.7392578125\n",
      "Batch: 90, Loss: 0.787596583366394, Accuracy: 0.7333984375\n",
      "Batch: 91, Loss: 0.8007660508155823, Accuracy: 0.7333984375\n",
      "Batch: 92, Loss: 0.8324735164642334, Accuracy: 0.7294921875\n",
      "Batch: 93, Loss: 0.7922808527946472, Accuracy: 0.7412109375\n",
      "Batch: 94, Loss: 0.844761848449707, Accuracy: 0.7158203125\n",
      "Batch: 95, Loss: 0.843441367149353, Accuracy: 0.70703125\n",
      "Batch: 96, Loss: 0.7890015244483948, Accuracy: 0.7353515625\n",
      "Batch: 97, Loss: 0.6699085831642151, Accuracy: 0.7783203125\n",
      "Batch: 98, Loss: 0.7554948925971985, Accuracy: 0.7548828125\n",
      "Batch: 99, Loss: 0.7605224847793579, Accuracy: 0.75390625\n",
      "Batch: 100, Loss: 0.8310113549232483, Accuracy: 0.712890625\n",
      "Batch: 101, Loss: 0.8536161780357361, Accuracy: 0.71875\n",
      "Batch: 102, Loss: 0.8302371501922607, Accuracy: 0.7333984375\n",
      "Batch: 103, Loss: 0.837338924407959, Accuracy: 0.7392578125\n",
      "Batch: 104, Loss: 0.7387758493423462, Accuracy: 0.7431640625\n",
      "Batch: 105, Loss: 0.8541406989097595, Accuracy: 0.7255859375\n",
      "Batch: 106, Loss: 0.7806574106216431, Accuracy: 0.7421875\n",
      "Batch: 107, Loss: 0.8433139324188232, Accuracy: 0.736328125\n",
      "Batch: 108, Loss: 0.8107656240463257, Accuracy: 0.7275390625\n",
      "Batch: 109, Loss: 0.9159268736839294, Accuracy: 0.7001953125\n",
      "Batch: 110, Loss: 0.7503366470336914, Accuracy: 0.73828125\n",
      "Batch: 111, Loss: 0.8472526669502258, Accuracy: 0.7275390625\n",
      "Batch: 112, Loss: 0.7876554131507874, Accuracy: 0.7568359375\n",
      "Batch: 113, Loss: 0.831622838973999, Accuracy: 0.72265625\n",
      "Batch: 114, Loss: 0.9041855335235596, Accuracy: 0.705078125\n",
      "Batch: 115, Loss: 0.9427096247673035, Accuracy: 0.72265625\n",
      "Batch: 116, Loss: 0.8963168263435364, Accuracy: 0.72265625\n",
      "Batch: 117, Loss: 0.8781294822692871, Accuracy: 0.7158203125\n",
      "Batch: 118, Loss: 0.698439359664917, Accuracy: 0.7705078125\n",
      "Batch: 119, Loss: 0.6760308742523193, Accuracy: 0.771484375\n",
      "Batch: 120, Loss: 0.8577443957328796, Accuracy: 0.7099609375\n",
      "Batch: 121, Loss: 0.875632107257843, Accuracy: 0.7119140625\n",
      "Batch: 122, Loss: 0.8041496872901917, Accuracy: 0.744140625\n",
      "Batch: 123, Loss: 0.769364595413208, Accuracy: 0.7490234375\n",
      "Batch: 124, Loss: 0.8350745439529419, Accuracy: 0.7314453125\n",
      "Batch: 125, Loss: 0.8806340098381042, Accuracy: 0.7158203125\n",
      "Batch: 126, Loss: 0.8475844264030457, Accuracy: 0.7138671875\n",
      "Batch: 127, Loss: 0.7481418251991272, Accuracy: 0.765625\n",
      "Batch: 128, Loss: 0.9287128448486328, Accuracy: 0.7255859375\n",
      "Batch: 129, Loss: 0.743773341178894, Accuracy: 0.7705078125\n",
      "Batch: 130, Loss: 0.9351596236228943, Accuracy: 0.7099609375\n",
      "Batch: 131, Loss: 0.8354005217552185, Accuracy: 0.7236328125\n",
      "Batch: 132, Loss: 0.8722888231277466, Accuracy: 0.7275390625\n",
      "Batch: 133, Loss: 0.7780766487121582, Accuracy: 0.74609375\n",
      "Batch: 134, Loss: 0.8746365904808044, Accuracy: 0.6982421875\n",
      "Batch: 135, Loss: 0.7559545040130615, Accuracy: 0.7568359375\n",
      "Batch: 136, Loss: 0.805485725402832, Accuracy: 0.74609375\n",
      "Batch: 137, Loss: 0.8002316355705261, Accuracy: 0.7158203125\n",
      "Batch: 138, Loss: 0.7098701000213623, Accuracy: 0.759765625\n",
      "Batch: 139, Loss: 0.7649824619293213, Accuracy: 0.748046875\n",
      "Batch: 140, Loss: 0.7783546447753906, Accuracy: 0.7275390625\n",
      "Batch: 141, Loss: 0.8687863349914551, Accuracy: 0.7314453125\n",
      "Batch: 142, Loss: 0.8834069967269897, Accuracy: 0.6982421875\n",
      "Batch: 143, Loss: 0.8458126783370972, Accuracy: 0.7119140625\n",
      "Batch: 144, Loss: 0.8371360301971436, Accuracy: 0.7255859375\n",
      "Batch: 145, Loss: 0.7980709075927734, Accuracy: 0.7265625\n",
      "Batch: 147, Loss: 0.8717963695526123, Accuracy: 0.7158203125\n",
      "Batch: 148, Loss: 0.9293817281723022, Accuracy: 0.6923828125\n",
      "Batch: 149, Loss: 0.8142736554145813, Accuracy: 0.732421875\n",
      "Batch: 150, Loss: 0.8144466876983643, Accuracy: 0.7353515625\n",
      "Batch: 151, Loss: 0.7335501313209534, Accuracy: 0.7568359375\n",
      "Epoch 40/80\n",
      "Batch: 1, Loss: 1.0691356658935547, Accuracy: 0.6640625\n",
      "Batch: 2, Loss: 0.901200532913208, Accuracy: 0.6875\n",
      "Batch: 3, Loss: 0.8031666874885559, Accuracy: 0.7353515625\n",
      "Batch: 4, Loss: 0.7320791482925415, Accuracy: 0.7529296875\n",
      "Batch: 5, Loss: 0.7625206708908081, Accuracy: 0.7626953125\n",
      "Batch: 6, Loss: 0.8328429460525513, Accuracy: 0.7099609375\n",
      "Batch: 7, Loss: 0.8512929677963257, Accuracy: 0.6943359375\n",
      "Batch: 8, Loss: 0.8074249029159546, Accuracy: 0.7255859375\n",
      "Batch: 9, Loss: 0.7676169872283936, Accuracy: 0.75\n",
      "Batch: 10, Loss: 0.7561760544776917, Accuracy: 0.7568359375\n",
      "Batch: 11, Loss: 0.8982065916061401, Accuracy: 0.693359375\n",
      "Batch: 12, Loss: 0.8890234231948853, Accuracy: 0.71875\n",
      "Batch: 13, Loss: 0.6737184524536133, Accuracy: 0.783203125\n",
      "Batch: 14, Loss: 0.9263956546783447, Accuracy: 0.6982421875\n",
      "Batch: 15, Loss: 0.7757829427719116, Accuracy: 0.759765625\n",
      "Batch: 16, Loss: 0.8062044382095337, Accuracy: 0.736328125\n",
      "Batch: 17, Loss: 0.8514912128448486, Accuracy: 0.724609375\n",
      "Batch: 18, Loss: 0.8276629447937012, Accuracy: 0.7294921875\n",
      "Batch: 19, Loss: 0.8629671335220337, Accuracy: 0.7275390625\n",
      "Batch: 20, Loss: 0.7489521503448486, Accuracy: 0.763671875\n",
      "Batch: 21, Loss: 0.7688834071159363, Accuracy: 0.7451171875\n",
      "Batch: 22, Loss: 0.9027195572853088, Accuracy: 0.716796875\n",
      "Batch: 23, Loss: 0.8600660562515259, Accuracy: 0.7099609375\n",
      "Batch: 24, Loss: 0.8583700656890869, Accuracy: 0.72265625\n",
      "Batch: 25, Loss: 0.8193316459655762, Accuracy: 0.736328125\n",
      "Batch: 26, Loss: 0.7021498680114746, Accuracy: 0.7724609375\n",
      "Batch: 27, Loss: 0.762019157409668, Accuracy: 0.7421875\n",
      "Batch: 28, Loss: 0.8127433061599731, Accuracy: 0.734375\n",
      "Batch: 29, Loss: 0.8149139881134033, Accuracy: 0.73046875\n",
      "Batch: 30, Loss: 0.7222461700439453, Accuracy: 0.7724609375\n",
      "Batch: 31, Loss: 0.7375599145889282, Accuracy: 0.763671875\n",
      "Batch: 32, Loss: 0.7508059740066528, Accuracy: 0.7373046875\n",
      "Batch: 33, Loss: 0.8831526041030884, Accuracy: 0.7099609375\n",
      "Batch: 34, Loss: 0.9238125681877136, Accuracy: 0.6884765625\n",
      "Batch: 35, Loss: 0.8877289295196533, Accuracy: 0.7099609375\n",
      "Batch: 36, Loss: 0.9025563597679138, Accuracy: 0.71875\n",
      "Batch: 37, Loss: 0.8103126287460327, Accuracy: 0.7265625\n",
      "Batch: 38, Loss: 0.8509246706962585, Accuracy: 0.69921875\n",
      "Batch: 39, Loss: 0.8603054881095886, Accuracy: 0.7265625\n",
      "Batch: 40, Loss: 0.7890599966049194, Accuracy: 0.7392578125\n",
      "Batch: 41, Loss: 0.7575273513793945, Accuracy: 0.75\n",
      "Batch: 42, Loss: 0.6304967403411865, Accuracy: 0.796875\n",
      "Batch: 43, Loss: 0.8436434864997864, Accuracy: 0.7177734375\n",
      "Batch: 44, Loss: 0.8383411169052124, Accuracy: 0.7158203125\n",
      "Batch: 45, Loss: 0.7297641038894653, Accuracy: 0.7607421875\n",
      "Batch: 47, Loss: 0.7947899699211121, Accuracy: 0.7666015625\n",
      "Batch: 48, Loss: 0.7419320344924927, Accuracy: 0.767578125\n",
      "Batch: 49, Loss: 0.8786266446113586, Accuracy: 0.7275390625\n",
      "Batch: 50, Loss: 0.8475615978240967, Accuracy: 0.73046875\n",
      "Batch: 51, Loss: 0.8683005571365356, Accuracy: 0.7099609375\n",
      "Batch: 52, Loss: 0.8624961972236633, Accuracy: 0.7275390625\n",
      "Batch: 53, Loss: 0.754409670829773, Accuracy: 0.7607421875\n",
      "Batch: 54, Loss: 0.8033910989761353, Accuracy: 0.73046875\n",
      "Batch: 55, Loss: 0.9092897772789001, Accuracy: 0.70703125\n",
      "Batch: 56, Loss: 0.893261194229126, Accuracy: 0.697265625\n",
      "Batch: 57, Loss: 0.8431113362312317, Accuracy: 0.73046875\n",
      "Batch: 58, Loss: 0.9133732318878174, Accuracy: 0.72265625\n",
      "Batch: 59, Loss: 0.765742301940918, Accuracy: 0.7431640625\n",
      "Batch: 60, Loss: 0.7702385783195496, Accuracy: 0.75\n",
      "Batch: 61, Loss: 0.8587675094604492, Accuracy: 0.71875\n",
      "Batch: 62, Loss: 0.7968312501907349, Accuracy: 0.75390625\n",
      "Batch: 63, Loss: 0.8816156387329102, Accuracy: 0.7080078125\n",
      "Batch: 64, Loss: 0.8191850781440735, Accuracy: 0.7294921875\n",
      "Batch: 65, Loss: 0.8311430215835571, Accuracy: 0.7431640625\n",
      "Batch: 66, Loss: 0.8001227378845215, Accuracy: 0.73828125\n",
      "Batch: 67, Loss: 0.8918431997299194, Accuracy: 0.7060546875\n",
      "Batch: 68, Loss: 0.9151835441589355, Accuracy: 0.701171875\n",
      "Batch: 69, Loss: 0.832595705986023, Accuracy: 0.7421875\n",
      "Batch: 70, Loss: 0.7921619415283203, Accuracy: 0.74609375\n",
      "Batch: 71, Loss: 0.8754638433456421, Accuracy: 0.716796875\n",
      "Batch: 72, Loss: 0.7085566520690918, Accuracy: 0.75390625\n",
      "Batch: 73, Loss: 0.754351019859314, Accuracy: 0.75\n",
      "Batch: 74, Loss: 0.7320324778556824, Accuracy: 0.767578125\n",
      "Batch: 75, Loss: 0.7614277601242065, Accuracy: 0.755859375\n",
      "Batch: 76, Loss: 0.8119587898254395, Accuracy: 0.720703125\n",
      "Batch: 77, Loss: 0.7545069456100464, Accuracy: 0.76171875\n",
      "Batch: 78, Loss: 0.749249279499054, Accuracy: 0.763671875\n",
      "Batch: 79, Loss: 0.6932402849197388, Accuracy: 0.7783203125\n",
      "Batch: 80, Loss: 0.7445393800735474, Accuracy: 0.7509765625\n",
      "Batch: 81, Loss: 0.865626871585846, Accuracy: 0.7109375\n",
      "Batch: 82, Loss: 0.8502960205078125, Accuracy: 0.73046875\n",
      "Batch: 83, Loss: 0.6936152577400208, Accuracy: 0.78515625\n",
      "Batch: 84, Loss: 0.7671985626220703, Accuracy: 0.759765625\n",
      "Batch: 85, Loss: 0.7319062948226929, Accuracy: 0.7626953125\n",
      "Batch: 86, Loss: 0.9275174736976624, Accuracy: 0.7001953125\n",
      "Batch: 87, Loss: 0.7577366828918457, Accuracy: 0.7509765625\n",
      "Batch: 88, Loss: 0.8323121070861816, Accuracy: 0.7373046875\n",
      "Batch: 89, Loss: 0.8262413144111633, Accuracy: 0.7421875\n",
      "Batch: 90, Loss: 0.787959098815918, Accuracy: 0.751953125\n",
      "Batch: 91, Loss: 0.7974534034729004, Accuracy: 0.732421875\n",
      "Batch: 92, Loss: 0.8438931703567505, Accuracy: 0.7138671875\n",
      "Batch: 93, Loss: 0.8012745976448059, Accuracy: 0.736328125\n",
      "Batch: 94, Loss: 0.8283707499504089, Accuracy: 0.724609375\n",
      "Batch: 95, Loss: 0.8453131914138794, Accuracy: 0.70703125\n",
      "Batch: 96, Loss: 0.8051998615264893, Accuracy: 0.7392578125\n",
      "Batch: 97, Loss: 0.685486912727356, Accuracy: 0.7685546875\n",
      "Batch: 98, Loss: 0.7339942455291748, Accuracy: 0.759765625\n",
      "Batch: 99, Loss: 0.7728676795959473, Accuracy: 0.7421875\n",
      "Batch: 100, Loss: 0.7880514860153198, Accuracy: 0.74609375\n",
      "Batch: 101, Loss: 0.880158543586731, Accuracy: 0.71875\n",
      "Batch: 102, Loss: 0.7923091650009155, Accuracy: 0.75\n",
      "Batch: 103, Loss: 0.8168545961380005, Accuracy: 0.7431640625\n",
      "Batch: 104, Loss: 0.7467650175094604, Accuracy: 0.7421875\n",
      "Batch: 105, Loss: 0.8686189651489258, Accuracy: 0.7158203125\n",
      "Batch: 106, Loss: 0.7664222717285156, Accuracy: 0.7451171875\n",
      "Batch: 107, Loss: 0.8578276634216309, Accuracy: 0.7373046875\n",
      "Batch: 108, Loss: 0.794347882270813, Accuracy: 0.7333984375\n",
      "Batch: 109, Loss: 0.9171299934387207, Accuracy: 0.7021484375\n",
      "Batch: 110, Loss: 0.7421711683273315, Accuracy: 0.751953125\n",
      "Batch: 111, Loss: 0.8426298499107361, Accuracy: 0.7275390625\n",
      "Batch: 112, Loss: 0.7939793467521667, Accuracy: 0.7626953125\n",
      "Batch: 113, Loss: 0.8185399174690247, Accuracy: 0.7373046875\n",
      "Batch: 114, Loss: 0.9231013059616089, Accuracy: 0.6953125\n",
      "Batch: 115, Loss: 0.9774689674377441, Accuracy: 0.703125\n",
      "Batch: 116, Loss: 0.9095591306686401, Accuracy: 0.7236328125\n",
      "Batch: 117, Loss: 0.879398763179779, Accuracy: 0.7197265625\n",
      "Batch: 118, Loss: 0.7114464044570923, Accuracy: 0.775390625\n",
      "Batch: 119, Loss: 0.698431670665741, Accuracy: 0.76953125\n",
      "Batch: 120, Loss: 0.8709830641746521, Accuracy: 0.71484375\n",
      "Batch: 121, Loss: 0.8680598735809326, Accuracy: 0.73828125\n",
      "Batch: 122, Loss: 0.7881523966789246, Accuracy: 0.7470703125\n",
      "Batch: 123, Loss: 0.7666555643081665, Accuracy: 0.7490234375\n",
      "Batch: 124, Loss: 0.822756290435791, Accuracy: 0.7431640625\n",
      "Batch: 125, Loss: 0.8718347549438477, Accuracy: 0.7158203125\n",
      "Batch: 126, Loss: 0.8656966686248779, Accuracy: 0.7109375\n",
      "Batch: 127, Loss: 0.7395905256271362, Accuracy: 0.7744140625\n",
      "Batch: 128, Loss: 0.9390630722045898, Accuracy: 0.7197265625\n",
      "Batch: 129, Loss: 0.7506473064422607, Accuracy: 0.74609375\n",
      "Batch: 130, Loss: 0.9191819429397583, Accuracy: 0.70703125\n",
      "Batch: 131, Loss: 0.8337773084640503, Accuracy: 0.73046875\n",
      "Batch: 132, Loss: 0.8323056697845459, Accuracy: 0.7412109375\n",
      "Batch: 133, Loss: 0.7607641220092773, Accuracy: 0.7548828125\n",
      "Batch: 134, Loss: 0.8525704145431519, Accuracy: 0.7236328125\n",
      "Batch: 135, Loss: 0.7388834953308105, Accuracy: 0.7587890625\n",
      "Batch: 136, Loss: 0.8121165037155151, Accuracy: 0.7373046875\n",
      "Batch: 137, Loss: 0.8142918944358826, Accuracy: 0.7236328125\n",
      "Batch: 138, Loss: 0.6979180574417114, Accuracy: 0.767578125\n",
      "Batch: 139, Loss: 0.7327039241790771, Accuracy: 0.74609375\n",
      "Batch: 142, Loss: 0.8674882054328918, Accuracy: 0.716796875\n",
      "Batch: 143, Loss: 0.7971234321594238, Accuracy: 0.75390625\n",
      "Batch: 144, Loss: 0.7958630323410034, Accuracy: 0.74609375\n",
      "Batch: 145, Loss: 0.771023154258728, Accuracy: 0.7373046875\n",
      "Batch: 146, Loss: 0.8383552432060242, Accuracy: 0.7275390625\n",
      "Batch: 147, Loss: 0.8579267859458923, Accuracy: 0.708984375\n",
      "Batch: 148, Loss: 0.8918905854225159, Accuracy: 0.7021484375\n",
      "Batch: 149, Loss: 0.8096556663513184, Accuracy: 0.74609375\n",
      "Batch: 150, Loss: 0.8141816258430481, Accuracy: 0.7236328125\n",
      "Batch: 151, Loss: 0.7068328261375427, Accuracy: 0.767578125\n",
      "Saved Weights at epoch 40 to file Weights_40.h5\n",
      "Epoch 41/80\n",
      "Batch: 1, Loss: 1.0694855451583862, Accuracy: 0.6630859375\n",
      "Batch: 2, Loss: 0.8914932012557983, Accuracy: 0.685546875\n",
      "Batch: 3, Loss: 0.8291018009185791, Accuracy: 0.716796875\n",
      "Batch: 4, Loss: 0.7053980827331543, Accuracy: 0.783203125\n",
      "Batch: 5, Loss: 0.7476951479911804, Accuracy: 0.767578125\n",
      "Batch: 6, Loss: 0.8373810648918152, Accuracy: 0.7099609375\n",
      "Batch: 7, Loss: 0.8379359245300293, Accuracy: 0.7119140625\n",
      "Batch: 8, Loss: 0.7851482629776001, Accuracy: 0.7255859375\n",
      "Batch: 9, Loss: 0.7674799561500549, Accuracy: 0.759765625\n",
      "Batch: 10, Loss: 0.7359989881515503, Accuracy: 0.744140625\n",
      "Batch: 11, Loss: 0.9039652943611145, Accuracy: 0.6865234375\n",
      "Batch: 12, Loss: 0.8782188892364502, Accuracy: 0.7216796875\n",
      "Batch: 13, Loss: 0.6499278545379639, Accuracy: 0.7978515625\n",
      "Batch: 14, Loss: 0.888614296913147, Accuracy: 0.69921875\n",
      "Batch: 15, Loss: 0.7483984231948853, Accuracy: 0.7646484375\n",
      "Batch: 16, Loss: 0.8024067878723145, Accuracy: 0.74609375\n",
      "Batch: 17, Loss: 0.8320282697677612, Accuracy: 0.7353515625\n",
      "Batch: 18, Loss: 0.8213697671890259, Accuracy: 0.728515625\n",
      "Batch: 19, Loss: 0.841742753982544, Accuracy: 0.7314453125\n",
      "Batch: 20, Loss: 0.7443629503250122, Accuracy: 0.759765625\n",
      "Batch: 21, Loss: 0.7528636455535889, Accuracy: 0.7646484375\n",
      "Batch: 22, Loss: 0.8883926868438721, Accuracy: 0.7255859375\n",
      "Batch: 23, Loss: 0.8298838138580322, Accuracy: 0.7216796875\n",
      "Batch: 24, Loss: 0.8503351211547852, Accuracy: 0.7275390625\n",
      "Batch: 25, Loss: 0.8067330121994019, Accuracy: 0.7353515625\n",
      "Batch: 26, Loss: 0.6980949640274048, Accuracy: 0.7724609375\n",
      "Batch: 27, Loss: 0.7520253658294678, Accuracy: 0.7392578125\n",
      "Batch: 28, Loss: 0.8179986476898193, Accuracy: 0.724609375\n",
      "Batch: 29, Loss: 0.7851505279541016, Accuracy: 0.74609375\n",
      "Batch: 30, Loss: 0.7504244446754456, Accuracy: 0.7568359375\n",
      "Batch: 31, Loss: 0.7235413789749146, Accuracy: 0.7626953125\n",
      "Batch: 32, Loss: 0.7340758442878723, Accuracy: 0.75390625\n",
      "Batch: 33, Loss: 0.8836468458175659, Accuracy: 0.7099609375\n",
      "Batch: 34, Loss: 0.9098397493362427, Accuracy: 0.712890625\n",
      "Batch: 35, Loss: 0.8570928573608398, Accuracy: 0.72265625\n",
      "Batch: 36, Loss: 0.883259654045105, Accuracy: 0.7236328125\n",
      "Batch: 37, Loss: 0.8114520907402039, Accuracy: 0.7265625\n",
      "Batch: 38, Loss: 0.8066095113754272, Accuracy: 0.724609375\n",
      "Batch: 39, Loss: 0.8084577322006226, Accuracy: 0.7392578125\n",
      "Batch: 40, Loss: 0.7988553643226624, Accuracy: 0.7314453125\n",
      "Batch: 41, Loss: 0.7758712768554688, Accuracy: 0.75\n",
      "Batch: 42, Loss: 0.639180600643158, Accuracy: 0.77734375\n",
      "Batch: 43, Loss: 0.8248672485351562, Accuracy: 0.7138671875\n",
      "Batch: 44, Loss: 0.8308998942375183, Accuracy: 0.7109375\n",
      "Batch: 45, Loss: 0.7215175628662109, Accuracy: 0.7470703125\n",
      "Batch: 46, Loss: 0.7403255701065063, Accuracy: 0.7568359375\n",
      "Batch: 47, Loss: 0.7922134399414062, Accuracy: 0.7646484375\n",
      "Batch: 48, Loss: 0.722004234790802, Accuracy: 0.7646484375\n",
      "Batch: 49, Loss: 0.8691999316215515, Accuracy: 0.716796875\n",
      "Batch: 50, Loss: 0.8373653292655945, Accuracy: 0.7177734375\n",
      "Batch: 51, Loss: 0.8557873964309692, Accuracy: 0.7138671875\n",
      "Batch: 52, Loss: 0.8493248820304871, Accuracy: 0.7099609375\n",
      "Batch: 53, Loss: 0.7457174062728882, Accuracy: 0.7548828125\n",
      "Batch: 54, Loss: 0.8103742599487305, Accuracy: 0.7294921875\n",
      "Batch: 55, Loss: 0.9164786338806152, Accuracy: 0.693359375\n",
      "Batch: 56, Loss: 0.8887189626693726, Accuracy: 0.7119140625\n",
      "Batch: 57, Loss: 0.8347655534744263, Accuracy: 0.7177734375\n",
      "Batch: 58, Loss: 0.907224178314209, Accuracy: 0.708984375\n",
      "Batch: 59, Loss: 0.7791083455085754, Accuracy: 0.75\n",
      "Batch: 60, Loss: 0.7327339053153992, Accuracy: 0.7626953125\n",
      "Batch: 61, Loss: 0.8472800254821777, Accuracy: 0.7294921875\n",
      "Batch: 62, Loss: 0.7947217226028442, Accuracy: 0.74609375\n",
      "Batch: 63, Loss: 0.8282736539840698, Accuracy: 0.734375\n",
      "Batch: 64, Loss: 0.8002075552940369, Accuracy: 0.7333984375\n",
      "Batch: 65, Loss: 0.8198521137237549, Accuracy: 0.740234375\n",
      "Batch: 66, Loss: 0.8124565482139587, Accuracy: 0.7421875\n",
      "Batch: 67, Loss: 0.9122436046600342, Accuracy: 0.7060546875\n",
      "Batch: 68, Loss: 0.9108338356018066, Accuracy: 0.7119140625\n",
      "Batch: 69, Loss: 0.8063920736312866, Accuracy: 0.736328125\n",
      "Batch: 70, Loss: 0.7982656955718994, Accuracy: 0.751953125\n",
      "Batch: 71, Loss: 0.8419228792190552, Accuracy: 0.7236328125\n",
      "Batch: 72, Loss: 0.7349663972854614, Accuracy: 0.744140625\n",
      "Batch: 73, Loss: 0.7501351833343506, Accuracy: 0.75390625\n",
      "Batch: 74, Loss: 0.7248513698577881, Accuracy: 0.7626953125\n",
      "Batch: 75, Loss: 0.7428773045539856, Accuracy: 0.75390625\n",
      "Batch: 76, Loss: 0.8266882300376892, Accuracy: 0.7294921875\n",
      "Batch: 77, Loss: 0.7489113807678223, Accuracy: 0.75\n",
      "Batch: 78, Loss: 0.7699412107467651, Accuracy: 0.75390625\n",
      "Batch: 79, Loss: 0.7007080316543579, Accuracy: 0.783203125\n",
      "Batch: 80, Loss: 0.7792031764984131, Accuracy: 0.7470703125\n",
      "Batch: 82, Loss: 0.826491117477417, Accuracy: 0.7294921875\n",
      "Batch: 83, Loss: 0.7291479706764221, Accuracy: 0.779296875\n",
      "Batch: 84, Loss: 0.7781569957733154, Accuracy: 0.759765625\n",
      "Batch: 85, Loss: 0.7659633159637451, Accuracy: 0.75390625\n",
      "Batch: 86, Loss: 0.9342654943466187, Accuracy: 0.6962890625\n",
      "Batch: 87, Loss: 0.7451538443565369, Accuracy: 0.7490234375\n",
      "Batch: 88, Loss: 0.8569916486740112, Accuracy: 0.744140625\n",
      "Batch: 89, Loss: 0.8161654472351074, Accuracy: 0.7373046875\n",
      "Batch: 90, Loss: 0.7836262583732605, Accuracy: 0.755859375\n",
      "Batch: 91, Loss: 0.7792108058929443, Accuracy: 0.73828125\n",
      "Batch: 92, Loss: 0.8091130256652832, Accuracy: 0.73828125\n",
      "Batch: 93, Loss: 0.7847055792808533, Accuracy: 0.736328125\n",
      "Batch: 94, Loss: 0.8066549897193909, Accuracy: 0.73046875\n",
      "Batch: 95, Loss: 0.8282647132873535, Accuracy: 0.7138671875\n",
      "Batch: 96, Loss: 0.7914496064186096, Accuracy: 0.7412109375\n",
      "Batch: 97, Loss: 0.6600813269615173, Accuracy: 0.7861328125\n",
      "Batch: 98, Loss: 0.7518928050994873, Accuracy: 0.76953125\n",
      "Batch: 99, Loss: 0.7424384355545044, Accuracy: 0.7509765625\n",
      "Batch: 100, Loss: 0.7885183095932007, Accuracy: 0.7314453125\n",
      "Batch: 101, Loss: 0.8505560755729675, Accuracy: 0.7275390625\n",
      "Batch: 102, Loss: 0.7932205200195312, Accuracy: 0.7509765625\n",
      "Batch: 103, Loss: 0.8108817338943481, Accuracy: 0.7451171875\n",
      "Batch: 104, Loss: 0.7583147287368774, Accuracy: 0.736328125\n",
      "Batch: 105, Loss: 0.8514121770858765, Accuracy: 0.7333984375\n",
      "Batch: 106, Loss: 0.779091477394104, Accuracy: 0.7529296875\n",
      "Batch: 107, Loss: 0.817961573600769, Accuracy: 0.7333984375\n",
      "Batch: 108, Loss: 0.806440532207489, Accuracy: 0.7333984375\n",
      "Batch: 109, Loss: 0.8902660608291626, Accuracy: 0.6953125\n",
      "Batch: 110, Loss: 0.7635028958320618, Accuracy: 0.75\n",
      "Batch: 111, Loss: 0.8217301368713379, Accuracy: 0.7314453125\n",
      "Batch: 112, Loss: 0.7733350992202759, Accuracy: 0.755859375\n",
      "Batch: 113, Loss: 0.7966469526290894, Accuracy: 0.7373046875\n",
      "Batch: 114, Loss: 0.9363148212432861, Accuracy: 0.697265625\n",
      "Batch: 115, Loss: 0.954041063785553, Accuracy: 0.7001953125\n",
      "Batch: 116, Loss: 0.8768280148506165, Accuracy: 0.7255859375\n",
      "Batch: 117, Loss: 0.8566126823425293, Accuracy: 0.7158203125\n",
      "Batch: 118, Loss: 0.714514970779419, Accuracy: 0.7763671875\n",
      "Batch: 119, Loss: 0.6738801002502441, Accuracy: 0.7685546875\n",
      "Batch: 120, Loss: 0.8701030611991882, Accuracy: 0.71484375\n",
      "Batch: 121, Loss: 0.8793036341667175, Accuracy: 0.7138671875\n",
      "Batch: 122, Loss: 0.786169171333313, Accuracy: 0.7470703125\n",
      "Batch: 123, Loss: 0.7560843229293823, Accuracy: 0.76171875\n",
      "Batch: 124, Loss: 0.8276093006134033, Accuracy: 0.720703125\n",
      "Batch: 125, Loss: 0.8798023462295532, Accuracy: 0.71875\n",
      "Batch: 126, Loss: 0.8410030603408813, Accuracy: 0.7314453125\n",
      "Batch: 127, Loss: 0.7111636400222778, Accuracy: 0.779296875\n",
      "Batch: 128, Loss: 0.9186063408851624, Accuracy: 0.7236328125\n",
      "Batch: 129, Loss: 0.7427144646644592, Accuracy: 0.767578125\n",
      "Batch: 130, Loss: 0.9333605170249939, Accuracy: 0.7001953125\n",
      "Batch: 131, Loss: 0.8465976715087891, Accuracy: 0.7255859375\n",
      "Batch: 132, Loss: 0.8172532916069031, Accuracy: 0.7451171875\n",
      "Batch: 133, Loss: 0.757731020450592, Accuracy: 0.7431640625\n",
      "Batch: 134, Loss: 0.8427430391311646, Accuracy: 0.7080078125\n",
      "Batch: 135, Loss: 0.758547306060791, Accuracy: 0.7490234375\n",
      "Batch: 136, Loss: 0.8076180219650269, Accuracy: 0.7353515625\n",
      "Batch: 137, Loss: 0.8356575965881348, Accuracy: 0.7099609375\n",
      "Batch: 138, Loss: 0.7290282249450684, Accuracy: 0.755859375\n",
      "Batch: 139, Loss: 0.7639458179473877, Accuracy: 0.7353515625\n",
      "Batch: 140, Loss: 0.7966119050979614, Accuracy: 0.7275390625\n",
      "Batch: 141, Loss: 0.8569890260696411, Accuracy: 0.7177734375\n",
      "Batch: 142, Loss: 0.8929833173751831, Accuracy: 0.7060546875\n",
      "Batch: 143, Loss: 0.8339986801147461, Accuracy: 0.7314453125\n",
      "Batch: 144, Loss: 0.7909679412841797, Accuracy: 0.74609375\n",
      "Batch: 145, Loss: 0.7687134742736816, Accuracy: 0.736328125\n",
      "Batch: 146, Loss: 0.8451151847839355, Accuracy: 0.7216796875\n",
      "Batch: 147, Loss: 0.825158417224884, Accuracy: 0.732421875\n",
      "Batch: 148, Loss: 0.9030100107192993, Accuracy: 0.7001953125\n",
      "Batch: 149, Loss: 0.8186179399490356, Accuracy: 0.73046875\n",
      "Batch: 150, Loss: 0.7719572186470032, Accuracy: 0.73828125\n",
      "Batch: 151, Loss: 0.743600606918335, Accuracy: 0.755859375\n",
      "Epoch 42/80\n",
      "Batch: 1, Loss: 1.042004942893982, Accuracy: 0.6611328125\n",
      "Batch: 2, Loss: 0.9054280519485474, Accuracy: 0.697265625\n",
      "Batch: 3, Loss: 0.7974467873573303, Accuracy: 0.73828125\n",
      "Batch: 4, Loss: 0.7159411907196045, Accuracy: 0.7685546875\n",
      "Batch: 5, Loss: 0.7591911554336548, Accuracy: 0.75390625\n",
      "Batch: 6, Loss: 0.800594687461853, Accuracy: 0.73828125\n",
      "Batch: 7, Loss: 0.8249304294586182, Accuracy: 0.7138671875\n",
      "Batch: 8, Loss: 0.7693675756454468, Accuracy: 0.7275390625\n",
      "Batch: 9, Loss: 0.7346828579902649, Accuracy: 0.7744140625\n",
      "Batch: 10, Loss: 0.7335010766983032, Accuracy: 0.7490234375\n",
      "Batch: 11, Loss: 0.9002745151519775, Accuracy: 0.6669921875\n",
      "Batch: 12, Loss: 0.8774928450584412, Accuracy: 0.724609375\n",
      "Batch: 13, Loss: 0.6561405658721924, Accuracy: 0.78125\n",
      "Batch: 14, Loss: 0.8663504123687744, Accuracy: 0.7109375\n",
      "Batch: 15, Loss: 0.7439277768135071, Accuracy: 0.755859375\n",
      "Batch: 16, Loss: 0.7833064794540405, Accuracy: 0.7529296875\n",
      "Batch: 17, Loss: 0.8124688863754272, Accuracy: 0.724609375\n",
      "Batch: 18, Loss: 0.7942488789558411, Accuracy: 0.740234375\n",
      "Batch: 19, Loss: 0.842118501663208, Accuracy: 0.7529296875\n",
      "Batch: 20, Loss: 0.7225165367126465, Accuracy: 0.76953125\n",
      "Batch: 21, Loss: 0.7406402826309204, Accuracy: 0.7529296875\n",
      "Batch: 22, Loss: 0.8788726329803467, Accuracy: 0.71875\n",
      "Batch: 23, Loss: 0.8288163542747498, Accuracy: 0.7177734375\n",
      "Batch: 24, Loss: 0.8294028043746948, Accuracy: 0.7255859375\n",
      "Batch: 25, Loss: 0.7945703268051147, Accuracy: 0.75\n",
      "Batch: 26, Loss: 0.6998614072799683, Accuracy: 0.7705078125\n",
      "Batch: 28, Loss: 0.8064700961112976, Accuracy: 0.7294921875\n",
      "Batch: 29, Loss: 0.7803030610084534, Accuracy: 0.7529296875\n",
      "Batch: 30, Loss: 0.7294828295707703, Accuracy: 0.77734375\n",
      "Batch: 31, Loss: 0.7587642669677734, Accuracy: 0.7490234375\n",
      "Batch: 32, Loss: 0.7451244592666626, Accuracy: 0.75390625\n",
      "Batch: 33, Loss: 0.8546545505523682, Accuracy: 0.728515625\n",
      "Batch: 34, Loss: 0.9092785716056824, Accuracy: 0.703125\n",
      "Batch: 35, Loss: 0.8556111454963684, Accuracy: 0.71875\n",
      "Batch: 36, Loss: 0.864951491355896, Accuracy: 0.7236328125\n",
      "Batch: 37, Loss: 0.7855508923530579, Accuracy: 0.76171875\n",
      "Batch: 38, Loss: 0.8036389946937561, Accuracy: 0.728515625\n",
      "Batch: 39, Loss: 0.8160637021064758, Accuracy: 0.7255859375\n",
      "Batch: 40, Loss: 0.7805958986282349, Accuracy: 0.7431640625\n",
      "Batch: 41, Loss: 0.7352155447006226, Accuracy: 0.755859375\n",
      "Batch: 42, Loss: 0.6359778642654419, Accuracy: 0.787109375\n",
      "Batch: 43, Loss: 0.8224467039108276, Accuracy: 0.7216796875\n",
      "Batch: 44, Loss: 0.8147377371788025, Accuracy: 0.724609375\n",
      "Batch: 45, Loss: 0.7036948204040527, Accuracy: 0.767578125\n",
      "Batch: 46, Loss: 0.7346029877662659, Accuracy: 0.763671875\n",
      "Batch: 47, Loss: 0.7819055318832397, Accuracy: 0.7607421875\n",
      "Batch: 48, Loss: 0.7306836843490601, Accuracy: 0.7587890625\n",
      "Batch: 49, Loss: 0.8666211366653442, Accuracy: 0.7197265625\n",
      "Batch: 50, Loss: 0.8225603103637695, Accuracy: 0.7265625\n",
      "Batch: 51, Loss: 0.8407274484634399, Accuracy: 0.73046875\n",
      "Batch: 52, Loss: 0.8407322764396667, Accuracy: 0.7353515625\n",
      "Batch: 53, Loss: 0.7466835975646973, Accuracy: 0.7529296875\n",
      "Batch: 54, Loss: 0.7726683020591736, Accuracy: 0.7431640625\n",
      "Batch: 55, Loss: 0.8822529315948486, Accuracy: 0.6904296875\n",
      "Batch: 56, Loss: 0.8900266885757446, Accuracy: 0.712890625\n",
      "Batch: 57, Loss: 0.8284331560134888, Accuracy: 0.72265625\n",
      "Batch: 58, Loss: 0.8764203786849976, Accuracy: 0.728515625\n",
      "Batch: 59, Loss: 0.7647918462753296, Accuracy: 0.75\n",
      "Batch: 60, Loss: 0.7641910314559937, Accuracy: 0.75\n",
      "Batch: 61, Loss: 0.8425090909004211, Accuracy: 0.724609375\n",
      "Batch: 62, Loss: 0.7752610445022583, Accuracy: 0.755859375\n",
      "Batch: 63, Loss: 0.8243100643157959, Accuracy: 0.734375\n",
      "Batch: 64, Loss: 0.8184849619865417, Accuracy: 0.73828125\n",
      "Batch: 65, Loss: 0.8354179859161377, Accuracy: 0.7373046875\n",
      "Batch: 66, Loss: 0.7988273501396179, Accuracy: 0.7470703125\n",
      "Batch: 67, Loss: 0.8861531019210815, Accuracy: 0.724609375\n",
      "Batch: 68, Loss: 0.9335090517997742, Accuracy: 0.7119140625\n",
      "Batch: 69, Loss: 0.8021478056907654, Accuracy: 0.7373046875\n",
      "Batch: 70, Loss: 0.7893037796020508, Accuracy: 0.7509765625\n",
      "Batch: 71, Loss: 0.8598026037216187, Accuracy: 0.7041015625\n",
      "Batch: 72, Loss: 0.7143570184707642, Accuracy: 0.7705078125\n",
      "Batch: 73, Loss: 0.7264642119407654, Accuracy: 0.7685546875\n",
      "Batch: 74, Loss: 0.7161691784858704, Accuracy: 0.7626953125\n",
      "Batch: 75, Loss: 0.7532545328140259, Accuracy: 0.7568359375\n",
      "Batch: 76, Loss: 0.8076444268226624, Accuracy: 0.734375\n",
      "Batch: 77, Loss: 0.7409365177154541, Accuracy: 0.7666015625\n",
      "Batch: 78, Loss: 0.7493296265602112, Accuracy: 0.7548828125\n",
      "Batch: 79, Loss: 0.6740635633468628, Accuracy: 0.77734375\n",
      "Batch: 80, Loss: 0.7670636773109436, Accuracy: 0.7431640625\n",
      "Batch: 81, Loss: 0.8626161813735962, Accuracy: 0.712890625\n",
      "Batch: 82, Loss: 0.8331561088562012, Accuracy: 0.7314453125\n",
      "Batch: 83, Loss: 0.71409010887146, Accuracy: 0.7841796875\n",
      "Batch: 84, Loss: 0.7510347366333008, Accuracy: 0.751953125\n",
      "Batch: 85, Loss: 0.7625408172607422, Accuracy: 0.75\n",
      "Batch: 86, Loss: 0.9162812232971191, Accuracy: 0.71484375\n",
      "Batch: 87, Loss: 0.7412824034690857, Accuracy: 0.7646484375\n",
      "Batch: 88, Loss: 0.8272435665130615, Accuracy: 0.7392578125\n",
      "Batch: 89, Loss: 0.8077245950698853, Accuracy: 0.7421875\n",
      "Batch: 90, Loss: 0.7641312479972839, Accuracy: 0.751953125\n",
      "Batch: 91, Loss: 0.7743767499923706, Accuracy: 0.7490234375\n",
      "Batch: 92, Loss: 0.8039054870605469, Accuracy: 0.7294921875\n",
      "Batch: 93, Loss: 0.8117390871047974, Accuracy: 0.74609375\n",
      "Batch: 94, Loss: 0.8096863031387329, Accuracy: 0.7314453125\n",
      "Batch: 95, Loss: 0.8371506929397583, Accuracy: 0.7080078125\n",
      "Batch: 96, Loss: 0.7711083292961121, Accuracy: 0.74609375\n",
      "Batch: 97, Loss: 0.6801753044128418, Accuracy: 0.7734375\n",
      "Batch: 98, Loss: 0.7446599006652832, Accuracy: 0.7685546875\n",
      "Batch: 99, Loss: 0.7798084020614624, Accuracy: 0.75\n",
      "Batch: 100, Loss: 0.7862288951873779, Accuracy: 0.7451171875\n",
      "Batch: 101, Loss: 0.8321881890296936, Accuracy: 0.7333984375\n",
      "Batch: 102, Loss: 0.7795193791389465, Accuracy: 0.748046875\n",
      "Batch: 103, Loss: 0.7941617965698242, Accuracy: 0.7490234375\n",
      "Batch: 104, Loss: 0.7443499565124512, Accuracy: 0.759765625\n",
      "Batch: 105, Loss: 0.8430078625679016, Accuracy: 0.728515625\n",
      "Batch: 106, Loss: 0.7410067319869995, Accuracy: 0.75390625\n",
      "Batch: 107, Loss: 0.8175127506256104, Accuracy: 0.7421875\n",
      "Batch: 108, Loss: 0.7874116897583008, Accuracy: 0.73046875\n",
      "Batch: 109, Loss: 0.8673804402351379, Accuracy: 0.7158203125\n",
      "Batch: 110, Loss: 0.713142991065979, Accuracy: 0.7646484375\n",
      "Batch: 111, Loss: 0.8169513940811157, Accuracy: 0.7392578125\n",
      "Batch: 112, Loss: 0.7955855131149292, Accuracy: 0.76171875\n",
      "Batch: 113, Loss: 0.8099965453147888, Accuracy: 0.7451171875\n",
      "Batch: 114, Loss: 0.8991302251815796, Accuracy: 0.7001953125\n",
      "Batch: 115, Loss: 0.9146288633346558, Accuracy: 0.708984375\n",
      "Batch: 116, Loss: 0.8594473600387573, Accuracy: 0.7314453125\n",
      "Batch: 117, Loss: 0.8438540101051331, Accuracy: 0.7353515625\n",
      "Batch: 120, Loss: 0.8535094261169434, Accuracy: 0.7294921875\n",
      "Batch: 121, Loss: 0.8379693031311035, Accuracy: 0.7255859375\n",
      "Batch: 122, Loss: 0.7585852146148682, Accuracy: 0.75\n",
      "Batch: 123, Loss: 0.7612326741218567, Accuracy: 0.7451171875\n",
      "Batch: 124, Loss: 0.8127080798149109, Accuracy: 0.7294921875\n",
      "Batch: 125, Loss: 0.8494863510131836, Accuracy: 0.7255859375\n",
      "Batch: 126, Loss: 0.8623343110084534, Accuracy: 0.701171875\n",
      "Batch: 127, Loss: 0.732390820980072, Accuracy: 0.7734375\n",
      "Batch: 128, Loss: 0.9003607034683228, Accuracy: 0.7431640625\n",
      "Batch: 129, Loss: 0.7512664198875427, Accuracy: 0.7509765625\n",
      "Batch: 130, Loss: 0.9405472278594971, Accuracy: 0.70703125\n",
      "Batch: 131, Loss: 0.8202937245368958, Accuracy: 0.7392578125\n",
      "Batch: 132, Loss: 0.821008026599884, Accuracy: 0.7470703125\n",
      "Batch: 133, Loss: 0.7598198652267456, Accuracy: 0.748046875\n",
      "Batch: 134, Loss: 0.857795000076294, Accuracy: 0.701171875\n",
      "Batch: 135, Loss: 0.7449585199356079, Accuracy: 0.759765625\n",
      "Batch: 136, Loss: 0.8372209072113037, Accuracy: 0.73046875\n",
      "Batch: 137, Loss: 0.7909088730812073, Accuracy: 0.728515625\n",
      "Batch: 138, Loss: 0.7069465517997742, Accuracy: 0.763671875\n",
      "Batch: 139, Loss: 0.7693254947662354, Accuracy: 0.7470703125\n",
      "Batch: 140, Loss: 0.7795724272727966, Accuracy: 0.7451171875\n",
      "Batch: 141, Loss: 0.8375599980354309, Accuracy: 0.73046875\n",
      "Batch: 142, Loss: 0.8431726694107056, Accuracy: 0.7236328125\n",
      "Batch: 143, Loss: 0.7978062629699707, Accuracy: 0.7490234375\n",
      "Batch: 144, Loss: 0.8077327609062195, Accuracy: 0.7314453125\n",
      "Batch: 145, Loss: 0.7655758857727051, Accuracy: 0.7294921875\n",
      "Batch: 146, Loss: 0.8638957738876343, Accuracy: 0.7265625\n",
      "Batch: 147, Loss: 0.8601181507110596, Accuracy: 0.7060546875\n",
      "Batch: 148, Loss: 0.9058591723442078, Accuracy: 0.708984375\n",
      "Batch: 149, Loss: 0.8138746023178101, Accuracy: 0.7353515625\n",
      "Batch: 150, Loss: 0.7635736465454102, Accuracy: 0.7421875\n",
      "Batch: 151, Loss: 0.7172436714172363, Accuracy: 0.7724609375\n",
      "Epoch 43/80\n",
      "Batch: 1, Loss: 1.055589199066162, Accuracy: 0.6650390625\n",
      "Batch: 2, Loss: 0.8459564447402954, Accuracy: 0.708984375\n",
      "Batch: 3, Loss: 0.7913256883621216, Accuracy: 0.7255859375\n",
      "Batch: 4, Loss: 0.7121663689613342, Accuracy: 0.767578125\n",
      "Batch: 5, Loss: 0.7632771730422974, Accuracy: 0.7529296875\n",
      "Batch: 6, Loss: 0.806877851486206, Accuracy: 0.728515625\n",
      "Batch: 7, Loss: 0.8221126794815063, Accuracy: 0.69921875\n",
      "Batch: 8, Loss: 0.7747220396995544, Accuracy: 0.73828125\n",
      "Batch: 9, Loss: 0.7511909008026123, Accuracy: 0.765625\n",
      "Batch: 10, Loss: 0.7534230947494507, Accuracy: 0.736328125\n",
      "Batch: 11, Loss: 0.8602734208106995, Accuracy: 0.7021484375\n",
      "Batch: 12, Loss: 0.8641036152839661, Accuracy: 0.7216796875\n",
      "Batch: 13, Loss: 0.6409180164337158, Accuracy: 0.80078125\n",
      "Batch: 17, Loss: 0.816570520401001, Accuracy: 0.736328125\n",
      "Batch: 18, Loss: 0.826389491558075, Accuracy: 0.736328125\n",
      "Batch: 19, Loss: 0.8280017375946045, Accuracy: 0.740234375\n",
      "Batch: 20, Loss: 0.737093448638916, Accuracy: 0.7685546875\n",
      "Batch: 21, Loss: 0.750175952911377, Accuracy: 0.751953125\n",
      "Batch: 22, Loss: 0.8878129720687866, Accuracy: 0.720703125\n",
      "Batch: 23, Loss: 0.8241997957229614, Accuracy: 0.7197265625\n",
      "Batch: 24, Loss: 0.844791054725647, Accuracy: 0.71875\n",
      "Batch: 25, Loss: 0.7828694581985474, Accuracy: 0.755859375\n",
      "Batch: 26, Loss: 0.6867110729217529, Accuracy: 0.7734375\n",
      "Batch: 27, Loss: 0.7475147247314453, Accuracy: 0.7626953125\n",
      "Batch: 28, Loss: 0.8261953592300415, Accuracy: 0.7431640625\n",
      "Batch: 29, Loss: 0.7751771807670593, Accuracy: 0.755859375\n",
      "Batch: 30, Loss: 0.7359613180160522, Accuracy: 0.7666015625\n",
      "Batch: 31, Loss: 0.7336328625679016, Accuracy: 0.759765625\n",
      "Batch: 32, Loss: 0.7354239225387573, Accuracy: 0.7548828125\n",
      "Batch: 33, Loss: 0.8378954529762268, Accuracy: 0.7314453125\n",
      "Batch: 34, Loss: 0.8819172382354736, Accuracy: 0.712890625\n",
      "Batch: 35, Loss: 0.8383333683013916, Accuracy: 0.7255859375\n",
      "Batch: 36, Loss: 0.871113657951355, Accuracy: 0.7294921875\n",
      "Batch: 37, Loss: 0.8075361847877502, Accuracy: 0.736328125\n",
      "Batch: 38, Loss: 0.8218125700950623, Accuracy: 0.72265625\n",
      "Batch: 39, Loss: 0.804543137550354, Accuracy: 0.7373046875\n",
      "Batch: 40, Loss: 0.7804373502731323, Accuracy: 0.74609375\n",
      "Batch: 41, Loss: 0.7415144443511963, Accuracy: 0.76171875\n",
      "Batch: 42, Loss: 0.6100510954856873, Accuracy: 0.7802734375\n",
      "Batch: 43, Loss: 0.8050661683082581, Accuracy: 0.7294921875\n",
      "Batch: 44, Loss: 0.8186821937561035, Accuracy: 0.720703125\n",
      "Batch: 45, Loss: 0.7133841514587402, Accuracy: 0.7548828125\n",
      "Batch: 46, Loss: 0.7415008544921875, Accuracy: 0.7578125\n",
      "Batch: 47, Loss: 0.7535508871078491, Accuracy: 0.771484375\n",
      "Batch: 48, Loss: 0.7136610746383667, Accuracy: 0.7578125\n",
      "Batch: 49, Loss: 0.8512822389602661, Accuracy: 0.7294921875\n",
      "Batch: 50, Loss: 0.8342901468276978, Accuracy: 0.7275390625\n",
      "Batch: 51, Loss: 0.8628532290458679, Accuracy: 0.7265625\n",
      "Batch: 52, Loss: 0.8467352390289307, Accuracy: 0.7451171875\n",
      "Batch: 53, Loss: 0.7238104343414307, Accuracy: 0.7509765625\n",
      "Batch: 54, Loss: 0.7694178223609924, Accuracy: 0.7548828125\n",
      "Batch: 55, Loss: 0.9206566214561462, Accuracy: 0.6904296875\n",
      "Batch: 56, Loss: 0.870705783367157, Accuracy: 0.712890625\n",
      "Batch: 57, Loss: 0.8223665952682495, Accuracy: 0.7216796875\n",
      "Batch: 58, Loss: 0.9008203148841858, Accuracy: 0.71484375\n",
      "Batch: 59, Loss: 0.7651485204696655, Accuracy: 0.75\n",
      "Batch: 60, Loss: 0.7503536939620972, Accuracy: 0.763671875\n",
      "Batch: 61, Loss: 0.8444517850875854, Accuracy: 0.7275390625\n",
      "Batch: 62, Loss: 0.767232358455658, Accuracy: 0.7451171875\n",
      "Batch: 63, Loss: 0.8439527153968811, Accuracy: 0.7314453125\n",
      "Batch: 64, Loss: 0.8072888255119324, Accuracy: 0.7275390625\n",
      "Batch: 65, Loss: 0.8189030885696411, Accuracy: 0.744140625\n",
      "Batch: 66, Loss: 0.7946188449859619, Accuracy: 0.7421875\n",
      "Batch: 67, Loss: 0.8824556469917297, Accuracy: 0.728515625\n",
      "Batch: 68, Loss: 0.9083974957466125, Accuracy: 0.701171875\n",
      "Batch: 69, Loss: 0.8041818737983704, Accuracy: 0.7431640625\n",
      "Batch: 70, Loss: 0.7694647312164307, Accuracy: 0.7587890625\n",
      "Batch: 71, Loss: 0.845514178276062, Accuracy: 0.7099609375\n",
      "Batch: 72, Loss: 0.6906192302703857, Accuracy: 0.7705078125\n",
      "Batch: 73, Loss: 0.7360765933990479, Accuracy: 0.7685546875\n",
      "Batch: 74, Loss: 0.691942572593689, Accuracy: 0.77734375\n",
      "Batch: 75, Loss: 0.7246218919754028, Accuracy: 0.759765625\n",
      "Batch: 76, Loss: 0.8250662088394165, Accuracy: 0.7353515625\n",
      "Batch: 77, Loss: 0.7387025356292725, Accuracy: 0.76171875\n",
      "Batch: 78, Loss: 0.7400510907173157, Accuracy: 0.74609375\n",
      "Batch: 79, Loss: 0.7009921073913574, Accuracy: 0.7861328125\n",
      "Batch: 80, Loss: 0.7487800121307373, Accuracy: 0.751953125\n",
      "Batch: 81, Loss: 0.8467932939529419, Accuracy: 0.6982421875\n",
      "Batch: 82, Loss: 0.8477873802185059, Accuracy: 0.73046875\n",
      "Batch: 83, Loss: 0.6913303732872009, Accuracy: 0.78125\n",
      "Batch: 84, Loss: 0.7586688995361328, Accuracy: 0.7529296875\n",
      "Batch: 85, Loss: 0.7578878402709961, Accuracy: 0.759765625\n",
      "Batch: 86, Loss: 0.9194623231887817, Accuracy: 0.7060546875\n",
      "Batch: 87, Loss: 0.7487930655479431, Accuracy: 0.7587890625\n",
      "Batch: 88, Loss: 0.8282564878463745, Accuracy: 0.7470703125\n",
      "Batch: 89, Loss: 0.8028583526611328, Accuracy: 0.748046875\n",
      "Batch: 90, Loss: 0.7947983741760254, Accuracy: 0.7509765625\n",
      "Batch: 91, Loss: 0.7683738470077515, Accuracy: 0.751953125\n",
      "Batch: 92, Loss: 0.791683554649353, Accuracy: 0.7392578125\n",
      "Batch: 93, Loss: 0.7773380875587463, Accuracy: 0.73828125\n",
      "Batch: 94, Loss: 0.7952651977539062, Accuracy: 0.744140625\n",
      "Batch: 95, Loss: 0.8379768133163452, Accuracy: 0.7109375\n",
      "Batch: 96, Loss: 0.7788207530975342, Accuracy: 0.7509765625\n",
      "Batch: 97, Loss: 0.6625185608863831, Accuracy: 0.7734375\n",
      "Batch: 98, Loss: 0.7313119173049927, Accuracy: 0.7646484375\n",
      "Batch: 99, Loss: 0.7634588479995728, Accuracy: 0.765625\n",
      "Batch: 100, Loss: 0.7796354293823242, Accuracy: 0.7568359375\n",
      "Batch: 101, Loss: 0.869335412979126, Accuracy: 0.716796875\n",
      "Batch: 102, Loss: 0.7705901861190796, Accuracy: 0.7412109375\n",
      "Batch: 103, Loss: 0.7902762293815613, Accuracy: 0.7548828125\n",
      "Batch: 105, Loss: 0.8210105895996094, Accuracy: 0.7373046875\n",
      "Batch: 106, Loss: 0.7403708100318909, Accuracy: 0.7470703125\n",
      "Batch: 107, Loss: 0.8011763095855713, Accuracy: 0.748046875\n",
      "Batch: 108, Loss: 0.7575479745864868, Accuracy: 0.740234375\n",
      "Batch: 109, Loss: 0.8790379762649536, Accuracy: 0.72265625\n",
      "Batch: 110, Loss: 0.7548724412918091, Accuracy: 0.75390625\n",
      "Batch: 111, Loss: 0.815443754196167, Accuracy: 0.7431640625\n",
      "Batch: 112, Loss: 0.7660770416259766, Accuracy: 0.7548828125\n",
      "Batch: 113, Loss: 0.7976090312004089, Accuracy: 0.736328125\n",
      "Batch: 114, Loss: 0.8711186647415161, Accuracy: 0.7216796875\n",
      "Batch: 115, Loss: 0.93593430519104, Accuracy: 0.7177734375\n",
      "Batch: 116, Loss: 0.8607871532440186, Accuracy: 0.7294921875\n",
      "Batch: 117, Loss: 0.8503039479255676, Accuracy: 0.7265625\n",
      "Batch: 118, Loss: 0.6762499809265137, Accuracy: 0.783203125\n",
      "Batch: 119, Loss: 0.6752924919128418, Accuracy: 0.7841796875\n",
      "Batch: 120, Loss: 0.8046431541442871, Accuracy: 0.75\n",
      "Batch: 121, Loss: 0.8415606021881104, Accuracy: 0.73046875\n",
      "Batch: 122, Loss: 0.7611950635910034, Accuracy: 0.7705078125\n",
      "Batch: 123, Loss: 0.7445065975189209, Accuracy: 0.7568359375\n",
      "Batch: 124, Loss: 0.7859576940536499, Accuracy: 0.7392578125\n",
      "Batch: 125, Loss: 0.867499589920044, Accuracy: 0.7236328125\n",
      "Batch: 126, Loss: 0.8209202885627747, Accuracy: 0.73046875\n",
      "Batch: 127, Loss: 0.7081773281097412, Accuracy: 0.7822265625\n",
      "Batch: 128, Loss: 0.8769898414611816, Accuracy: 0.7294921875\n",
      "Batch: 129, Loss: 0.7155431509017944, Accuracy: 0.755859375\n",
      "Batch: 130, Loss: 0.9044976234436035, Accuracy: 0.7158203125\n",
      "Batch: 131, Loss: 0.8058056831359863, Accuracy: 0.7412109375\n",
      "Batch: 132, Loss: 0.8252055644989014, Accuracy: 0.7470703125\n",
      "Batch: 133, Loss: 0.7540169954299927, Accuracy: 0.7412109375\n",
      "Batch: 134, Loss: 0.8445992469787598, Accuracy: 0.7177734375\n",
      "Batch: 135, Loss: 0.733229398727417, Accuracy: 0.7587890625\n",
      "Batch: 136, Loss: 0.807137131690979, Accuracy: 0.74609375\n",
      "Batch: 137, Loss: 0.7774708867073059, Accuracy: 0.7353515625\n",
      "Batch: 138, Loss: 0.699689507484436, Accuracy: 0.7646484375\n",
      "Batch: 139, Loss: 0.7442333102226257, Accuracy: 0.7607421875\n",
      "Batch: 140, Loss: 0.7937188744544983, Accuracy: 0.7412109375\n",
      "Batch: 141, Loss: 0.8276936411857605, Accuracy: 0.736328125\n",
      "Batch: 142, Loss: 0.8439525365829468, Accuracy: 0.7119140625\n",
      "Batch: 143, Loss: 0.7853636741638184, Accuracy: 0.7392578125\n",
      "Batch: 144, Loss: 0.786096453666687, Accuracy: 0.734375\n",
      "Batch: 145, Loss: 0.7436255812644958, Accuracy: 0.7412109375\n",
      "Batch: 146, Loss: 0.8250882625579834, Accuracy: 0.7353515625\n",
      "Batch: 147, Loss: 0.7988060116767883, Accuracy: 0.7392578125\n",
      "Batch: 148, Loss: 0.8992844820022583, Accuracy: 0.705078125\n",
      "Batch: 149, Loss: 0.79320228099823, Accuracy: 0.7392578125\n",
      "Batch: 150, Loss: 0.7723464965820312, Accuracy: 0.7509765625\n",
      "Batch: 151, Loss: 0.7080683708190918, Accuracy: 0.76953125\n",
      "Epoch 44/80\n",
      "Batch: 1, Loss: 1.0389480590820312, Accuracy: 0.6650390625\n",
      "Batch: 2, Loss: 0.8383685350418091, Accuracy: 0.7119140625\n",
      "Batch: 3, Loss: 0.7805342078208923, Accuracy: 0.736328125\n",
      "Batch: 4, Loss: 0.6933071613311768, Accuracy: 0.7861328125\n",
      "Batch: 5, Loss: 0.7432173490524292, Accuracy: 0.767578125\n",
      "Batch: 6, Loss: 0.8088541030883789, Accuracy: 0.7275390625\n",
      "Batch: 7, Loss: 0.8107852935791016, Accuracy: 0.7275390625\n",
      "Batch: 8, Loss: 0.7472728490829468, Accuracy: 0.7451171875\n",
      "Batch: 9, Loss: 0.7384469509124756, Accuracy: 0.7646484375\n",
      "Batch: 10, Loss: 0.7226999998092651, Accuracy: 0.75390625\n",
      "Batch: 11, Loss: 0.8733141422271729, Accuracy: 0.69921875\n",
      "Batch: 12, Loss: 0.8534547090530396, Accuracy: 0.72265625\n",
      "Batch: 13, Loss: 0.6478177905082703, Accuracy: 0.791015625\n",
      "Batch: 14, Loss: 0.8872165679931641, Accuracy: 0.7080078125\n",
      "Batch: 15, Loss: 0.7233612537384033, Accuracy: 0.7802734375\n",
      "Batch: 16, Loss: 0.7846344113349915, Accuracy: 0.75\n",
      "Batch: 17, Loss: 0.8081101179122925, Accuracy: 0.7314453125\n",
      "Batch: 18, Loss: 0.7976946234703064, Accuracy: 0.736328125\n",
      "Batch: 19, Loss: 0.8404814004898071, Accuracy: 0.7373046875\n",
      "Batch: 20, Loss: 0.715388834476471, Accuracy: 0.7763671875\n",
      "Batch: 21, Loss: 0.7312667369842529, Accuracy: 0.7548828125\n",
      "Batch: 22, Loss: 0.8796539306640625, Accuracy: 0.7275390625\n",
      "Batch: 23, Loss: 0.8005540370941162, Accuracy: 0.7314453125\n",
      "Batch: 24, Loss: 0.8292271494865417, Accuracy: 0.71875\n",
      "Batch: 25, Loss: 0.7896668910980225, Accuracy: 0.7578125\n",
      "Batch: 26, Loss: 0.6822524666786194, Accuracy: 0.7705078125\n",
      "Batch: 27, Loss: 0.7104727029800415, Accuracy: 0.7705078125\n",
      "Batch: 28, Loss: 0.7868545055389404, Accuracy: 0.7373046875\n",
      "Batch: 29, Loss: 0.7598375082015991, Accuracy: 0.75390625\n",
      "Batch: 30, Loss: 0.7112308144569397, Accuracy: 0.7822265625\n",
      "Batch: 31, Loss: 0.7174066305160522, Accuracy: 0.7763671875\n",
      "Batch: 32, Loss: 0.6999484300613403, Accuracy: 0.7490234375\n",
      "Batch: 33, Loss: 0.8588341474533081, Accuracy: 0.732421875\n",
      "Batch: 34, Loss: 0.9126622676849365, Accuracy: 0.7109375\n",
      "Batch: 35, Loss: 0.8246511220932007, Accuracy: 0.7294921875\n",
      "Batch: 36, Loss: 0.865777850151062, Accuracy: 0.7265625\n",
      "Batch: 37, Loss: 0.8053460121154785, Accuracy: 0.7431640625\n",
      "Batch: 38, Loss: 0.8068341612815857, Accuracy: 0.7294921875\n",
      "Batch: 39, Loss: 0.8269984126091003, Accuracy: 0.734375\n",
      "Batch: 40, Loss: 0.7523349523544312, Accuracy: 0.763671875\n",
      "Batch: 41, Loss: 0.7085320949554443, Accuracy: 0.7705078125\n",
      "Batch: 42, Loss: 0.5945489406585693, Accuracy: 0.7958984375\n",
      "Batch: 44, Loss: 0.8256778717041016, Accuracy: 0.7265625\n",
      "Batch: 45, Loss: 0.6964044570922852, Accuracy: 0.7578125\n",
      "Batch: 46, Loss: 0.7074352502822876, Accuracy: 0.763671875\n",
      "Batch: 47, Loss: 0.783511757850647, Accuracy: 0.7529296875\n",
      "Batch: 48, Loss: 0.6912338137626648, Accuracy: 0.7646484375\n",
      "Batch: 49, Loss: 0.8346110582351685, Accuracy: 0.7333984375\n",
      "Batch: 50, Loss: 0.8297905921936035, Accuracy: 0.724609375\n",
      "Batch: 51, Loss: 0.8423707485198975, Accuracy: 0.7333984375\n",
      "Batch: 52, Loss: 0.8144649267196655, Accuracy: 0.74609375\n",
      "Batch: 53, Loss: 0.7187429666519165, Accuracy: 0.755859375\n",
      "Batch: 54, Loss: 0.7813562154769897, Accuracy: 0.734375\n",
      "Batch: 55, Loss: 0.8574349880218506, Accuracy: 0.7158203125\n",
      "Batch: 56, Loss: 0.8361828327178955, Accuracy: 0.724609375\n",
      "Batch: 57, Loss: 0.8029313087463379, Accuracy: 0.7373046875\n",
      "Batch: 58, Loss: 0.8485450744628906, Accuracy: 0.7353515625\n",
      "Batch: 59, Loss: 0.7442164421081543, Accuracy: 0.75390625\n",
      "Batch: 60, Loss: 0.7299330234527588, Accuracy: 0.759765625\n",
      "Batch: 61, Loss: 0.824960470199585, Accuracy: 0.73046875\n",
      "Batch: 62, Loss: 0.7884789109230042, Accuracy: 0.7587890625\n",
      "Batch: 63, Loss: 0.830950140953064, Accuracy: 0.7265625\n",
      "Batch: 64, Loss: 0.8077609539031982, Accuracy: 0.734375\n",
      "Batch: 65, Loss: 0.831861674785614, Accuracy: 0.73828125\n",
      "Batch: 66, Loss: 0.8034451007843018, Accuracy: 0.7314453125\n",
      "Batch: 67, Loss: 0.8780621290206909, Accuracy: 0.73046875\n",
      "Batch: 68, Loss: 0.9025875926017761, Accuracy: 0.7158203125\n",
      "Batch: 69, Loss: 0.8484533429145813, Accuracy: 0.736328125\n",
      "Batch: 70, Loss: 0.7507582306861877, Accuracy: 0.7763671875\n",
      "Batch: 71, Loss: 0.8345494270324707, Accuracy: 0.724609375\n",
      "Batch: 72, Loss: 0.7075467705726624, Accuracy: 0.7763671875\n",
      "Batch: 73, Loss: 0.7314844131469727, Accuracy: 0.7548828125\n",
      "Batch: 74, Loss: 0.712040364742279, Accuracy: 0.7724609375\n",
      "Batch: 75, Loss: 0.7252565622329712, Accuracy: 0.763671875\n",
      "Batch: 76, Loss: 0.7930039167404175, Accuracy: 0.734375\n",
      "Batch: 77, Loss: 0.7511625289916992, Accuracy: 0.7470703125\n",
      "Batch: 78, Loss: 0.7254992723464966, Accuracy: 0.7666015625\n",
      "Batch: 79, Loss: 0.7014058828353882, Accuracy: 0.775390625\n",
      "Batch: 80, Loss: 0.7458912134170532, Accuracy: 0.751953125\n",
      "Batch: 81, Loss: 0.8473527431488037, Accuracy: 0.7119140625\n",
      "Batch: 82, Loss: 0.8187705278396606, Accuracy: 0.7265625\n",
      "Batch: 83, Loss: 0.7033319473266602, Accuracy: 0.7734375\n",
      "Batch: 84, Loss: 0.7474521398544312, Accuracy: 0.759765625\n",
      "Batch: 85, Loss: 0.738571047782898, Accuracy: 0.7666015625\n",
      "Batch: 86, Loss: 0.8827725648880005, Accuracy: 0.740234375\n",
      "Batch: 87, Loss: 0.7319310903549194, Accuracy: 0.765625\n",
      "Batch: 88, Loss: 0.8307198286056519, Accuracy: 0.732421875\n",
      "Batch: 89, Loss: 0.7815724611282349, Accuracy: 0.7451171875\n",
      "Batch: 90, Loss: 0.7690606117248535, Accuracy: 0.763671875\n",
      "Batch: 91, Loss: 0.7564194798469543, Accuracy: 0.7509765625\n",
      "Batch: 92, Loss: 0.7784587144851685, Accuracy: 0.73828125\n",
      "Batch: 93, Loss: 0.7785731554031372, Accuracy: 0.7451171875\n",
      "Batch: 94, Loss: 0.797394335269928, Accuracy: 0.7353515625\n",
      "Batch: 95, Loss: 0.8355333805084229, Accuracy: 0.708984375\n",
      "Batch: 96, Loss: 0.7707057595252991, Accuracy: 0.7431640625\n",
      "Batch: 97, Loss: 0.6666280031204224, Accuracy: 0.7626953125\n",
      "Batch: 98, Loss: 0.7551788091659546, Accuracy: 0.7548828125\n",
      "Batch: 99, Loss: 0.7304081916809082, Accuracy: 0.7763671875\n",
      "Batch: 100, Loss: 0.7607913017272949, Accuracy: 0.7548828125\n",
      "Batch: 101, Loss: 0.8254925012588501, Accuracy: 0.736328125\n",
      "Batch: 102, Loss: 0.7698432803153992, Accuracy: 0.7578125\n",
      "Batch: 103, Loss: 0.7730280160903931, Accuracy: 0.751953125\n",
      "Batch: 104, Loss: 0.7439942955970764, Accuracy: 0.74609375\n",
      "Batch: 105, Loss: 0.810153603553772, Accuracy: 0.736328125\n",
      "Batch: 106, Loss: 0.7418733835220337, Accuracy: 0.751953125\n",
      "Batch: 107, Loss: 0.8092927932739258, Accuracy: 0.73828125\n",
      "Batch: 108, Loss: 0.7569764852523804, Accuracy: 0.7548828125\n",
      "Batch: 109, Loss: 0.8620133399963379, Accuracy: 0.7255859375\n",
      "Batch: 110, Loss: 0.7307459712028503, Accuracy: 0.76171875\n",
      "Batch: 111, Loss: 0.7986798882484436, Accuracy: 0.75390625\n",
      "Batch: 112, Loss: 0.7477346658706665, Accuracy: 0.7548828125\n",
      "Batch: 113, Loss: 0.7871232032775879, Accuracy: 0.7470703125\n",
      "Batch: 114, Loss: 0.8930693864822388, Accuracy: 0.7001953125\n",
      "Batch: 115, Loss: 0.9361515045166016, Accuracy: 0.6884765625\n",
      "Batch: 116, Loss: 0.8495965600013733, Accuracy: 0.740234375\n",
      "Batch: 117, Loss: 0.8170859813690186, Accuracy: 0.75\n",
      "Batch: 118, Loss: 0.6965136528015137, Accuracy: 0.7861328125\n",
      "Batch: 119, Loss: 0.6528830528259277, Accuracy: 0.7822265625\n",
      "Batch: 120, Loss: 0.8102934956550598, Accuracy: 0.7373046875\n",
      "Batch: 121, Loss: 0.7973869442939758, Accuracy: 0.74609375\n",
      "Batch: 122, Loss: 0.7534688711166382, Accuracy: 0.7626953125\n",
      "Batch: 123, Loss: 0.7359638214111328, Accuracy: 0.7548828125\n",
      "Batch: 124, Loss: 0.775619387626648, Accuracy: 0.740234375\n",
      "Batch: 125, Loss: 0.8575429916381836, Accuracy: 0.7236328125\n",
      "Batch: 126, Loss: 0.833214521408081, Accuracy: 0.744140625\n",
      "Batch: 127, Loss: 0.6865038275718689, Accuracy: 0.7978515625\n",
      "Batch: 128, Loss: 0.9113194942474365, Accuracy: 0.7255859375\n",
      "Batch: 129, Loss: 0.7149609327316284, Accuracy: 0.77734375\n",
      "Batch: 130, Loss: 0.8765404224395752, Accuracy: 0.7236328125\n",
      "Batch: 131, Loss: 0.774939775466919, Accuracy: 0.740234375\n",
      "Batch: 135, Loss: 0.7484500408172607, Accuracy: 0.751953125\n",
      "Batch: 136, Loss: 0.817642092704773, Accuracy: 0.7294921875\n",
      "Batch: 137, Loss: 0.7769801020622253, Accuracy: 0.728515625\n",
      "Batch: 138, Loss: 0.6866008639335632, Accuracy: 0.7734375\n",
      "Batch: 139, Loss: 0.7116248607635498, Accuracy: 0.755859375\n",
      "Batch: 140, Loss: 0.7786321043968201, Accuracy: 0.7314453125\n",
      "Batch: 141, Loss: 0.8383851051330566, Accuracy: 0.7412109375\n",
      "Batch: 142, Loss: 0.8579316735267639, Accuracy: 0.716796875\n",
      "Batch: 143, Loss: 0.8049597144126892, Accuracy: 0.740234375\n",
      "Batch: 144, Loss: 0.8215848803520203, Accuracy: 0.7294921875\n",
      "Batch: 145, Loss: 0.7410258054733276, Accuracy: 0.74609375\n",
      "Batch: 146, Loss: 0.8114033937454224, Accuracy: 0.7451171875\n",
      "Batch: 147, Loss: 0.8101153373718262, Accuracy: 0.7333984375\n",
      "Batch: 148, Loss: 0.903549075126648, Accuracy: 0.701171875\n",
      "Batch: 149, Loss: 0.7694828510284424, Accuracy: 0.7509765625\n",
      "Batch: 150, Loss: 0.7602223753929138, Accuracy: 0.7392578125\n",
      "Batch: 151, Loss: 0.6934343576431274, Accuracy: 0.7734375\n",
      "Epoch 45/80\n",
      "Batch: 1, Loss: 0.982335090637207, Accuracy: 0.6884765625\n",
      "Batch: 2, Loss: 0.855542778968811, Accuracy: 0.7275390625\n",
      "Batch: 3, Loss: 0.7823771238327026, Accuracy: 0.7265625\n",
      "Batch: 4, Loss: 0.7134443521499634, Accuracy: 0.755859375\n",
      "Batch: 5, Loss: 0.7491511106491089, Accuracy: 0.7587890625\n",
      "Batch: 6, Loss: 0.7971031069755554, Accuracy: 0.7255859375\n",
      "Batch: 7, Loss: 0.7851721048355103, Accuracy: 0.7275390625\n",
      "Batch: 8, Loss: 0.7407172322273254, Accuracy: 0.751953125\n",
      "Batch: 9, Loss: 0.7325822114944458, Accuracy: 0.767578125\n",
      "Batch: 10, Loss: 0.7142906188964844, Accuracy: 0.7431640625\n",
      "Batch: 11, Loss: 0.8607122302055359, Accuracy: 0.71484375\n",
      "Batch: 12, Loss: 0.8148546814918518, Accuracy: 0.734375\n",
      "Batch: 13, Loss: 0.647698163986206, Accuracy: 0.79296875\n",
      "Batch: 14, Loss: 0.8481985330581665, Accuracy: 0.72265625\n",
      "Batch: 15, Loss: 0.7076307535171509, Accuracy: 0.779296875\n",
      "Batch: 16, Loss: 0.7719038128852844, Accuracy: 0.7578125\n",
      "Batch: 17, Loss: 0.8159616589546204, Accuracy: 0.7275390625\n",
      "Batch: 18, Loss: 0.7896158695220947, Accuracy: 0.75\n",
      "Batch: 19, Loss: 0.8234562277793884, Accuracy: 0.748046875\n",
      "Batch: 20, Loss: 0.6890368461608887, Accuracy: 0.78125\n",
      "Batch: 21, Loss: 0.7317414283752441, Accuracy: 0.755859375\n",
      "Batch: 22, Loss: 0.8473218679428101, Accuracy: 0.7373046875\n",
      "Batch: 23, Loss: 0.8172279596328735, Accuracy: 0.732421875\n",
      "Batch: 24, Loss: 0.8148119449615479, Accuracy: 0.73046875\n",
      "Batch: 25, Loss: 0.7868130207061768, Accuracy: 0.748046875\n",
      "Batch: 26, Loss: 0.7041323184967041, Accuracy: 0.7724609375\n",
      "Batch: 29, Loss: 0.7717190384864807, Accuracy: 0.74609375\n",
      "Batch: 30, Loss: 0.6962387561798096, Accuracy: 0.783203125\n",
      "Batch: 31, Loss: 0.7079097032546997, Accuracy: 0.7646484375\n",
      "Batch: 32, Loss: 0.7048242688179016, Accuracy: 0.7529296875\n",
      "Batch: 33, Loss: 0.8620145320892334, Accuracy: 0.71875\n",
      "Batch: 34, Loss: 0.884335458278656, Accuracy: 0.7021484375\n",
      "Batch: 35, Loss: 0.8469582796096802, Accuracy: 0.7265625\n",
      "Batch: 36, Loss: 0.8525358438491821, Accuracy: 0.7197265625\n",
      "Batch: 37, Loss: 0.7632837891578674, Accuracy: 0.75\n",
      "Batch: 38, Loss: 0.811042308807373, Accuracy: 0.7158203125\n",
      "Batch: 39, Loss: 0.7862653136253357, Accuracy: 0.7412109375\n",
      "Batch: 40, Loss: 0.7761447429656982, Accuracy: 0.7431640625\n",
      "Batch: 41, Loss: 0.7387360334396362, Accuracy: 0.76171875\n",
      "Batch: 42, Loss: 0.6217266321182251, Accuracy: 0.787109375\n",
      "Batch: 43, Loss: 0.813576340675354, Accuracy: 0.7353515625\n",
      "Batch: 44, Loss: 0.7920674085617065, Accuracy: 0.7275390625\n",
      "Batch: 45, Loss: 0.7059282064437866, Accuracy: 0.7607421875\n",
      "Batch: 46, Loss: 0.6982481479644775, Accuracy: 0.76953125\n",
      "Batch: 47, Loss: 0.7462500929832458, Accuracy: 0.79296875\n",
      "Batch: 48, Loss: 0.7296509742736816, Accuracy: 0.7607421875\n",
      "Batch: 49, Loss: 0.8255491256713867, Accuracy: 0.740234375\n",
      "Batch: 50, Loss: 0.8163918256759644, Accuracy: 0.7431640625\n",
      "Batch: 51, Loss: 0.8103588223457336, Accuracy: 0.734375\n",
      "Batch: 52, Loss: 0.7903258800506592, Accuracy: 0.7421875\n",
      "Batch: 53, Loss: 0.7198399901390076, Accuracy: 0.7705078125\n",
      "Batch: 54, Loss: 0.7531336545944214, Accuracy: 0.75390625\n",
      "Batch: 55, Loss: 0.8644953370094299, Accuracy: 0.7001953125\n",
      "Batch: 56, Loss: 0.8491029739379883, Accuracy: 0.7275390625\n",
      "Batch: 57, Loss: 0.8060905933380127, Accuracy: 0.7431640625\n",
      "Batch: 58, Loss: 0.8774811625480652, Accuracy: 0.7294921875\n",
      "Batch: 59, Loss: 0.7806760668754578, Accuracy: 0.7451171875\n",
      "Batch: 60, Loss: 0.7243428826332092, Accuracy: 0.76171875\n",
      "Batch: 61, Loss: 0.8146662712097168, Accuracy: 0.732421875\n",
      "Batch: 62, Loss: 0.7632225751876831, Accuracy: 0.7412109375\n",
      "Batch: 63, Loss: 0.8193806409835815, Accuracy: 0.74609375\n",
      "Batch: 64, Loss: 0.7611775398254395, Accuracy: 0.73828125\n",
      "Batch: 65, Loss: 0.787078320980072, Accuracy: 0.7646484375\n",
      "Batch: 66, Loss: 0.7756467461585999, Accuracy: 0.744140625\n",
      "Batch: 67, Loss: 0.8712546229362488, Accuracy: 0.7333984375\n",
      "Batch: 68, Loss: 0.8844721913337708, Accuracy: 0.7138671875\n",
      "Batch: 69, Loss: 0.7994638085365295, Accuracy: 0.7255859375\n",
      "Batch: 72, Loss: 0.695249080657959, Accuracy: 0.76953125\n",
      "Batch: 73, Loss: 0.7167320847511292, Accuracy: 0.779296875\n",
      "Batch: 74, Loss: 0.7127991318702698, Accuracy: 0.7734375\n",
      "Batch: 75, Loss: 0.7103997468948364, Accuracy: 0.7607421875\n",
      "Batch: 76, Loss: 0.7776552438735962, Accuracy: 0.7431640625\n",
      "Batch: 77, Loss: 0.696820080280304, Accuracy: 0.775390625\n",
      "Batch: 78, Loss: 0.7179689407348633, Accuracy: 0.763671875\n",
      "Batch: 79, Loss: 0.6797345876693726, Accuracy: 0.7802734375\n",
      "Batch: 80, Loss: 0.7195366024971008, Accuracy: 0.767578125\n",
      "Batch: 81, Loss: 0.8422132730484009, Accuracy: 0.7177734375\n",
      "Batch: 82, Loss: 0.8188169598579407, Accuracy: 0.734375\n",
      "Batch: 83, Loss: 0.6981664896011353, Accuracy: 0.78125\n",
      "Batch: 84, Loss: 0.7505213618278503, Accuracy: 0.759765625\n",
      "Batch: 85, Loss: 0.7429294586181641, Accuracy: 0.763671875\n",
      "Batch: 86, Loss: 0.8882217407226562, Accuracy: 0.7138671875\n",
      "Batch: 87, Loss: 0.709240198135376, Accuracy: 0.76953125\n",
      "Batch: 88, Loss: 0.8177914619445801, Accuracy: 0.7470703125\n",
      "Batch: 89, Loss: 0.8100395202636719, Accuracy: 0.74609375\n",
      "Batch: 90, Loss: 0.7433849573135376, Accuracy: 0.76171875\n",
      "Batch: 91, Loss: 0.7259634733200073, Accuracy: 0.7412109375\n",
      "Batch: 92, Loss: 0.7962321043014526, Accuracy: 0.728515625\n",
      "Batch: 93, Loss: 0.7679567337036133, Accuracy: 0.7421875\n",
      "Batch: 94, Loss: 0.78347247838974, Accuracy: 0.7333984375\n",
      "Batch: 95, Loss: 0.8058183789253235, Accuracy: 0.7236328125\n",
      "Batch: 96, Loss: 0.7398567199707031, Accuracy: 0.755859375\n",
      "Batch: 97, Loss: 0.6443656086921692, Accuracy: 0.78125\n",
      "Batch: 98, Loss: 0.7249026298522949, Accuracy: 0.7724609375\n",
      "Batch: 99, Loss: 0.7461561560630798, Accuracy: 0.755859375\n",
      "Batch: 100, Loss: 0.7764692306518555, Accuracy: 0.751953125\n",
      "Batch: 101, Loss: 0.8248162269592285, Accuracy: 0.736328125\n",
      "Batch: 102, Loss: 0.7685666084289551, Accuracy: 0.74609375\n",
      "Batch: 103, Loss: 0.7990652918815613, Accuracy: 0.7578125\n",
      "Batch: 104, Loss: 0.7397925853729248, Accuracy: 0.75390625\n",
      "Batch: 105, Loss: 0.8178541660308838, Accuracy: 0.7265625\n",
      "Batch: 106, Loss: 0.6982570886611938, Accuracy: 0.7763671875\n",
      "Batch: 107, Loss: 0.7884606122970581, Accuracy: 0.748046875\n",
      "Batch: 108, Loss: 0.7609958648681641, Accuracy: 0.7490234375\n",
      "Batch: 109, Loss: 0.859386682510376, Accuracy: 0.703125\n",
      "Batch: 110, Loss: 0.7257237434387207, Accuracy: 0.755859375\n",
      "Batch: 111, Loss: 0.7996706962585449, Accuracy: 0.748046875\n",
      "Batch: 112, Loss: 0.7528703212738037, Accuracy: 0.76953125\n",
      "Batch: 113, Loss: 0.7916939854621887, Accuracy: 0.7294921875\n",
      "Batch: 116, Loss: 0.8445953726768494, Accuracy: 0.736328125\n",
      "Batch: 117, Loss: 0.8286760449409485, Accuracy: 0.7275390625\n",
      "Batch: 118, Loss: 0.6660797595977783, Accuracy: 0.8056640625\n",
      "Batch: 119, Loss: 0.6554458737373352, Accuracy: 0.783203125\n",
      "Batch: 120, Loss: 0.8083103895187378, Accuracy: 0.736328125\n",
      "Batch: 121, Loss: 0.825832188129425, Accuracy: 0.732421875\n",
      "Batch: 122, Loss: 0.7384287118911743, Accuracy: 0.763671875\n",
      "Batch: 123, Loss: 0.7429844737052917, Accuracy: 0.767578125\n",
      "Batch: 124, Loss: 0.7665247917175293, Accuracy: 0.7421875\n",
      "Batch: 125, Loss: 0.8286514282226562, Accuracy: 0.7275390625\n",
      "Batch: 126, Loss: 0.8101061582565308, Accuracy: 0.7294921875\n",
      "Batch: 127, Loss: 0.7009753584861755, Accuracy: 0.7919921875\n",
      "Batch: 128, Loss: 0.8688204288482666, Accuracy: 0.7578125\n",
      "Batch: 129, Loss: 0.7310080528259277, Accuracy: 0.779296875\n",
      "Batch: 130, Loss: 0.8661452531814575, Accuracy: 0.71875\n",
      "Batch: 131, Loss: 0.7938740849494934, Accuracy: 0.7255859375\n",
      "Batch: 132, Loss: 0.8065922856330872, Accuracy: 0.7421875\n",
      "Batch: 133, Loss: 0.7390776872634888, Accuracy: 0.7548828125\n",
      "Batch: 134, Loss: 0.801210880279541, Accuracy: 0.7333984375\n",
      "Batch: 135, Loss: 0.7231153249740601, Accuracy: 0.767578125\n",
      "Batch: 136, Loss: 0.7989509105682373, Accuracy: 0.7431640625\n",
      "Batch: 137, Loss: 0.7742495536804199, Accuracy: 0.736328125\n",
      "Batch: 138, Loss: 0.6946117877960205, Accuracy: 0.7646484375\n",
      "Batch: 139, Loss: 0.7218436002731323, Accuracy: 0.7666015625\n",
      "Batch: 140, Loss: 0.776443362236023, Accuracy: 0.734375\n",
      "Batch: 141, Loss: 0.8162746429443359, Accuracy: 0.73046875\n",
      "Batch: 142, Loss: 0.8259027004241943, Accuracy: 0.7216796875\n",
      "Batch: 143, Loss: 0.7926177382469177, Accuracy: 0.748046875\n",
      "Batch: 144, Loss: 0.7945597767829895, Accuracy: 0.7509765625\n",
      "Batch: 145, Loss: 0.746279776096344, Accuracy: 0.736328125\n",
      "Batch: 146, Loss: 0.8023712038993835, Accuracy: 0.73828125\n",
      "Batch: 147, Loss: 0.8004118204116821, Accuracy: 0.7255859375\n",
      "Batch: 148, Loss: 0.8712077140808105, Accuracy: 0.708984375\n",
      "Batch: 149, Loss: 0.789219856262207, Accuracy: 0.75\n",
      "Batch: 150, Loss: 0.7417954206466675, Accuracy: 0.765625\n",
      "Batch: 151, Loss: 0.7155449986457825, Accuracy: 0.7568359375\n",
      "Epoch 46/80\n",
      "Batch: 1, Loss: 1.003058671951294, Accuracy: 0.6806640625\n",
      "Batch: 2, Loss: 0.8297716379165649, Accuracy: 0.7216796875\n",
      "Batch: 3, Loss: 0.8000879287719727, Accuracy: 0.73046875\n",
      "Batch: 4, Loss: 0.6733287572860718, Accuracy: 0.7822265625\n",
      "Batch: 5, Loss: 0.7496188879013062, Accuracy: 0.7470703125\n",
      "Batch: 6, Loss: 0.8075185418128967, Accuracy: 0.7314453125\n",
      "Batch: 8, Loss: 0.7474979162216187, Accuracy: 0.7333984375\n",
      "Batch: 9, Loss: 0.7167601585388184, Accuracy: 0.767578125\n",
      "Batch: 10, Loss: 0.7231484651565552, Accuracy: 0.748046875\n",
      "Batch: 11, Loss: 0.8406531810760498, Accuracy: 0.716796875\n",
      "Batch: 12, Loss: 0.8246128559112549, Accuracy: 0.732421875\n",
      "Batch: 13, Loss: 0.6327350735664368, Accuracy: 0.794921875\n",
      "Batch: 14, Loss: 0.8557721376419067, Accuracy: 0.7119140625\n",
      "Batch: 15, Loss: 0.7299562692642212, Accuracy: 0.775390625\n",
      "Batch: 16, Loss: 0.747943639755249, Accuracy: 0.7568359375\n",
      "Batch: 17, Loss: 0.8121335506439209, Accuracy: 0.7265625\n",
      "Batch: 18, Loss: 0.8093032836914062, Accuracy: 0.736328125\n",
      "Batch: 19, Loss: 0.8047429323196411, Accuracy: 0.734375\n",
      "Batch: 20, Loss: 0.6837842464447021, Accuracy: 0.7890625\n",
      "Batch: 21, Loss: 0.726570725440979, Accuracy: 0.7666015625\n",
      "Batch: 22, Loss: 0.8486130833625793, Accuracy: 0.73828125\n",
      "Batch: 23, Loss: 0.7959903478622437, Accuracy: 0.7392578125\n",
      "Batch: 24, Loss: 0.802243709564209, Accuracy: 0.7314453125\n",
      "Batch: 25, Loss: 0.7484209537506104, Accuracy: 0.76171875\n",
      "Batch: 26, Loss: 0.7002654671669006, Accuracy: 0.763671875\n",
      "Batch: 27, Loss: 0.7241157293319702, Accuracy: 0.76171875\n",
      "Batch: 28, Loss: 0.7874593138694763, Accuracy: 0.7373046875\n",
      "Batch: 29, Loss: 0.7606716156005859, Accuracy: 0.7431640625\n",
      "Batch: 30, Loss: 0.6724607944488525, Accuracy: 0.7880859375\n",
      "Batch: 31, Loss: 0.7136596441268921, Accuracy: 0.7763671875\n",
      "Batch: 32, Loss: 0.720151424407959, Accuracy: 0.7509765625\n",
      "Batch: 33, Loss: 0.8531623482704163, Accuracy: 0.720703125\n",
      "Batch: 34, Loss: 0.8667728900909424, Accuracy: 0.720703125\n",
      "Batch: 35, Loss: 0.8331166505813599, Accuracy: 0.724609375\n",
      "Batch: 36, Loss: 0.8199673891067505, Accuracy: 0.736328125\n",
      "Batch: 37, Loss: 0.786381185054779, Accuracy: 0.7529296875\n",
      "Batch: 38, Loss: 0.786155104637146, Accuracy: 0.7294921875\n",
      "Batch: 39, Loss: 0.7854890823364258, Accuracy: 0.740234375\n",
      "Batch: 40, Loss: 0.7493256330490112, Accuracy: 0.7578125\n",
      "Batch: 41, Loss: 0.6917819380760193, Accuracy: 0.7744140625\n",
      "Batch: 42, Loss: 0.6073086261749268, Accuracy: 0.7939453125\n",
      "Batch: 43, Loss: 0.80405592918396, Accuracy: 0.7392578125\n",
      "Batch: 44, Loss: 0.7933162450790405, Accuracy: 0.7255859375\n",
      "Batch: 45, Loss: 0.698226809501648, Accuracy: 0.7734375\n",
      "Batch: 46, Loss: 0.7039341926574707, Accuracy: 0.7666015625\n",
      "Batch: 47, Loss: 0.7460681200027466, Accuracy: 0.7724609375\n",
      "Batch: 48, Loss: 0.7005732655525208, Accuracy: 0.771484375\n",
      "Batch: 49, Loss: 0.8172729015350342, Accuracy: 0.736328125\n",
      "Batch: 50, Loss: 0.7852979898452759, Accuracy: 0.74609375\n",
      "Batch: 51, Loss: 0.7950776815414429, Accuracy: 0.751953125\n",
      "Batch: 54, Loss: 0.7430970668792725, Accuracy: 0.7548828125\n",
      "Batch: 55, Loss: 0.8546720743179321, Accuracy: 0.712890625\n",
      "Batch: 56, Loss: 0.8603420257568359, Accuracy: 0.7138671875\n",
      "Batch: 57, Loss: 0.7968920469284058, Accuracy: 0.7373046875\n",
      "Batch: 58, Loss: 0.8608468174934387, Accuracy: 0.724609375\n",
      "Batch: 59, Loss: 0.788418173789978, Accuracy: 0.7451171875\n",
      "Batch: 60, Loss: 0.726498007774353, Accuracy: 0.759765625\n",
      "Batch: 61, Loss: 0.8015438318252563, Accuracy: 0.744140625\n",
      "Batch: 62, Loss: 0.7672387361526489, Accuracy: 0.7509765625\n",
      "Batch: 63, Loss: 0.8011647462844849, Accuracy: 0.748046875\n",
      "Batch: 64, Loss: 0.7882155179977417, Accuracy: 0.73828125\n",
      "Batch: 65, Loss: 0.7839247584342957, Accuracy: 0.751953125\n",
      "Batch: 66, Loss: 0.7734411358833313, Accuracy: 0.75390625\n",
      "Batch: 67, Loss: 0.8446004986763, Accuracy: 0.7294921875\n",
      "Batch: 68, Loss: 0.8728559017181396, Accuracy: 0.7353515625\n",
      "Batch: 69, Loss: 0.8124079704284668, Accuracy: 0.736328125\n",
      "Batch: 70, Loss: 0.762108325958252, Accuracy: 0.7568359375\n",
      "Batch: 71, Loss: 0.8116792440414429, Accuracy: 0.724609375\n",
      "Batch: 72, Loss: 0.6977676153182983, Accuracy: 0.765625\n",
      "Batch: 73, Loss: 0.7366605997085571, Accuracy: 0.7724609375\n",
      "Batch: 74, Loss: 0.6931709051132202, Accuracy: 0.783203125\n",
      "Batch: 75, Loss: 0.7045825719833374, Accuracy: 0.771484375\n",
      "Batch: 76, Loss: 0.7978109121322632, Accuracy: 0.744140625\n",
      "Batch: 77, Loss: 0.730453372001648, Accuracy: 0.7548828125\n",
      "Batch: 78, Loss: 0.7266620993614197, Accuracy: 0.7646484375\n",
      "Batch: 79, Loss: 0.6514406204223633, Accuracy: 0.791015625\n",
      "Batch: 80, Loss: 0.7283141016960144, Accuracy: 0.75\n",
      "Batch: 81, Loss: 0.8219985961914062, Accuracy: 0.720703125\n",
      "Batch: 82, Loss: 0.8055694103240967, Accuracy: 0.7177734375\n",
      "Batch: 83, Loss: 0.6511775851249695, Accuracy: 0.796875\n",
      "Batch: 84, Loss: 0.7259160280227661, Accuracy: 0.759765625\n",
      "Batch: 85, Loss: 0.7260782122612, Accuracy: 0.775390625\n",
      "Batch: 86, Loss: 0.8507568836212158, Accuracy: 0.734375\n",
      "Batch: 87, Loss: 0.7266424894332886, Accuracy: 0.7626953125\n",
      "Batch: 88, Loss: 0.8186557292938232, Accuracy: 0.736328125\n",
      "Batch: 89, Loss: 0.7837604284286499, Accuracy: 0.755859375\n",
      "Batch: 90, Loss: 0.7412137985229492, Accuracy: 0.7646484375\n",
      "Batch: 91, Loss: 0.7751463055610657, Accuracy: 0.75\n",
      "Batch: 92, Loss: 0.7893596887588501, Accuracy: 0.7373046875\n",
      "Batch: 93, Loss: 0.7522011995315552, Accuracy: 0.7548828125\n",
      "Batch: 94, Loss: 0.7515786290168762, Accuracy: 0.7421875\n",
      "Batch: 95, Loss: 0.8242876529693604, Accuracy: 0.736328125\n",
      "Batch: 96, Loss: 0.7772716283798218, Accuracy: 0.7470703125\n",
      "Batch: 97, Loss: 0.6249745488166809, Accuracy: 0.7919921875\n",
      "Batch: 98, Loss: 0.7166973352432251, Accuracy: 0.7685546875\n",
      "Batch: 99, Loss: 0.7432395815849304, Accuracy: 0.7548828125\n",
      "Batch: 100, Loss: 0.7722902894020081, Accuracy: 0.732421875\n",
      "Batch: 101, Loss: 0.8073379993438721, Accuracy: 0.740234375\n",
      "Batch: 102, Loss: 0.7514746785163879, Accuracy: 0.7548828125\n",
      "Batch: 103, Loss: 0.744892954826355, Accuracy: 0.7763671875\n",
      "Batch: 104, Loss: 0.7036815881729126, Accuracy: 0.76171875\n",
      "Batch: 105, Loss: 0.8215189576148987, Accuracy: 0.740234375\n",
      "Batch: 106, Loss: 0.7323428392410278, Accuracy: 0.759765625\n",
      "Batch: 107, Loss: 0.7750208973884583, Accuracy: 0.751953125\n",
      "Batch: 108, Loss: 0.7518969774246216, Accuracy: 0.7509765625\n",
      "Batch: 109, Loss: 0.8308670520782471, Accuracy: 0.73046875\n",
      "Batch: 110, Loss: 0.6916974186897278, Accuracy: 0.7763671875\n",
      "Batch: 111, Loss: 0.7659542560577393, Accuracy: 0.7529296875\n",
      "Batch: 112, Loss: 0.7514516115188599, Accuracy: 0.765625\n",
      "Batch: 113, Loss: 0.8023490905761719, Accuracy: 0.73828125\n",
      "Batch: 114, Loss: 0.8513888716697693, Accuracy: 0.71484375\n",
      "Batch: 115, Loss: 0.9276946783065796, Accuracy: 0.71484375\n",
      "Batch: 116, Loss: 0.8161921501159668, Accuracy: 0.736328125\n",
      "Batch: 117, Loss: 0.8061221241950989, Accuracy: 0.7470703125\n",
      "Batch: 118, Loss: 0.675459623336792, Accuracy: 0.7880859375\n",
      "Batch: 119, Loss: 0.6499803066253662, Accuracy: 0.7939453125\n",
      "Batch: 120, Loss: 0.8182096481323242, Accuracy: 0.7294921875\n",
      "Batch: 121, Loss: 0.824958324432373, Accuracy: 0.7333984375\n",
      "Batch: 122, Loss: 0.7571703195571899, Accuracy: 0.76171875\n",
      "Batch: 123, Loss: 0.7355718016624451, Accuracy: 0.7529296875\n",
      "Batch: 124, Loss: 0.798462986946106, Accuracy: 0.724609375\n",
      "Batch: 125, Loss: 0.8517903089523315, Accuracy: 0.7177734375\n",
      "Batch: 126, Loss: 0.8024196624755859, Accuracy: 0.7353515625\n",
      "Batch: 127, Loss: 0.685829758644104, Accuracy: 0.7841796875\n",
      "Batch: 128, Loss: 0.8783729672431946, Accuracy: 0.736328125\n",
      "Batch: 129, Loss: 0.701594352722168, Accuracy: 0.7900390625\n",
      "Batch: 130, Loss: 0.859614372253418, Accuracy: 0.7294921875\n",
      "Batch: 131, Loss: 0.8256900310516357, Accuracy: 0.734375\n",
      "Batch: 132, Loss: 0.8416916131973267, Accuracy: 0.7451171875\n",
      "Batch: 133, Loss: 0.7672299146652222, Accuracy: 0.74609375\n",
      "Batch: 134, Loss: 0.8398897647857666, Accuracy: 0.7177734375\n",
      "Batch: 135, Loss: 0.707416296005249, Accuracy: 0.77734375\n",
      "Batch: 136, Loss: 0.7925341129302979, Accuracy: 0.740234375\n",
      "Batch: 137, Loss: 0.7497864961624146, Accuracy: 0.734375\n",
      "Batch: 138, Loss: 0.6909658908843994, Accuracy: 0.76171875\n",
      "Batch: 139, Loss: 0.7324578762054443, Accuracy: 0.7568359375\n",
      "Batch: 140, Loss: 0.7522729635238647, Accuracy: 0.748046875\n",
      "Batch: 141, Loss: 0.788844645023346, Accuracy: 0.732421875\n",
      "Batch: 142, Loss: 0.8380874395370483, Accuracy: 0.7373046875\n",
      "Batch: 144, Loss: 0.7708132266998291, Accuracy: 0.73828125\n",
      "Batch: 145, Loss: 0.7142922878265381, Accuracy: 0.771484375\n",
      "Batch: 146, Loss: 0.8117520809173584, Accuracy: 0.732421875\n",
      "Batch: 147, Loss: 0.7986485958099365, Accuracy: 0.7421875\n",
      "Batch: 148, Loss: 0.8793351054191589, Accuracy: 0.7080078125\n",
      "Batch: 149, Loss: 0.7897104620933533, Accuracy: 0.7431640625\n",
      "Batch: 150, Loss: 0.760039210319519, Accuracy: 0.7548828125\n",
      "Batch: 151, Loss: 0.693348228931427, Accuracy: 0.7802734375\n",
      "Epoch 47/80\n",
      "Batch: 1, Loss: 1.0138728618621826, Accuracy: 0.66796875\n",
      "Batch: 2, Loss: 0.8229629993438721, Accuracy: 0.7158203125\n",
      "Batch: 3, Loss: 0.7768954038619995, Accuracy: 0.7412109375\n",
      "Batch: 4, Loss: 0.6530598402023315, Accuracy: 0.7841796875\n",
      "Batch: 5, Loss: 0.7137306928634644, Accuracy: 0.7724609375\n",
      "Batch: 6, Loss: 0.7648008465766907, Accuracy: 0.7412109375\n",
      "Batch: 7, Loss: 0.794232964515686, Accuracy: 0.73046875\n",
      "Batch: 8, Loss: 0.7500557899475098, Accuracy: 0.736328125\n",
      "Batch: 9, Loss: 0.7326227426528931, Accuracy: 0.7734375\n",
      "Batch: 10, Loss: 0.7261759042739868, Accuracy: 0.755859375\n",
      "Batch: 11, Loss: 0.8607654571533203, Accuracy: 0.7119140625\n",
      "Batch: 12, Loss: 0.8326672315597534, Accuracy: 0.7421875\n",
      "Batch: 13, Loss: 0.5966271162033081, Accuracy: 0.8076171875\n",
      "Batch: 14, Loss: 0.7975596189498901, Accuracy: 0.7421875\n",
      "Batch: 15, Loss: 0.7140758037567139, Accuracy: 0.7666015625\n",
      "Batch: 16, Loss: 0.7724878191947937, Accuracy: 0.767578125\n",
      "Batch: 17, Loss: 0.7927898168563843, Accuracy: 0.7451171875\n",
      "Batch: 18, Loss: 0.7760316133499146, Accuracy: 0.7529296875\n",
      "Batch: 19, Loss: 0.7928519248962402, Accuracy: 0.7392578125\n",
      "Batch: 20, Loss: 0.6821761727333069, Accuracy: 0.7919921875\n",
      "Batch: 21, Loss: 0.699108362197876, Accuracy: 0.7802734375\n",
      "Batch: 22, Loss: 0.8407394289970398, Accuracy: 0.748046875\n",
      "Batch: 23, Loss: 0.8021420240402222, Accuracy: 0.720703125\n",
      "Batch: 24, Loss: 0.8396081924438477, Accuracy: 0.720703125\n",
      "Batch: 25, Loss: 0.7505849599838257, Accuracy: 0.759765625\n",
      "Batch: 26, Loss: 0.681085467338562, Accuracy: 0.78125\n",
      "Batch: 27, Loss: 0.7066894769668579, Accuracy: 0.75\n",
      "Batch: 28, Loss: 0.7762950658798218, Accuracy: 0.744140625\n",
      "Batch: 29, Loss: 0.7550297379493713, Accuracy: 0.7490234375\n",
      "Batch: 30, Loss: 0.7018550634384155, Accuracy: 0.783203125\n",
      "Batch: 31, Loss: 0.6822189688682556, Accuracy: 0.7822265625\n",
      "Batch: 32, Loss: 0.7171635627746582, Accuracy: 0.771484375\n",
      "Batch: 33, Loss: 0.8508141040802002, Accuracy: 0.7236328125\n",
      "Batch: 34, Loss: 0.8598854541778564, Accuracy: 0.7333984375\n",
      "Batch: 35, Loss: 0.8149749040603638, Accuracy: 0.7373046875\n",
      "Batch: 37, Loss: 0.7704200148582458, Accuracy: 0.7431640625\n",
      "Batch: 38, Loss: 0.8022701740264893, Accuracy: 0.7216796875\n",
      "Batch: 39, Loss: 0.7626059651374817, Accuracy: 0.7607421875\n",
      "Batch: 40, Loss: 0.7353657484054565, Accuracy: 0.7490234375\n",
      "Batch: 41, Loss: 0.7088890075683594, Accuracy: 0.7607421875\n",
      "Batch: 42, Loss: 0.5744566917419434, Accuracy: 0.8115234375\n",
      "Batch: 43, Loss: 0.7860671281814575, Accuracy: 0.728515625\n",
      "Batch: 44, Loss: 0.7851932048797607, Accuracy: 0.7255859375\n",
      "Batch: 45, Loss: 0.6820007562637329, Accuracy: 0.7783203125\n",
      "Batch: 46, Loss: 0.6925407648086548, Accuracy: 0.76953125\n",
      "Batch: 47, Loss: 0.7490418553352356, Accuracy: 0.78125\n",
      "Batch: 48, Loss: 0.6907786130905151, Accuracy: 0.7724609375\n",
      "Batch: 49, Loss: 0.7971255779266357, Accuracy: 0.7353515625\n",
      "Batch: 50, Loss: 0.7676377296447754, Accuracy: 0.7470703125\n",
      "Batch: 51, Loss: 0.8028787970542908, Accuracy: 0.7392578125\n",
      "Batch: 52, Loss: 0.7895561456680298, Accuracy: 0.734375\n",
      "Batch: 53, Loss: 0.6900861859321594, Accuracy: 0.78125\n",
      "Batch: 54, Loss: 0.7496470212936401, Accuracy: 0.759765625\n",
      "Batch: 55, Loss: 0.8597533702850342, Accuracy: 0.7119140625\n",
      "Batch: 56, Loss: 0.8567423820495605, Accuracy: 0.701171875\n",
      "Batch: 57, Loss: 0.7903151512145996, Accuracy: 0.736328125\n",
      "Batch: 58, Loss: 0.8765488266944885, Accuracy: 0.720703125\n",
      "Batch: 59, Loss: 0.7510360479354858, Accuracy: 0.7509765625\n",
      "Batch: 60, Loss: 0.71943598985672, Accuracy: 0.7666015625\n",
      "Batch: 61, Loss: 0.8117755055427551, Accuracy: 0.7158203125\n",
      "Batch: 62, Loss: 0.7296642065048218, Accuracy: 0.775390625\n",
      "Batch: 63, Loss: 0.7864733934402466, Accuracy: 0.7509765625\n",
      "Batch: 64, Loss: 0.7767032384872437, Accuracy: 0.7392578125\n",
      "Batch: 65, Loss: 0.7954938411712646, Accuracy: 0.7607421875\n",
      "Batch: 66, Loss: 0.7659672498703003, Accuracy: 0.74609375\n",
      "Batch: 67, Loss: 0.8450685739517212, Accuracy: 0.7255859375\n",
      "Batch: 68, Loss: 0.904415488243103, Accuracy: 0.7255859375\n",
      "Batch: 69, Loss: 0.7766488790512085, Accuracy: 0.7373046875\n",
      "Batch: 70, Loss: 0.74761962890625, Accuracy: 0.76171875\n",
      "Batch: 71, Loss: 0.7778418064117432, Accuracy: 0.74609375\n",
      "Batch: 72, Loss: 0.6756350994110107, Accuracy: 0.7568359375\n",
      "Batch: 73, Loss: 0.6997222304344177, Accuracy: 0.7734375\n",
      "Batch: 74, Loss: 0.7054417729377747, Accuracy: 0.78125\n",
      "Batch: 75, Loss: 0.6932806968688965, Accuracy: 0.7763671875\n",
      "Batch: 76, Loss: 0.7889809012413025, Accuracy: 0.7470703125\n",
      "Batch: 77, Loss: 0.703626275062561, Accuracy: 0.7744140625\n",
      "Batch: 81, Loss: 0.8190191984176636, Accuracy: 0.71484375\n",
      "Batch: 82, Loss: 0.7962332367897034, Accuracy: 0.7294921875\n",
      "Batch: 83, Loss: 0.6870370507240295, Accuracy: 0.775390625\n",
      "Batch: 84, Loss: 0.740995466709137, Accuracy: 0.759765625\n",
      "Batch: 85, Loss: 0.7246890664100647, Accuracy: 0.7724609375\n",
      "Batch: 86, Loss: 0.8706259727478027, Accuracy: 0.7265625\n",
      "Batch: 87, Loss: 0.7365477085113525, Accuracy: 0.7666015625\n",
      "Batch: 88, Loss: 0.8112107515335083, Accuracy: 0.751953125\n",
      "Batch: 89, Loss: 0.7607218027114868, Accuracy: 0.7587890625\n",
      "Batch: 90, Loss: 0.7313860654830933, Accuracy: 0.765625\n",
      "Batch: 91, Loss: 0.7522721290588379, Accuracy: 0.7529296875\n",
      "Batch: 92, Loss: 0.7942179441452026, Accuracy: 0.732421875\n",
      "Batch: 93, Loss: 0.7520422339439392, Accuracy: 0.7392578125\n",
      "Batch: 94, Loss: 0.7666292190551758, Accuracy: 0.744140625\n",
      "Batch: 95, Loss: 0.8030593395233154, Accuracy: 0.7255859375\n",
      "Batch: 96, Loss: 0.7715353965759277, Accuracy: 0.736328125\n",
      "Batch: 97, Loss: 0.6276883482933044, Accuracy: 0.7978515625\n",
      "Batch: 98, Loss: 0.6950811147689819, Accuracy: 0.7919921875\n",
      "Batch: 99, Loss: 0.7514915466308594, Accuracy: 0.748046875\n",
      "Batch: 100, Loss: 0.7760759592056274, Accuracy: 0.75\n",
      "Batch: 101, Loss: 0.790635347366333, Accuracy: 0.7353515625\n",
      "Batch: 102, Loss: 0.778392493724823, Accuracy: 0.7587890625\n",
      "Batch: 103, Loss: 0.7731987833976746, Accuracy: 0.7587890625\n",
      "Batch: 104, Loss: 0.7131730318069458, Accuracy: 0.75390625\n",
      "Batch: 105, Loss: 0.7990661859512329, Accuracy: 0.7275390625\n",
      "Batch: 106, Loss: 0.7241426706314087, Accuracy: 0.7685546875\n",
      "Batch: 107, Loss: 0.7848939895629883, Accuracy: 0.7451171875\n",
      "Batch: 108, Loss: 0.7530004382133484, Accuracy: 0.73828125\n",
      "Batch: 109, Loss: 0.8202978372573853, Accuracy: 0.7177734375\n",
      "Batch: 110, Loss: 0.7035512924194336, Accuracy: 0.771484375\n",
      "Batch: 111, Loss: 0.8239036202430725, Accuracy: 0.73828125\n",
      "Batch: 112, Loss: 0.7749729156494141, Accuracy: 0.75390625\n",
      "Batch: 113, Loss: 0.7868511080741882, Accuracy: 0.7470703125\n",
      "Batch: 114, Loss: 0.8278361558914185, Accuracy: 0.732421875\n",
      "Batch: 115, Loss: 0.879571795463562, Accuracy: 0.7177734375\n",
      "Batch: 116, Loss: 0.8245758414268494, Accuracy: 0.7353515625\n",
      "Batch: 117, Loss: 0.8126442432403564, Accuracy: 0.7392578125\n",
      "Batch: 118, Loss: 0.6908999681472778, Accuracy: 0.783203125\n",
      "Batch: 119, Loss: 0.6459478735923767, Accuracy: 0.794921875\n",
      "Batch: 120, Loss: 0.789389431476593, Accuracy: 0.751953125\n",
      "Batch: 121, Loss: 0.7943090200424194, Accuracy: 0.75390625\n",
      "Batch: 124, Loss: 0.7554985284805298, Accuracy: 0.751953125\n",
      "Batch: 125, Loss: 0.8244228959083557, Accuracy: 0.728515625\n",
      "Batch: 126, Loss: 0.8012774586677551, Accuracy: 0.734375\n",
      "Batch: 127, Loss: 0.6720260381698608, Accuracy: 0.787109375\n",
      "Batch: 128, Loss: 0.8708458542823792, Accuracy: 0.7470703125\n",
      "Batch: 129, Loss: 0.7201620936393738, Accuracy: 0.7548828125\n",
      "Batch: 130, Loss: 0.8698477745056152, Accuracy: 0.7119140625\n",
      "Batch: 131, Loss: 0.7977885603904724, Accuracy: 0.740234375\n",
      "Batch: 132, Loss: 0.819879412651062, Accuracy: 0.7412109375\n",
      "Batch: 133, Loss: 0.7395790815353394, Accuracy: 0.7548828125\n",
      "Batch: 134, Loss: 0.817725419998169, Accuracy: 0.7255859375\n",
      "Batch: 135, Loss: 0.7339146137237549, Accuracy: 0.7587890625\n",
      "Batch: 136, Loss: 0.788731575012207, Accuracy: 0.7607421875\n",
      "Batch: 137, Loss: 0.7715829610824585, Accuracy: 0.728515625\n",
      "Batch: 138, Loss: 0.6726945638656616, Accuracy: 0.779296875\n",
      "Batch: 139, Loss: 0.7309544086456299, Accuracy: 0.74609375\n",
      "Batch: 140, Loss: 0.7201220989227295, Accuracy: 0.763671875\n",
      "Batch: 141, Loss: 0.8056025505065918, Accuracy: 0.7421875\n",
      "Batch: 142, Loss: 0.8154550790786743, Accuracy: 0.7412109375\n",
      "Batch: 143, Loss: 0.7733356952667236, Accuracy: 0.74609375\n",
      "Batch: 144, Loss: 0.7638381719589233, Accuracy: 0.7568359375\n",
      "Batch: 145, Loss: 0.7144650220870972, Accuracy: 0.740234375\n",
      "Batch: 146, Loss: 0.7896441221237183, Accuracy: 0.7470703125\n",
      "Batch: 147, Loss: 0.8018590211868286, Accuracy: 0.7333984375\n",
      "Batch: 148, Loss: 0.8669506907463074, Accuracy: 0.7138671875\n",
      "Batch: 149, Loss: 0.7443238496780396, Accuracy: 0.7578125\n",
      "Batch: 150, Loss: 0.7470920085906982, Accuracy: 0.7529296875\n",
      "Batch: 151, Loss: 0.6667872667312622, Accuracy: 0.783203125\n",
      "Epoch 48/80\n",
      "Batch: 1, Loss: 0.9971650838851929, Accuracy: 0.6865234375\n",
      "Batch: 2, Loss: 0.8368703126907349, Accuracy: 0.708984375\n",
      "Batch: 3, Loss: 0.7397985458374023, Accuracy: 0.75390625\n",
      "Batch: 4, Loss: 0.7037753462791443, Accuracy: 0.7763671875\n",
      "Batch: 5, Loss: 0.7148246765136719, Accuracy: 0.7724609375\n",
      "Batch: 6, Loss: 0.7809906601905823, Accuracy: 0.72265625\n",
      "Batch: 7, Loss: 0.7976380586624146, Accuracy: 0.7421875\n",
      "Batch: 8, Loss: 0.741041362285614, Accuracy: 0.75390625\n",
      "Batch: 9, Loss: 0.7063215970993042, Accuracy: 0.7763671875\n",
      "Batch: 10, Loss: 0.6946731805801392, Accuracy: 0.7724609375\n",
      "Batch: 11, Loss: 0.8475524187088013, Accuracy: 0.716796875\n",
      "Batch: 12, Loss: 0.847558856010437, Accuracy: 0.7333984375\n",
      "Batch: 13, Loss: 0.6419721841812134, Accuracy: 0.78125\n",
      "Batch: 15, Loss: 0.7404755353927612, Accuracy: 0.763671875\n",
      "Batch: 16, Loss: 0.7625857591629028, Accuracy: 0.7607421875\n",
      "Batch: 17, Loss: 0.792798638343811, Accuracy: 0.75390625\n",
      "Batch: 18, Loss: 0.792471170425415, Accuracy: 0.7451171875\n",
      "Batch: 19, Loss: 0.8103982210159302, Accuracy: 0.74609375\n",
      "Batch: 20, Loss: 0.694572925567627, Accuracy: 0.7822265625\n",
      "Batch: 21, Loss: 0.724033772945404, Accuracy: 0.7666015625\n",
      "Batch: 22, Loss: 0.8567801713943481, Accuracy: 0.7412109375\n",
      "Batch: 23, Loss: 0.8032814264297485, Accuracy: 0.7294921875\n",
      "Batch: 24, Loss: 0.7978827357292175, Accuracy: 0.7294921875\n",
      "Batch: 25, Loss: 0.774338960647583, Accuracy: 0.7509765625\n",
      "Batch: 26, Loss: 0.6526522040367126, Accuracy: 0.7783203125\n",
      "Batch: 27, Loss: 0.7084441781044006, Accuracy: 0.7548828125\n",
      "Batch: 28, Loss: 0.7554507851600647, Accuracy: 0.7646484375\n",
      "Batch: 29, Loss: 0.7214193344116211, Accuracy: 0.7705078125\n",
      "Batch: 30, Loss: 0.6807266473770142, Accuracy: 0.806640625\n",
      "Batch: 31, Loss: 0.6944865584373474, Accuracy: 0.7763671875\n",
      "Batch: 32, Loss: 0.6926021575927734, Accuracy: 0.767578125\n",
      "Batch: 33, Loss: 0.8190382719039917, Accuracy: 0.7373046875\n",
      "Batch: 34, Loss: 0.8476107120513916, Accuracy: 0.7216796875\n",
      "Batch: 35, Loss: 0.7988136410713196, Accuracy: 0.7421875\n",
      "Batch: 36, Loss: 0.8288646936416626, Accuracy: 0.734375\n",
      "Batch: 37, Loss: 0.7592260837554932, Accuracy: 0.7470703125\n",
      "Batch: 38, Loss: 0.7552807331085205, Accuracy: 0.7431640625\n",
      "Batch: 39, Loss: 0.7659409046173096, Accuracy: 0.751953125\n",
      "Batch: 40, Loss: 0.7294867038726807, Accuracy: 0.771484375\n",
      "Batch: 41, Loss: 0.7202603816986084, Accuracy: 0.7607421875\n",
      "Batch: 42, Loss: 0.5987605452537537, Accuracy: 0.7958984375\n",
      "Batch: 43, Loss: 0.7831324338912964, Accuracy: 0.7216796875\n",
      "Batch: 44, Loss: 0.7900639772415161, Accuracy: 0.7470703125\n",
      "Batch: 45, Loss: 0.6787452101707458, Accuracy: 0.771484375\n",
      "Batch: 46, Loss: 0.6804238557815552, Accuracy: 0.7763671875\n",
      "Batch: 47, Loss: 0.7321105003356934, Accuracy: 0.7734375\n",
      "Batch: 48, Loss: 0.6741815805435181, Accuracy: 0.7783203125\n",
      "Batch: 49, Loss: 0.8054203391075134, Accuracy: 0.7421875\n",
      "Batch: 50, Loss: 0.7968818545341492, Accuracy: 0.7490234375\n",
      "Batch: 51, Loss: 0.7971426248550415, Accuracy: 0.75\n",
      "Batch: 52, Loss: 0.7990744113922119, Accuracy: 0.75\n",
      "Batch: 53, Loss: 0.6823201179504395, Accuracy: 0.775390625\n",
      "Batch: 54, Loss: 0.7140282988548279, Accuracy: 0.7646484375\n",
      "Batch: 55, Loss: 0.8505407571792603, Accuracy: 0.720703125\n",
      "Batch: 56, Loss: 0.8437256217002869, Accuracy: 0.7138671875\n",
      "Batch: 58, Loss: 0.851125180721283, Accuracy: 0.7236328125\n",
      "Batch: 59, Loss: 0.7631680369377136, Accuracy: 0.74609375\n",
      "Batch: 60, Loss: 0.7165507674217224, Accuracy: 0.775390625\n",
      "Batch: 61, Loss: 0.8104913234710693, Accuracy: 0.74609375\n",
      "Batch: 62, Loss: 0.7514316439628601, Accuracy: 0.748046875\n",
      "Batch: 63, Loss: 0.7676995992660522, Accuracy: 0.7490234375\n",
      "Batch: 64, Loss: 0.768486499786377, Accuracy: 0.7509765625\n",
      "Batch: 65, Loss: 0.8037172555923462, Accuracy: 0.74609375\n",
      "Batch: 66, Loss: 0.7712857127189636, Accuracy: 0.75390625\n",
      "Batch: 67, Loss: 0.8411444425582886, Accuracy: 0.7431640625\n",
      "Batch: 68, Loss: 0.8616341352462769, Accuracy: 0.7353515625\n",
      "Batch: 69, Loss: 0.7596979141235352, Accuracy: 0.7666015625\n",
      "Batch: 70, Loss: 0.7285181879997253, Accuracy: 0.7626953125\n",
      "Batch: 71, Loss: 0.8054518699645996, Accuracy: 0.71875\n",
      "Batch: 72, Loss: 0.6684737205505371, Accuracy: 0.7822265625\n",
      "Batch: 73, Loss: 0.7163635492324829, Accuracy: 0.7587890625\n",
      "Batch: 74, Loss: 0.670586884021759, Accuracy: 0.7900390625\n",
      "Batch: 75, Loss: 0.7007761001586914, Accuracy: 0.771484375\n",
      "Batch: 76, Loss: 0.7904083728790283, Accuracy: 0.734375\n",
      "Batch: 77, Loss: 0.6990493535995483, Accuracy: 0.767578125\n",
      "Batch: 78, Loss: 0.7121927738189697, Accuracy: 0.7734375\n",
      "Batch: 79, Loss: 0.672122061252594, Accuracy: 0.7890625\n",
      "Batch: 80, Loss: 0.7221575975418091, Accuracy: 0.7646484375\n",
      "Batch: 81, Loss: 0.8341007232666016, Accuracy: 0.7080078125\n",
      "Batch: 82, Loss: 0.7903188467025757, Accuracy: 0.74609375\n",
      "Batch: 83, Loss: 0.6619033813476562, Accuracy: 0.798828125\n",
      "Batch: 84, Loss: 0.7239686250686646, Accuracy: 0.765625\n",
      "Batch: 85, Loss: 0.7400115728378296, Accuracy: 0.771484375\n",
      "Batch: 86, Loss: 0.884913444519043, Accuracy: 0.7275390625\n",
      "Batch: 87, Loss: 0.7224125862121582, Accuracy: 0.759765625\n",
      "Batch: 88, Loss: 0.806992769241333, Accuracy: 0.7568359375\n",
      "Batch: 89, Loss: 0.7681961059570312, Accuracy: 0.755859375\n",
      "Batch: 90, Loss: 0.7133874893188477, Accuracy: 0.7666015625\n",
      "Batch: 91, Loss: 0.7695885300636292, Accuracy: 0.7451171875\n",
      "Batch: 92, Loss: 0.7367760539054871, Accuracy: 0.755859375\n",
      "Batch: 93, Loss: 0.7456023693084717, Accuracy: 0.75390625\n",
      "Batch: 94, Loss: 0.8014124631881714, Accuracy: 0.736328125\n",
      "Batch: 95, Loss: 0.7872101068496704, Accuracy: 0.7177734375\n",
      "Batch: 96, Loss: 0.7248567342758179, Accuracy: 0.7626953125\n",
      "Batch: 97, Loss: 0.6316313743591309, Accuracy: 0.783203125\n",
      "Batch: 98, Loss: 0.7014327645301819, Accuracy: 0.77734375\n",
      "Batch: 99, Loss: 0.7182585000991821, Accuracy: 0.7626953125\n",
      "Batch: 100, Loss: 0.7698109149932861, Accuracy: 0.7353515625\n",
      "Batch: 101, Loss: 0.8077261447906494, Accuracy: 0.734375\n",
      "Batch: 102, Loss: 0.7569066286087036, Accuracy: 0.7490234375\n",
      "Batch: 103, Loss: 0.7699974775314331, Accuracy: 0.76171875\n",
      "Batch: 104, Loss: 0.7048304677009583, Accuracy: 0.765625\n",
      "Batch: 105, Loss: 0.7818894386291504, Accuracy: 0.7470703125\n",
      "Batch: 106, Loss: 0.7327051162719727, Accuracy: 0.765625\n",
      "Batch: 107, Loss: 0.7629228234291077, Accuracy: 0.7685546875\n",
      "Batch: 108, Loss: 0.7373950481414795, Accuracy: 0.7548828125\n",
      "Batch: 109, Loss: 0.8137181401252747, Accuracy: 0.71484375\n",
      "Batch: 110, Loss: 0.6974050998687744, Accuracy: 0.7734375\n",
      "Batch: 111, Loss: 0.7839134931564331, Accuracy: 0.74609375\n",
      "Batch: 112, Loss: 0.7516674995422363, Accuracy: 0.7626953125\n",
      "Batch: 113, Loss: 0.7785243988037109, Accuracy: 0.744140625\n",
      "Batch: 114, Loss: 0.8421748280525208, Accuracy: 0.7275390625\n",
      "Batch: 115, Loss: 0.8946313858032227, Accuracy: 0.720703125\n",
      "Batch: 116, Loss: 0.8306406736373901, Accuracy: 0.7333984375\n",
      "Batch: 117, Loss: 0.8075258731842041, Accuracy: 0.74609375\n",
      "Batch: 118, Loss: 0.6321808099746704, Accuracy: 0.8017578125\n",
      "Batch: 119, Loss: 0.6383931636810303, Accuracy: 0.79296875\n",
      "Batch: 120, Loss: 0.8203853368759155, Accuracy: 0.7412109375\n",
      "Batch: 121, Loss: 0.798650860786438, Accuracy: 0.744140625\n",
      "Batch: 122, Loss: 0.7445070743560791, Accuracy: 0.763671875\n",
      "Batch: 123, Loss: 0.7107053995132446, Accuracy: 0.7470703125\n",
      "Batch: 124, Loss: 0.73829185962677, Accuracy: 0.7548828125\n",
      "Batch: 125, Loss: 0.8030163049697876, Accuracy: 0.736328125\n",
      "Batch: 126, Loss: 0.810226321220398, Accuracy: 0.7431640625\n",
      "Batch: 127, Loss: 0.6528439521789551, Accuracy: 0.7939453125\n",
      "Batch: 128, Loss: 0.8246932029724121, Accuracy: 0.7568359375\n",
      "Batch: 129, Loss: 0.6947290301322937, Accuracy: 0.76171875\n",
      "Batch: 130, Loss: 0.8602066040039062, Accuracy: 0.7333984375\n",
      "Batch: 131, Loss: 0.785515546798706, Accuracy: 0.740234375\n",
      "Batch: 132, Loss: 0.8188841342926025, Accuracy: 0.7451171875\n",
      "Batch: 133, Loss: 0.7358095645904541, Accuracy: 0.7646484375\n",
      "Batch: 134, Loss: 0.8033199310302734, Accuracy: 0.724609375\n",
      "Batch: 135, Loss: 0.7137072086334229, Accuracy: 0.7724609375\n",
      "Batch: 136, Loss: 0.75311279296875, Accuracy: 0.75\n",
      "Batch: 137, Loss: 0.7828803658485413, Accuracy: 0.7392578125\n",
      "Batch: 138, Loss: 0.6746487617492676, Accuracy: 0.783203125\n",
      "Batch: 139, Loss: 0.7097330093383789, Accuracy: 0.765625\n",
      "Batch: 140, Loss: 0.7471238374710083, Accuracy: 0.76171875\n",
      "Batch: 141, Loss: 0.8218642473220825, Accuracy: 0.7353515625\n",
      "Batch: 142, Loss: 0.8047527074813843, Accuracy: 0.736328125\n",
      "Batch: 143, Loss: 0.7710427045822144, Accuracy: 0.75\n",
      "Batch: 144, Loss: 0.7554494142532349, Accuracy: 0.7412109375\n",
      "Batch: 145, Loss: 0.7466814517974854, Accuracy: 0.740234375\n",
      "Batch: 146, Loss: 0.7644113302230835, Accuracy: 0.755859375\n",
      "Batch: 147, Loss: 0.7709871530532837, Accuracy: 0.7451171875\n",
      "Batch: 148, Loss: 0.8774654865264893, Accuracy: 0.7001953125\n",
      "Batch: 149, Loss: 0.7552950382232666, Accuracy: 0.751953125\n",
      "Batch: 150, Loss: 0.7534691095352173, Accuracy: 0.7666015625\n",
      "Batch: 151, Loss: 0.6829760074615479, Accuracy: 0.7734375\n",
      "Epoch 49/80\n",
      "Batch: 1, Loss: 1.019901990890503, Accuracy: 0.6669921875\n",
      "Batch: 2, Loss: 0.8276856541633606, Accuracy: 0.7197265625\n",
      "Batch: 3, Loss: 0.7498810291290283, Accuracy: 0.7412109375\n",
      "Batch: 4, Loss: 0.6596959233283997, Accuracy: 0.7958984375\n",
      "Batch: 5, Loss: 0.714148223400116, Accuracy: 0.78515625\n",
      "Batch: 6, Loss: 0.7965319156646729, Accuracy: 0.740234375\n",
      "Batch: 7, Loss: 0.774015486240387, Accuracy: 0.7275390625\n",
      "Batch: 8, Loss: 0.7361736297607422, Accuracy: 0.7548828125\n",
      "Batch: 9, Loss: 0.7116717100143433, Accuracy: 0.76953125\n",
      "Batch: 10, Loss: 0.6808960437774658, Accuracy: 0.7724609375\n",
      "Batch: 11, Loss: 0.8523367643356323, Accuracy: 0.708984375\n",
      "Batch: 12, Loss: 0.8195708990097046, Accuracy: 0.7421875\n",
      "Batch: 13, Loss: 0.6281064748764038, Accuracy: 0.7841796875\n",
      "Batch: 14, Loss: 0.83138108253479, Accuracy: 0.71875\n",
      "Batch: 15, Loss: 0.6800801753997803, Accuracy: 0.765625\n",
      "Batch: 16, Loss: 0.7646811604499817, Accuracy: 0.775390625\n",
      "Batch: 17, Loss: 0.7953127026557922, Accuracy: 0.7421875\n",
      "Batch: 18, Loss: 0.7553619146347046, Accuracy: 0.75390625\n",
      "Batch: 19, Loss: 0.7869222164154053, Accuracy: 0.759765625\n",
      "Batch: 20, Loss: 0.6798436045646667, Accuracy: 0.7802734375\n",
      "Batch: 21, Loss: 0.700119137763977, Accuracy: 0.7734375\n",
      "Batch: 22, Loss: 0.8330246210098267, Accuracy: 0.7353515625\n",
      "Batch: 23, Loss: 0.8167961835861206, Accuracy: 0.744140625\n",
      "Batch: 24, Loss: 0.7906535863876343, Accuracy: 0.7333984375\n",
      "Batch: 25, Loss: 0.7463147640228271, Accuracy: 0.751953125\n",
      "Batch: 26, Loss: 0.6681768894195557, Accuracy: 0.7841796875\n",
      "Batch: 27, Loss: 0.6964719891548157, Accuracy: 0.765625\n",
      "Batch: 28, Loss: 0.7793888449668884, Accuracy: 0.7412109375\n",
      "Batch: 29, Loss: 0.7277700901031494, Accuracy: 0.76953125\n",
      "Batch: 30, Loss: 0.6547158360481262, Accuracy: 0.7822265625\n",
      "Batch: 31, Loss: 0.6962281465530396, Accuracy: 0.76953125\n",
      "Batch: 32, Loss: 0.6982736587524414, Accuracy: 0.7802734375\n",
      "Batch: 33, Loss: 0.8241214752197266, Accuracy: 0.7314453125\n",
      "Batch: 34, Loss: 0.8337379693984985, Accuracy: 0.720703125\n",
      "Batch: 35, Loss: 0.8089861273765564, Accuracy: 0.7529296875\n",
      "Batch: 36, Loss: 0.8059008121490479, Accuracy: 0.748046875\n",
      "Batch: 37, Loss: 0.7602724432945251, Accuracy: 0.75390625\n",
      "Batch: 38, Loss: 0.7801206111907959, Accuracy: 0.73828125\n",
      "Batch: 39, Loss: 0.7618721127510071, Accuracy: 0.7470703125\n",
      "Batch: 40, Loss: 0.734015703201294, Accuracy: 0.76953125\n",
      "Batch: 41, Loss: 0.7028520107269287, Accuracy: 0.767578125\n",
      "Batch: 42, Loss: 0.5737277269363403, Accuracy: 0.8037109375\n",
      "Batch: 43, Loss: 0.7720653414726257, Accuracy: 0.736328125\n",
      "Batch: 44, Loss: 0.7751543521881104, Accuracy: 0.7490234375\n",
      "Batch: 45, Loss: 0.675682783126831, Accuracy: 0.77734375\n",
      "Batch: 48, Loss: 0.701984167098999, Accuracy: 0.7734375\n",
      "Batch: 49, Loss: 0.7947607040405273, Accuracy: 0.7509765625\n",
      "Batch: 50, Loss: 0.7954739332199097, Accuracy: 0.744140625\n",
      "Batch: 51, Loss: 0.775297999382019, Accuracy: 0.744140625\n",
      "Batch: 52, Loss: 0.7721556425094604, Accuracy: 0.7470703125\n",
      "Batch: 53, Loss: 0.690676212310791, Accuracy: 0.765625\n",
      "Batch: 54, Loss: 0.7567213773727417, Accuracy: 0.7392578125\n",
      "Batch: 55, Loss: 0.8376779556274414, Accuracy: 0.7275390625\n",
      "Batch: 56, Loss: 0.8376122713088989, Accuracy: 0.7294921875\n",
      "Batch: 57, Loss: 0.7832434177398682, Accuracy: 0.7451171875\n",
      "Batch: 58, Loss: 0.8459649085998535, Accuracy: 0.71875\n",
      "Batch: 59, Loss: 0.739856481552124, Accuracy: 0.7587890625\n",
      "Batch: 60, Loss: 0.7045578956604004, Accuracy: 0.77734375\n",
      "Batch: 61, Loss: 0.793063223361969, Accuracy: 0.7451171875\n",
      "Batch: 62, Loss: 0.7230435609817505, Accuracy: 0.767578125\n",
      "Batch: 63, Loss: 0.775436520576477, Accuracy: 0.75390625\n",
      "Batch: 64, Loss: 0.7892336845397949, Accuracy: 0.72265625\n",
      "Batch: 65, Loss: 0.7752399444580078, Accuracy: 0.7529296875\n",
      "Batch: 66, Loss: 0.7648794651031494, Accuracy: 0.7568359375\n",
      "Batch: 67, Loss: 0.8383210897445679, Accuracy: 0.736328125\n",
      "Batch: 68, Loss: 0.8729937076568604, Accuracy: 0.72265625\n",
      "Batch: 69, Loss: 0.7654882669448853, Accuracy: 0.75\n",
      "Batch: 70, Loss: 0.7257975339889526, Accuracy: 0.7783203125\n",
      "Batch: 71, Loss: 0.7997220158576965, Accuracy: 0.7333984375\n",
      "Batch: 72, Loss: 0.6739094257354736, Accuracy: 0.7802734375\n",
      "Batch: 73, Loss: 0.704941987991333, Accuracy: 0.77734375\n",
      "Batch: 74, Loss: 0.6789106130599976, Accuracy: 0.787109375\n",
      "Batch: 75, Loss: 0.7023456692695618, Accuracy: 0.7626953125\n",
      "Batch: 76, Loss: 0.7714382410049438, Accuracy: 0.7490234375\n",
      "Batch: 77, Loss: 0.7073878049850464, Accuracy: 0.763671875\n",
      "Batch: 78, Loss: 0.7113264799118042, Accuracy: 0.779296875\n",
      "Batch: 79, Loss: 0.6368229985237122, Accuracy: 0.8076171875\n",
      "Batch: 80, Loss: 0.7239116430282593, Accuracy: 0.763671875\n",
      "Batch: 81, Loss: 0.8238229751586914, Accuracy: 0.720703125\n",
      "Batch: 82, Loss: 0.7709259986877441, Accuracy: 0.73828125\n",
      "Batch: 83, Loss: 0.6654047966003418, Accuracy: 0.79296875\n",
      "Batch: 84, Loss: 0.7277930378913879, Accuracy: 0.7607421875\n",
      "Batch: 85, Loss: 0.7267777919769287, Accuracy: 0.7783203125\n",
      "Batch: 86, Loss: 0.8706693053245544, Accuracy: 0.7255859375\n",
      "Batch: 87, Loss: 0.7243438959121704, Accuracy: 0.7568359375\n",
      "Batch: 88, Loss: 0.8107143044471741, Accuracy: 0.7548828125\n",
      "Batch: 89, Loss: 0.7835198640823364, Accuracy: 0.75390625\n",
      "Batch: 90, Loss: 0.7122201919555664, Accuracy: 0.7802734375\n",
      "Batch: 91, Loss: 0.7531836032867432, Accuracy: 0.7607421875\n",
      "Batch: 92, Loss: 0.7509628534317017, Accuracy: 0.7490234375\n",
      "Batch: 93, Loss: 0.7370269298553467, Accuracy: 0.7607421875\n",
      "Batch: 94, Loss: 0.7779684066772461, Accuracy: 0.73828125\n",
      "Batch: 95, Loss: 0.7965949177742004, Accuracy: 0.728515625\n",
      "Batch: 96, Loss: 0.728011965751648, Accuracy: 0.759765625\n",
      "Batch: 97, Loss: 0.6241947412490845, Accuracy: 0.79296875\n",
      "Batch: 98, Loss: 0.6967593431472778, Accuracy: 0.7744140625\n",
      "Batch: 99, Loss: 0.7236232757568359, Accuracy: 0.763671875\n",
      "Batch: 100, Loss: 0.7416726350784302, Accuracy: 0.7607421875\n",
      "Batch: 101, Loss: 0.7899966239929199, Accuracy: 0.7255859375\n",
      "Batch: 102, Loss: 0.7460116744041443, Accuracy: 0.759765625\n",
      "Batch: 103, Loss: 0.7589377164840698, Accuracy: 0.76953125\n",
      "Batch: 104, Loss: 0.7022819519042969, Accuracy: 0.7626953125\n",
      "Batch: 105, Loss: 0.7906485795974731, Accuracy: 0.740234375\n",
      "Batch: 106, Loss: 0.7232985496520996, Accuracy: 0.767578125\n",
      "Batch: 107, Loss: 0.7640124559402466, Accuracy: 0.759765625\n",
      "Batch: 108, Loss: 0.7196898460388184, Accuracy: 0.767578125\n",
      "Batch: 109, Loss: 0.8402311205863953, Accuracy: 0.72265625\n",
      "Batch: 110, Loss: 0.6791813373565674, Accuracy: 0.7744140625\n",
      "Batch: 111, Loss: 0.7779046893119812, Accuracy: 0.75\n",
      "Batch: 112, Loss: 0.7369700074195862, Accuracy: 0.7607421875\n",
      "Batch: 113, Loss: 0.7344045042991638, Accuracy: 0.7529296875\n",
      "Batch: 114, Loss: 0.841957151889801, Accuracy: 0.7333984375\n",
      "Batch: 115, Loss: 0.8790822625160217, Accuracy: 0.71875\n",
      "Batch: 116, Loss: 0.7985332012176514, Accuracy: 0.7509765625\n",
      "Batch: 117, Loss: 0.8116559386253357, Accuracy: 0.7431640625\n",
      "Batch: 118, Loss: 0.6606065034866333, Accuracy: 0.794921875\n",
      "Batch: 119, Loss: 0.6399139165878296, Accuracy: 0.787109375\n",
      "Batch: 120, Loss: 0.7817215919494629, Accuracy: 0.7529296875\n",
      "Batch: 121, Loss: 0.800006628036499, Accuracy: 0.7431640625\n",
      "Batch: 122, Loss: 0.7382134199142456, Accuracy: 0.7626953125\n",
      "Batch: 123, Loss: 0.7275410890579224, Accuracy: 0.765625\n",
      "Batch: 124, Loss: 0.7333989143371582, Accuracy: 0.7509765625\n",
      "Batch: 125, Loss: 0.8195695281028748, Accuracy: 0.7412109375\n",
      "Batch: 126, Loss: 0.8195527791976929, Accuracy: 0.740234375\n",
      "Batch: 127, Loss: 0.6618886590003967, Accuracy: 0.794921875\n",
      "Batch: 128, Loss: 0.8502069115638733, Accuracy: 0.748046875\n",
      "Batch: 129, Loss: 0.7040339708328247, Accuracy: 0.7685546875\n",
      "Batch: 130, Loss: 0.8396728038787842, Accuracy: 0.716796875\n",
      "Batch: 131, Loss: 0.7801228761672974, Accuracy: 0.744140625\n",
      "Batch: 132, Loss: 0.7954392433166504, Accuracy: 0.7529296875\n",
      "Batch: 133, Loss: 0.7145207524299622, Accuracy: 0.7529296875\n",
      "Batch: 134, Loss: 0.793270468711853, Accuracy: 0.740234375\n",
      "Batch: 135, Loss: 0.7318450808525085, Accuracy: 0.759765625\n",
      "Batch: 136, Loss: 0.7647911310195923, Accuracy: 0.759765625\n",
      "Batch: 138, Loss: 0.6685763597488403, Accuracy: 0.7705078125\n",
      "Batch: 139, Loss: 0.7153774499893188, Accuracy: 0.751953125\n",
      "Batch: 140, Loss: 0.7456247806549072, Accuracy: 0.74609375\n",
      "Batch: 141, Loss: 0.8050587177276611, Accuracy: 0.7412109375\n",
      "Batch: 142, Loss: 0.7767449617385864, Accuracy: 0.740234375\n",
      "Batch: 143, Loss: 0.7630905508995056, Accuracy: 0.744140625\n",
      "Batch: 144, Loss: 0.7939031720161438, Accuracy: 0.748046875\n",
      "Batch: 145, Loss: 0.732892632484436, Accuracy: 0.751953125\n",
      "Batch: 146, Loss: 0.7758049964904785, Accuracy: 0.73828125\n",
      "Batch: 147, Loss: 0.7604007124900818, Accuracy: 0.7451171875\n",
      "Batch: 148, Loss: 0.8582893013954163, Accuracy: 0.7119140625\n",
      "Batch: 149, Loss: 0.7558642625808716, Accuracy: 0.7529296875\n",
      "Batch: 150, Loss: 0.7188323140144348, Accuracy: 0.767578125\n",
      "Batch: 151, Loss: 0.6872113943099976, Accuracy: 0.767578125\n",
      "Epoch 50/80\n",
      "Batch: 1, Loss: 0.9744012355804443, Accuracy: 0.6796875\n",
      "Batch: 2, Loss: 0.822793185710907, Accuracy: 0.7236328125\n",
      "Batch: 3, Loss: 0.7391674518585205, Accuracy: 0.7578125\n",
      "Batch: 4, Loss: 0.6634788513183594, Accuracy: 0.78515625\n",
      "Batch: 5, Loss: 0.6968468427658081, Accuracy: 0.767578125\n",
      "Batch: 6, Loss: 0.7623128294944763, Accuracy: 0.740234375\n",
      "Batch: 7, Loss: 0.7737902402877808, Accuracy: 0.7529296875\n",
      "Batch: 8, Loss: 0.7264699935913086, Accuracy: 0.748046875\n",
      "Batch: 9, Loss: 0.6963788270950317, Accuracy: 0.78125\n",
      "Batch: 10, Loss: 0.6854240894317627, Accuracy: 0.7666015625\n",
      "Batch: 11, Loss: 0.8491969108581543, Accuracy: 0.71484375\n",
      "Batch: 12, Loss: 0.8196128010749817, Accuracy: 0.7421875\n",
      "Batch: 13, Loss: 0.6089303493499756, Accuracy: 0.7900390625\n",
      "Batch: 14, Loss: 0.8110364675521851, Accuracy: 0.7412109375\n",
      "Batch: 15, Loss: 0.6929994821548462, Accuracy: 0.779296875\n",
      "Batch: 16, Loss: 0.7279176712036133, Accuracy: 0.775390625\n",
      "Batch: 17, Loss: 0.7637185454368591, Accuracy: 0.75\n",
      "Batch: 18, Loss: 0.7788305282592773, Accuracy: 0.7490234375\n",
      "Batch: 19, Loss: 0.7861396670341492, Accuracy: 0.7451171875\n",
      "Batch: 20, Loss: 0.6777794361114502, Accuracy: 0.7734375\n",
      "Batch: 21, Loss: 0.697138786315918, Accuracy: 0.7705078125\n",
      "Batch: 22, Loss: 0.8363586664199829, Accuracy: 0.7431640625\n",
      "Batch: 23, Loss: 0.7859401702880859, Accuracy: 0.734375\n",
      "Batch: 24, Loss: 0.7857280969619751, Accuracy: 0.748046875\n",
      "Batch: 25, Loss: 0.7270796298980713, Accuracy: 0.7724609375\n",
      "Batch: 26, Loss: 0.6473425626754761, Accuracy: 0.78125\n",
      "Batch: 27, Loss: 0.7262619733810425, Accuracy: 0.7607421875\n",
      "Batch: 28, Loss: 0.7730353474617004, Accuracy: 0.7412109375\n",
      "Batch: 31, Loss: 0.6991044282913208, Accuracy: 0.7822265625\n",
      "Batch: 32, Loss: 0.6806153059005737, Accuracy: 0.7578125\n",
      "Batch: 33, Loss: 0.7998615503311157, Accuracy: 0.744140625\n",
      "Batch: 34, Loss: 0.8432269096374512, Accuracy: 0.728515625\n",
      "Batch: 35, Loss: 0.8198102712631226, Accuracy: 0.7314453125\n",
      "Batch: 36, Loss: 0.8198978900909424, Accuracy: 0.744140625\n",
      "Batch: 37, Loss: 0.7630041837692261, Accuracy: 0.7490234375\n",
      "Batch: 38, Loss: 0.7614210844039917, Accuracy: 0.7421875\n",
      "Batch: 39, Loss: 0.7703974843025208, Accuracy: 0.748046875\n",
      "Batch: 40, Loss: 0.7457106113433838, Accuracy: 0.7607421875\n",
      "Batch: 41, Loss: 0.7236257791519165, Accuracy: 0.7578125\n",
      "Batch: 42, Loss: 0.5962474942207336, Accuracy: 0.7978515625\n",
      "Batch: 43, Loss: 0.7782511115074158, Accuracy: 0.7431640625\n",
      "Batch: 44, Loss: 0.7648336887359619, Accuracy: 0.7333984375\n",
      "Batch: 45, Loss: 0.6726827025413513, Accuracy: 0.771484375\n",
      "Batch: 46, Loss: 0.7184608578681946, Accuracy: 0.7568359375\n",
      "Batch: 47, Loss: 0.7283322215080261, Accuracy: 0.783203125\n",
      "Batch: 48, Loss: 0.692957878112793, Accuracy: 0.7783203125\n",
      "Batch: 49, Loss: 0.8173729181289673, Accuracy: 0.7373046875\n",
      "Batch: 50, Loss: 0.7962208390235901, Accuracy: 0.748046875\n",
      "Batch: 51, Loss: 0.7964932918548584, Accuracy: 0.728515625\n",
      "Batch: 52, Loss: 0.8163681626319885, Accuracy: 0.7373046875\n",
      "Batch: 53, Loss: 0.7012031078338623, Accuracy: 0.775390625\n",
      "Batch: 54, Loss: 0.7230009436607361, Accuracy: 0.75\n",
      "Batch: 55, Loss: 0.8191125392913818, Accuracy: 0.7197265625\n",
      "Batch: 56, Loss: 0.820457398891449, Accuracy: 0.7333984375\n",
      "Batch: 57, Loss: 0.8032802939414978, Accuracy: 0.7431640625\n",
      "Batch: 58, Loss: 0.8595781326293945, Accuracy: 0.736328125\n",
      "Batch: 59, Loss: 0.7681657075881958, Accuracy: 0.7666015625\n",
      "Batch: 60, Loss: 0.7138227820396423, Accuracy: 0.763671875\n",
      "Batch: 61, Loss: 0.7978767156600952, Accuracy: 0.7314453125\n",
      "Batch: 62, Loss: 0.7086888551712036, Accuracy: 0.7802734375\n",
      "Batch: 63, Loss: 0.7632246613502502, Accuracy: 0.7431640625\n",
      "Batch: 64, Loss: 0.7795274257659912, Accuracy: 0.7470703125\n",
      "Batch: 65, Loss: 0.7775121331214905, Accuracy: 0.7412109375\n",
      "Batch: 66, Loss: 0.777708113193512, Accuracy: 0.74609375\n",
      "Batch: 67, Loss: 0.8494274020195007, Accuracy: 0.73828125\n",
      "Batch: 68, Loss: 0.851204514503479, Accuracy: 0.736328125\n",
      "Batch: 69, Loss: 0.7830462455749512, Accuracy: 0.7451171875\n",
      "Batch: 70, Loss: 0.7351665496826172, Accuracy: 0.76171875\n",
      "Batch: 71, Loss: 0.775562047958374, Accuracy: 0.740234375\n",
      "Batch: 72, Loss: 0.6899832487106323, Accuracy: 0.7724609375\n",
      "Batch: 73, Loss: 0.6889687776565552, Accuracy: 0.77734375\n",
      "Batch: 74, Loss: 0.6806409955024719, Accuracy: 0.7705078125\n",
      "Batch: 75, Loss: 0.6847783327102661, Accuracy: 0.7783203125\n",
      "Batch: 76, Loss: 0.7494618892669678, Accuracy: 0.744140625\n",
      "Batch: 77, Loss: 0.6899471282958984, Accuracy: 0.765625\n",
      "Batch: 78, Loss: 0.6916021108627319, Accuracy: 0.7822265625\n",
      "Batch: 79, Loss: 0.648087739944458, Accuracy: 0.787109375\n",
      "Batch: 80, Loss: 0.7181657552719116, Accuracy: 0.7646484375\n",
      "Batch: 81, Loss: 0.808095395565033, Accuracy: 0.72265625\n",
      "Batch: 82, Loss: 0.7918046712875366, Accuracy: 0.74609375\n",
      "Batch: 83, Loss: 0.6779997944831848, Accuracy: 0.76953125\n",
      "Batch: 84, Loss: 0.729839563369751, Accuracy: 0.7666015625\n",
      "Batch: 85, Loss: 0.7288961410522461, Accuracy: 0.759765625\n",
      "Batch: 86, Loss: 0.8767692446708679, Accuracy: 0.7314453125\n",
      "Batch: 87, Loss: 0.7143439054489136, Accuracy: 0.7646484375\n",
      "Batch: 88, Loss: 0.8070286512374878, Accuracy: 0.7587890625\n",
      "Batch: 89, Loss: 0.739316463470459, Accuracy: 0.7763671875\n",
      "Batch: 90, Loss: 0.6962742805480957, Accuracy: 0.7724609375\n",
      "Batch: 91, Loss: 0.7373307943344116, Accuracy: 0.7548828125\n",
      "Batch: 92, Loss: 0.7632923126220703, Accuracy: 0.751953125\n",
      "Batch: 93, Loss: 0.7578551769256592, Accuracy: 0.75390625\n",
      "Batch: 94, Loss: 0.7570548057556152, Accuracy: 0.7646484375\n",
      "Batch: 95, Loss: 0.7924559116363525, Accuracy: 0.728515625\n",
      "Batch: 96, Loss: 0.7298630475997925, Accuracy: 0.751953125\n",
      "Batch: 97, Loss: 0.6154967546463013, Accuracy: 0.7861328125\n",
      "Batch: 98, Loss: 0.7006602883338928, Accuracy: 0.771484375\n",
      "Batch: 99, Loss: 0.7158207893371582, Accuracy: 0.76953125\n",
      "Batch: 100, Loss: 0.7625278234481812, Accuracy: 0.75390625\n",
      "Batch: 101, Loss: 0.7833932638168335, Accuracy: 0.7421875\n",
      "Batch: 102, Loss: 0.738314151763916, Accuracy: 0.7578125\n",
      "Batch: 103, Loss: 0.7589650750160217, Accuracy: 0.7744140625\n",
      "Batch: 104, Loss: 0.6789906024932861, Accuracy: 0.7734375\n",
      "Batch: 105, Loss: 0.7698857188224792, Accuracy: 0.744140625\n",
      "Batch: 106, Loss: 0.7169593572616577, Accuracy: 0.763671875\n",
      "Batch: 107, Loss: 0.7652338743209839, Accuracy: 0.7490234375\n",
      "Batch: 108, Loss: 0.7118222117424011, Accuracy: 0.7587890625\n",
      "Batch: 109, Loss: 0.8308279514312744, Accuracy: 0.7236328125\n",
      "Batch: 110, Loss: 0.68993079662323, Accuracy: 0.7763671875\n",
      "Batch: 111, Loss: 0.7575646638870239, Accuracy: 0.759765625\n",
      "Batch: 112, Loss: 0.7426644563674927, Accuracy: 0.767578125\n",
      "Batch: 113, Loss: 0.7604103088378906, Accuracy: 0.744140625\n",
      "Batch: 114, Loss: 0.8270505666732788, Accuracy: 0.728515625\n",
      "Batch: 115, Loss: 0.8805843591690063, Accuracy: 0.720703125\n",
      "Batch: 116, Loss: 0.8034852743148804, Accuracy: 0.751953125\n",
      "Batch: 117, Loss: 0.7710323929786682, Accuracy: 0.74609375\n",
      "Batch: 118, Loss: 0.6318556666374207, Accuracy: 0.794921875\n",
      "Batch: 119, Loss: 0.6148335933685303, Accuracy: 0.7890625\n",
      "Batch: 121, Loss: 0.8092749118804932, Accuracy: 0.7373046875\n",
      "Batch: 122, Loss: 0.7423473596572876, Accuracy: 0.759765625\n",
      "Batch: 123, Loss: 0.6915067434310913, Accuracy: 0.7802734375\n",
      "Batch: 124, Loss: 0.7565963268280029, Accuracy: 0.755859375\n",
      "Batch: 125, Loss: 0.8125966191291809, Accuracy: 0.740234375\n",
      "Batch: 126, Loss: 0.7623466849327087, Accuracy: 0.7451171875\n",
      "Batch: 127, Loss: 0.63818359375, Accuracy: 0.7958984375\n",
      "Batch: 128, Loss: 0.8506344556808472, Accuracy: 0.740234375\n",
      "Batch: 129, Loss: 0.6670721769332886, Accuracy: 0.7783203125\n",
      "Batch: 130, Loss: 0.8427489995956421, Accuracy: 0.736328125\n",
      "Batch: 131, Loss: 0.7781500220298767, Accuracy: 0.748046875\n",
      "Batch: 132, Loss: 0.8097720146179199, Accuracy: 0.740234375\n",
      "Batch: 133, Loss: 0.7215572595596313, Accuracy: 0.7626953125\n",
      "Batch: 134, Loss: 0.7890430092811584, Accuracy: 0.736328125\n",
      "Batch: 135, Loss: 0.7280563116073608, Accuracy: 0.7685546875\n",
      "Batch: 136, Loss: 0.7535744905471802, Accuracy: 0.759765625\n",
      "Batch: 137, Loss: 0.8015509247779846, Accuracy: 0.73046875\n",
      "Batch: 138, Loss: 0.6716663837432861, Accuracy: 0.771484375\n",
      "Batch: 139, Loss: 0.7114261388778687, Accuracy: 0.7587890625\n",
      "Batch: 140, Loss: 0.7419617176055908, Accuracy: 0.763671875\n",
      "Batch: 141, Loss: 0.7841253280639648, Accuracy: 0.7451171875\n",
      "Batch: 142, Loss: 0.81348717212677, Accuracy: 0.7373046875\n",
      "Batch: 143, Loss: 0.7632291316986084, Accuracy: 0.7509765625\n",
      "Batch: 144, Loss: 0.7622883319854736, Accuracy: 0.75\n",
      "Batch: 145, Loss: 0.7108615040779114, Accuracy: 0.748046875\n",
      "Batch: 146, Loss: 0.7677596211433411, Accuracy: 0.73828125\n",
      "Batch: 147, Loss: 0.756866455078125, Accuracy: 0.7646484375\n",
      "Batch: 148, Loss: 0.8614268898963928, Accuracy: 0.7158203125\n",
      "Batch: 149, Loss: 0.7423840761184692, Accuracy: 0.75\n",
      "Batch: 150, Loss: 0.7345209121704102, Accuracy: 0.75390625\n",
      "Batch: 151, Loss: 0.6497578620910645, Accuracy: 0.7919921875\n",
      "Saved Weights at epoch 50 to file Weights_50.h5\n",
      "Epoch 51/80\n",
      "Batch: 1, Loss: 0.9549300074577332, Accuracy: 0.7138671875\n",
      "Batch: 2, Loss: 0.808862566947937, Accuracy: 0.7255859375\n",
      "Batch: 3, Loss: 0.7478355169296265, Accuracy: 0.7646484375\n",
      "Batch: 4, Loss: 0.6429226398468018, Accuracy: 0.7998046875\n",
      "Batch: 5, Loss: 0.7319391965866089, Accuracy: 0.76953125\n",
      "Batch: 6, Loss: 0.7701168656349182, Accuracy: 0.7421875\n",
      "Batch: 7, Loss: 0.7544175386428833, Accuracy: 0.7412109375\n",
      "Batch: 8, Loss: 0.6862838268280029, Accuracy: 0.7568359375\n",
      "Batch: 9, Loss: 0.6907603740692139, Accuracy: 0.7744140625\n",
      "Batch: 10, Loss: 0.6847091913223267, Accuracy: 0.771484375\n",
      "Batch: 11, Loss: 0.8283771276473999, Accuracy: 0.7060546875\n",
      "Batch: 12, Loss: 0.7879056930541992, Accuracy: 0.734375\n",
      "Batch: 13, Loss: 0.6067540645599365, Accuracy: 0.798828125\n",
      "Batch: 16, Loss: 0.7505984902381897, Accuracy: 0.765625\n",
      "Batch: 17, Loss: 0.788192868232727, Accuracy: 0.7353515625\n",
      "Batch: 18, Loss: 0.7617294788360596, Accuracy: 0.751953125\n",
      "Batch: 19, Loss: 0.7390962839126587, Accuracy: 0.7802734375\n",
      "Batch: 20, Loss: 0.6742506623268127, Accuracy: 0.7900390625\n",
      "Batch: 21, Loss: 0.6891138553619385, Accuracy: 0.7646484375\n",
      "Batch: 22, Loss: 0.8330168128013611, Accuracy: 0.7421875\n",
      "Batch: 23, Loss: 0.7714177370071411, Accuracy: 0.736328125\n",
      "Batch: 24, Loss: 0.7574597597122192, Accuracy: 0.7421875\n",
      "Batch: 25, Loss: 0.7485543489456177, Accuracy: 0.7470703125\n",
      "Batch: 26, Loss: 0.6600567698478699, Accuracy: 0.7822265625\n",
      "Batch: 27, Loss: 0.7010873556137085, Accuracy: 0.765625\n",
      "Batch: 28, Loss: 0.7524261474609375, Accuracy: 0.7587890625\n",
      "Batch: 29, Loss: 0.7367488741874695, Accuracy: 0.74609375\n",
      "Batch: 30, Loss: 0.661521852016449, Accuracy: 0.79296875\n",
      "Batch: 31, Loss: 0.657723605632782, Accuracy: 0.7763671875\n",
      "Batch: 32, Loss: 0.6533419489860535, Accuracy: 0.7744140625\n",
      "Batch: 33, Loss: 0.8011562824249268, Accuracy: 0.740234375\n",
      "Batch: 34, Loss: 0.8329533338546753, Accuracy: 0.71875\n",
      "Batch: 35, Loss: 0.7811087369918823, Accuracy: 0.7470703125\n",
      "Batch: 36, Loss: 0.8075743913650513, Accuracy: 0.732421875\n",
      "Batch: 37, Loss: 0.749152421951294, Accuracy: 0.7607421875\n",
      "Batch: 38, Loss: 0.7611376643180847, Accuracy: 0.748046875\n",
      "Batch: 39, Loss: 0.755159854888916, Accuracy: 0.7470703125\n",
      "Batch: 40, Loss: 0.7361513376235962, Accuracy: 0.75390625\n",
      "Batch: 41, Loss: 0.6907382011413574, Accuracy: 0.771484375\n",
      "Batch: 42, Loss: 0.5634798407554626, Accuracy: 0.8115234375\n",
      "Batch: 43, Loss: 0.7742183208465576, Accuracy: 0.7265625\n",
      "Batch: 44, Loss: 0.725212574005127, Accuracy: 0.7568359375\n",
      "Batch: 45, Loss: 0.6571598052978516, Accuracy: 0.779296875\n",
      "Batch: 46, Loss: 0.6737853288650513, Accuracy: 0.7841796875\n",
      "Batch: 47, Loss: 0.7197116613388062, Accuracy: 0.7783203125\n",
      "Batch: 48, Loss: 0.6714961528778076, Accuracy: 0.77734375\n",
      "Batch: 49, Loss: 0.7804126143455505, Accuracy: 0.7451171875\n",
      "Batch: 50, Loss: 0.7550719976425171, Accuracy: 0.771484375\n",
      "Batch: 51, Loss: 0.7688775062561035, Accuracy: 0.7470703125\n",
      "Batch: 52, Loss: 0.7612781524658203, Accuracy: 0.7626953125\n",
      "Batch: 53, Loss: 0.6782549619674683, Accuracy: 0.7724609375\n",
      "Batch: 54, Loss: 0.7467678785324097, Accuracy: 0.7529296875\n",
      "Batch: 55, Loss: 0.8082495331764221, Accuracy: 0.734375\n",
      "Batch: 56, Loss: 0.8282116651535034, Accuracy: 0.7197265625\n",
      "Batch: 58, Loss: 0.7947494983673096, Accuracy: 0.7392578125\n",
      "Batch: 59, Loss: 0.7199113368988037, Accuracy: 0.7724609375\n",
      "Batch: 60, Loss: 0.7145568132400513, Accuracy: 0.7783203125\n",
      "Batch: 61, Loss: 0.8120941519737244, Accuracy: 0.73828125\n",
      "Batch: 62, Loss: 0.7035150527954102, Accuracy: 0.7587890625\n",
      "Batch: 63, Loss: 0.7961574196815491, Accuracy: 0.7421875\n",
      "Batch: 64, Loss: 0.7512775659561157, Accuracy: 0.751953125\n",
      "Batch: 65, Loss: 0.7688881158828735, Accuracy: 0.76171875\n",
      "Batch: 66, Loss: 0.752022922039032, Accuracy: 0.7490234375\n",
      "Batch: 67, Loss: 0.8404757976531982, Accuracy: 0.7421875\n",
      "Batch: 68, Loss: 0.8763879537582397, Accuracy: 0.72265625\n",
      "Batch: 69, Loss: 0.8032389283180237, Accuracy: 0.7470703125\n",
      "Batch: 70, Loss: 0.7236968278884888, Accuracy: 0.7763671875\n",
      "Batch: 71, Loss: 0.7880030274391174, Accuracy: 0.744140625\n",
      "Batch: 72, Loss: 0.6687602400779724, Accuracy: 0.7666015625\n",
      "Batch: 73, Loss: 0.6852301359176636, Accuracy: 0.779296875\n",
      "Batch: 74, Loss: 0.6428237557411194, Accuracy: 0.8017578125\n",
      "Batch: 75, Loss: 0.6854369044303894, Accuracy: 0.7724609375\n",
      "Batch: 76, Loss: 0.7770763635635376, Accuracy: 0.744140625\n",
      "Batch: 77, Loss: 0.7120152711868286, Accuracy: 0.7685546875\n",
      "Batch: 78, Loss: 0.6967711448669434, Accuracy: 0.7802734375\n",
      "Batch: 79, Loss: 0.6249706745147705, Accuracy: 0.8037109375\n",
      "Batch: 80, Loss: 0.7135204076766968, Accuracy: 0.7666015625\n",
      "Batch: 81, Loss: 0.7997990250587463, Accuracy: 0.7294921875\n",
      "Batch: 82, Loss: 0.7795731425285339, Accuracy: 0.7333984375\n",
      "Batch: 83, Loss: 0.6523160338401794, Accuracy: 0.775390625\n",
      "Batch: 84, Loss: 0.6954524517059326, Accuracy: 0.779296875\n",
      "Batch: 85, Loss: 0.7102683186531067, Accuracy: 0.7734375\n",
      "Batch: 86, Loss: 0.8687700033187866, Accuracy: 0.72265625\n",
      "Batch: 87, Loss: 0.6806520819664001, Accuracy: 0.78515625\n",
      "Batch: 88, Loss: 0.7670708894729614, Accuracy: 0.7685546875\n",
      "Batch: 89, Loss: 0.7672397494316101, Accuracy: 0.7607421875\n",
      "Batch: 90, Loss: 0.700888991355896, Accuracy: 0.7744140625\n",
      "Batch: 91, Loss: 0.7098808288574219, Accuracy: 0.763671875\n",
      "Batch: 92, Loss: 0.7602213621139526, Accuracy: 0.7626953125\n",
      "Batch: 93, Loss: 0.7072135210037231, Accuracy: 0.7705078125\n",
      "Batch: 94, Loss: 0.764628529548645, Accuracy: 0.7333984375\n",
      "Batch: 95, Loss: 0.7982648015022278, Accuracy: 0.7314453125\n",
      "Batch: 96, Loss: 0.7066650390625, Accuracy: 0.7626953125\n",
      "Batch: 97, Loss: 0.6263458132743835, Accuracy: 0.7744140625\n",
      "Batch: 98, Loss: 0.6877651810646057, Accuracy: 0.7861328125\n",
      "Batch: 99, Loss: 0.6986178159713745, Accuracy: 0.7705078125\n",
      "Batch: 100, Loss: 0.7413330078125, Accuracy: 0.7568359375\n",
      "Batch: 101, Loss: 0.7703367471694946, Accuracy: 0.748046875\n",
      "Batch: 102, Loss: 0.7277483940124512, Accuracy: 0.7509765625\n",
      "Batch: 103, Loss: 0.7305666208267212, Accuracy: 0.7734375\n",
      "Batch: 104, Loss: 0.6740965843200684, Accuracy: 0.7734375\n",
      "Batch: 105, Loss: 0.7719555497169495, Accuracy: 0.755859375\n",
      "Batch: 106, Loss: 0.7150106430053711, Accuracy: 0.7529296875\n",
      "Batch: 107, Loss: 0.7555088996887207, Accuracy: 0.76171875\n",
      "Batch: 108, Loss: 0.7436251044273376, Accuracy: 0.74609375\n",
      "Batch: 109, Loss: 0.8143520355224609, Accuracy: 0.7197265625\n",
      "Batch: 110, Loss: 0.7013734579086304, Accuracy: 0.75390625\n",
      "Batch: 111, Loss: 0.7564935088157654, Accuracy: 0.7529296875\n",
      "Batch: 112, Loss: 0.7447341680526733, Accuracy: 0.771484375\n",
      "Batch: 113, Loss: 0.7450903654098511, Accuracy: 0.7587890625\n",
      "Batch: 114, Loss: 0.8307817578315735, Accuracy: 0.7265625\n",
      "Batch: 115, Loss: 0.8758276700973511, Accuracy: 0.716796875\n",
      "Batch: 116, Loss: 0.798822283744812, Accuracy: 0.7509765625\n",
      "Batch: 117, Loss: 0.789280116558075, Accuracy: 0.734375\n",
      "Batch: 118, Loss: 0.630601167678833, Accuracy: 0.794921875\n",
      "Batch: 119, Loss: 0.6088360548019409, Accuracy: 0.802734375\n",
      "Batch: 120, Loss: 0.7742729783058167, Accuracy: 0.7529296875\n",
      "Batch: 121, Loss: 0.7748897075653076, Accuracy: 0.7255859375\n",
      "Batch: 122, Loss: 0.71427321434021, Accuracy: 0.7685546875\n",
      "Batch: 123, Loss: 0.6889344453811646, Accuracy: 0.7802734375\n",
      "Batch: 124, Loss: 0.7650721669197083, Accuracy: 0.7421875\n",
      "Batch: 125, Loss: 0.8201832175254822, Accuracy: 0.728515625\n",
      "Batch: 126, Loss: 0.7905024290084839, Accuracy: 0.736328125\n",
      "Batch: 127, Loss: 0.6737831830978394, Accuracy: 0.7919921875\n",
      "Batch: 128, Loss: 0.8486043810844421, Accuracy: 0.7412109375\n",
      "Batch: 129, Loss: 0.6695890426635742, Accuracy: 0.78125\n",
      "Batch: 130, Loss: 0.8254202008247375, Accuracy: 0.72265625\n",
      "Batch: 131, Loss: 0.7617394924163818, Accuracy: 0.7490234375\n",
      "Batch: 132, Loss: 0.8025621175765991, Accuracy: 0.751953125\n",
      "Batch: 133, Loss: 0.7152552604675293, Accuracy: 0.751953125\n",
      "Batch: 134, Loss: 0.7779273986816406, Accuracy: 0.73828125\n",
      "Batch: 135, Loss: 0.6913554072380066, Accuracy: 0.765625\n",
      "Batch: 136, Loss: 0.7373175621032715, Accuracy: 0.751953125\n",
      "Batch: 137, Loss: 0.7540939450263977, Accuracy: 0.740234375\n",
      "Batch: 138, Loss: 0.6554973721504211, Accuracy: 0.7861328125\n",
      "Batch: 139, Loss: 0.6961232423782349, Accuracy: 0.7685546875\n",
      "Batch: 140, Loss: 0.7156144976615906, Accuracy: 0.7568359375\n",
      "Batch: 141, Loss: 0.7915855646133423, Accuracy: 0.7509765625\n",
      "Batch: 142, Loss: 0.8124527931213379, Accuracy: 0.7421875\n",
      "Batch: 143, Loss: 0.7214043140411377, Accuracy: 0.7568359375\n",
      "Batch: 144, Loss: 0.7657350897789001, Accuracy: 0.7626953125\n",
      "Batch: 145, Loss: 0.7155182957649231, Accuracy: 0.7412109375\n",
      "Batch: 146, Loss: 0.7896050214767456, Accuracy: 0.7392578125\n",
      "Batch: 147, Loss: 0.7751038074493408, Accuracy: 0.7490234375\n",
      "Batch: 148, Loss: 0.8404639959335327, Accuracy: 0.7275390625\n",
      "Batch: 149, Loss: 0.7331565618515015, Accuracy: 0.7490234375\n",
      "Batch: 150, Loss: 0.7177562713623047, Accuracy: 0.751953125\n",
      "Batch: 151, Loss: 0.6606154441833496, Accuracy: 0.794921875\n",
      "Epoch 52/80\n",
      "Batch: 1, Loss: 0.9423009753227234, Accuracy: 0.6982421875\n",
      "Batch: 2, Loss: 0.8194981813430786, Accuracy: 0.716796875\n",
      "Batch: 3, Loss: 0.7441413402557373, Accuracy: 0.751953125\n",
      "Batch: 4, Loss: 0.6525484323501587, Accuracy: 0.78515625\n",
      "Batch: 5, Loss: 0.6879633665084839, Accuracy: 0.7900390625\n",
      "Batch: 6, Loss: 0.7506616115570068, Accuracy: 0.73828125\n",
      "Batch: 7, Loss: 0.7529678344726562, Accuracy: 0.7333984375\n",
      "Batch: 8, Loss: 0.7146782875061035, Accuracy: 0.763671875\n",
      "Batch: 9, Loss: 0.7117435932159424, Accuracy: 0.7607421875\n",
      "Batch: 10, Loss: 0.6661940813064575, Accuracy: 0.771484375\n",
      "Batch: 11, Loss: 0.8156299591064453, Accuracy: 0.705078125\n",
      "Batch: 12, Loss: 0.7953771352767944, Accuracy: 0.740234375\n",
      "Batch: 13, Loss: 0.6069460511207581, Accuracy: 0.794921875\n",
      "Batch: 14, Loss: 0.7743847370147705, Accuracy: 0.736328125\n",
      "Batch: 15, Loss: 0.6961658000946045, Accuracy: 0.7861328125\n",
      "Batch: 16, Loss: 0.7391905784606934, Accuracy: 0.767578125\n",
      "Batch: 17, Loss: 0.7457190752029419, Accuracy: 0.7431640625\n",
      "Batch: 18, Loss: 0.7501575350761414, Accuracy: 0.7578125\n",
      "Batch: 19, Loss: 0.751620888710022, Accuracy: 0.7509765625\n",
      "Batch: 20, Loss: 0.655376672744751, Accuracy: 0.79296875\n",
      "Batch: 21, Loss: 0.6677066683769226, Accuracy: 0.77734375\n",
      "Batch: 22, Loss: 0.8286596536636353, Accuracy: 0.736328125\n",
      "Batch: 23, Loss: 0.7679290771484375, Accuracy: 0.73828125\n",
      "Batch: 24, Loss: 0.7934781312942505, Accuracy: 0.7314453125\n",
      "Batch: 25, Loss: 0.7205832004547119, Accuracy: 0.7724609375\n",
      "Batch: 26, Loss: 0.6569249033927917, Accuracy: 0.779296875\n",
      "Batch: 27, Loss: 0.6734543442726135, Accuracy: 0.7744140625\n",
      "Batch: 28, Loss: 0.7723654508590698, Accuracy: 0.7392578125\n",
      "Batch: 29, Loss: 0.7160665988922119, Accuracy: 0.75\n",
      "Batch: 30, Loss: 0.6580854654312134, Accuracy: 0.7958984375\n",
      "Batch: 31, Loss: 0.6571849584579468, Accuracy: 0.7900390625\n",
      "Batch: 32, Loss: 0.6943808197975159, Accuracy: 0.7568359375\n",
      "Batch: 33, Loss: 0.815060555934906, Accuracy: 0.7392578125\n",
      "Batch: 34, Loss: 0.8127853274345398, Accuracy: 0.734375\n",
      "Batch: 35, Loss: 0.7923238277435303, Accuracy: 0.734375\n",
      "Batch: 36, Loss: 0.7754635214805603, Accuracy: 0.7607421875\n",
      "Batch: 37, Loss: 0.7381118535995483, Accuracy: 0.7578125\n",
      "Batch: 38, Loss: 0.7788162231445312, Accuracy: 0.7392578125\n",
      "Batch: 39, Loss: 0.731875479221344, Accuracy: 0.75390625\n",
      "Batch: 40, Loss: 0.7370272874832153, Accuracy: 0.759765625\n",
      "Batch: 41, Loss: 0.688488245010376, Accuracy: 0.775390625\n",
      "Batch: 42, Loss: 0.60772705078125, Accuracy: 0.7900390625\n",
      "Batch: 43, Loss: 0.7389616966247559, Accuracy: 0.755859375\n",
      "Batch: 44, Loss: 0.7441063523292542, Accuracy: 0.751953125\n",
      "Batch: 45, Loss: 0.6450459957122803, Accuracy: 0.783203125\n",
      "Batch: 46, Loss: 0.6850566864013672, Accuracy: 0.76953125\n",
      "Batch: 47, Loss: 0.7091560363769531, Accuracy: 0.7822265625\n",
      "Batch: 48, Loss: 0.6713332533836365, Accuracy: 0.78125\n",
      "Batch: 49, Loss: 0.7705100178718567, Accuracy: 0.7392578125\n",
      "Batch: 50, Loss: 0.799126386642456, Accuracy: 0.7431640625\n",
      "Batch: 51, Loss: 0.7662839293479919, Accuracy: 0.7587890625\n",
      "Batch: 52, Loss: 0.7723560929298401, Accuracy: 0.7626953125\n",
      "Batch: 53, Loss: 0.6597230434417725, Accuracy: 0.794921875\n",
      "Batch: 54, Loss: 0.7059261202812195, Accuracy: 0.7705078125\n",
      "Batch: 55, Loss: 0.8133943676948547, Accuracy: 0.724609375\n",
      "Batch: 56, Loss: 0.8269554376602173, Accuracy: 0.7294921875\n",
      "Batch: 57, Loss: 0.77776038646698, Accuracy: 0.732421875\n",
      "Batch: 58, Loss: 0.8428183794021606, Accuracy: 0.724609375\n",
      "Batch: 59, Loss: 0.713878870010376, Accuracy: 0.765625\n",
      "Batch: 60, Loss: 0.6943581104278564, Accuracy: 0.765625\n",
      "Batch: 61, Loss: 0.7825518846511841, Accuracy: 0.7470703125\n",
      "Batch: 62, Loss: 0.7113955020904541, Accuracy: 0.7626953125\n",
      "Batch: 63, Loss: 0.7521190643310547, Accuracy: 0.7451171875\n",
      "Batch: 64, Loss: 0.7457988262176514, Accuracy: 0.7548828125\n",
      "Batch: 65, Loss: 0.7651762366294861, Accuracy: 0.7626953125\n",
      "Batch: 66, Loss: 0.7508814334869385, Accuracy: 0.7646484375\n",
      "Batch: 67, Loss: 0.7872461676597595, Accuracy: 0.7421875\n",
      "Batch: 68, Loss: 0.8334801197052002, Accuracy: 0.7333984375\n",
      "Batch: 69, Loss: 0.771321177482605, Accuracy: 0.7529296875\n",
      "Batch: 70, Loss: 0.6960837244987488, Accuracy: 0.783203125\n",
      "Batch: 71, Loss: 0.7667965888977051, Accuracy: 0.7392578125\n",
      "Batch: 72, Loss: 0.64499831199646, Accuracy: 0.7841796875\n",
      "Batch: 73, Loss: 0.6970350742340088, Accuracy: 0.76953125\n",
      "Batch: 74, Loss: 0.6622462272644043, Accuracy: 0.78515625\n",
      "Batch: 75, Loss: 0.6621863842010498, Accuracy: 0.78125\n",
      "Batch: 76, Loss: 0.7153158783912659, Accuracy: 0.771484375\n",
      "Batch: 77, Loss: 0.7066880464553833, Accuracy: 0.771484375\n",
      "Batch: 78, Loss: 0.7034412026405334, Accuracy: 0.78515625\n",
      "Batch: 79, Loss: 0.6388435959815979, Accuracy: 0.8037109375\n",
      "Batch: 80, Loss: 0.7235403656959534, Accuracy: 0.7626953125\n",
      "Batch: 81, Loss: 0.7983006238937378, Accuracy: 0.7255859375\n",
      "Batch: 82, Loss: 0.76722252368927, Accuracy: 0.751953125\n",
      "Batch: 83, Loss: 0.6605174541473389, Accuracy: 0.7841796875\n",
      "Batch: 84, Loss: 0.7088592648506165, Accuracy: 0.7646484375\n",
      "Batch: 85, Loss: 0.7206047773361206, Accuracy: 0.77734375\n",
      "Batch: 86, Loss: 0.8514111042022705, Accuracy: 0.7216796875\n",
      "Batch: 87, Loss: 0.6874668598175049, Accuracy: 0.7822265625\n",
      "Batch: 88, Loss: 0.7687952518463135, Accuracy: 0.7578125\n",
      "Batch: 89, Loss: 0.743251383304596, Accuracy: 0.7724609375\n",
      "Batch: 90, Loss: 0.7108368873596191, Accuracy: 0.783203125\n",
      "Batch: 91, Loss: 0.717004656791687, Accuracy: 0.763671875\n",
      "Batch: 92, Loss: 0.7372454404830933, Accuracy: 0.75\n",
      "Batch: 93, Loss: 0.735697865486145, Accuracy: 0.75390625\n",
      "Batch: 94, Loss: 0.7757918238639832, Accuracy: 0.7373046875\n",
      "Batch: 95, Loss: 0.7989408373832703, Accuracy: 0.732421875\n",
      "Batch: 96, Loss: 0.7231618762016296, Accuracy: 0.7646484375\n",
      "Batch: 97, Loss: 0.5921510457992554, Accuracy: 0.794921875\n",
      "Batch: 98, Loss: 0.6897389888763428, Accuracy: 0.7763671875\n",
      "Batch: 99, Loss: 0.7205215692520142, Accuracy: 0.771484375\n",
      "Batch: 100, Loss: 0.7333359718322754, Accuracy: 0.76953125\n",
      "Batch: 101, Loss: 0.7467995285987854, Accuracy: 0.7548828125\n",
      "Batch: 102, Loss: 0.7231945991516113, Accuracy: 0.763671875\n",
      "Batch: 103, Loss: 0.7246620059013367, Accuracy: 0.7724609375\n",
      "Batch: 104, Loss: 0.7033514380455017, Accuracy: 0.76953125\n",
      "Batch: 105, Loss: 0.7628663182258606, Accuracy: 0.75390625\n",
      "Batch: 106, Loss: 0.6919151544570923, Accuracy: 0.7626953125\n",
      "Batch: 107, Loss: 0.7571192979812622, Accuracy: 0.7666015625\n",
      "Batch: 108, Loss: 0.7001355886459351, Accuracy: 0.767578125\n",
      "Batch: 109, Loss: 0.7896318435668945, Accuracy: 0.7412109375\n",
      "Batch: 110, Loss: 0.6730742454528809, Accuracy: 0.77734375\n",
      "Batch: 111, Loss: 0.7522342205047607, Accuracy: 0.7666015625\n",
      "Batch: 112, Loss: 0.7431766986846924, Accuracy: 0.755859375\n",
      "Batch: 113, Loss: 0.7451902627944946, Accuracy: 0.7509765625\n",
      "Batch: 114, Loss: 0.8535134196281433, Accuracy: 0.7109375\n",
      "Batch: 115, Loss: 0.8771023750305176, Accuracy: 0.720703125\n",
      "Batch: 116, Loss: 0.7761029601097107, Accuracy: 0.7548828125\n",
      "Batch: 117, Loss: 0.8019590973854065, Accuracy: 0.7373046875\n",
      "Batch: 118, Loss: 0.6296693086624146, Accuracy: 0.7998046875\n",
      "Batch: 119, Loss: 0.613301694393158, Accuracy: 0.7900390625\n",
      "Batch: 120, Loss: 0.7414301633834839, Accuracy: 0.7685546875\n",
      "Batch: 121, Loss: 0.7681242227554321, Accuracy: 0.7431640625\n",
      "Batch: 122, Loss: 0.6928451061248779, Accuracy: 0.775390625\n",
      "Batch: 123, Loss: 0.677330732345581, Accuracy: 0.7744140625\n",
      "Batch: 124, Loss: 0.7570066452026367, Accuracy: 0.734375\n",
      "Batch: 125, Loss: 0.8104568719863892, Accuracy: 0.74609375\n",
      "Batch: 126, Loss: 0.7605294585227966, Accuracy: 0.73828125\n",
      "Batch: 127, Loss: 0.6631940007209778, Accuracy: 0.8037109375\n",
      "Batch: 128, Loss: 0.8505948781967163, Accuracy: 0.755859375\n",
      "Batch: 129, Loss: 0.6646682024002075, Accuracy: 0.7919921875\n",
      "Batch: 130, Loss: 0.8694137334823608, Accuracy: 0.71484375\n",
      "Batch: 131, Loss: 0.7118610143661499, Accuracy: 0.7587890625\n",
      "Batch: 132, Loss: 0.7632936835289001, Accuracy: 0.7626953125\n",
      "Batch: 133, Loss: 0.7216027975082397, Accuracy: 0.7529296875\n",
      "Batch: 134, Loss: 0.7622252702713013, Accuracy: 0.7333984375\n",
      "Batch: 135, Loss: 0.6973364353179932, Accuracy: 0.76953125\n",
      "Batch: 136, Loss: 0.7422095537185669, Accuracy: 0.75390625\n",
      "Batch: 137, Loss: 0.758869469165802, Accuracy: 0.7421875\n",
      "Batch: 138, Loss: 0.6620769500732422, Accuracy: 0.771484375\n",
      "Batch: 140, Loss: 0.7158935070037842, Accuracy: 0.765625\n",
      "Batch: 141, Loss: 0.7676529884338379, Accuracy: 0.732421875\n",
      "Batch: 142, Loss: 0.7831876873970032, Accuracy: 0.7509765625\n",
      "Batch: 143, Loss: 0.7586162090301514, Accuracy: 0.7529296875\n",
      "Batch: 144, Loss: 0.7339267730712891, Accuracy: 0.7578125\n",
      "Batch: 145, Loss: 0.72730553150177, Accuracy: 0.73046875\n",
      "Batch: 146, Loss: 0.7749534845352173, Accuracy: 0.7509765625\n",
      "Batch: 147, Loss: 0.7450398802757263, Accuracy: 0.7412109375\n",
      "Batch: 148, Loss: 0.8459967374801636, Accuracy: 0.72265625\n",
      "Batch: 149, Loss: 0.7176712155342102, Accuracy: 0.7685546875\n",
      "Batch: 150, Loss: 0.721893310546875, Accuracy: 0.75390625\n",
      "Batch: 151, Loss: 0.6795641779899597, Accuracy: 0.7841796875\n",
      "Epoch 53/80\n",
      "Batch: 1, Loss: 0.9578477144241333, Accuracy: 0.703125\n",
      "Batch: 2, Loss: 0.8350907564163208, Accuracy: 0.705078125\n",
      "Batch: 3, Loss: 0.7609032988548279, Accuracy: 0.744140625\n",
      "Batch: 4, Loss: 0.6433847546577454, Accuracy: 0.7998046875\n",
      "Batch: 5, Loss: 0.7010326981544495, Accuracy: 0.7783203125\n",
      "Batch: 6, Loss: 0.7549945116043091, Accuracy: 0.7568359375\n",
      "Batch: 7, Loss: 0.771756649017334, Accuracy: 0.7314453125\n",
      "Batch: 8, Loss: 0.7225598096847534, Accuracy: 0.759765625\n",
      "Batch: 9, Loss: 0.6895782947540283, Accuracy: 0.7900390625\n",
      "Batch: 10, Loss: 0.6723676919937134, Accuracy: 0.767578125\n",
      "Batch: 11, Loss: 0.8294159173965454, Accuracy: 0.71875\n",
      "Batch: 12, Loss: 0.7943208813667297, Accuracy: 0.748046875\n",
      "Batch: 13, Loss: 0.5967928171157837, Accuracy: 0.796875\n",
      "Batch: 14, Loss: 0.7819820642471313, Accuracy: 0.7412109375\n",
      "Batch: 15, Loss: 0.7023869156837463, Accuracy: 0.7802734375\n",
      "Batch: 16, Loss: 0.7067444324493408, Accuracy: 0.77734375\n",
      "Batch: 17, Loss: 0.7574253082275391, Accuracy: 0.748046875\n",
      "Batch: 18, Loss: 0.746334433555603, Accuracy: 0.755859375\n",
      "Batch: 19, Loss: 0.7461222410202026, Accuracy: 0.76171875\n",
      "Batch: 20, Loss: 0.6550439596176147, Accuracy: 0.787109375\n",
      "Batch: 21, Loss: 0.6827338933944702, Accuracy: 0.771484375\n",
      "Batch: 22, Loss: 0.7837345600128174, Accuracy: 0.755859375\n",
      "Batch: 23, Loss: 0.7915726900100708, Accuracy: 0.7490234375\n",
      "Batch: 24, Loss: 0.8081085681915283, Accuracy: 0.73046875\n",
      "Batch: 25, Loss: 0.7314040660858154, Accuracy: 0.767578125\n",
      "Batch: 26, Loss: 0.665549635887146, Accuracy: 0.783203125\n",
      "Batch: 27, Loss: 0.6926282048225403, Accuracy: 0.7734375\n",
      "Batch: 28, Loss: 0.7852527499198914, Accuracy: 0.732421875\n",
      "Batch: 29, Loss: 0.7225576639175415, Accuracy: 0.763671875\n",
      "Batch: 30, Loss: 0.6443341970443726, Accuracy: 0.810546875\n",
      "Batch: 31, Loss: 0.6619091033935547, Accuracy: 0.779296875\n",
      "Batch: 34, Loss: 0.8430090546607971, Accuracy: 0.720703125\n",
      "Batch: 35, Loss: 0.7904631495475769, Accuracy: 0.73828125\n",
      "Batch: 36, Loss: 0.7875573635101318, Accuracy: 0.751953125\n",
      "Batch: 37, Loss: 0.7431985139846802, Accuracy: 0.7470703125\n",
      "Batch: 38, Loss: 0.7561230063438416, Accuracy: 0.7451171875\n",
      "Batch: 39, Loss: 0.7579173445701599, Accuracy: 0.7509765625\n",
      "Batch: 40, Loss: 0.7271531820297241, Accuracy: 0.7724609375\n",
      "Batch: 41, Loss: 0.678911566734314, Accuracy: 0.767578125\n",
      "Batch: 42, Loss: 0.5595147609710693, Accuracy: 0.814453125\n",
      "Batch: 43, Loss: 0.7425456643104553, Accuracy: 0.75\n",
      "Batch: 44, Loss: 0.7496284246444702, Accuracy: 0.7431640625\n",
      "Batch: 45, Loss: 0.6669497489929199, Accuracy: 0.7666015625\n",
      "Batch: 46, Loss: 0.6856249570846558, Accuracy: 0.7841796875\n",
      "Batch: 47, Loss: 0.684267520904541, Accuracy: 0.79296875\n",
      "Batch: 48, Loss: 0.6525579690933228, Accuracy: 0.794921875\n",
      "Batch: 49, Loss: 0.7512238025665283, Accuracy: 0.7509765625\n",
      "Batch: 50, Loss: 0.7547744512557983, Accuracy: 0.76953125\n",
      "Batch: 51, Loss: 0.7581700682640076, Accuracy: 0.7529296875\n",
      "Batch: 52, Loss: 0.7607152462005615, Accuracy: 0.7529296875\n",
      "Batch: 53, Loss: 0.6698418855667114, Accuracy: 0.79296875\n",
      "Batch: 54, Loss: 0.701568603515625, Accuracy: 0.7705078125\n",
      "Batch: 55, Loss: 0.7862385511398315, Accuracy: 0.7255859375\n",
      "Batch: 56, Loss: 0.8078485727310181, Accuracy: 0.7255859375\n",
      "Batch: 57, Loss: 0.7493463754653931, Accuracy: 0.73828125\n",
      "Batch: 58, Loss: 0.8414903879165649, Accuracy: 0.736328125\n",
      "Batch: 59, Loss: 0.7217719554901123, Accuracy: 0.7744140625\n",
      "Batch: 60, Loss: 0.6909042596817017, Accuracy: 0.779296875\n",
      "Batch: 61, Loss: 0.7694694995880127, Accuracy: 0.755859375\n",
      "Batch: 62, Loss: 0.7075378894805908, Accuracy: 0.7705078125\n",
      "Batch: 63, Loss: 0.7561286687850952, Accuracy: 0.7451171875\n",
      "Batch: 64, Loss: 0.731724202632904, Accuracy: 0.7529296875\n",
      "Batch: 65, Loss: 0.7587131261825562, Accuracy: 0.7587890625\n",
      "Batch: 66, Loss: 0.7495148181915283, Accuracy: 0.75390625\n",
      "Batch: 67, Loss: 0.8324571251869202, Accuracy: 0.736328125\n",
      "Batch: 68, Loss: 0.8543151617050171, Accuracy: 0.728515625\n",
      "Batch: 69, Loss: 0.7463904023170471, Accuracy: 0.7607421875\n",
      "Batch: 70, Loss: 0.7190592288970947, Accuracy: 0.7841796875\n",
      "Batch: 71, Loss: 0.7646604776382446, Accuracy: 0.7490234375\n",
      "Batch: 72, Loss: 0.6311230063438416, Accuracy: 0.79296875\n",
      "Batch: 73, Loss: 0.6639378666877747, Accuracy: 0.783203125\n",
      "Batch: 74, Loss: 0.6514939069747925, Accuracy: 0.7919921875\n",
      "Batch: 76, Loss: 0.7506858110427856, Accuracy: 0.7509765625\n",
      "Batch: 77, Loss: 0.684912383556366, Accuracy: 0.76953125\n",
      "Batch: 78, Loss: 0.6796815991401672, Accuracy: 0.7646484375\n",
      "Batch: 79, Loss: 0.6339073181152344, Accuracy: 0.7978515625\n",
      "Batch: 80, Loss: 0.7031184434890747, Accuracy: 0.763671875\n",
      "Batch: 81, Loss: 0.7925688028335571, Accuracy: 0.720703125\n",
      "Batch: 82, Loss: 0.7409093976020813, Accuracy: 0.7568359375\n",
      "Batch: 83, Loss: 0.6542954444885254, Accuracy: 0.796875\n",
      "Batch: 84, Loss: 0.7030138969421387, Accuracy: 0.783203125\n",
      "Batch: 85, Loss: 0.6881792545318604, Accuracy: 0.7734375\n",
      "Batch: 86, Loss: 0.8510752320289612, Accuracy: 0.7255859375\n",
      "Batch: 87, Loss: 0.6995099782943726, Accuracy: 0.765625\n",
      "Batch: 88, Loss: 0.7813166379928589, Accuracy: 0.7451171875\n",
      "Batch: 89, Loss: 0.7574539184570312, Accuracy: 0.7724609375\n",
      "Batch: 90, Loss: 0.7138906717300415, Accuracy: 0.767578125\n",
      "Batch: 91, Loss: 0.7169888019561768, Accuracy: 0.763671875\n",
      "Batch: 92, Loss: 0.7430341243743896, Accuracy: 0.7568359375\n",
      "Batch: 93, Loss: 0.7168343663215637, Accuracy: 0.7646484375\n",
      "Batch: 94, Loss: 0.7273068428039551, Accuracy: 0.7529296875\n",
      "Batch: 95, Loss: 0.7738527059555054, Accuracy: 0.736328125\n",
      "Batch: 96, Loss: 0.7020423412322998, Accuracy: 0.7626953125\n",
      "Batch: 97, Loss: 0.6160877346992493, Accuracy: 0.791015625\n",
      "Batch: 98, Loss: 0.6837952136993408, Accuracy: 0.7841796875\n",
      "Batch: 99, Loss: 0.7056563496589661, Accuracy: 0.7724609375\n",
      "Batch: 100, Loss: 0.7479261755943298, Accuracy: 0.759765625\n",
      "Batch: 101, Loss: 0.7754687666893005, Accuracy: 0.7392578125\n",
      "Batch: 102, Loss: 0.7250299453735352, Accuracy: 0.767578125\n",
      "Batch: 103, Loss: 0.7095304727554321, Accuracy: 0.775390625\n",
      "Batch: 104, Loss: 0.6772230863571167, Accuracy: 0.7685546875\n",
      "Batch: 105, Loss: 0.764162540435791, Accuracy: 0.75390625\n",
      "Batch: 106, Loss: 0.6876219511032104, Accuracy: 0.7841796875\n",
      "Batch: 107, Loss: 0.7319326400756836, Accuracy: 0.77734375\n",
      "Batch: 108, Loss: 0.7010718584060669, Accuracy: 0.76171875\n",
      "Batch: 109, Loss: 0.7873808741569519, Accuracy: 0.75\n",
      "Batch: 110, Loss: 0.6960862874984741, Accuracy: 0.767578125\n",
      "Batch: 111, Loss: 0.7694264054298401, Accuracy: 0.7509765625\n",
      "Batch: 112, Loss: 0.7141780257225037, Accuracy: 0.7626953125\n",
      "Batch: 113, Loss: 0.7150831818580627, Accuracy: 0.765625\n",
      "Batch: 114, Loss: 0.7824552059173584, Accuracy: 0.73828125\n",
      "Batch: 115, Loss: 0.869088351726532, Accuracy: 0.7255859375\n",
      "Batch: 116, Loss: 0.7698368430137634, Accuracy: 0.7578125\n",
      "Batch: 117, Loss: 0.7344538569450378, Accuracy: 0.76171875\n",
      "Batch: 118, Loss: 0.6221398115158081, Accuracy: 0.8056640625\n",
      "Batch: 119, Loss: 0.5922760963439941, Accuracy: 0.80078125\n",
      "Batch: 120, Loss: 0.7380159497261047, Accuracy: 0.751953125\n",
      "Batch: 121, Loss: 0.7570862770080566, Accuracy: 0.7490234375\n",
      "Batch: 123, Loss: 0.6894850134849548, Accuracy: 0.771484375\n",
      "Batch: 124, Loss: 0.7315084934234619, Accuracy: 0.759765625\n",
      "Batch: 125, Loss: 0.7972242832183838, Accuracy: 0.73046875\n",
      "Batch: 126, Loss: 0.7623538970947266, Accuracy: 0.7509765625\n",
      "Batch: 127, Loss: 0.6060652732849121, Accuracy: 0.8046875\n",
      "Batch: 128, Loss: 0.8265304565429688, Accuracy: 0.755859375\n",
      "Batch: 129, Loss: 0.6642786264419556, Accuracy: 0.7802734375\n",
      "Batch: 130, Loss: 0.8507672548294067, Accuracy: 0.7265625\n",
      "Batch: 131, Loss: 0.7280292510986328, Accuracy: 0.7685546875\n",
      "Batch: 132, Loss: 0.7816833257675171, Accuracy: 0.7548828125\n",
      "Batch: 133, Loss: 0.7204729914665222, Accuracy: 0.748046875\n",
      "Batch: 134, Loss: 0.7518801689147949, Accuracy: 0.7548828125\n",
      "Batch: 135, Loss: 0.675043523311615, Accuracy: 0.767578125\n",
      "Batch: 136, Loss: 0.7342951893806458, Accuracy: 0.75390625\n",
      "Batch: 137, Loss: 0.7297618389129639, Accuracy: 0.759765625\n",
      "Batch: 138, Loss: 0.656604528427124, Accuracy: 0.7880859375\n",
      "Batch: 139, Loss: 0.6731157302856445, Accuracy: 0.7802734375\n",
      "Batch: 140, Loss: 0.7071511745452881, Accuracy: 0.7587890625\n",
      "Batch: 141, Loss: 0.7423945665359497, Accuracy: 0.7607421875\n",
      "Batch: 142, Loss: 0.7721856832504272, Accuracy: 0.7568359375\n",
      "Batch: 143, Loss: 0.7299119234085083, Accuracy: 0.763671875\n",
      "Batch: 144, Loss: 0.7302368879318237, Accuracy: 0.7626953125\n",
      "Batch: 145, Loss: 0.692889928817749, Accuracy: 0.751953125\n",
      "Batch: 146, Loss: 0.7855914831161499, Accuracy: 0.7470703125\n",
      "Batch: 147, Loss: 0.7599538564682007, Accuracy: 0.75\n",
      "Batch: 148, Loss: 0.8309412598609924, Accuracy: 0.7275390625\n",
      "Batch: 149, Loss: 0.7189539670944214, Accuracy: 0.759765625\n",
      "Batch: 150, Loss: 0.7156197428703308, Accuracy: 0.775390625\n",
      "Batch: 151, Loss: 0.6523417830467224, Accuracy: 0.7861328125\n",
      "Epoch 54/80\n",
      "Batch: 1, Loss: 0.9600933790206909, Accuracy: 0.7109375\n",
      "Batch: 2, Loss: 0.8217348456382751, Accuracy: 0.71484375\n",
      "Batch: 3, Loss: 0.746123194694519, Accuracy: 0.7548828125\n",
      "Batch: 4, Loss: 0.6455579996109009, Accuracy: 0.80078125\n",
      "Batch: 5, Loss: 0.722058117389679, Accuracy: 0.7724609375\n",
      "Batch: 6, Loss: 0.740037739276886, Accuracy: 0.759765625\n",
      "Batch: 7, Loss: 0.7452818155288696, Accuracy: 0.7578125\n",
      "Batch: 8, Loss: 0.6626617908477783, Accuracy: 0.7724609375\n",
      "Batch: 9, Loss: 0.6858620643615723, Accuracy: 0.771484375\n",
      "Batch: 10, Loss: 0.6664896011352539, Accuracy: 0.7685546875\n",
      "Batch: 11, Loss: 0.8158715963363647, Accuracy: 0.7255859375\n",
      "Batch: 12, Loss: 0.7919226884841919, Accuracy: 0.7470703125\n",
      "Batch: 13, Loss: 0.5917341709136963, Accuracy: 0.8056640625\n",
      "Batch: 14, Loss: 0.7833771109580994, Accuracy: 0.7421875\n",
      "Batch: 15, Loss: 0.6710867285728455, Accuracy: 0.7802734375\n",
      "Batch: 18, Loss: 0.7607767581939697, Accuracy: 0.7626953125\n",
      "Batch: 19, Loss: 0.7415047883987427, Accuracy: 0.76953125\n",
      "Batch: 20, Loss: 0.659137487411499, Accuracy: 0.7998046875\n",
      "Batch: 21, Loss: 0.6600768566131592, Accuracy: 0.787109375\n",
      "Batch: 22, Loss: 0.796974778175354, Accuracy: 0.7509765625\n",
      "Batch: 23, Loss: 0.757495641708374, Accuracy: 0.736328125\n",
      "Batch: 24, Loss: 0.7850998640060425, Accuracy: 0.74609375\n",
      "Batch: 25, Loss: 0.7194443941116333, Accuracy: 0.7607421875\n",
      "Batch: 26, Loss: 0.6466147303581238, Accuracy: 0.7919921875\n",
      "Batch: 27, Loss: 0.653136134147644, Accuracy: 0.767578125\n",
      "Batch: 28, Loss: 0.7426272630691528, Accuracy: 0.75\n",
      "Batch: 29, Loss: 0.6847696900367737, Accuracy: 0.7744140625\n",
      "Batch: 30, Loss: 0.6457354426383972, Accuracy: 0.8095703125\n",
      "Batch: 31, Loss: 0.6301684975624084, Accuracy: 0.7841796875\n",
      "Batch: 32, Loss: 0.674663782119751, Accuracy: 0.7587890625\n",
      "Batch: 33, Loss: 0.7862738966941833, Accuracy: 0.7451171875\n",
      "Batch: 34, Loss: 0.8287805914878845, Accuracy: 0.732421875\n",
      "Batch: 35, Loss: 0.7653684020042419, Accuracy: 0.7568359375\n",
      "Batch: 36, Loss: 0.7704759240150452, Accuracy: 0.751953125\n",
      "Batch: 37, Loss: 0.7336217761039734, Accuracy: 0.7646484375\n",
      "Batch: 38, Loss: 0.7545472979545593, Accuracy: 0.7412109375\n",
      "Batch: 39, Loss: 0.7411638498306274, Accuracy: 0.7646484375\n",
      "Batch: 40, Loss: 0.7148433923721313, Accuracy: 0.7587890625\n",
      "Batch: 41, Loss: 0.6842843294143677, Accuracy: 0.7666015625\n",
      "Batch: 42, Loss: 0.5541126132011414, Accuracy: 0.822265625\n",
      "Batch: 43, Loss: 0.7281167507171631, Accuracy: 0.763671875\n",
      "Batch: 44, Loss: 0.7090036869049072, Accuracy: 0.7548828125\n",
      "Batch: 45, Loss: 0.6347730755805969, Accuracy: 0.7783203125\n",
      "Batch: 46, Loss: 0.6672265529632568, Accuracy: 0.77734375\n",
      "Batch: 47, Loss: 0.7070164680480957, Accuracy: 0.77734375\n",
      "Batch: 48, Loss: 0.6431500911712646, Accuracy: 0.7900390625\n",
      "Batch: 49, Loss: 0.7671927213668823, Accuracy: 0.744140625\n",
      "Batch: 50, Loss: 0.742531418800354, Accuracy: 0.755859375\n",
      "Batch: 51, Loss: 0.7639868259429932, Accuracy: 0.7490234375\n",
      "Batch: 52, Loss: 0.7258999943733215, Accuracy: 0.7587890625\n",
      "Batch: 53, Loss: 0.6549873352050781, Accuracy: 0.787109375\n",
      "Batch: 54, Loss: 0.7152729034423828, Accuracy: 0.7646484375\n",
      "Batch: 55, Loss: 0.7985134124755859, Accuracy: 0.7255859375\n",
      "Batch: 56, Loss: 0.8051785230636597, Accuracy: 0.72265625\n",
      "Batch: 57, Loss: 0.7416666746139526, Accuracy: 0.7587890625\n",
      "Batch: 58, Loss: 0.8295652270317078, Accuracy: 0.7431640625\n",
      "Batch: 59, Loss: 0.7272195816040039, Accuracy: 0.767578125\n",
      "Batch: 60, Loss: 0.6831563711166382, Accuracy: 0.77734375\n",
      "Batch: 61, Loss: 0.7812349796295166, Accuracy: 0.7568359375\n",
      "Batch: 63, Loss: 0.7475783228874207, Accuracy: 0.7578125\n",
      "Batch: 64, Loss: 0.7247399091720581, Accuracy: 0.7587890625\n",
      "Batch: 65, Loss: 0.7467203140258789, Accuracy: 0.76171875\n",
      "Batch: 66, Loss: 0.7301471829414368, Accuracy: 0.7705078125\n",
      "Batch: 67, Loss: 0.7746874690055847, Accuracy: 0.7578125\n",
      "Batch: 68, Loss: 0.8389639854431152, Accuracy: 0.736328125\n",
      "Batch: 69, Loss: 0.784734845161438, Accuracy: 0.7509765625\n",
      "Batch: 70, Loss: 0.7148737907409668, Accuracy: 0.77734375\n",
      "Batch: 71, Loss: 0.8004128932952881, Accuracy: 0.720703125\n",
      "Batch: 72, Loss: 0.6515861749649048, Accuracy: 0.7744140625\n",
      "Batch: 73, Loss: 0.6856484413146973, Accuracy: 0.775390625\n",
      "Batch: 74, Loss: 0.674864649772644, Accuracy: 0.77734375\n",
      "Batch: 75, Loss: 0.6731904745101929, Accuracy: 0.7822265625\n",
      "Batch: 76, Loss: 0.7284934520721436, Accuracy: 0.7607421875\n",
      "Batch: 77, Loss: 0.6540071964263916, Accuracy: 0.7744140625\n",
      "Batch: 78, Loss: 0.6458845138549805, Accuracy: 0.7958984375\n",
      "Batch: 79, Loss: 0.633224606513977, Accuracy: 0.7958984375\n",
      "Batch: 80, Loss: 0.6848085522651672, Accuracy: 0.7666015625\n",
      "Batch: 81, Loss: 0.7856401205062866, Accuracy: 0.7216796875\n",
      "Batch: 82, Loss: 0.7730238437652588, Accuracy: 0.75\n",
      "Batch: 83, Loss: 0.6631171703338623, Accuracy: 0.791015625\n",
      "Batch: 84, Loss: 0.6865981221199036, Accuracy: 0.775390625\n",
      "Batch: 85, Loss: 0.6976139545440674, Accuracy: 0.7705078125\n",
      "Batch: 86, Loss: 0.8530176877975464, Accuracy: 0.7421875\n",
      "Batch: 87, Loss: 0.6751154661178589, Accuracy: 0.7841796875\n",
      "Batch: 88, Loss: 0.7862160801887512, Accuracy: 0.75\n",
      "Batch: 89, Loss: 0.7288520336151123, Accuracy: 0.767578125\n",
      "Batch: 90, Loss: 0.6848280429840088, Accuracy: 0.7744140625\n",
      "Batch: 91, Loss: 0.693294107913971, Accuracy: 0.771484375\n",
      "Batch: 92, Loss: 0.7376137971878052, Accuracy: 0.7568359375\n",
      "Batch: 93, Loss: 0.7193292379379272, Accuracy: 0.759765625\n",
      "Batch: 94, Loss: 0.7556153535842896, Accuracy: 0.7509765625\n",
      "Batch: 95, Loss: 0.7918642163276672, Accuracy: 0.7294921875\n",
      "Batch: 96, Loss: 0.7081447243690491, Accuracy: 0.7685546875\n",
      "Batch: 97, Loss: 0.6013401746749878, Accuracy: 0.7900390625\n",
      "Batch: 98, Loss: 0.6731225252151489, Accuracy: 0.7763671875\n",
      "Batch: 99, Loss: 0.6988467574119568, Accuracy: 0.7734375\n",
      "Batch: 100, Loss: 0.7218823432922363, Accuracy: 0.7578125\n",
      "Batch: 101, Loss: 0.7396606802940369, Accuracy: 0.7578125\n",
      "Batch: 102, Loss: 0.7089420557022095, Accuracy: 0.759765625\n",
      "Batch: 103, Loss: 0.7414687275886536, Accuracy: 0.7685546875\n",
      "Batch: 104, Loss: 0.6696539521217346, Accuracy: 0.7724609375\n",
      "Batch: 105, Loss: 0.7466856837272644, Accuracy: 0.763671875\n",
      "Batch: 106, Loss: 0.6856085658073425, Accuracy: 0.76953125\n",
      "Batch: 107, Loss: 0.7356879711151123, Accuracy: 0.7763671875\n",
      "Batch: 108, Loss: 0.7003653049468994, Accuracy: 0.7587890625\n",
      "Batch: 109, Loss: 0.7801707983016968, Accuracy: 0.736328125\n",
      "Batch: 110, Loss: 0.6715435981750488, Accuracy: 0.779296875\n",
      "Batch: 113, Loss: 0.7459099292755127, Accuracy: 0.7587890625\n",
      "Batch: 114, Loss: 0.830630898475647, Accuracy: 0.732421875\n",
      "Batch: 115, Loss: 0.8474045991897583, Accuracy: 0.7236328125\n",
      "Batch: 116, Loss: 0.7875005602836609, Accuracy: 0.755859375\n",
      "Batch: 117, Loss: 0.7550147771835327, Accuracy: 0.7587890625\n",
      "Batch: 118, Loss: 0.6265282034873962, Accuracy: 0.7939453125\n",
      "Batch: 119, Loss: 0.5951235294342041, Accuracy: 0.7998046875\n",
      "Batch: 120, Loss: 0.7601763010025024, Accuracy: 0.7587890625\n",
      "Batch: 121, Loss: 0.7486484050750732, Accuracy: 0.7626953125\n",
      "Batch: 122, Loss: 0.6795287728309631, Accuracy: 0.771484375\n",
      "Batch: 123, Loss: 0.6568511724472046, Accuracy: 0.794921875\n",
      "Batch: 124, Loss: 0.734797477722168, Accuracy: 0.7548828125\n",
      "Batch: 125, Loss: 0.7812057733535767, Accuracy: 0.744140625\n",
      "Batch: 126, Loss: 0.7689889669418335, Accuracy: 0.75\n",
      "Batch: 127, Loss: 0.6642452478408813, Accuracy: 0.79296875\n",
      "Batch: 128, Loss: 0.795894205570221, Accuracy: 0.7470703125\n",
      "Batch: 129, Loss: 0.6684361696243286, Accuracy: 0.7744140625\n",
      "Batch: 130, Loss: 0.817365288734436, Accuracy: 0.7412109375\n",
      "Batch: 131, Loss: 0.717657744884491, Accuracy: 0.7666015625\n",
      "Batch: 132, Loss: 0.7949343323707581, Accuracy: 0.7490234375\n",
      "Batch: 133, Loss: 0.7084987163543701, Accuracy: 0.7587890625\n",
      "Batch: 134, Loss: 0.7930512428283691, Accuracy: 0.7392578125\n",
      "Batch: 135, Loss: 0.7029533982276917, Accuracy: 0.7763671875\n",
      "Batch: 136, Loss: 0.7249568104743958, Accuracy: 0.76953125\n",
      "Batch: 137, Loss: 0.7396924495697021, Accuracy: 0.744140625\n",
      "Batch: 138, Loss: 0.646308183670044, Accuracy: 0.7783203125\n",
      "Batch: 139, Loss: 0.6870936155319214, Accuracy: 0.7587890625\n",
      "Batch: 140, Loss: 0.728516697883606, Accuracy: 0.7490234375\n",
      "Batch: 141, Loss: 0.7698075175285339, Accuracy: 0.736328125\n",
      "Batch: 142, Loss: 0.7526868581771851, Accuracy: 0.7490234375\n",
      "Batch: 143, Loss: 0.750289797782898, Accuracy: 0.75390625\n",
      "Batch: 144, Loss: 0.7408578395843506, Accuracy: 0.76171875\n",
      "Batch: 145, Loss: 0.7083266973495483, Accuracy: 0.759765625\n",
      "Batch: 146, Loss: 0.7754088640213013, Accuracy: 0.751953125\n",
      "Batch: 147, Loss: 0.7472659349441528, Accuracy: 0.7587890625\n",
      "Batch: 148, Loss: 0.8358829021453857, Accuracy: 0.724609375\n",
      "Batch: 149, Loss: 0.7018029689788818, Accuracy: 0.7578125\n",
      "Batch: 150, Loss: 0.6841963529586792, Accuracy: 0.7744140625\n",
      "Batch: 151, Loss: 0.6428694725036621, Accuracy: 0.7783203125\n",
      "Epoch 55/80\n",
      "Batch: 1, Loss: 0.9533029198646545, Accuracy: 0.6923828125\n",
      "Batch: 2, Loss: 0.7716039419174194, Accuracy: 0.72265625\n",
      "Batch: 3, Loss: 0.7356142401695251, Accuracy: 0.7470703125\n",
      "Batch: 4, Loss: 0.6501320600509644, Accuracy: 0.79296875\n",
      "Batch: 8, Loss: 0.682502031326294, Accuracy: 0.7607421875\n",
      "Batch: 9, Loss: 0.6890217065811157, Accuracy: 0.775390625\n",
      "Batch: 10, Loss: 0.6590227484703064, Accuracy: 0.77734375\n",
      "Batch: 11, Loss: 0.811309814453125, Accuracy: 0.7216796875\n",
      "Batch: 12, Loss: 0.774116039276123, Accuracy: 0.75\n",
      "Batch: 13, Loss: 0.6072406768798828, Accuracy: 0.794921875\n",
      "Batch: 14, Loss: 0.8040241599082947, Accuracy: 0.73828125\n",
      "Batch: 15, Loss: 0.6487210988998413, Accuracy: 0.7861328125\n",
      "Batch: 16, Loss: 0.7226006984710693, Accuracy: 0.7666015625\n",
      "Batch: 17, Loss: 0.7717552185058594, Accuracy: 0.7373046875\n",
      "Batch: 18, Loss: 0.7716991901397705, Accuracy: 0.7509765625\n",
      "Batch: 19, Loss: 0.7391007542610168, Accuracy: 0.771484375\n",
      "Batch: 20, Loss: 0.650717556476593, Accuracy: 0.7880859375\n",
      "Batch: 21, Loss: 0.660507082939148, Accuracy: 0.78515625\n",
      "Batch: 22, Loss: 0.7718491554260254, Accuracy: 0.7578125\n",
      "Batch: 23, Loss: 0.7598066329956055, Accuracy: 0.7451171875\n",
      "Batch: 24, Loss: 0.7533305883407593, Accuracy: 0.74609375\n",
      "Batch: 25, Loss: 0.7260569334030151, Accuracy: 0.755859375\n",
      "Batch: 26, Loss: 0.6363295316696167, Accuracy: 0.7822265625\n",
      "Batch: 27, Loss: 0.6793462038040161, Accuracy: 0.7724609375\n",
      "Batch: 28, Loss: 0.7295924425125122, Accuracy: 0.759765625\n",
      "Batch: 29, Loss: 0.7020612359046936, Accuracy: 0.7685546875\n",
      "Batch: 30, Loss: 0.6475575566291809, Accuracy: 0.7978515625\n",
      "Batch: 31, Loss: 0.6405333280563354, Accuracy: 0.791015625\n",
      "Batch: 32, Loss: 0.6594951152801514, Accuracy: 0.7783203125\n",
      "Batch: 33, Loss: 0.7659003138542175, Accuracy: 0.7548828125\n",
      "Batch: 34, Loss: 0.8208522796630859, Accuracy: 0.732421875\n",
      "Batch: 35, Loss: 0.7385583519935608, Accuracy: 0.7607421875\n",
      "Batch: 36, Loss: 0.7828959226608276, Accuracy: 0.7509765625\n",
      "Batch: 37, Loss: 0.7518689632415771, Accuracy: 0.7607421875\n",
      "Batch: 38, Loss: 0.7441321611404419, Accuracy: 0.748046875\n",
      "Batch: 39, Loss: 0.7341136932373047, Accuracy: 0.7685546875\n",
      "Batch: 40, Loss: 0.6956867575645447, Accuracy: 0.77734375\n",
      "Batch: 41, Loss: 0.6732684373855591, Accuracy: 0.7734375\n",
      "Batch: 42, Loss: 0.5447524189949036, Accuracy: 0.8125\n",
      "Batch: 43, Loss: 0.7382912635803223, Accuracy: 0.7607421875\n",
      "Batch: 44, Loss: 0.7247992753982544, Accuracy: 0.74609375\n",
      "Batch: 45, Loss: 0.6488673686981201, Accuracy: 0.7802734375\n",
      "Batch: 46, Loss: 0.647148609161377, Accuracy: 0.794921875\n",
      "Batch: 47, Loss: 0.6844033002853394, Accuracy: 0.791015625\n",
      "Batch: 48, Loss: 0.6594996452331543, Accuracy: 0.7783203125\n",
      "Batch: 49, Loss: 0.7133711576461792, Accuracy: 0.7666015625\n",
      "Batch: 50, Loss: 0.7124687433242798, Accuracy: 0.7734375\n",
      "Batch: 51, Loss: 0.7326928377151489, Accuracy: 0.7724609375\n",
      "Batch: 52, Loss: 0.7167154550552368, Accuracy: 0.7724609375\n",
      "Batch: 56, Loss: 0.8069198131561279, Accuracy: 0.73828125\n",
      "Batch: 57, Loss: 0.7608736157417297, Accuracy: 0.748046875\n",
      "Batch: 58, Loss: 0.8115434646606445, Accuracy: 0.736328125\n",
      "Batch: 59, Loss: 0.7052502632141113, Accuracy: 0.7685546875\n",
      "Batch: 60, Loss: 0.6689862608909607, Accuracy: 0.779296875\n",
      "Batch: 61, Loss: 0.7669500112533569, Accuracy: 0.7568359375\n",
      "Batch: 62, Loss: 0.6877328753471375, Accuracy: 0.77734375\n",
      "Batch: 63, Loss: 0.7246392965316772, Accuracy: 0.759765625\n",
      "Batch: 64, Loss: 0.724482536315918, Accuracy: 0.75390625\n",
      "Batch: 65, Loss: 0.7434591054916382, Accuracy: 0.771484375\n",
      "Batch: 66, Loss: 0.7328839302062988, Accuracy: 0.775390625\n",
      "Batch: 67, Loss: 0.806401789188385, Accuracy: 0.7421875\n",
      "Batch: 68, Loss: 0.8183050155639648, Accuracy: 0.7333984375\n",
      "Batch: 69, Loss: 0.7411463260650635, Accuracy: 0.76171875\n",
      "Batch: 70, Loss: 0.7035937905311584, Accuracy: 0.775390625\n",
      "Batch: 71, Loss: 0.7695814371109009, Accuracy: 0.74609375\n",
      "Batch: 72, Loss: 0.6327474117279053, Accuracy: 0.787109375\n",
      "Batch: 73, Loss: 0.658784031867981, Accuracy: 0.7890625\n",
      "Batch: 74, Loss: 0.6420907974243164, Accuracy: 0.7880859375\n",
      "Batch: 75, Loss: 0.6719278693199158, Accuracy: 0.7890625\n",
      "Batch: 76, Loss: 0.7075378894805908, Accuracy: 0.76953125\n",
      "Batch: 77, Loss: 0.6482909917831421, Accuracy: 0.7783203125\n",
      "Batch: 78, Loss: 0.6719368696212769, Accuracy: 0.7822265625\n",
      "Batch: 79, Loss: 0.6094194054603577, Accuracy: 0.810546875\n",
      "Batch: 80, Loss: 0.6718174815177917, Accuracy: 0.78125\n",
      "Batch: 81, Loss: 0.7824864387512207, Accuracy: 0.734375\n",
      "Batch: 82, Loss: 0.7360662221908569, Accuracy: 0.7578125\n",
      "Batch: 83, Loss: 0.6317213773727417, Accuracy: 0.802734375\n",
      "Batch: 84, Loss: 0.6888350248336792, Accuracy: 0.7705078125\n",
      "Batch: 85, Loss: 0.6887205243110657, Accuracy: 0.78125\n",
      "Batch: 86, Loss: 0.8286504745483398, Accuracy: 0.732421875\n",
      "Batch: 87, Loss: 0.6678680181503296, Accuracy: 0.794921875\n",
      "Batch: 88, Loss: 0.7828580141067505, Accuracy: 0.7646484375\n",
      "Batch: 89, Loss: 0.717774510383606, Accuracy: 0.7783203125\n",
      "Batch: 90, Loss: 0.6951554417610168, Accuracy: 0.7802734375\n",
      "Batch: 91, Loss: 0.7258553504943848, Accuracy: 0.7626953125\n",
      "Batch: 92, Loss: 0.7488633990287781, Accuracy: 0.75\n",
      "Batch: 93, Loss: 0.6877866387367249, Accuracy: 0.7705078125\n",
      "Batch: 94, Loss: 0.7342644929885864, Accuracy: 0.75\n",
      "Batch: 95, Loss: 0.7573390007019043, Accuracy: 0.744140625\n",
      "Batch: 96, Loss: 0.7017802000045776, Accuracy: 0.76953125\n",
      "Batch: 97, Loss: 0.58121657371521, Accuracy: 0.7939453125\n",
      "Batch: 98, Loss: 0.6847860813140869, Accuracy: 0.7705078125\n",
      "Batch: 99, Loss: 0.7102338075637817, Accuracy: 0.7626953125\n",
      "Batch: 102, Loss: 0.6847763061523438, Accuracy: 0.7880859375\n",
      "Batch: 103, Loss: 0.6928072571754456, Accuracy: 0.7939453125\n",
      "Batch: 104, Loss: 0.6680082082748413, Accuracy: 0.7763671875\n",
      "Batch: 105, Loss: 0.7301866412162781, Accuracy: 0.759765625\n",
      "Batch: 106, Loss: 0.6756448745727539, Accuracy: 0.7705078125\n",
      "Batch: 107, Loss: 0.7428265810012817, Accuracy: 0.765625\n",
      "Batch: 108, Loss: 0.681584894657135, Accuracy: 0.76171875\n",
      "Batch: 109, Loss: 0.7998675107955933, Accuracy: 0.7265625\n",
      "Batch: 110, Loss: 0.6882772445678711, Accuracy: 0.7587890625\n",
      "Batch: 111, Loss: 0.7406987547874451, Accuracy: 0.7666015625\n",
      "Batch: 112, Loss: 0.7048867344856262, Accuracy: 0.7548828125\n",
      "Batch: 113, Loss: 0.7118380069732666, Accuracy: 0.765625\n",
      "Batch: 114, Loss: 0.797529935836792, Accuracy: 0.7529296875\n",
      "Batch: 115, Loss: 0.844412088394165, Accuracy: 0.732421875\n",
      "Batch: 116, Loss: 0.7457345724105835, Accuracy: 0.7626953125\n",
      "Batch: 117, Loss: 0.7455599308013916, Accuracy: 0.7587890625\n",
      "Batch: 118, Loss: 0.6152942180633545, Accuracy: 0.810546875\n",
      "Batch: 119, Loss: 0.592104434967041, Accuracy: 0.8115234375\n",
      "Batch: 120, Loss: 0.7347404360771179, Accuracy: 0.7568359375\n",
      "Batch: 121, Loss: 0.7337570190429688, Accuracy: 0.7626953125\n",
      "Batch: 122, Loss: 0.71314537525177, Accuracy: 0.7744140625\n",
      "Batch: 123, Loss: 0.686860978603363, Accuracy: 0.76953125\n",
      "Batch: 124, Loss: 0.7199071645736694, Accuracy: 0.7685546875\n",
      "Batch: 125, Loss: 0.7899048328399658, Accuracy: 0.7470703125\n",
      "Batch: 126, Loss: 0.7533448934555054, Accuracy: 0.7509765625\n",
      "Batch: 127, Loss: 0.6102467775344849, Accuracy: 0.7978515625\n",
      "Batch: 128, Loss: 0.8069671392440796, Accuracy: 0.74609375\n",
      "Batch: 129, Loss: 0.6641218066215515, Accuracy: 0.7783203125\n",
      "Batch: 130, Loss: 0.8364360332489014, Accuracy: 0.7216796875\n",
      "Batch: 131, Loss: 0.6998367309570312, Accuracy: 0.763671875\n",
      "Batch: 132, Loss: 0.7415342330932617, Accuracy: 0.7490234375\n",
      "Batch: 133, Loss: 0.7091533541679382, Accuracy: 0.771484375\n",
      "Batch: 134, Loss: 0.7496871948242188, Accuracy: 0.7470703125\n",
      "Batch: 135, Loss: 0.6800130605697632, Accuracy: 0.78125\n",
      "Batch: 136, Loss: 0.7560482025146484, Accuracy: 0.7470703125\n",
      "Batch: 137, Loss: 0.7308776378631592, Accuracy: 0.7587890625\n",
      "Batch: 138, Loss: 0.6288284063339233, Accuracy: 0.7861328125\n",
      "Batch: 139, Loss: 0.6616199612617493, Accuracy: 0.7822265625\n",
      "Batch: 140, Loss: 0.7243001461029053, Accuracy: 0.765625\n",
      "Batch: 141, Loss: 0.7524323463439941, Accuracy: 0.755859375\n",
      "Batch: 142, Loss: 0.7582117915153503, Accuracy: 0.7587890625\n",
      "Batch: 143, Loss: 0.7403647899627686, Accuracy: 0.765625\n",
      "Batch: 144, Loss: 0.7460870146751404, Accuracy: 0.7548828125\n",
      "Batch: 145, Loss: 0.701801061630249, Accuracy: 0.759765625\n",
      "Batch: 146, Loss: 0.752655029296875, Accuracy: 0.751953125\n",
      "Batch: 147, Loss: 0.7326366901397705, Accuracy: 0.7587890625\n",
      "Batch: 148, Loss: 0.8420989513397217, Accuracy: 0.7138671875\n",
      "Batch: 149, Loss: 0.700142502784729, Accuracy: 0.7685546875\n",
      "Batch: 150, Loss: 0.7128303050994873, Accuracy: 0.74609375\n",
      "Batch: 151, Loss: 0.6383515000343323, Accuracy: 0.78515625\n",
      "Epoch 56/80\n",
      "Batch: 1, Loss: 0.9636145830154419, Accuracy: 0.70703125\n",
      "Batch: 2, Loss: 0.7785090208053589, Accuracy: 0.73046875\n",
      "Batch: 3, Loss: 0.7099063396453857, Accuracy: 0.7607421875\n",
      "Batch: 4, Loss: 0.6080088019371033, Accuracy: 0.8125\n",
      "Batch: 5, Loss: 0.7019243836402893, Accuracy: 0.7705078125\n",
      "Batch: 6, Loss: 0.7580947875976562, Accuracy: 0.73828125\n",
      "Batch: 7, Loss: 0.7408207654953003, Accuracy: 0.7548828125\n",
      "Batch: 8, Loss: 0.6864669322967529, Accuracy: 0.7666015625\n",
      "Batch: 9, Loss: 0.6907005310058594, Accuracy: 0.7734375\n",
      "Batch: 10, Loss: 0.6615655422210693, Accuracy: 0.7724609375\n",
      "Batch: 11, Loss: 0.8195204734802246, Accuracy: 0.7138671875\n",
      "Batch: 12, Loss: 0.7623891830444336, Accuracy: 0.751953125\n",
      "Batch: 13, Loss: 0.5620095729827881, Accuracy: 0.8134765625\n",
      "Batch: 14, Loss: 0.8069297075271606, Accuracy: 0.7314453125\n",
      "Batch: 15, Loss: 0.6441836953163147, Accuracy: 0.7978515625\n",
      "Batch: 16, Loss: 0.7146106958389282, Accuracy: 0.775390625\n",
      "Batch: 17, Loss: 0.7457444667816162, Accuracy: 0.755859375\n",
      "Batch: 18, Loss: 0.7474657297134399, Accuracy: 0.755859375\n",
      "Batch: 19, Loss: 0.7300465703010559, Accuracy: 0.7685546875\n",
      "Batch: 20, Loss: 0.6371930837631226, Accuracy: 0.7861328125\n",
      "Batch: 21, Loss: 0.6476668119430542, Accuracy: 0.78125\n",
      "Batch: 22, Loss: 0.8197662234306335, Accuracy: 0.7392578125\n",
      "Batch: 23, Loss: 0.7537910342216492, Accuracy: 0.7490234375\n",
      "Batch: 24, Loss: 0.7600430250167847, Accuracy: 0.75\n",
      "Batch: 25, Loss: 0.7007348537445068, Accuracy: 0.7724609375\n",
      "Batch: 26, Loss: 0.6341344714164734, Accuracy: 0.7939453125\n",
      "Batch: 27, Loss: 0.685521125793457, Accuracy: 0.76171875\n",
      "Batch: 28, Loss: 0.7444639205932617, Accuracy: 0.7568359375\n",
      "Batch: 29, Loss: 0.699209988117218, Accuracy: 0.7685546875\n",
      "Batch: 30, Loss: 0.6443756818771362, Accuracy: 0.7998046875\n",
      "Batch: 31, Loss: 0.6564329862594604, Accuracy: 0.7861328125\n",
      "Batch: 32, Loss: 0.6810608506202698, Accuracy: 0.78125\n",
      "Batch: 33, Loss: 0.7778609991073608, Accuracy: 0.759765625\n",
      "Batch: 34, Loss: 0.8121867179870605, Accuracy: 0.7333984375\n",
      "Batch: 35, Loss: 0.7431390285491943, Accuracy: 0.7685546875\n",
      "Batch: 36, Loss: 0.7551581859588623, Accuracy: 0.7578125\n",
      "Batch: 37, Loss: 0.7073935270309448, Accuracy: 0.767578125\n",
      "Batch: 38, Loss: 0.7423479557037354, Accuracy: 0.74609375\n",
      "Batch: 39, Loss: 0.7150722146034241, Accuracy: 0.7763671875\n",
      "Batch: 40, Loss: 0.684867799282074, Accuracy: 0.7607421875\n",
      "Batch: 41, Loss: 0.6527482271194458, Accuracy: 0.78125\n",
      "Batch: 45, Loss: 0.630815863609314, Accuracy: 0.7958984375\n",
      "Batch: 46, Loss: 0.6327948570251465, Accuracy: 0.796875\n",
      "Batch: 47, Loss: 0.6885102987289429, Accuracy: 0.7861328125\n",
      "Batch: 48, Loss: 0.6455744504928589, Accuracy: 0.794921875\n",
      "Batch: 49, Loss: 0.7539281845092773, Accuracy: 0.7548828125\n",
      "Batch: 50, Loss: 0.7483803629875183, Accuracy: 0.7490234375\n",
      "Batch: 51, Loss: 0.7570216655731201, Accuracy: 0.7373046875\n",
      "Batch: 52, Loss: 0.7163957357406616, Accuracy: 0.7646484375\n",
      "Batch: 53, Loss: 0.6267378330230713, Accuracy: 0.7890625\n",
      "Batch: 54, Loss: 0.7095826864242554, Accuracy: 0.7626953125\n",
      "Batch: 55, Loss: 0.8125029802322388, Accuracy: 0.724609375\n",
      "Batch: 56, Loss: 0.7916858196258545, Accuracy: 0.740234375\n",
      "Batch: 57, Loss: 0.7424744367599487, Accuracy: 0.75390625\n",
      "Batch: 58, Loss: 0.7969835996627808, Accuracy: 0.75390625\n",
      "Batch: 59, Loss: 0.6724210977554321, Accuracy: 0.77734375\n",
      "Batch: 60, Loss: 0.69855797290802, Accuracy: 0.7705078125\n",
      "Batch: 61, Loss: 0.7770408391952515, Accuracy: 0.748046875\n",
      "Batch: 62, Loss: 0.6872689723968506, Accuracy: 0.767578125\n",
      "Batch: 63, Loss: 0.7459371089935303, Accuracy: 0.7578125\n",
      "Batch: 64, Loss: 0.7171195149421692, Accuracy: 0.76171875\n",
      "Batch: 65, Loss: 0.7221086025238037, Accuracy: 0.771484375\n",
      "Batch: 66, Loss: 0.7293143272399902, Accuracy: 0.7783203125\n",
      "Batch: 67, Loss: 0.8117443323135376, Accuracy: 0.7470703125\n",
      "Batch: 68, Loss: 0.8257337808609009, Accuracy: 0.736328125\n",
      "Batch: 69, Loss: 0.7734696269035339, Accuracy: 0.75\n",
      "Batch: 70, Loss: 0.6745514869689941, Accuracy: 0.7822265625\n",
      "Batch: 71, Loss: 0.751023530960083, Accuracy: 0.740234375\n",
      "Batch: 72, Loss: 0.6136506795883179, Accuracy: 0.796875\n",
      "Batch: 73, Loss: 0.6503564119338989, Accuracy: 0.787109375\n",
      "Batch: 74, Loss: 0.6128783226013184, Accuracy: 0.80859375\n",
      "Batch: 75, Loss: 0.6647363901138306, Accuracy: 0.765625\n",
      "Batch: 76, Loss: 0.7060739994049072, Accuracy: 0.7744140625\n",
      "Batch: 77, Loss: 0.6490277051925659, Accuracy: 0.7919921875\n",
      "Batch: 78, Loss: 0.6719906330108643, Accuracy: 0.7802734375\n",
      "Batch: 79, Loss: 0.6249357461929321, Accuracy: 0.80078125\n",
      "Batch: 80, Loss: 0.685429036617279, Accuracy: 0.7685546875\n",
      "Batch: 81, Loss: 0.7939045429229736, Accuracy: 0.716796875\n",
      "Batch: 82, Loss: 0.7497889399528503, Accuracy: 0.75\n",
      "Batch: 83, Loss: 0.6265897750854492, Accuracy: 0.7958984375\n",
      "Batch: 84, Loss: 0.6563346982002258, Accuracy: 0.796875\n",
      "Batch: 85, Loss: 0.6990832090377808, Accuracy: 0.7734375\n",
      "Batch: 86, Loss: 0.8202588558197021, Accuracy: 0.732421875\n",
      "Batch: 87, Loss: 0.6675289869308472, Accuracy: 0.7890625\n",
      "Batch: 88, Loss: 0.7718545198440552, Accuracy: 0.7578125\n",
      "Batch: 89, Loss: 0.7301798462867737, Accuracy: 0.7734375\n",
      "Batch: 90, Loss: 0.6981366276741028, Accuracy: 0.77734375\n",
      "Batch: 91, Loss: 0.6902757883071899, Accuracy: 0.755859375\n",
      "Batch: 92, Loss: 0.7623819708824158, Accuracy: 0.748046875\n",
      "Batch: 93, Loss: 0.6907060146331787, Accuracy: 0.7763671875\n",
      "Batch: 94, Loss: 0.7389004826545715, Accuracy: 0.7587890625\n",
      "Batch: 95, Loss: 0.774885892868042, Accuracy: 0.7412109375\n",
      "Batch: 96, Loss: 0.6802128553390503, Accuracy: 0.767578125\n",
      "Batch: 97, Loss: 0.5854746103286743, Accuracy: 0.8017578125\n",
      "Batch: 98, Loss: 0.6807926893234253, Accuracy: 0.779296875\n",
      "Batch: 99, Loss: 0.7108824253082275, Accuracy: 0.7705078125\n",
      "Batch: 100, Loss: 0.7323441505432129, Accuracy: 0.75390625\n",
      "Batch: 101, Loss: 0.7499186992645264, Accuracy: 0.751953125\n",
      "Batch: 102, Loss: 0.698860764503479, Accuracy: 0.771484375\n",
      "Batch: 103, Loss: 0.7136340141296387, Accuracy: 0.794921875\n",
      "Batch: 104, Loss: 0.699816882610321, Accuracy: 0.7626953125\n",
      "Batch: 105, Loss: 0.7571467161178589, Accuracy: 0.7548828125\n",
      "Batch: 106, Loss: 0.6748406887054443, Accuracy: 0.7841796875\n",
      "Batch: 107, Loss: 0.7372825145721436, Accuracy: 0.7705078125\n",
      "Batch: 108, Loss: 0.7165763974189758, Accuracy: 0.7626953125\n",
      "Batch: 109, Loss: 0.7610710859298706, Accuracy: 0.7470703125\n",
      "Batch: 110, Loss: 0.6759706139564514, Accuracy: 0.7744140625\n",
      "Batch: 111, Loss: 0.7365841269493103, Accuracy: 0.7646484375\n",
      "Batch: 112, Loss: 0.7143667936325073, Accuracy: 0.7666015625\n",
      "Batch: 113, Loss: 0.7260064482688904, Accuracy: 0.7529296875\n",
      "Batch: 114, Loss: 0.8071633577346802, Accuracy: 0.7333984375\n",
      "Batch: 115, Loss: 0.8638134002685547, Accuracy: 0.736328125\n",
      "Batch: 116, Loss: 0.747305691242218, Accuracy: 0.7626953125\n",
      "Batch: 117, Loss: 0.7458080649375916, Accuracy: 0.7529296875\n",
      "Batch: 118, Loss: 0.6311904191970825, Accuracy: 0.796875\n",
      "Batch: 119, Loss: 0.604617714881897, Accuracy: 0.8017578125\n",
      "Batch: 120, Loss: 0.7673963308334351, Accuracy: 0.7578125\n",
      "Batch: 121, Loss: 0.7374633550643921, Accuracy: 0.7568359375\n",
      "Batch: 122, Loss: 0.66886305809021, Accuracy: 0.78515625\n",
      "Batch: 123, Loss: 0.6652122735977173, Accuracy: 0.779296875\n",
      "Batch: 124, Loss: 0.7292746305465698, Accuracy: 0.7685546875\n",
      "Batch: 125, Loss: 0.7956736087799072, Accuracy: 0.751953125\n",
      "Batch: 126, Loss: 0.7389736771583557, Accuracy: 0.765625\n",
      "Batch: 127, Loss: 0.6422504186630249, Accuracy: 0.794921875\n",
      "Batch: 128, Loss: 0.8089104890823364, Accuracy: 0.751953125\n",
      "Batch: 129, Loss: 0.6622340679168701, Accuracy: 0.7900390625\n",
      "Batch: 130, Loss: 0.8132755756378174, Accuracy: 0.7333984375\n",
      "Batch: 131, Loss: 0.7230842113494873, Accuracy: 0.755859375\n",
      "Batch: 132, Loss: 0.7558631300926208, Accuracy: 0.759765625\n",
      "Batch: 133, Loss: 0.6724807024002075, Accuracy: 0.7763671875\n",
      "Batch: 134, Loss: 0.7699018120765686, Accuracy: 0.74609375\n",
      "Batch: 135, Loss: 0.6970012187957764, Accuracy: 0.7841796875\n",
      "Batch: 136, Loss: 0.7292025089263916, Accuracy: 0.755859375\n",
      "Batch: 139, Loss: 0.6846238970756531, Accuracy: 0.763671875\n",
      "Batch: 140, Loss: 0.702295184135437, Accuracy: 0.7685546875\n",
      "Batch: 141, Loss: 0.7514249086380005, Accuracy: 0.7568359375\n",
      "Batch: 142, Loss: 0.7590509057044983, Accuracy: 0.7421875\n",
      "Batch: 143, Loss: 0.7042229771614075, Accuracy: 0.76171875\n",
      "Batch: 144, Loss: 0.7373234629631042, Accuracy: 0.748046875\n",
      "Batch: 145, Loss: 0.6977106332778931, Accuracy: 0.75390625\n",
      "Batch: 146, Loss: 0.7766207456588745, Accuracy: 0.7451171875\n",
      "Batch: 147, Loss: 0.7376214265823364, Accuracy: 0.755859375\n",
      "Batch: 148, Loss: 0.8185040950775146, Accuracy: 0.7333984375\n",
      "Batch: 149, Loss: 0.6862435340881348, Accuracy: 0.7734375\n",
      "Batch: 150, Loss: 0.7162912487983704, Accuracy: 0.763671875\n",
      "Batch: 151, Loss: 0.6457515954971313, Accuracy: 0.7939453125\n",
      "Epoch 57/80\n",
      "Batch: 1, Loss: 0.9645950794219971, Accuracy: 0.6982421875\n",
      "Batch: 2, Loss: 0.8374714851379395, Accuracy: 0.712890625\n",
      "Batch: 3, Loss: 0.7023542523384094, Accuracy: 0.7626953125\n",
      "Batch: 4, Loss: 0.6336185932159424, Accuracy: 0.794921875\n",
      "Batch: 5, Loss: 0.7058613896369934, Accuracy: 0.775390625\n",
      "Batch: 6, Loss: 0.7685486078262329, Accuracy: 0.7353515625\n",
      "Batch: 7, Loss: 0.7673200368881226, Accuracy: 0.74609375\n",
      "Batch: 8, Loss: 0.6874682903289795, Accuracy: 0.7705078125\n",
      "Batch: 9, Loss: 0.6479809880256653, Accuracy: 0.7880859375\n",
      "Batch: 10, Loss: 0.6469804644584656, Accuracy: 0.7802734375\n",
      "Batch: 11, Loss: 0.7696760892868042, Accuracy: 0.736328125\n",
      "Batch: 12, Loss: 0.7744697332382202, Accuracy: 0.755859375\n",
      "Batch: 13, Loss: 0.579249382019043, Accuracy: 0.8125\n",
      "Batch: 14, Loss: 0.7666928768157959, Accuracy: 0.73828125\n",
      "Batch: 15, Loss: 0.663476824760437, Accuracy: 0.783203125\n",
      "Batch: 16, Loss: 0.7052333354949951, Accuracy: 0.7822265625\n",
      "Batch: 17, Loss: 0.7414736747741699, Accuracy: 0.7470703125\n",
      "Batch: 18, Loss: 0.7273939251899719, Accuracy: 0.7529296875\n",
      "Batch: 19, Loss: 0.7335191965103149, Accuracy: 0.77734375\n",
      "Batch: 20, Loss: 0.649797260761261, Accuracy: 0.787109375\n",
      "Batch: 21, Loss: 0.6819420456886292, Accuracy: 0.767578125\n",
      "Batch: 22, Loss: 0.7951975464820862, Accuracy: 0.7490234375\n",
      "Batch: 23, Loss: 0.7592276334762573, Accuracy: 0.74609375\n",
      "Batch: 24, Loss: 0.7403159141540527, Accuracy: 0.7451171875\n",
      "Batch: 25, Loss: 0.7172544002532959, Accuracy: 0.763671875\n",
      "Batch: 26, Loss: 0.6509996056556702, Accuracy: 0.7822265625\n",
      "Batch: 27, Loss: 0.6821557283401489, Accuracy: 0.7666015625\n",
      "Batch: 28, Loss: 0.7398582696914673, Accuracy: 0.755859375\n",
      "Batch: 29, Loss: 0.6934448480606079, Accuracy: 0.7578125\n",
      "Batch: 30, Loss: 0.6315994262695312, Accuracy: 0.8046875\n",
      "Batch: 31, Loss: 0.6223134398460388, Accuracy: 0.794921875\n",
      "Batch: 32, Loss: 0.6640094518661499, Accuracy: 0.7734375\n",
      "Batch: 34, Loss: 0.7790133953094482, Accuracy: 0.740234375\n",
      "Batch: 35, Loss: 0.7287026643753052, Accuracy: 0.7587890625\n",
      "Batch: 36, Loss: 0.7467933893203735, Accuracy: 0.7578125\n",
      "Batch: 37, Loss: 0.7229166030883789, Accuracy: 0.759765625\n",
      "Batch: 38, Loss: 0.7227147817611694, Accuracy: 0.7421875\n",
      "Batch: 39, Loss: 0.7260435819625854, Accuracy: 0.7724609375\n",
      "Batch: 40, Loss: 0.6877491474151611, Accuracy: 0.7822265625\n",
      "Batch: 41, Loss: 0.6615430116653442, Accuracy: 0.7861328125\n",
      "Batch: 42, Loss: 0.5658504962921143, Accuracy: 0.818359375\n",
      "Batch: 43, Loss: 0.7264443039894104, Accuracy: 0.7578125\n",
      "Batch: 44, Loss: 0.711400032043457, Accuracy: 0.744140625\n",
      "Batch: 45, Loss: 0.6370935440063477, Accuracy: 0.76953125\n",
      "Batch: 46, Loss: 0.6629106402397156, Accuracy: 0.79296875\n",
      "Batch: 47, Loss: 0.6855446100234985, Accuracy: 0.7880859375\n",
      "Batch: 48, Loss: 0.630580723285675, Accuracy: 0.78515625\n",
      "Batch: 49, Loss: 0.7285544872283936, Accuracy: 0.771484375\n",
      "Batch: 50, Loss: 0.7321046590805054, Accuracy: 0.75\n",
      "Batch: 51, Loss: 0.6989946365356445, Accuracy: 0.7626953125\n",
      "Batch: 52, Loss: 0.7323365211486816, Accuracy: 0.763671875\n",
      "Batch: 53, Loss: 0.6561233997344971, Accuracy: 0.791015625\n",
      "Batch: 54, Loss: 0.7195488810539246, Accuracy: 0.7529296875\n",
      "Batch: 55, Loss: 0.8010367155075073, Accuracy: 0.7255859375\n",
      "Batch: 56, Loss: 0.7932865023612976, Accuracy: 0.7294921875\n",
      "Batch: 57, Loss: 0.7370709776878357, Accuracy: 0.755859375\n",
      "Batch: 58, Loss: 0.7811912298202515, Accuracy: 0.751953125\n",
      "Batch: 59, Loss: 0.6886705756187439, Accuracy: 0.771484375\n",
      "Batch: 60, Loss: 0.6753883361816406, Accuracy: 0.7744140625\n",
      "Batch: 61, Loss: 0.7559418678283691, Accuracy: 0.7509765625\n",
      "Batch: 62, Loss: 0.6696518659591675, Accuracy: 0.7685546875\n",
      "Batch: 63, Loss: 0.7271819710731506, Accuracy: 0.767578125\n",
      "Batch: 64, Loss: 0.7191616296768188, Accuracy: 0.7529296875\n",
      "Batch: 65, Loss: 0.7234808802604675, Accuracy: 0.7490234375\n",
      "Batch: 66, Loss: 0.7441248893737793, Accuracy: 0.767578125\n",
      "Batch: 67, Loss: 0.8004733920097351, Accuracy: 0.7490234375\n",
      "Batch: 68, Loss: 0.8292529582977295, Accuracy: 0.73046875\n",
      "Batch: 69, Loss: 0.7293221950531006, Accuracy: 0.7626953125\n",
      "Batch: 70, Loss: 0.6884945631027222, Accuracy: 0.775390625\n",
      "Batch: 71, Loss: 0.7474411725997925, Accuracy: 0.7421875\n",
      "Batch: 72, Loss: 0.619111180305481, Accuracy: 0.7763671875\n",
      "Batch: 73, Loss: 0.6654151678085327, Accuracy: 0.783203125\n",
      "Batch: 74, Loss: 0.6373128890991211, Accuracy: 0.79296875\n",
      "Batch: 75, Loss: 0.6505273580551147, Accuracy: 0.7822265625\n",
      "Batch: 76, Loss: 0.7290107607841492, Accuracy: 0.751953125\n",
      "Batch: 77, Loss: 0.6477239727973938, Accuracy: 0.7822265625\n",
      "Batch: 78, Loss: 0.6709361672401428, Accuracy: 0.78515625\n",
      "Batch: 79, Loss: 0.6178420782089233, Accuracy: 0.8046875\n",
      "Batch: 81, Loss: 0.7743909955024719, Accuracy: 0.7294921875\n",
      "Batch: 82, Loss: 0.7535013556480408, Accuracy: 0.748046875\n",
      "Batch: 83, Loss: 0.6086530685424805, Accuracy: 0.80078125\n",
      "Batch: 84, Loss: 0.6501646041870117, Accuracy: 0.798828125\n",
      "Batch: 85, Loss: 0.6885801553726196, Accuracy: 0.7724609375\n",
      "Batch: 86, Loss: 0.8087494373321533, Accuracy: 0.7412109375\n",
      "Batch: 87, Loss: 0.650136411190033, Accuracy: 0.7919921875\n",
      "Batch: 88, Loss: 0.7383774518966675, Accuracy: 0.765625\n",
      "Batch: 89, Loss: 0.7147358655929565, Accuracy: 0.7744140625\n",
      "Batch: 90, Loss: 0.6865952014923096, Accuracy: 0.7861328125\n",
      "Batch: 91, Loss: 0.6840463280677795, Accuracy: 0.7646484375\n",
      "Batch: 92, Loss: 0.7078055143356323, Accuracy: 0.763671875\n",
      "Batch: 93, Loss: 0.6944259405136108, Accuracy: 0.7666015625\n",
      "Batch: 94, Loss: 0.7389552593231201, Accuracy: 0.7431640625\n",
      "Batch: 95, Loss: 0.7427199482917786, Accuracy: 0.736328125\n",
      "Batch: 96, Loss: 0.6913601160049438, Accuracy: 0.76953125\n",
      "Batch: 97, Loss: 0.6002958416938782, Accuracy: 0.7900390625\n",
      "Batch: 98, Loss: 0.6770350933074951, Accuracy: 0.77734375\n",
      "Batch: 99, Loss: 0.6901659965515137, Accuracy: 0.7734375\n",
      "Batch: 100, Loss: 0.7045720219612122, Accuracy: 0.7763671875\n",
      "Batch: 101, Loss: 0.7177584767341614, Accuracy: 0.7626953125\n",
      "Batch: 102, Loss: 0.7063432931900024, Accuracy: 0.7666015625\n",
      "Batch: 103, Loss: 0.6953271627426147, Accuracy: 0.7880859375\n",
      "Batch: 104, Loss: 0.6654242277145386, Accuracy: 0.7861328125\n",
      "Batch: 105, Loss: 0.7254315614700317, Accuracy: 0.7568359375\n",
      "Batch: 106, Loss: 0.6716855764389038, Accuracy: 0.775390625\n",
      "Batch: 107, Loss: 0.7104143500328064, Accuracy: 0.771484375\n",
      "Batch: 108, Loss: 0.6894751191139221, Accuracy: 0.767578125\n",
      "Batch: 109, Loss: 0.7873544692993164, Accuracy: 0.7431640625\n",
      "Batch: 110, Loss: 0.6786693334579468, Accuracy: 0.7724609375\n",
      "Batch: 111, Loss: 0.7202150821685791, Accuracy: 0.76953125\n",
      "Batch: 112, Loss: 0.7009507417678833, Accuracy: 0.7724609375\n",
      "Batch: 113, Loss: 0.7179029583930969, Accuracy: 0.77734375\n",
      "Batch: 114, Loss: 0.8064531087875366, Accuracy: 0.71875\n",
      "Batch: 115, Loss: 0.8286412954330444, Accuracy: 0.744140625\n",
      "Batch: 116, Loss: 0.7876810431480408, Accuracy: 0.7490234375\n",
      "Batch: 117, Loss: 0.7314151525497437, Accuracy: 0.755859375\n",
      "Batch: 118, Loss: 0.6139864921569824, Accuracy: 0.818359375\n",
      "Batch: 119, Loss: 0.57759690284729, Accuracy: 0.796875\n",
      "Batch: 120, Loss: 0.7394270896911621, Accuracy: 0.7548828125\n",
      "Batch: 121, Loss: 0.7504720687866211, Accuracy: 0.759765625\n",
      "Batch: 122, Loss: 0.6841457486152649, Accuracy: 0.791015625\n",
      "Batch: 123, Loss: 0.6468966603279114, Accuracy: 0.7734375\n",
      "Batch: 124, Loss: 0.7219416499137878, Accuracy: 0.7568359375\n",
      "Batch: 125, Loss: 0.7530984878540039, Accuracy: 0.76171875\n",
      "Batch: 126, Loss: 0.7588762640953064, Accuracy: 0.7451171875\n",
      "Batch: 129, Loss: 0.6506847143173218, Accuracy: 0.783203125\n",
      "Batch: 130, Loss: 0.8178650736808777, Accuracy: 0.7294921875\n",
      "Batch: 131, Loss: 0.7151815295219421, Accuracy: 0.76171875\n",
      "Batch: 132, Loss: 0.7377802133560181, Accuracy: 0.767578125\n",
      "Batch: 133, Loss: 0.692294716835022, Accuracy: 0.7587890625\n",
      "Batch: 134, Loss: 0.7573056221008301, Accuracy: 0.736328125\n",
      "Batch: 135, Loss: 0.6591528654098511, Accuracy: 0.7900390625\n",
      "Batch: 136, Loss: 0.7319531440734863, Accuracy: 0.76953125\n",
      "Batch: 137, Loss: 0.723456621170044, Accuracy: 0.7568359375\n",
      "Batch: 138, Loss: 0.6417737007141113, Accuracy: 0.779296875\n",
      "Batch: 139, Loss: 0.694554328918457, Accuracy: 0.7685546875\n",
      "Batch: 140, Loss: 0.7130399346351624, Accuracy: 0.763671875\n",
      "Batch: 141, Loss: 0.7433619499206543, Accuracy: 0.7490234375\n",
      "Batch: 142, Loss: 0.7832187414169312, Accuracy: 0.73828125\n",
      "Batch: 143, Loss: 0.7553243637084961, Accuracy: 0.75390625\n",
      "Batch: 144, Loss: 0.7381290793418884, Accuracy: 0.7587890625\n",
      "Batch: 145, Loss: 0.7189022302627563, Accuracy: 0.7666015625\n",
      "Batch: 146, Loss: 0.7388696670532227, Accuracy: 0.759765625\n",
      "Batch: 147, Loss: 0.7402123212814331, Accuracy: 0.7587890625\n",
      "Batch: 148, Loss: 0.8207792043685913, Accuracy: 0.7294921875\n",
      "Batch: 149, Loss: 0.7314028739929199, Accuracy: 0.755859375\n",
      "Batch: 150, Loss: 0.6908856630325317, Accuracy: 0.7646484375\n",
      "Batch: 151, Loss: 0.648446261882782, Accuracy: 0.7890625\n",
      "Epoch 58/80\n",
      "Batch: 1, Loss: 0.9387242794036865, Accuracy: 0.70703125\n",
      "Batch: 2, Loss: 0.7838320136070251, Accuracy: 0.7216796875\n",
      "Batch: 3, Loss: 0.6891084313392639, Accuracy: 0.7734375\n",
      "Batch: 4, Loss: 0.6418002247810364, Accuracy: 0.7919921875\n",
      "Batch: 5, Loss: 0.6868425011634827, Accuracy: 0.7783203125\n",
      "Batch: 6, Loss: 0.7177583575248718, Accuracy: 0.755859375\n",
      "Batch: 7, Loss: 0.7211631536483765, Accuracy: 0.7568359375\n",
      "Batch: 8, Loss: 0.6680302023887634, Accuracy: 0.78515625\n",
      "Batch: 9, Loss: 0.6423812508583069, Accuracy: 0.779296875\n",
      "Batch: 10, Loss: 0.663286566734314, Accuracy: 0.77734375\n",
      "Batch: 11, Loss: 0.7856877446174622, Accuracy: 0.72265625\n",
      "Batch: 12, Loss: 0.7626667022705078, Accuracy: 0.75390625\n",
      "Batch: 13, Loss: 0.5809119939804077, Accuracy: 0.7919921875\n",
      "Batch: 14, Loss: 0.7361270189285278, Accuracy: 0.76171875\n",
      "Batch: 15, Loss: 0.6535929441452026, Accuracy: 0.7861328125\n",
      "Batch: 16, Loss: 0.6871832609176636, Accuracy: 0.783203125\n",
      "Batch: 17, Loss: 0.7273567914962769, Accuracy: 0.7607421875\n",
      "Batch: 18, Loss: 0.7266558408737183, Accuracy: 0.7744140625\n",
      "Batch: 19, Loss: 0.7517502903938293, Accuracy: 0.7578125\n",
      "Batch: 20, Loss: 0.6316673755645752, Accuracy: 0.7958984375\n",
      "Batch: 21, Loss: 0.6640380620956421, Accuracy: 0.77734375\n",
      "Batch: 22, Loss: 0.7752656936645508, Accuracy: 0.7529296875\n",
      "Batch: 23, Loss: 0.7542325258255005, Accuracy: 0.7451171875\n",
      "Batch: 26, Loss: 0.6315687894821167, Accuracy: 0.796875\n",
      "Batch: 27, Loss: 0.6393135786056519, Accuracy: 0.78515625\n",
      "Batch: 28, Loss: 0.7482457160949707, Accuracy: 0.7529296875\n",
      "Batch: 29, Loss: 0.6619991660118103, Accuracy: 0.7802734375\n",
      "Batch: 30, Loss: 0.6326498985290527, Accuracy: 0.796875\n",
      "Batch: 31, Loss: 0.6346615552902222, Accuracy: 0.7958984375\n",
      "Batch: 32, Loss: 0.6439869403839111, Accuracy: 0.794921875\n",
      "Batch: 33, Loss: 0.7647517919540405, Accuracy: 0.7578125\n",
      "Batch: 34, Loss: 0.765815019607544, Accuracy: 0.7451171875\n",
      "Batch: 35, Loss: 0.7231553792953491, Accuracy: 0.7724609375\n",
      "Batch: 36, Loss: 0.7778162956237793, Accuracy: 0.7529296875\n",
      "Batch: 37, Loss: 0.73238205909729, Accuracy: 0.76171875\n",
      "Batch: 38, Loss: 0.7263833284378052, Accuracy: 0.7548828125\n",
      "Batch: 39, Loss: 0.7210376262664795, Accuracy: 0.7705078125\n",
      "Batch: 40, Loss: 0.6965345144271851, Accuracy: 0.7744140625\n",
      "Batch: 41, Loss: 0.6584867238998413, Accuracy: 0.7861328125\n",
      "Batch: 42, Loss: 0.5525994896888733, Accuracy: 0.8125\n",
      "Batch: 43, Loss: 0.7271589040756226, Accuracy: 0.755859375\n",
      "Batch: 44, Loss: 0.7309048175811768, Accuracy: 0.7421875\n",
      "Batch: 45, Loss: 0.6356940269470215, Accuracy: 0.775390625\n",
      "Batch: 46, Loss: 0.6496015191078186, Accuracy: 0.7958984375\n",
      "Batch: 47, Loss: 0.6860575675964355, Accuracy: 0.77734375\n",
      "Batch: 48, Loss: 0.6186188459396362, Accuracy: 0.7998046875\n",
      "Batch: 49, Loss: 0.7368791699409485, Accuracy: 0.7646484375\n",
      "Batch: 50, Loss: 0.7045463919639587, Accuracy: 0.7685546875\n",
      "Batch: 51, Loss: 0.7278027534484863, Accuracy: 0.7626953125\n",
      "Batch: 52, Loss: 0.7225781679153442, Accuracy: 0.7705078125\n",
      "Batch: 53, Loss: 0.6156859993934631, Accuracy: 0.802734375\n",
      "Batch: 54, Loss: 0.6700409054756165, Accuracy: 0.771484375\n",
      "Batch: 55, Loss: 0.7989515066146851, Accuracy: 0.7265625\n",
      "Batch: 56, Loss: 0.7552605867385864, Accuracy: 0.75\n",
      "Batch: 57, Loss: 0.7528231739997864, Accuracy: 0.748046875\n",
      "Batch: 58, Loss: 0.8184911012649536, Accuracy: 0.7353515625\n",
      "Batch: 59, Loss: 0.7044824361801147, Accuracy: 0.7646484375\n",
      "Batch: 60, Loss: 0.6420428156852722, Accuracy: 0.7978515625\n",
      "Batch: 61, Loss: 0.7546249628067017, Accuracy: 0.7470703125\n",
      "Batch: 62, Loss: 0.6775075197219849, Accuracy: 0.7724609375\n",
      "Batch: 63, Loss: 0.735718846321106, Accuracy: 0.75390625\n",
      "Batch: 64, Loss: 0.7181290984153748, Accuracy: 0.763671875\n",
      "Batch: 65, Loss: 0.7235108017921448, Accuracy: 0.767578125\n",
      "Batch: 66, Loss: 0.7058205604553223, Accuracy: 0.765625\n",
      "Batch: 67, Loss: 0.7727866768836975, Accuracy: 0.7724609375\n",
      "Batch: 68, Loss: 0.8107684850692749, Accuracy: 0.75\n",
      "Batch: 69, Loss: 0.7436712980270386, Accuracy: 0.751953125\n",
      "Batch: 70, Loss: 0.6853179931640625, Accuracy: 0.783203125\n",
      "Batch: 73, Loss: 0.6571189165115356, Accuracy: 0.7822265625\n",
      "Batch: 74, Loss: 0.6285117864608765, Accuracy: 0.802734375\n",
      "Batch: 75, Loss: 0.6579883694648743, Accuracy: 0.7880859375\n",
      "Batch: 76, Loss: 0.7323832511901855, Accuracy: 0.748046875\n",
      "Batch: 77, Loss: 0.6553016901016235, Accuracy: 0.787109375\n",
      "Batch: 78, Loss: 0.6706204414367676, Accuracy: 0.7763671875\n",
      "Batch: 79, Loss: 0.5924467444419861, Accuracy: 0.8125\n",
      "Batch: 80, Loss: 0.6787147521972656, Accuracy: 0.7666015625\n",
      "Batch: 81, Loss: 0.7759130001068115, Accuracy: 0.734375\n",
      "Batch: 82, Loss: 0.7261918783187866, Accuracy: 0.7705078125\n",
      "Batch: 83, Loss: 0.6088278889656067, Accuracy: 0.8056640625\n",
      "Batch: 84, Loss: 0.62874436378479, Accuracy: 0.8056640625\n",
      "Batch: 85, Loss: 0.6621677875518799, Accuracy: 0.7890625\n",
      "Batch: 86, Loss: 0.7853391170501709, Accuracy: 0.7421875\n",
      "Batch: 87, Loss: 0.6389188766479492, Accuracy: 0.7939453125\n",
      "Batch: 88, Loss: 0.7178133130073547, Accuracy: 0.7685546875\n",
      "Batch: 89, Loss: 0.7117446660995483, Accuracy: 0.783203125\n",
      "Batch: 90, Loss: 0.6723999977111816, Accuracy: 0.7861328125\n",
      "Batch: 91, Loss: 0.7016168236732483, Accuracy: 0.7626953125\n",
      "Batch: 92, Loss: 0.7242513298988342, Accuracy: 0.7578125\n",
      "Batch: 93, Loss: 0.692364513874054, Accuracy: 0.7763671875\n",
      "Batch: 94, Loss: 0.7320799231529236, Accuracy: 0.75390625\n",
      "Batch: 95, Loss: 0.7355006337165833, Accuracy: 0.751953125\n",
      "Batch: 96, Loss: 0.6984241008758545, Accuracy: 0.775390625\n",
      "Batch: 97, Loss: 0.5791054964065552, Accuracy: 0.798828125\n",
      "Batch: 98, Loss: 0.6468684673309326, Accuracy: 0.8017578125\n",
      "Batch: 99, Loss: 0.6824678182601929, Accuracy: 0.765625\n",
      "Batch: 100, Loss: 0.7307604551315308, Accuracy: 0.7646484375\n",
      "Batch: 101, Loss: 0.7335414886474609, Accuracy: 0.7666015625\n",
      "Batch: 102, Loss: 0.6883915662765503, Accuracy: 0.7734375\n",
      "Batch: 103, Loss: 0.6925226449966431, Accuracy: 0.7861328125\n",
      "Batch: 104, Loss: 0.6445056200027466, Accuracy: 0.791015625\n",
      "Batch: 105, Loss: 0.7379164695739746, Accuracy: 0.765625\n",
      "Batch: 106, Loss: 0.6729167699813843, Accuracy: 0.7783203125\n",
      "Batch: 107, Loss: 0.7028464078903198, Accuracy: 0.77734375\n",
      "Batch: 108, Loss: 0.7186684608459473, Accuracy: 0.7490234375\n",
      "Batch: 109, Loss: 0.7592004537582397, Accuracy: 0.751953125\n",
      "Batch: 110, Loss: 0.6649056077003479, Accuracy: 0.7802734375\n",
      "Batch: 111, Loss: 0.7176312208175659, Accuracy: 0.7783203125\n",
      "Batch: 112, Loss: 0.7063673734664917, Accuracy: 0.7724609375\n",
      "Batch: 113, Loss: 0.694149374961853, Accuracy: 0.7734375\n",
      "Batch: 114, Loss: 0.8044005632400513, Accuracy: 0.7314453125\n",
      "Batch: 115, Loss: 0.824357271194458, Accuracy: 0.7421875\n",
      "Batch: 116, Loss: 0.7430148720741272, Accuracy: 0.7587890625\n",
      "Batch: 117, Loss: 0.7267712950706482, Accuracy: 0.7705078125\n",
      "Batch: 119, Loss: 0.6044797897338867, Accuracy: 0.791015625\n",
      "Batch: 120, Loss: 0.740347146987915, Accuracy: 0.7431640625\n",
      "Batch: 121, Loss: 0.7343946695327759, Accuracy: 0.75390625\n",
      "Batch: 122, Loss: 0.6538628935813904, Accuracy: 0.7890625\n",
      "Batch: 123, Loss: 0.6599036455154419, Accuracy: 0.7890625\n",
      "Batch: 124, Loss: 0.7121371030807495, Accuracy: 0.7626953125\n",
      "Batch: 125, Loss: 0.788716197013855, Accuracy: 0.748046875\n",
      "Batch: 126, Loss: 0.7410441637039185, Accuracy: 0.7470703125\n",
      "Batch: 127, Loss: 0.6162301898002625, Accuracy: 0.80859375\n",
      "Batch: 128, Loss: 0.7782862186431885, Accuracy: 0.7734375\n",
      "Batch: 129, Loss: 0.6512211561203003, Accuracy: 0.7822265625\n",
      "Batch: 130, Loss: 0.7887183427810669, Accuracy: 0.74609375\n",
      "Batch: 131, Loss: 0.7068180441856384, Accuracy: 0.7763671875\n",
      "Batch: 132, Loss: 0.7552827596664429, Accuracy: 0.771484375\n",
      "Batch: 133, Loss: 0.6803686618804932, Accuracy: 0.765625\n",
      "Batch: 134, Loss: 0.7555964589118958, Accuracy: 0.748046875\n",
      "Batch: 135, Loss: 0.6634010672569275, Accuracy: 0.7724609375\n",
      "Batch: 136, Loss: 0.7342933416366577, Accuracy: 0.7626953125\n",
      "Batch: 137, Loss: 0.7081015110015869, Accuracy: 0.7470703125\n",
      "Batch: 138, Loss: 0.6260168552398682, Accuracy: 0.791015625\n",
      "Batch: 139, Loss: 0.6536898612976074, Accuracy: 0.78125\n",
      "Batch: 140, Loss: 0.7037495374679565, Accuracy: 0.7607421875\n",
      "Batch: 141, Loss: 0.7446999549865723, Accuracy: 0.7548828125\n",
      "Batch: 142, Loss: 0.7876940965652466, Accuracy: 0.740234375\n",
      "Batch: 143, Loss: 0.6852998733520508, Accuracy: 0.7734375\n",
      "Batch: 144, Loss: 0.7242528796195984, Accuracy: 0.7763671875\n",
      "Batch: 145, Loss: 0.7021889686584473, Accuracy: 0.748046875\n",
      "Batch: 146, Loss: 0.7351179718971252, Accuracy: 0.755859375\n",
      "Batch: 147, Loss: 0.7644333243370056, Accuracy: 0.7548828125\n",
      "Batch: 148, Loss: 0.830119252204895, Accuracy: 0.7265625\n",
      "Batch: 149, Loss: 0.6766003370285034, Accuracy: 0.7822265625\n",
      "Batch: 150, Loss: 0.7024973034858704, Accuracy: 0.763671875\n",
      "Batch: 151, Loss: 0.6272213459014893, Accuracy: 0.7900390625\n",
      "Epoch 59/80\n",
      "Batch: 1, Loss: 0.9215608835220337, Accuracy: 0.7109375\n",
      "Batch: 2, Loss: 0.7918855547904968, Accuracy: 0.7255859375\n",
      "Batch: 3, Loss: 0.7216107845306396, Accuracy: 0.7666015625\n",
      "Batch: 4, Loss: 0.6272903680801392, Accuracy: 0.791015625\n",
      "Batch: 5, Loss: 0.6777019500732422, Accuracy: 0.78515625\n",
      "Batch: 6, Loss: 0.7101644277572632, Accuracy: 0.759765625\n",
      "Batch: 7, Loss: 0.7220186591148376, Accuracy: 0.740234375\n",
      "Batch: 8, Loss: 0.6694233417510986, Accuracy: 0.7724609375\n",
      "Batch: 9, Loss: 0.6711646318435669, Accuracy: 0.79296875\n",
      "Batch: 10, Loss: 0.6631045341491699, Accuracy: 0.7734375\n",
      "Batch: 11, Loss: 0.7821248173713684, Accuracy: 0.720703125\n",
      "Batch: 12, Loss: 0.7673377990722656, Accuracy: 0.7509765625\n",
      "Batch: 13, Loss: 0.5672519207000732, Accuracy: 0.8232421875\n",
      "Batch: 14, Loss: 0.7924607992172241, Accuracy: 0.74609375\n",
      "Batch: 16, Loss: 0.6673735976219177, Accuracy: 0.7890625\n",
      "Batch: 17, Loss: 0.7353307008743286, Accuracy: 0.7431640625\n",
      "Batch: 18, Loss: 0.7021181583404541, Accuracy: 0.767578125\n",
      "Batch: 19, Loss: 0.7054113149642944, Accuracy: 0.7724609375\n",
      "Batch: 20, Loss: 0.602678120136261, Accuracy: 0.8134765625\n",
      "Batch: 21, Loss: 0.6576411128044128, Accuracy: 0.78515625\n",
      "Batch: 22, Loss: 0.7720102667808533, Accuracy: 0.7529296875\n",
      "Batch: 23, Loss: 0.7630573511123657, Accuracy: 0.7392578125\n",
      "Batch: 24, Loss: 0.738798975944519, Accuracy: 0.748046875\n",
      "Batch: 25, Loss: 0.6865599155426025, Accuracy: 0.76171875\n",
      "Batch: 26, Loss: 0.6030901074409485, Accuracy: 0.798828125\n",
      "Batch: 27, Loss: 0.6747745275497437, Accuracy: 0.78515625\n",
      "Batch: 28, Loss: 0.7217410206794739, Accuracy: 0.7529296875\n",
      "Batch: 29, Loss: 0.672497034072876, Accuracy: 0.77734375\n",
      "Batch: 30, Loss: 0.6094420552253723, Accuracy: 0.8134765625\n",
      "Batch: 31, Loss: 0.6296815872192383, Accuracy: 0.8037109375\n",
      "Batch: 32, Loss: 0.6440675854682922, Accuracy: 0.76953125\n",
      "Batch: 33, Loss: 0.7331224083900452, Accuracy: 0.755859375\n",
      "Batch: 34, Loss: 0.7970949411392212, Accuracy: 0.7421875\n",
      "Batch: 35, Loss: 0.7577304840087891, Accuracy: 0.767578125\n",
      "Batch: 36, Loss: 0.7381304502487183, Accuracy: 0.7861328125\n",
      "Batch: 37, Loss: 0.7083677649497986, Accuracy: 0.77734375\n",
      "Batch: 38, Loss: 0.7213801145553589, Accuracy: 0.7412109375\n",
      "Batch: 39, Loss: 0.7310441732406616, Accuracy: 0.76171875\n",
      "Batch: 40, Loss: 0.6820017099380493, Accuracy: 0.76953125\n",
      "Batch: 41, Loss: 0.6401987075805664, Accuracy: 0.7939453125\n",
      "Batch: 42, Loss: 0.5257211327552795, Accuracy: 0.8203125\n",
      "Batch: 43, Loss: 0.7231703996658325, Accuracy: 0.7587890625\n",
      "Batch: 44, Loss: 0.6730663776397705, Accuracy: 0.7646484375\n",
      "Batch: 45, Loss: 0.622440755367279, Accuracy: 0.7998046875\n",
      "Batch: 46, Loss: 0.6390426158905029, Accuracy: 0.7900390625\n",
      "Batch: 47, Loss: 0.6720317602157593, Accuracy: 0.80078125\n",
      "Batch: 48, Loss: 0.6115596294403076, Accuracy: 0.7880859375\n",
      "Batch: 49, Loss: 0.7398434281349182, Accuracy: 0.7587890625\n",
      "Batch: 50, Loss: 0.6861705183982849, Accuracy: 0.7802734375\n",
      "Batch: 51, Loss: 0.704964280128479, Accuracy: 0.7724609375\n",
      "Batch: 52, Loss: 0.7133951783180237, Accuracy: 0.7763671875\n",
      "Batch: 53, Loss: 0.6233025789260864, Accuracy: 0.7919921875\n",
      "Batch: 54, Loss: 0.667266845703125, Accuracy: 0.7841796875\n",
      "Batch: 55, Loss: 0.7933425307273865, Accuracy: 0.734375\n",
      "Batch: 56, Loss: 0.7641319036483765, Accuracy: 0.7412109375\n",
      "Batch: 57, Loss: 0.7205973267555237, Accuracy: 0.7666015625\n",
      "Batch: 58, Loss: 0.7683655023574829, Accuracy: 0.748046875\n",
      "Batch: 59, Loss: 0.6737083792686462, Accuracy: 0.7861328125\n",
      "Batch: 60, Loss: 0.6629737615585327, Accuracy: 0.7841796875\n",
      "Batch: 61, Loss: 0.7555860280990601, Accuracy: 0.765625\n",
      "Batch: 62, Loss: 0.6771660447120667, Accuracy: 0.77734375\n",
      "Batch: 63, Loss: 0.7272878289222717, Accuracy: 0.7685546875\n",
      "Batch: 64, Loss: 0.7202715277671814, Accuracy: 0.763671875\n",
      "Batch: 65, Loss: 0.7110371589660645, Accuracy: 0.7841796875\n",
      "Batch: 66, Loss: 0.677584171295166, Accuracy: 0.791015625\n",
      "Batch: 67, Loss: 0.7696983218193054, Accuracy: 0.74609375\n",
      "Batch: 68, Loss: 0.788581132888794, Accuracy: 0.7412109375\n",
      "Batch: 69, Loss: 0.7286113500595093, Accuracy: 0.76171875\n",
      "Batch: 70, Loss: 0.6742072105407715, Accuracy: 0.7900390625\n",
      "Batch: 71, Loss: 0.7360970973968506, Accuracy: 0.7490234375\n",
      "Batch: 72, Loss: 0.6113729476928711, Accuracy: 0.796875\n",
      "Batch: 73, Loss: 0.6688283085823059, Accuracy: 0.7919921875\n",
      "Batch: 74, Loss: 0.6320503950119019, Accuracy: 0.80859375\n",
      "Batch: 75, Loss: 0.6464000940322876, Accuracy: 0.7822265625\n",
      "Batch: 76, Loss: 0.7118215560913086, Accuracy: 0.7724609375\n",
      "Batch: 77, Loss: 0.6352570056915283, Accuracy: 0.78125\n",
      "Batch: 78, Loss: 0.6629775166511536, Accuracy: 0.78515625\n",
      "Batch: 79, Loss: 0.6022241115570068, Accuracy: 0.8095703125\n",
      "Batch: 80, Loss: 0.640652060508728, Accuracy: 0.7880859375\n",
      "Batch: 81, Loss: 0.7727078199386597, Accuracy: 0.7236328125\n",
      "Batch: 82, Loss: 0.7141532897949219, Accuracy: 0.7802734375\n",
      "Batch: 83, Loss: 0.6120139956474304, Accuracy: 0.80078125\n",
      "Batch: 84, Loss: 0.6596779823303223, Accuracy: 0.78125\n",
      "Batch: 85, Loss: 0.6696724891662598, Accuracy: 0.7734375\n",
      "Batch: 86, Loss: 0.8349915742874146, Accuracy: 0.7373046875\n",
      "Batch: 87, Loss: 0.6393374800682068, Accuracy: 0.8017578125\n",
      "Batch: 88, Loss: 0.7364364862442017, Accuracy: 0.759765625\n",
      "Batch: 89, Loss: 0.6976479887962341, Accuracy: 0.7763671875\n",
      "Batch: 90, Loss: 0.6916436553001404, Accuracy: 0.7646484375\n",
      "Batch: 91, Loss: 0.6823243498802185, Accuracy: 0.7744140625\n",
      "Batch: 92, Loss: 0.7260702848434448, Accuracy: 0.755859375\n",
      "Batch: 93, Loss: 0.6870554685592651, Accuracy: 0.787109375\n",
      "Batch: 94, Loss: 0.7292611598968506, Accuracy: 0.7578125\n",
      "Batch: 95, Loss: 0.7374401092529297, Accuracy: 0.748046875\n",
      "Batch: 96, Loss: 0.6773374080657959, Accuracy: 0.7646484375\n",
      "Batch: 97, Loss: 0.5701287984848022, Accuracy: 0.8076171875\n",
      "Batch: 98, Loss: 0.6543992757797241, Accuracy: 0.787109375\n",
      "Batch: 99, Loss: 0.6634542346000671, Accuracy: 0.7880859375\n",
      "Batch: 100, Loss: 0.6990752220153809, Accuracy: 0.76953125\n",
      "Batch: 101, Loss: 0.6984071731567383, Accuracy: 0.76171875\n",
      "Batch: 102, Loss: 0.6762190461158752, Accuracy: 0.7822265625\n",
      "Batch: 103, Loss: 0.6771856546401978, Accuracy: 0.783203125\n",
      "Batch: 104, Loss: 0.6411969065666199, Accuracy: 0.7802734375\n",
      "Batch: 105, Loss: 0.7420324683189392, Accuracy: 0.7607421875\n",
      "Batch: 106, Loss: 0.6733825206756592, Accuracy: 0.7783203125\n",
      "Batch: 107, Loss: 0.7146860361099243, Accuracy: 0.7822265625\n",
      "Batch: 108, Loss: 0.6599210500717163, Accuracy: 0.7685546875\n",
      "Batch: 109, Loss: 0.7848148345947266, Accuracy: 0.736328125\n",
      "Batch: 112, Loss: 0.6864452362060547, Accuracy: 0.77734375\n",
      "Batch: 113, Loss: 0.7050184011459351, Accuracy: 0.7705078125\n",
      "Batch: 114, Loss: 0.7799427509307861, Accuracy: 0.75\n",
      "Batch: 115, Loss: 0.8198455572128296, Accuracy: 0.748046875\n",
      "Batch: 116, Loss: 0.7525182962417603, Accuracy: 0.7578125\n",
      "Batch: 117, Loss: 0.7173787355422974, Accuracy: 0.7666015625\n",
      "Batch: 118, Loss: 0.5817160606384277, Accuracy: 0.818359375\n",
      "Batch: 119, Loss: 0.5827686190605164, Accuracy: 0.7998046875\n",
      "Batch: 120, Loss: 0.7395209074020386, Accuracy: 0.76171875\n",
      "Batch: 121, Loss: 0.7391637563705444, Accuracy: 0.7490234375\n",
      "Batch: 122, Loss: 0.6587486863136292, Accuracy: 0.787109375\n",
      "Batch: 123, Loss: 0.6472300291061401, Accuracy: 0.794921875\n",
      "Batch: 124, Loss: 0.6740265488624573, Accuracy: 0.7724609375\n",
      "Batch: 125, Loss: 0.7635124921798706, Accuracy: 0.748046875\n",
      "Batch: 126, Loss: 0.7141758799552917, Accuracy: 0.7734375\n",
      "Batch: 127, Loss: 0.5960129499435425, Accuracy: 0.8173828125\n",
      "Batch: 128, Loss: 0.7909654378890991, Accuracy: 0.7626953125\n",
      "Batch: 129, Loss: 0.6286193132400513, Accuracy: 0.80078125\n",
      "Batch: 130, Loss: 0.8178429007530212, Accuracy: 0.7392578125\n",
      "Batch: 131, Loss: 0.6566979885101318, Accuracy: 0.7861328125\n",
      "Batch: 132, Loss: 0.7571126222610474, Accuracy: 0.7705078125\n",
      "Batch: 133, Loss: 0.6658216714859009, Accuracy: 0.78515625\n",
      "Batch: 134, Loss: 0.7278143167495728, Accuracy: 0.7587890625\n",
      "Batch: 135, Loss: 0.6359882354736328, Accuracy: 0.7919921875\n",
      "Batch: 136, Loss: 0.7151632308959961, Accuracy: 0.765625\n",
      "Batch: 137, Loss: 0.7074493169784546, Accuracy: 0.7529296875\n",
      "Batch: 138, Loss: 0.6102861166000366, Accuracy: 0.7939453125\n",
      "Batch: 139, Loss: 0.6495040059089661, Accuracy: 0.7939453125\n",
      "Batch: 140, Loss: 0.6982321739196777, Accuracy: 0.7587890625\n",
      "Batch: 141, Loss: 0.7541234493255615, Accuracy: 0.7646484375\n",
      "Batch: 142, Loss: 0.7768349647521973, Accuracy: 0.751953125\n",
      "Batch: 143, Loss: 0.7300814390182495, Accuracy: 0.767578125\n",
      "Batch: 144, Loss: 0.7291237115859985, Accuracy: 0.7490234375\n",
      "Batch: 145, Loss: 0.6749938726425171, Accuracy: 0.759765625\n",
      "Batch: 146, Loss: 0.7235415577888489, Accuracy: 0.7734375\n",
      "Batch: 147, Loss: 0.7043019533157349, Accuracy: 0.77734375\n",
      "Batch: 148, Loss: 0.7962564826011658, Accuracy: 0.73046875\n",
      "Batch: 149, Loss: 0.6968820095062256, Accuracy: 0.7568359375\n",
      "Batch: 150, Loss: 0.7053160667419434, Accuracy: 0.7724609375\n",
      "Batch: 151, Loss: 0.6472295522689819, Accuracy: 0.796875\n",
      "Epoch 60/80\n",
      "Batch: 1, Loss: 0.9222492575645447, Accuracy: 0.70703125\n",
      "Batch: 2, Loss: 0.8034952282905579, Accuracy: 0.7373046875\n",
      "Batch: 4, Loss: 0.6468197107315063, Accuracy: 0.7919921875\n",
      "Batch: 5, Loss: 0.6812724471092224, Accuracy: 0.7734375\n",
      "Batch: 6, Loss: 0.7229027152061462, Accuracy: 0.75390625\n",
      "Batch: 7, Loss: 0.7412087917327881, Accuracy: 0.7412109375\n",
      "Batch: 8, Loss: 0.6717792749404907, Accuracy: 0.767578125\n",
      "Batch: 9, Loss: 0.648813009262085, Accuracy: 0.7939453125\n",
      "Batch: 10, Loss: 0.6612321138381958, Accuracy: 0.7666015625\n",
      "Batch: 11, Loss: 0.7746011018753052, Accuracy: 0.7255859375\n",
      "Batch: 12, Loss: 0.7784019708633423, Accuracy: 0.7431640625\n",
      "Batch: 13, Loss: 0.558619499206543, Accuracy: 0.8076171875\n",
      "Batch: 14, Loss: 0.7671840190887451, Accuracy: 0.75390625\n",
      "Batch: 15, Loss: 0.6621576547622681, Accuracy: 0.787109375\n",
      "Batch: 16, Loss: 0.7081685066223145, Accuracy: 0.77734375\n",
      "Batch: 17, Loss: 0.7168893814086914, Accuracy: 0.7568359375\n",
      "Batch: 18, Loss: 0.706985354423523, Accuracy: 0.7626953125\n",
      "Batch: 19, Loss: 0.744692325592041, Accuracy: 0.75390625\n",
      "Batch: 20, Loss: 0.6066052317619324, Accuracy: 0.80859375\n",
      "Batch: 21, Loss: 0.6677237749099731, Accuracy: 0.7900390625\n",
      "Batch: 22, Loss: 0.7828391790390015, Accuracy: 0.7509765625\n",
      "Batch: 23, Loss: 0.7338552474975586, Accuracy: 0.74609375\n",
      "Batch: 24, Loss: 0.7161917090415955, Accuracy: 0.751953125\n",
      "Batch: 25, Loss: 0.6859241127967834, Accuracy: 0.7685546875\n",
      "Batch: 26, Loss: 0.6098463535308838, Accuracy: 0.806640625\n",
      "Batch: 27, Loss: 0.6583822965621948, Accuracy: 0.775390625\n",
      "Batch: 28, Loss: 0.7114238739013672, Accuracy: 0.771484375\n",
      "Batch: 29, Loss: 0.6848562955856323, Accuracy: 0.759765625\n",
      "Batch: 30, Loss: 0.6208645701408386, Accuracy: 0.80859375\n",
      "Batch: 31, Loss: 0.6361343264579773, Accuracy: 0.7861328125\n",
      "Batch: 32, Loss: 0.6634352207183838, Accuracy: 0.7744140625\n",
      "Batch: 33, Loss: 0.7570074796676636, Accuracy: 0.75\n",
      "Batch: 34, Loss: 0.8109679222106934, Accuracy: 0.7294921875\n",
      "Batch: 35, Loss: 0.7070077657699585, Accuracy: 0.76953125\n",
      "Batch: 36, Loss: 0.7617589831352234, Accuracy: 0.775390625\n",
      "Batch: 37, Loss: 0.7074247002601624, Accuracy: 0.76953125\n",
      "Batch: 38, Loss: 0.7119075059890747, Accuracy: 0.748046875\n",
      "Batch: 39, Loss: 0.7154947519302368, Accuracy: 0.7744140625\n",
      "Batch: 40, Loss: 0.6830273866653442, Accuracy: 0.767578125\n",
      "Batch: 41, Loss: 0.6554077863693237, Accuracy: 0.7890625\n",
      "Batch: 42, Loss: 0.5610153079032898, Accuracy: 0.8095703125\n",
      "Batch: 43, Loss: 0.7341223955154419, Accuracy: 0.74609375\n",
      "Batch: 44, Loss: 0.7001975774765015, Accuracy: 0.7578125\n",
      "Batch: 45, Loss: 0.6199844479560852, Accuracy: 0.7939453125\n",
      "Batch: 46, Loss: 0.6323159337043762, Accuracy: 0.78125\n",
      "Batch: 47, Loss: 0.6651872396469116, Accuracy: 0.8056640625\n",
      "Batch: 50, Loss: 0.7060868740081787, Accuracy: 0.7763671875\n",
      "Batch: 51, Loss: 0.6954845190048218, Accuracy: 0.787109375\n",
      "Batch: 52, Loss: 0.7125368118286133, Accuracy: 0.763671875\n",
      "Batch: 53, Loss: 0.6575237512588501, Accuracy: 0.78515625\n",
      "Batch: 54, Loss: 0.6635705232620239, Accuracy: 0.7744140625\n",
      "Batch: 55, Loss: 0.7790509462356567, Accuracy: 0.736328125\n",
      "Batch: 56, Loss: 0.7586727142333984, Accuracy: 0.744140625\n",
      "Batch: 57, Loss: 0.7405167818069458, Accuracy: 0.75\n",
      "Batch: 58, Loss: 0.7802286148071289, Accuracy: 0.7646484375\n",
      "Batch: 59, Loss: 0.6848654747009277, Accuracy: 0.7763671875\n",
      "Batch: 60, Loss: 0.6583729982376099, Accuracy: 0.787109375\n",
      "Batch: 61, Loss: 0.7493066787719727, Accuracy: 0.7568359375\n",
      "Batch: 62, Loss: 0.6781612634658813, Accuracy: 0.7744140625\n",
      "Batch: 63, Loss: 0.721676230430603, Accuracy: 0.763671875\n",
      "Batch: 64, Loss: 0.7016379237174988, Accuracy: 0.763671875\n",
      "Batch: 65, Loss: 0.716999888420105, Accuracy: 0.7861328125\n",
      "Batch: 66, Loss: 0.7080710530281067, Accuracy: 0.7841796875\n",
      "Batch: 67, Loss: 0.7924659848213196, Accuracy: 0.751953125\n",
      "Batch: 68, Loss: 0.8115565776824951, Accuracy: 0.7294921875\n",
      "Batch: 69, Loss: 0.7047924399375916, Accuracy: 0.767578125\n",
      "Batch: 70, Loss: 0.7102319002151489, Accuracy: 0.7841796875\n",
      "Batch: 71, Loss: 0.7249975204467773, Accuracy: 0.748046875\n",
      "Batch: 72, Loss: 0.646173357963562, Accuracy: 0.7763671875\n",
      "Batch: 73, Loss: 0.6258945465087891, Accuracy: 0.7978515625\n",
      "Batch: 74, Loss: 0.6051324605941772, Accuracy: 0.806640625\n",
      "Batch: 75, Loss: 0.636751651763916, Accuracy: 0.787109375\n",
      "Batch: 76, Loss: 0.6999789476394653, Accuracy: 0.7724609375\n",
      "Batch: 77, Loss: 0.6540088653564453, Accuracy: 0.78125\n",
      "Batch: 78, Loss: 0.6523761749267578, Accuracy: 0.791015625\n",
      "Batch: 79, Loss: 0.6025334596633911, Accuracy: 0.8017578125\n",
      "Batch: 80, Loss: 0.6501727104187012, Accuracy: 0.7822265625\n",
      "Batch: 81, Loss: 0.7833376526832581, Accuracy: 0.736328125\n",
      "Batch: 82, Loss: 0.7295132279396057, Accuracy: 0.763671875\n",
      "Batch: 83, Loss: 0.6052075624465942, Accuracy: 0.8056640625\n",
      "Batch: 84, Loss: 0.6430585384368896, Accuracy: 0.78515625\n",
      "Batch: 85, Loss: 0.6722232103347778, Accuracy: 0.78125\n",
      "Batch: 86, Loss: 0.8008143305778503, Accuracy: 0.7373046875\n",
      "Batch: 87, Loss: 0.6684715747833252, Accuracy: 0.7919921875\n",
      "Batch: 88, Loss: 0.7201406359672546, Accuracy: 0.7646484375\n",
      "Batch: 89, Loss: 0.7045157551765442, Accuracy: 0.76953125\n",
      "Batch: 90, Loss: 0.6695994138717651, Accuracy: 0.79296875\n",
      "Batch: 91, Loss: 0.7027930617332458, Accuracy: 0.76171875\n",
      "Batch: 94, Loss: 0.7264928817749023, Accuracy: 0.7490234375\n",
      "Batch: 95, Loss: 0.7420461773872375, Accuracy: 0.7333984375\n",
      "Batch: 96, Loss: 0.6630174517631531, Accuracy: 0.78125\n",
      "Batch: 97, Loss: 0.5517390966415405, Accuracy: 0.80859375\n",
      "Batch: 98, Loss: 0.6494429707527161, Accuracy: 0.7783203125\n",
      "Batch: 99, Loss: 0.6819638013839722, Accuracy: 0.7900390625\n",
      "Batch: 100, Loss: 0.6931559443473816, Accuracy: 0.7646484375\n",
      "Batch: 101, Loss: 0.7220393419265747, Accuracy: 0.763671875\n",
      "Batch: 102, Loss: 0.6585046052932739, Accuracy: 0.78515625\n",
      "Batch: 103, Loss: 0.6952800750732422, Accuracy: 0.7861328125\n",
      "Batch: 104, Loss: 0.6490402221679688, Accuracy: 0.78515625\n",
      "Batch: 105, Loss: 0.7207331657409668, Accuracy: 0.7587890625\n",
      "Batch: 106, Loss: 0.6573323607444763, Accuracy: 0.78515625\n",
      "Batch: 107, Loss: 0.6918982267379761, Accuracy: 0.779296875\n",
      "Batch: 108, Loss: 0.6782008409500122, Accuracy: 0.7734375\n",
      "Batch: 109, Loss: 0.8053042888641357, Accuracy: 0.740234375\n",
      "Batch: 110, Loss: 0.6910148859024048, Accuracy: 0.7724609375\n",
      "Batch: 111, Loss: 0.7001306414604187, Accuracy: 0.7626953125\n",
      "Batch: 112, Loss: 0.6625603437423706, Accuracy: 0.7978515625\n",
      "Batch: 113, Loss: 0.6773756742477417, Accuracy: 0.78125\n",
      "Batch: 114, Loss: 0.7320062518119812, Accuracy: 0.7568359375\n",
      "Batch: 115, Loss: 0.8125250339508057, Accuracy: 0.736328125\n",
      "Batch: 116, Loss: 0.7557912468910217, Accuracy: 0.7607421875\n",
      "Batch: 117, Loss: 0.7118785977363586, Accuracy: 0.7744140625\n",
      "Batch: 118, Loss: 0.6123822927474976, Accuracy: 0.8056640625\n",
      "Batch: 119, Loss: 0.5624059438705444, Accuracy: 0.8056640625\n",
      "Batch: 120, Loss: 0.7445410490036011, Accuracy: 0.7490234375\n",
      "Batch: 121, Loss: 0.7412426471710205, Accuracy: 0.759765625\n",
      "Batch: 122, Loss: 0.6789542436599731, Accuracy: 0.7890625\n",
      "Batch: 123, Loss: 0.6481071710586548, Accuracy: 0.7890625\n",
      "Batch: 124, Loss: 0.6902784705162048, Accuracy: 0.7841796875\n",
      "Batch: 125, Loss: 0.742527425289154, Accuracy: 0.7666015625\n",
      "Batch: 126, Loss: 0.7583322525024414, Accuracy: 0.7529296875\n",
      "Batch: 127, Loss: 0.5963733196258545, Accuracy: 0.8134765625\n",
      "Batch: 128, Loss: 0.7836511731147766, Accuracy: 0.755859375\n",
      "Batch: 129, Loss: 0.6502066850662231, Accuracy: 0.7900390625\n",
      "Batch: 130, Loss: 0.8051403760910034, Accuracy: 0.7333984375\n",
      "Batch: 131, Loss: 0.6659938097000122, Accuracy: 0.7724609375\n",
      "Batch: 132, Loss: 0.7421103119850159, Accuracy: 0.7685546875\n",
      "Batch: 133, Loss: 0.6664470434188843, Accuracy: 0.78125\n",
      "Batch: 134, Loss: 0.7108749151229858, Accuracy: 0.75390625\n",
      "Batch: 135, Loss: 0.6564713716506958, Accuracy: 0.7880859375\n",
      "Batch: 136, Loss: 0.7122634053230286, Accuracy: 0.7802734375\n",
      "Batch: 139, Loss: 0.6490654945373535, Accuracy: 0.7841796875\n",
      "Batch: 140, Loss: 0.7205685973167419, Accuracy: 0.767578125\n",
      "Batch: 141, Loss: 0.7332111597061157, Accuracy: 0.759765625\n",
      "Batch: 142, Loss: 0.7410907745361328, Accuracy: 0.763671875\n",
      "Batch: 143, Loss: 0.7050787210464478, Accuracy: 0.7685546875\n",
      "Batch: 144, Loss: 0.7056021690368652, Accuracy: 0.7646484375\n",
      "Batch: 145, Loss: 0.6810206770896912, Accuracy: 0.7646484375\n",
      "Batch: 146, Loss: 0.7241624593734741, Accuracy: 0.7607421875\n",
      "Batch: 147, Loss: 0.7573680281639099, Accuracy: 0.7578125\n",
      "Batch: 148, Loss: 0.7719747424125671, Accuracy: 0.740234375\n",
      "Batch: 149, Loss: 0.6836350560188293, Accuracy: 0.7783203125\n",
      "Batch: 150, Loss: 0.6844555139541626, Accuracy: 0.76171875\n",
      "Batch: 151, Loss: 0.6354073882102966, Accuracy: 0.8037109375\n",
      "Saved Weights at epoch 60 to file Weights_60.h5\n",
      "Epoch 61/80\n",
      "Batch: 1, Loss: 0.9213488698005676, Accuracy: 0.7021484375\n",
      "Batch: 2, Loss: 0.769344687461853, Accuracy: 0.7373046875\n",
      "Batch: 3, Loss: 0.6547755002975464, Accuracy: 0.78125\n",
      "Batch: 4, Loss: 0.6200259923934937, Accuracy: 0.798828125\n",
      "Batch: 5, Loss: 0.6673913598060608, Accuracy: 0.783203125\n",
      "Batch: 6, Loss: 0.7048354744911194, Accuracy: 0.7607421875\n",
      "Batch: 7, Loss: 0.7394239902496338, Accuracy: 0.7509765625\n",
      "Batch: 8, Loss: 0.6672968864440918, Accuracy: 0.76953125\n",
      "Batch: 9, Loss: 0.6416825652122498, Accuracy: 0.7900390625\n",
      "Batch: 10, Loss: 0.6593907475471497, Accuracy: 0.767578125\n",
      "Batch: 11, Loss: 0.7947285175323486, Accuracy: 0.7138671875\n",
      "Batch: 12, Loss: 0.7542027235031128, Accuracy: 0.7626953125\n",
      "Batch: 13, Loss: 0.5564711093902588, Accuracy: 0.814453125\n",
      "Batch: 14, Loss: 0.7806922197341919, Accuracy: 0.7314453125\n",
      "Batch: 15, Loss: 0.6582848429679871, Accuracy: 0.7958984375\n",
      "Batch: 16, Loss: 0.7009308338165283, Accuracy: 0.7890625\n",
      "Batch: 17, Loss: 0.730908989906311, Accuracy: 0.748046875\n",
      "Batch: 18, Loss: 0.717871904373169, Accuracy: 0.7734375\n",
      "Batch: 19, Loss: 0.7408766150474548, Accuracy: 0.7607421875\n",
      "Batch: 20, Loss: 0.6130808591842651, Accuracy: 0.8115234375\n",
      "Batch: 21, Loss: 0.6483991146087646, Accuracy: 0.7744140625\n",
      "Batch: 22, Loss: 0.7675262689590454, Accuracy: 0.7734375\n",
      "Batch: 23, Loss: 0.7237740755081177, Accuracy: 0.76171875\n",
      "Batch: 24, Loss: 0.7438855171203613, Accuracy: 0.7509765625\n",
      "Batch: 25, Loss: 0.6804239749908447, Accuracy: 0.7734375\n",
      "Batch: 26, Loss: 0.6208365559577942, Accuracy: 0.8017578125\n",
      "Batch: 27, Loss: 0.6503528356552124, Accuracy: 0.787109375\n",
      "Batch: 28, Loss: 0.708851158618927, Accuracy: 0.7607421875\n",
      "Batch: 29, Loss: 0.6893059015274048, Accuracy: 0.7685546875\n",
      "Batch: 30, Loss: 0.612459659576416, Accuracy: 0.8125\n",
      "Batch: 31, Loss: 0.632483720779419, Accuracy: 0.7763671875\n",
      "Batch: 32, Loss: 0.646359920501709, Accuracy: 0.7783203125\n",
      "Batch: 34, Loss: 0.7706377506256104, Accuracy: 0.751953125\n",
      "Batch: 35, Loss: 0.7401247024536133, Accuracy: 0.7578125\n",
      "Batch: 36, Loss: 0.7154839038848877, Accuracy: 0.771484375\n",
      "Batch: 37, Loss: 0.6726637482643127, Accuracy: 0.775390625\n",
      "Batch: 38, Loss: 0.7154009342193604, Accuracy: 0.755859375\n",
      "Batch: 39, Loss: 0.7331219911575317, Accuracy: 0.76171875\n",
      "Batch: 40, Loss: 0.6549059152603149, Accuracy: 0.7890625\n",
      "Batch: 41, Loss: 0.6699510812759399, Accuracy: 0.7685546875\n",
      "Batch: 42, Loss: 0.539006233215332, Accuracy: 0.8173828125\n",
      "Batch: 43, Loss: 0.7196483612060547, Accuracy: 0.759765625\n",
      "Batch: 44, Loss: 0.7139496207237244, Accuracy: 0.7548828125\n",
      "Batch: 45, Loss: 0.6199268698692322, Accuracy: 0.783203125\n",
      "Batch: 46, Loss: 0.6327877044677734, Accuracy: 0.7958984375\n",
      "Batch: 47, Loss: 0.6805543303489685, Accuracy: 0.7880859375\n",
      "Batch: 48, Loss: 0.6194908022880554, Accuracy: 0.7958984375\n",
      "Batch: 49, Loss: 0.7348318696022034, Accuracy: 0.765625\n",
      "Batch: 50, Loss: 0.7193976640701294, Accuracy: 0.7646484375\n",
      "Batch: 51, Loss: 0.6920127868652344, Accuracy: 0.7734375\n",
      "Batch: 52, Loss: 0.7127639055252075, Accuracy: 0.7841796875\n",
      "Batch: 53, Loss: 0.6338362693786621, Accuracy: 0.79296875\n",
      "Batch: 54, Loss: 0.6583441495895386, Accuracy: 0.7890625\n",
      "Batch: 55, Loss: 0.7505249977111816, Accuracy: 0.744140625\n",
      "Batch: 56, Loss: 0.7574887871742249, Accuracy: 0.74609375\n",
      "Batch: 57, Loss: 0.7355035543441772, Accuracy: 0.765625\n",
      "Batch: 58, Loss: 0.7585110664367676, Accuracy: 0.7568359375\n",
      "Batch: 59, Loss: 0.6748660802841187, Accuracy: 0.775390625\n",
      "Batch: 60, Loss: 0.6587113738059998, Accuracy: 0.7890625\n",
      "Batch: 61, Loss: 0.7260413765907288, Accuracy: 0.7734375\n",
      "Batch: 62, Loss: 0.6758262515068054, Accuracy: 0.7783203125\n",
      "Batch: 63, Loss: 0.7592645883560181, Accuracy: 0.744140625\n",
      "Batch: 64, Loss: 0.7298095226287842, Accuracy: 0.7548828125\n",
      "Batch: 65, Loss: 0.7102454900741577, Accuracy: 0.7685546875\n",
      "Batch: 66, Loss: 0.6662177443504333, Accuracy: 0.7802734375\n",
      "Batch: 67, Loss: 0.801315426826477, Accuracy: 0.7470703125\n",
      "Batch: 68, Loss: 0.7994988560676575, Accuracy: 0.755859375\n",
      "Batch: 69, Loss: 0.748990535736084, Accuracy: 0.7509765625\n",
      "Batch: 70, Loss: 0.6901793479919434, Accuracy: 0.779296875\n",
      "Batch: 71, Loss: 0.7270032167434692, Accuracy: 0.7587890625\n",
      "Batch: 72, Loss: 0.6195869445800781, Accuracy: 0.7880859375\n",
      "Batch: 73, Loss: 0.6497931480407715, Accuracy: 0.79296875\n",
      "Batch: 74, Loss: 0.6089251637458801, Accuracy: 0.810546875\n",
      "Batch: 75, Loss: 0.6402720808982849, Accuracy: 0.7822265625\n",
      "Batch: 76, Loss: 0.6785486936569214, Accuracy: 0.76953125\n",
      "Batch: 77, Loss: 0.617488443851471, Accuracy: 0.8017578125\n",
      "Batch: 78, Loss: 0.6357121467590332, Accuracy: 0.794921875\n",
      "Batch: 79, Loss: 0.6330094337463379, Accuracy: 0.7919921875\n",
      "Batch: 80, Loss: 0.6409169435501099, Accuracy: 0.7880859375\n",
      "Batch: 82, Loss: 0.7108703851699829, Accuracy: 0.751953125\n",
      "Batch: 83, Loss: 0.6029304265975952, Accuracy: 0.7998046875\n",
      "Batch: 84, Loss: 0.6214476823806763, Accuracy: 0.7958984375\n",
      "Batch: 85, Loss: 0.650423526763916, Accuracy: 0.8017578125\n",
      "Batch: 86, Loss: 0.7960515022277832, Accuracy: 0.7529296875\n",
      "Batch: 87, Loss: 0.6316545009613037, Accuracy: 0.7978515625\n",
      "Batch: 88, Loss: 0.7477827668190002, Accuracy: 0.763671875\n",
      "Batch: 89, Loss: 0.6658310890197754, Accuracy: 0.787109375\n",
      "Batch: 90, Loss: 0.6437528133392334, Accuracy: 0.791015625\n",
      "Batch: 91, Loss: 0.6705123782157898, Accuracy: 0.78125\n",
      "Batch: 92, Loss: 0.6853586435317993, Accuracy: 0.7724609375\n",
      "Batch: 93, Loss: 0.7038926482200623, Accuracy: 0.7763671875\n",
      "Batch: 94, Loss: 0.7263959646224976, Accuracy: 0.7529296875\n",
      "Batch: 95, Loss: 0.738601565361023, Accuracy: 0.7509765625\n",
      "Batch: 96, Loss: 0.6774544715881348, Accuracy: 0.76171875\n",
      "Batch: 97, Loss: 0.5420046448707581, Accuracy: 0.818359375\n",
      "Batch: 98, Loss: 0.6492262482643127, Accuracy: 0.7900390625\n",
      "Batch: 99, Loss: 0.6756671667098999, Accuracy: 0.767578125\n",
      "Batch: 100, Loss: 0.713421106338501, Accuracy: 0.771484375\n",
      "Batch: 101, Loss: 0.7400658130645752, Accuracy: 0.7626953125\n",
      "Batch: 102, Loss: 0.6651468873023987, Accuracy: 0.7822265625\n",
      "Batch: 103, Loss: 0.6826517581939697, Accuracy: 0.783203125\n",
      "Batch: 104, Loss: 0.655938982963562, Accuracy: 0.7783203125\n",
      "Batch: 105, Loss: 0.7077632546424866, Accuracy: 0.7685546875\n",
      "Batch: 106, Loss: 0.6712281107902527, Accuracy: 0.7646484375\n",
      "Batch: 107, Loss: 0.7110280990600586, Accuracy: 0.7822265625\n",
      "Batch: 108, Loss: 0.6685635447502136, Accuracy: 0.7763671875\n",
      "Batch: 109, Loss: 0.764999270439148, Accuracy: 0.7421875\n",
      "Batch: 110, Loss: 0.6642906665802002, Accuracy: 0.7705078125\n",
      "Batch: 111, Loss: 0.6937925219535828, Accuracy: 0.7724609375\n",
      "Batch: 112, Loss: 0.6592498421669006, Accuracy: 0.7880859375\n",
      "Batch: 113, Loss: 0.6954899430274963, Accuracy: 0.759765625\n",
      "Batch: 114, Loss: 0.7562977075576782, Accuracy: 0.744140625\n",
      "Batch: 115, Loss: 0.837333083152771, Accuracy: 0.7451171875\n",
      "Batch: 116, Loss: 0.751448392868042, Accuracy: 0.748046875\n",
      "Batch: 117, Loss: 0.681732177734375, Accuracy: 0.783203125\n",
      "Batch: 118, Loss: 0.6221870183944702, Accuracy: 0.806640625\n",
      "Batch: 119, Loss: 0.5726156830787659, Accuracy: 0.8037109375\n",
      "Batch: 120, Loss: 0.7316645979881287, Accuracy: 0.7587890625\n",
      "Batch: 121, Loss: 0.7232949733734131, Accuracy: 0.7685546875\n",
      "Batch: 122, Loss: 0.6750454306602478, Accuracy: 0.7744140625\n",
      "Batch: 123, Loss: 0.658954381942749, Accuracy: 0.783203125\n",
      "Batch: 124, Loss: 0.6952767968177795, Accuracy: 0.787109375\n",
      "Batch: 125, Loss: 0.7635270357131958, Accuracy: 0.7529296875\n",
      "Batch: 126, Loss: 0.7378284931182861, Accuracy: 0.7509765625\n",
      "Batch: 127, Loss: 0.6112527847290039, Accuracy: 0.8115234375\n",
      "Batch: 128, Loss: 0.7806296348571777, Accuracy: 0.765625\n",
      "Batch: 129, Loss: 0.6521477103233337, Accuracy: 0.7783203125\n",
      "Batch: 130, Loss: 0.8011182546615601, Accuracy: 0.7431640625\n",
      "Batch: 131, Loss: 0.6566667556762695, Accuracy: 0.79296875\n",
      "Batch: 132, Loss: 0.7269819378852844, Accuracy: 0.7626953125\n",
      "Batch: 133, Loss: 0.6742775440216064, Accuracy: 0.779296875\n",
      "Batch: 134, Loss: 0.7076568007469177, Accuracy: 0.763671875\n",
      "Batch: 135, Loss: 0.6621013879776001, Accuracy: 0.775390625\n",
      "Batch: 136, Loss: 0.7240287065505981, Accuracy: 0.76171875\n",
      "Batch: 137, Loss: 0.7080156803131104, Accuracy: 0.759765625\n",
      "Batch: 138, Loss: 0.6386239528656006, Accuracy: 0.7783203125\n",
      "Batch: 139, Loss: 0.6620688438415527, Accuracy: 0.78125\n",
      "Batch: 140, Loss: 0.7234002351760864, Accuracy: 0.76171875\n",
      "Batch: 141, Loss: 0.7598066329956055, Accuracy: 0.7529296875\n",
      "Batch: 142, Loss: 0.776106059551239, Accuracy: 0.748046875\n",
      "Batch: 143, Loss: 0.6859805583953857, Accuracy: 0.77734375\n",
      "Batch: 144, Loss: 0.7139782905578613, Accuracy: 0.7548828125\n",
      "Batch: 145, Loss: 0.6728266477584839, Accuracy: 0.765625\n",
      "Batch: 146, Loss: 0.7320281863212585, Accuracy: 0.7646484375\n",
      "Batch: 147, Loss: 0.7304415702819824, Accuracy: 0.763671875\n",
      "Batch: 148, Loss: 0.8064226508140564, Accuracy: 0.7265625\n",
      "Batch: 149, Loss: 0.6768791079521179, Accuracy: 0.76953125\n",
      "Batch: 150, Loss: 0.6787904500961304, Accuracy: 0.7783203125\n",
      "Batch: 151, Loss: 0.6330437064170837, Accuracy: 0.7919921875\n",
      "Epoch 62/80\n",
      "Batch: 1, Loss: 0.9225308895111084, Accuracy: 0.7158203125\n",
      "Batch: 2, Loss: 0.7797126770019531, Accuracy: 0.7177734375\n",
      "Batch: 3, Loss: 0.6739378571510315, Accuracy: 0.767578125\n",
      "Batch: 4, Loss: 0.6214594841003418, Accuracy: 0.7939453125\n",
      "Batch: 5, Loss: 0.6669039726257324, Accuracy: 0.7734375\n",
      "Batch: 6, Loss: 0.7299578189849854, Accuracy: 0.75\n",
      "Batch: 7, Loss: 0.7417725324630737, Accuracy: 0.73828125\n",
      "Batch: 8, Loss: 0.6661712527275085, Accuracy: 0.775390625\n",
      "Batch: 9, Loss: 0.6515796184539795, Accuracy: 0.7880859375\n",
      "Batch: 10, Loss: 0.6262381672859192, Accuracy: 0.7783203125\n",
      "Batch: 11, Loss: 0.7647671699523926, Accuracy: 0.720703125\n",
      "Batch: 12, Loss: 0.7446695566177368, Accuracy: 0.7607421875\n",
      "Batch: 13, Loss: 0.5605055093765259, Accuracy: 0.8095703125\n",
      "Batch: 14, Loss: 0.7343423366546631, Accuracy: 0.7548828125\n",
      "Batch: 15, Loss: 0.6291359066963196, Accuracy: 0.794921875\n",
      "Batch: 16, Loss: 0.6700928211212158, Accuracy: 0.783203125\n",
      "Batch: 17, Loss: 0.7229071259498596, Accuracy: 0.76171875\n",
      "Batch: 18, Loss: 0.710425078868866, Accuracy: 0.74609375\n",
      "Batch: 19, Loss: 0.7183152437210083, Accuracy: 0.77734375\n",
      "Batch: 20, Loss: 0.630536675453186, Accuracy: 0.802734375\n",
      "Batch: 21, Loss: 0.6584644317626953, Accuracy: 0.7724609375\n",
      "Batch: 22, Loss: 0.7741843461990356, Accuracy: 0.7607421875\n",
      "Batch: 23, Loss: 0.7348878383636475, Accuracy: 0.759765625\n",
      "Batch: 24, Loss: 0.7220813035964966, Accuracy: 0.7607421875\n",
      "Batch: 25, Loss: 0.7036113142967224, Accuracy: 0.7783203125\n",
      "Batch: 28, Loss: 0.7155648469924927, Accuracy: 0.75\n",
      "Batch: 29, Loss: 0.6575416326522827, Accuracy: 0.7861328125\n",
      "Batch: 30, Loss: 0.5955934524536133, Accuracy: 0.806640625\n",
      "Batch: 31, Loss: 0.6242876052856445, Accuracy: 0.7998046875\n",
      "Batch: 32, Loss: 0.6482948064804077, Accuracy: 0.771484375\n",
      "Batch: 33, Loss: 0.7405007481575012, Accuracy: 0.771484375\n",
      "Batch: 34, Loss: 0.7557891011238098, Accuracy: 0.7578125\n",
      "Batch: 35, Loss: 0.7244148850440979, Accuracy: 0.7509765625\n",
      "Batch: 36, Loss: 0.7224975824356079, Accuracy: 0.7783203125\n",
      "Batch: 37, Loss: 0.7120736837387085, Accuracy: 0.7744140625\n",
      "Batch: 38, Loss: 0.7235500812530518, Accuracy: 0.7509765625\n",
      "Batch: 39, Loss: 0.7398542165756226, Accuracy: 0.759765625\n",
      "Batch: 40, Loss: 0.6879143714904785, Accuracy: 0.7705078125\n",
      "Batch: 41, Loss: 0.6783621311187744, Accuracy: 0.7685546875\n",
      "Batch: 42, Loss: 0.5300581455230713, Accuracy: 0.8232421875\n",
      "Batch: 43, Loss: 0.6930956244468689, Accuracy: 0.765625\n",
      "Batch: 44, Loss: 0.714514970779419, Accuracy: 0.7529296875\n",
      "Batch: 45, Loss: 0.6113985776901245, Accuracy: 0.798828125\n",
      "Batch: 46, Loss: 0.5998975038528442, Accuracy: 0.80078125\n",
      "Batch: 47, Loss: 0.6754854917526245, Accuracy: 0.7802734375\n",
      "Batch: 48, Loss: 0.6358746290206909, Accuracy: 0.7861328125\n",
      "Batch: 49, Loss: 0.7415721416473389, Accuracy: 0.7626953125\n",
      "Batch: 50, Loss: 0.6992685794830322, Accuracy: 0.7763671875\n",
      "Batch: 51, Loss: 0.6928313970565796, Accuracy: 0.7705078125\n",
      "Batch: 52, Loss: 0.7284184098243713, Accuracy: 0.76953125\n",
      "Batch: 53, Loss: 0.6191608905792236, Accuracy: 0.802734375\n",
      "Batch: 54, Loss: 0.6691000461578369, Accuracy: 0.7734375\n",
      "Batch: 55, Loss: 0.7625555396080017, Accuracy: 0.7373046875\n",
      "Batch: 56, Loss: 0.7539353370666504, Accuracy: 0.74609375\n",
      "Batch: 57, Loss: 0.7116076946258545, Accuracy: 0.7626953125\n",
      "Batch: 58, Loss: 0.7648947834968567, Accuracy: 0.7578125\n",
      "Batch: 59, Loss: 0.6573942303657532, Accuracy: 0.7841796875\n",
      "Batch: 60, Loss: 0.661106288433075, Accuracy: 0.779296875\n",
      "Batch: 61, Loss: 0.7310779094696045, Accuracy: 0.7646484375\n",
      "Batch: 62, Loss: 0.6903437376022339, Accuracy: 0.7724609375\n",
      "Batch: 63, Loss: 0.7370107173919678, Accuracy: 0.7607421875\n",
      "Batch: 64, Loss: 0.6925804615020752, Accuracy: 0.759765625\n",
      "Batch: 65, Loss: 0.6742079257965088, Accuracy: 0.78515625\n",
      "Batch: 66, Loss: 0.6995279788970947, Accuracy: 0.7763671875\n",
      "Batch: 67, Loss: 0.7624958753585815, Accuracy: 0.7607421875\n",
      "Batch: 68, Loss: 0.7913875579833984, Accuracy: 0.732421875\n",
      "Batch: 69, Loss: 0.7072910070419312, Accuracy: 0.759765625\n",
      "Batch: 70, Loss: 0.6624424457550049, Accuracy: 0.794921875\n",
      "Batch: 71, Loss: 0.7248149514198303, Accuracy: 0.7509765625\n",
      "Batch: 74, Loss: 0.6133161783218384, Accuracy: 0.80078125\n",
      "Batch: 75, Loss: 0.6372562646865845, Accuracy: 0.7880859375\n",
      "Batch: 76, Loss: 0.6505318880081177, Accuracy: 0.7822265625\n",
      "Batch: 77, Loss: 0.5933270454406738, Accuracy: 0.81640625\n",
      "Batch: 78, Loss: 0.5963535308837891, Accuracy: 0.798828125\n",
      "Batch: 79, Loss: 0.6091114282608032, Accuracy: 0.7939453125\n",
      "Batch: 80, Loss: 0.6186157464981079, Accuracy: 0.7841796875\n",
      "Batch: 81, Loss: 0.7643144130706787, Accuracy: 0.7275390625\n",
      "Batch: 82, Loss: 0.683954656124115, Accuracy: 0.7705078125\n",
      "Batch: 83, Loss: 0.6110478639602661, Accuracy: 0.80859375\n",
      "Batch: 84, Loss: 0.6550116539001465, Accuracy: 0.787109375\n",
      "Batch: 85, Loss: 0.674675464630127, Accuracy: 0.7890625\n",
      "Batch: 86, Loss: 0.7779026031494141, Accuracy: 0.755859375\n",
      "Batch: 87, Loss: 0.6543426513671875, Accuracy: 0.787109375\n",
      "Batch: 88, Loss: 0.6985793113708496, Accuracy: 0.7822265625\n",
      "Batch: 89, Loss: 0.6747736930847168, Accuracy: 0.775390625\n",
      "Batch: 90, Loss: 0.6152461767196655, Accuracy: 0.802734375\n",
      "Batch: 91, Loss: 0.6530346870422363, Accuracy: 0.7919921875\n",
      "Batch: 92, Loss: 0.7218673825263977, Accuracy: 0.7705078125\n",
      "Batch: 93, Loss: 0.6849457025527954, Accuracy: 0.779296875\n",
      "Batch: 94, Loss: 0.6807787418365479, Accuracy: 0.7744140625\n",
      "Batch: 95, Loss: 0.7339596748352051, Accuracy: 0.7568359375\n",
      "Batch: 96, Loss: 0.6735448837280273, Accuracy: 0.771484375\n",
      "Batch: 97, Loss: 0.5693094730377197, Accuracy: 0.80078125\n",
      "Batch: 98, Loss: 0.6357994079589844, Accuracy: 0.7919921875\n",
      "Batch: 99, Loss: 0.6669834852218628, Accuracy: 0.7861328125\n",
      "Batch: 100, Loss: 0.6927460432052612, Accuracy: 0.7763671875\n",
      "Batch: 101, Loss: 0.6994302272796631, Accuracy: 0.7685546875\n",
      "Batch: 102, Loss: 0.6668474674224854, Accuracy: 0.78125\n",
      "Batch: 103, Loss: 0.7063692212104797, Accuracy: 0.76953125\n",
      "Batch: 104, Loss: 0.6482632160186768, Accuracy: 0.77734375\n",
      "Batch: 105, Loss: 0.7019887566566467, Accuracy: 0.7666015625\n",
      "Batch: 106, Loss: 0.6566805839538574, Accuracy: 0.77734375\n",
      "Batch: 107, Loss: 0.6934541463851929, Accuracy: 0.7705078125\n",
      "Batch: 108, Loss: 0.6525987386703491, Accuracy: 0.7783203125\n",
      "Batch: 109, Loss: 0.7456732988357544, Accuracy: 0.7529296875\n",
      "Batch: 110, Loss: 0.6790035963058472, Accuracy: 0.7734375\n",
      "Batch: 111, Loss: 0.678925096988678, Accuracy: 0.7841796875\n",
      "Batch: 112, Loss: 0.6693142652511597, Accuracy: 0.775390625\n",
      "Batch: 113, Loss: 0.7159099578857422, Accuracy: 0.76171875\n",
      "Batch: 114, Loss: 0.7737686634063721, Accuracy: 0.763671875\n",
      "Batch: 115, Loss: 0.7832255363464355, Accuracy: 0.7373046875\n",
      "Batch: 116, Loss: 0.724148154258728, Accuracy: 0.767578125\n",
      "Batch: 117, Loss: 0.7028015851974487, Accuracy: 0.763671875\n",
      "Batch: 118, Loss: 0.5939748287200928, Accuracy: 0.8154296875\n",
      "Batch: 119, Loss: 0.5818294286727905, Accuracy: 0.810546875\n",
      "Batch: 120, Loss: 0.7014958262443542, Accuracy: 0.759765625\n",
      "Batch: 121, Loss: 0.745540976524353, Accuracy: 0.7646484375\n",
      "Batch: 122, Loss: 0.6540772914886475, Accuracy: 0.79296875\n",
      "Batch: 123, Loss: 0.6706253886222839, Accuracy: 0.7861328125\n",
      "Batch: 124, Loss: 0.6982863545417786, Accuracy: 0.775390625\n",
      "Batch: 125, Loss: 0.7644731998443604, Accuracy: 0.7509765625\n",
      "Batch: 126, Loss: 0.7429103255271912, Accuracy: 0.75390625\n",
      "Batch: 127, Loss: 0.5843719840049744, Accuracy: 0.8212890625\n",
      "Batch: 128, Loss: 0.7645413279533386, Accuracy: 0.7666015625\n",
      "Batch: 129, Loss: 0.6354362964630127, Accuracy: 0.78515625\n",
      "Batch: 130, Loss: 0.7535932064056396, Accuracy: 0.7529296875\n",
      "Batch: 131, Loss: 0.6914548873901367, Accuracy: 0.7666015625\n",
      "Batch: 132, Loss: 0.7540774345397949, Accuracy: 0.7548828125\n",
      "Batch: 133, Loss: 0.6501318216323853, Accuracy: 0.7939453125\n",
      "Batch: 134, Loss: 0.7109128832817078, Accuracy: 0.759765625\n",
      "Batch: 135, Loss: 0.6636142730712891, Accuracy: 0.7763671875\n",
      "Batch: 136, Loss: 0.7133511900901794, Accuracy: 0.7734375\n",
      "Batch: 137, Loss: 0.7496566772460938, Accuracy: 0.7421875\n",
      "Batch: 138, Loss: 0.6563947200775146, Accuracy: 0.783203125\n",
      "Batch: 139, Loss: 0.7455059289932251, Accuracy: 0.765625\n",
      "Batch: 140, Loss: 0.7402130961418152, Accuracy: 0.7685546875\n",
      "Batch: 141, Loss: 0.7745727896690369, Accuracy: 0.740234375\n",
      "Batch: 142, Loss: 0.7509710192680359, Accuracy: 0.759765625\n",
      "Batch: 143, Loss: 0.6859201192855835, Accuracy: 0.775390625\n",
      "Batch: 144, Loss: 0.6877759695053101, Accuracy: 0.7685546875\n",
      "Batch: 145, Loss: 0.6608712673187256, Accuracy: 0.7861328125\n",
      "Batch: 146, Loss: 0.7303363084793091, Accuracy: 0.76171875\n",
      "Batch: 147, Loss: 0.7332181930541992, Accuracy: 0.7451171875\n",
      "Batch: 148, Loss: 0.7644192576408386, Accuracy: 0.734375\n",
      "Batch: 149, Loss: 0.6835496425628662, Accuracy: 0.765625\n",
      "Batch: 150, Loss: 0.6986069083213806, Accuracy: 0.767578125\n",
      "Batch: 151, Loss: 0.623322606086731, Accuracy: 0.798828125\n",
      "Epoch 63/80\n",
      "Batch: 1, Loss: 0.93072909116745, Accuracy: 0.7001953125\n",
      "Batch: 2, Loss: 0.7881202697753906, Accuracy: 0.734375\n",
      "Batch: 3, Loss: 0.7047475576400757, Accuracy: 0.7685546875\n",
      "Batch: 4, Loss: 0.6281338930130005, Accuracy: 0.7998046875\n",
      "Batch: 5, Loss: 0.7107077836990356, Accuracy: 0.7763671875\n",
      "Batch: 6, Loss: 0.714164137840271, Accuracy: 0.755859375\n",
      "Batch: 7, Loss: 0.7369534969329834, Accuracy: 0.7333984375\n",
      "Batch: 8, Loss: 0.6756657361984253, Accuracy: 0.7802734375\n",
      "Batch: 9, Loss: 0.6496487855911255, Accuracy: 0.7783203125\n",
      "Batch: 10, Loss: 0.6172240972518921, Accuracy: 0.78125\n",
      "Batch: 11, Loss: 0.7836794257164001, Accuracy: 0.7265625\n",
      "Batch: 12, Loss: 0.7502279281616211, Accuracy: 0.7705078125\n",
      "Batch: 13, Loss: 0.5521089434623718, Accuracy: 0.81640625\n",
      "Batch: 14, Loss: 0.7458789944648743, Accuracy: 0.7587890625\n",
      "Batch: 15, Loss: 0.6409898996353149, Accuracy: 0.80078125\n",
      "Batch: 16, Loss: 0.6648209691047668, Accuracy: 0.802734375\n",
      "Batch: 17, Loss: 0.7198877334594727, Accuracy: 0.7626953125\n",
      "Batch: 18, Loss: 0.7174060940742493, Accuracy: 0.763671875\n",
      "Batch: 19, Loss: 0.7316157817840576, Accuracy: 0.7744140625\n",
      "Batch: 20, Loss: 0.6371638178825378, Accuracy: 0.7958984375\n",
      "Batch: 21, Loss: 0.6303939819335938, Accuracy: 0.79296875\n",
      "Batch: 22, Loss: 0.7878537178039551, Accuracy: 0.7607421875\n",
      "Batch: 23, Loss: 0.7144156098365784, Accuracy: 0.755859375\n",
      "Batch: 24, Loss: 0.712266206741333, Accuracy: 0.7548828125\n",
      "Batch: 25, Loss: 0.6430106163024902, Accuracy: 0.7939453125\n",
      "Batch: 26, Loss: 0.5949819684028625, Accuracy: 0.8076171875\n",
      "Batch: 27, Loss: 0.6384725570678711, Accuracy: 0.7890625\n",
      "Batch: 28, Loss: 0.7183058261871338, Accuracy: 0.755859375\n",
      "Batch: 29, Loss: 0.6853442192077637, Accuracy: 0.7724609375\n",
      "Batch: 30, Loss: 0.6229736804962158, Accuracy: 0.8076171875\n",
      "Batch: 31, Loss: 0.6389524340629578, Accuracy: 0.7880859375\n",
      "Batch: 32, Loss: 0.6537446975708008, Accuracy: 0.7685546875\n",
      "Batch: 33, Loss: 0.7384096384048462, Accuracy: 0.7705078125\n",
      "Batch: 34, Loss: 0.7531068325042725, Accuracy: 0.7451171875\n",
      "Batch: 35, Loss: 0.7408841848373413, Accuracy: 0.7568359375\n",
      "Batch: 36, Loss: 0.7663913369178772, Accuracy: 0.7607421875\n",
      "Batch: 37, Loss: 0.6693030595779419, Accuracy: 0.7822265625\n",
      "Batch: 38, Loss: 0.6925855875015259, Accuracy: 0.7626953125\n",
      "Batch: 39, Loss: 0.7080068588256836, Accuracy: 0.75\n",
      "Batch: 40, Loss: 0.6878607273101807, Accuracy: 0.7724609375\n",
      "Batch: 41, Loss: 0.6300035715103149, Accuracy: 0.7880859375\n",
      "Batch: 42, Loss: 0.5348274111747742, Accuracy: 0.8212890625\n",
      "Batch: 43, Loss: 0.6843029260635376, Accuracy: 0.78125\n",
      "Batch: 44, Loss: 0.6996901631355286, Accuracy: 0.765625\n",
      "Batch: 45, Loss: 0.6068665981292725, Accuracy: 0.7919921875\n",
      "Batch: 46, Loss: 0.6039835214614868, Accuracy: 0.8037109375\n",
      "Batch: 47, Loss: 0.6669478416442871, Accuracy: 0.7958984375\n",
      "Batch: 48, Loss: 0.6091639995574951, Accuracy: 0.7900390625\n",
      "Batch: 49, Loss: 0.7219377160072327, Accuracy: 0.7587890625\n",
      "Batch: 50, Loss: 0.6897559762001038, Accuracy: 0.7744140625\n",
      "Batch: 51, Loss: 0.6593184471130371, Accuracy: 0.7802734375\n",
      "Batch: 52, Loss: 0.6823519468307495, Accuracy: 0.78125\n",
      "Batch: 53, Loss: 0.616904616355896, Accuracy: 0.7958984375\n",
      "Batch: 54, Loss: 0.6759383678436279, Accuracy: 0.779296875\n",
      "Batch: 55, Loss: 0.7748703360557556, Accuracy: 0.7353515625\n",
      "Batch: 56, Loss: 0.7204453945159912, Accuracy: 0.7587890625\n",
      "Batch: 57, Loss: 0.7351895570755005, Accuracy: 0.7734375\n",
      "Batch: 58, Loss: 0.7700241804122925, Accuracy: 0.7490234375\n",
      "Batch: 59, Loss: 0.6604129076004028, Accuracy: 0.783203125\n",
      "Batch: 60, Loss: 0.6660956144332886, Accuracy: 0.7744140625\n",
      "Batch: 61, Loss: 0.7462792992591858, Accuracy: 0.76171875\n",
      "Batch: 64, Loss: 0.6932688355445862, Accuracy: 0.775390625\n",
      "Batch: 65, Loss: 0.6751530766487122, Accuracy: 0.779296875\n",
      "Batch: 66, Loss: 0.6878140568733215, Accuracy: 0.7841796875\n",
      "Batch: 67, Loss: 0.751716136932373, Accuracy: 0.767578125\n",
      "Batch: 68, Loss: 0.8166482448577881, Accuracy: 0.7275390625\n",
      "Batch: 69, Loss: 0.6615951061248779, Accuracy: 0.787109375\n",
      "Batch: 70, Loss: 0.6477868556976318, Accuracy: 0.787109375\n",
      "Batch: 71, Loss: 0.7330207824707031, Accuracy: 0.74609375\n",
      "Batch: 72, Loss: 0.6280146837234497, Accuracy: 0.7841796875\n",
      "Batch: 73, Loss: 0.6076186299324036, Accuracy: 0.794921875\n",
      "Batch: 74, Loss: 0.6023927927017212, Accuracy: 0.8095703125\n",
      "Batch: 75, Loss: 0.6181881427764893, Accuracy: 0.802734375\n",
      "Batch: 76, Loss: 0.6714771389961243, Accuracy: 0.7763671875\n",
      "Batch: 77, Loss: 0.6487771272659302, Accuracy: 0.7890625\n",
      "Batch: 78, Loss: 0.6543120741844177, Accuracy: 0.7861328125\n",
      "Batch: 79, Loss: 0.6038864254951477, Accuracy: 0.810546875\n",
      "Batch: 80, Loss: 0.6584792137145996, Accuracy: 0.7861328125\n",
      "Batch: 81, Loss: 0.7407422661781311, Accuracy: 0.7392578125\n",
      "Batch: 82, Loss: 0.6868405342102051, Accuracy: 0.7666015625\n",
      "Batch: 83, Loss: 0.5891987085342407, Accuracy: 0.8076171875\n",
      "Batch: 84, Loss: 0.6480110883712769, Accuracy: 0.7939453125\n",
      "Batch: 85, Loss: 0.6601922512054443, Accuracy: 0.7890625\n",
      "Batch: 86, Loss: 0.7787584066390991, Accuracy: 0.74609375\n",
      "Batch: 87, Loss: 0.6486902236938477, Accuracy: 0.791015625\n",
      "Batch: 88, Loss: 0.7483029365539551, Accuracy: 0.7626953125\n",
      "Batch: 89, Loss: 0.6859055757522583, Accuracy: 0.783203125\n",
      "Batch: 90, Loss: 0.6566674709320068, Accuracy: 0.7861328125\n",
      "Batch: 91, Loss: 0.6321771144866943, Accuracy: 0.7919921875\n",
      "Batch: 92, Loss: 0.6660976409912109, Accuracy: 0.7734375\n",
      "Batch: 93, Loss: 0.6666097044944763, Accuracy: 0.76953125\n",
      "Batch: 94, Loss: 0.6888046264648438, Accuracy: 0.7763671875\n",
      "Batch: 95, Loss: 0.7303873300552368, Accuracy: 0.7529296875\n",
      "Batch: 96, Loss: 0.7041873335838318, Accuracy: 0.7724609375\n",
      "Batch: 97, Loss: 0.5651241540908813, Accuracy: 0.7958984375\n",
      "Batch: 98, Loss: 0.6518261432647705, Accuracy: 0.7822265625\n",
      "Batch: 99, Loss: 0.6796145439147949, Accuracy: 0.7841796875\n",
      "Batch: 100, Loss: 0.6741237044334412, Accuracy: 0.779296875\n",
      "Batch: 101, Loss: 0.7074586153030396, Accuracy: 0.7578125\n",
      "Batch: 102, Loss: 0.6750637292861938, Accuracy: 0.7841796875\n",
      "Batch: 103, Loss: 0.6832481026649475, Accuracy: 0.78515625\n",
      "Batch: 104, Loss: 0.6194607615470886, Accuracy: 0.7958984375\n",
      "Batch: 105, Loss: 0.6911410689353943, Accuracy: 0.7822265625\n",
      "Batch: 106, Loss: 0.654573917388916, Accuracy: 0.791015625\n",
      "Batch: 107, Loss: 0.6955272555351257, Accuracy: 0.7783203125\n",
      "Batch: 111, Loss: 0.7082647085189819, Accuracy: 0.7744140625\n",
      "Batch: 112, Loss: 0.7015237808227539, Accuracy: 0.7734375\n",
      "Batch: 113, Loss: 0.6828948259353638, Accuracy: 0.7724609375\n",
      "Batch: 114, Loss: 0.8035891652107239, Accuracy: 0.748046875\n",
      "Batch: 115, Loss: 0.8371843099594116, Accuracy: 0.7470703125\n",
      "Batch: 116, Loss: 0.708066999912262, Accuracy: 0.7763671875\n",
      "Batch: 117, Loss: 0.6919933557510376, Accuracy: 0.77734375\n",
      "Batch: 118, Loss: 0.590795636177063, Accuracy: 0.8193359375\n",
      "Batch: 119, Loss: 0.5748603940010071, Accuracy: 0.802734375\n",
      "Batch: 120, Loss: 0.7273130416870117, Accuracy: 0.7734375\n",
      "Batch: 121, Loss: 0.7503851056098938, Accuracy: 0.759765625\n",
      "Batch: 122, Loss: 0.6260924339294434, Accuracy: 0.798828125\n",
      "Batch: 123, Loss: 0.6545476913452148, Accuracy: 0.7734375\n",
      "Batch: 124, Loss: 0.6924392580986023, Accuracy: 0.787109375\n",
      "Batch: 125, Loss: 0.7399210333824158, Accuracy: 0.76171875\n",
      "Batch: 126, Loss: 0.7157205939292908, Accuracy: 0.7646484375\n",
      "Batch: 127, Loss: 0.6364798545837402, Accuracy: 0.7919921875\n",
      "Batch: 128, Loss: 0.7843354940414429, Accuracy: 0.7646484375\n",
      "Batch: 129, Loss: 0.6431481838226318, Accuracy: 0.7900390625\n",
      "Batch: 130, Loss: 0.7637279033660889, Accuracy: 0.748046875\n",
      "Batch: 131, Loss: 0.676563560962677, Accuracy: 0.775390625\n",
      "Batch: 132, Loss: 0.7165689468383789, Accuracy: 0.7861328125\n",
      "Batch: 133, Loss: 0.6446939706802368, Accuracy: 0.7978515625\n",
      "Batch: 134, Loss: 0.7394967079162598, Accuracy: 0.75390625\n",
      "Batch: 135, Loss: 0.6461858749389648, Accuracy: 0.7890625\n",
      "Batch: 136, Loss: 0.7080565690994263, Accuracy: 0.7607421875\n",
      "Batch: 137, Loss: 0.6756321787834167, Accuracy: 0.76171875\n",
      "Batch: 138, Loss: 0.6291662454605103, Accuracy: 0.796875\n",
      "Batch: 139, Loss: 0.6495219469070435, Accuracy: 0.7841796875\n",
      "Batch: 140, Loss: 0.6700945496559143, Accuracy: 0.7705078125\n",
      "Batch: 141, Loss: 0.7499346733093262, Accuracy: 0.740234375\n",
      "Batch: 142, Loss: 0.7550169825553894, Accuracy: 0.7548828125\n",
      "Batch: 143, Loss: 0.686532735824585, Accuracy: 0.771484375\n",
      "Batch: 144, Loss: 0.7189867496490479, Accuracy: 0.759765625\n",
      "Batch: 145, Loss: 0.6712097525596619, Accuracy: 0.7744140625\n",
      "Batch: 146, Loss: 0.6940118074417114, Accuracy: 0.7763671875\n",
      "Batch: 147, Loss: 0.680465579032898, Accuracy: 0.767578125\n",
      "Batch: 148, Loss: 0.7816821336746216, Accuracy: 0.7314453125\n",
      "Batch: 149, Loss: 0.6681339740753174, Accuracy: 0.7841796875\n",
      "Batch: 150, Loss: 0.6626539826393127, Accuracy: 0.77734375\n",
      "Batch: 151, Loss: 0.6030536890029907, Accuracy: 0.7958984375\n",
      "Epoch 64/80\n",
      "Batch: 1, Loss: 0.8891655206680298, Accuracy: 0.7177734375\n",
      "Batch: 2, Loss: 0.7615920305252075, Accuracy: 0.74609375\n",
      "Batch: 3, Loss: 0.6661413908004761, Accuracy: 0.7734375\n",
      "Batch: 4, Loss: 0.62593013048172, Accuracy: 0.8076171875\n",
      "Batch: 5, Loss: 0.6608166694641113, Accuracy: 0.7841796875\n",
      "Batch: 9, Loss: 0.644059956073761, Accuracy: 0.7822265625\n",
      "Batch: 10, Loss: 0.6597027778625488, Accuracy: 0.7744140625\n",
      "Batch: 11, Loss: 0.7661921977996826, Accuracy: 0.7353515625\n",
      "Batch: 12, Loss: 0.7807143926620483, Accuracy: 0.7509765625\n",
      "Batch: 13, Loss: 0.5656007528305054, Accuracy: 0.8134765625\n",
      "Batch: 14, Loss: 0.7360245585441589, Accuracy: 0.7451171875\n",
      "Batch: 15, Loss: 0.629957914352417, Accuracy: 0.7939453125\n",
      "Batch: 16, Loss: 0.6709918975830078, Accuracy: 0.7958984375\n",
      "Batch: 17, Loss: 0.6868953704833984, Accuracy: 0.771484375\n",
      "Batch: 18, Loss: 0.7321289777755737, Accuracy: 0.765625\n",
      "Batch: 19, Loss: 0.7006086111068726, Accuracy: 0.78515625\n",
      "Batch: 20, Loss: 0.6100913286209106, Accuracy: 0.802734375\n",
      "Batch: 21, Loss: 0.639269232749939, Accuracy: 0.7822265625\n",
      "Batch: 22, Loss: 0.7680655717849731, Accuracy: 0.7626953125\n",
      "Batch: 23, Loss: 0.7059179544448853, Accuracy: 0.7646484375\n",
      "Batch: 24, Loss: 0.7053743600845337, Accuracy: 0.7587890625\n",
      "Batch: 25, Loss: 0.6705183982849121, Accuracy: 0.775390625\n",
      "Batch: 26, Loss: 0.5919468402862549, Accuracy: 0.7958984375\n",
      "Batch: 27, Loss: 0.6616480350494385, Accuracy: 0.78125\n",
      "Batch: 28, Loss: 0.7073516845703125, Accuracy: 0.7548828125\n",
      "Batch: 29, Loss: 0.6544105410575867, Accuracy: 0.7744140625\n",
      "Batch: 30, Loss: 0.5848075151443481, Accuracy: 0.8056640625\n",
      "Batch: 31, Loss: 0.6117536425590515, Accuracy: 0.796875\n",
      "Batch: 32, Loss: 0.6372190117835999, Accuracy: 0.7783203125\n",
      "Batch: 33, Loss: 0.7417523264884949, Accuracy: 0.763671875\n",
      "Batch: 34, Loss: 0.7816579937934875, Accuracy: 0.7431640625\n",
      "Batch: 35, Loss: 0.6958682537078857, Accuracy: 0.7841796875\n",
      "Batch: 36, Loss: 0.7307186126708984, Accuracy: 0.7783203125\n",
      "Batch: 37, Loss: 0.6827815771102905, Accuracy: 0.7734375\n",
      "Batch: 38, Loss: 0.689033031463623, Accuracy: 0.767578125\n",
      "Batch: 39, Loss: 0.7223542332649231, Accuracy: 0.765625\n",
      "Batch: 40, Loss: 0.6769497394561768, Accuracy: 0.7783203125\n",
      "Batch: 41, Loss: 0.6536398530006409, Accuracy: 0.7822265625\n",
      "Batch: 42, Loss: 0.5471030473709106, Accuracy: 0.8095703125\n",
      "Batch: 43, Loss: 0.7203673124313354, Accuracy: 0.7587890625\n",
      "Batch: 44, Loss: 0.6933990120887756, Accuracy: 0.7626953125\n",
      "Batch: 45, Loss: 0.5845932960510254, Accuracy: 0.8046875\n",
      "Batch: 46, Loss: 0.5847713947296143, Accuracy: 0.8125\n",
      "Batch: 47, Loss: 0.6513292193412781, Accuracy: 0.8046875\n",
      "Batch: 48, Loss: 0.6164158582687378, Accuracy: 0.8046875\n",
      "Batch: 49, Loss: 0.7192772626876831, Accuracy: 0.7705078125\n",
      "Batch: 50, Loss: 0.7085126638412476, Accuracy: 0.7724609375\n",
      "Batch: 52, Loss: 0.6991358399391174, Accuracy: 0.78125\n",
      "Batch: 53, Loss: 0.6207168102264404, Accuracy: 0.7939453125\n",
      "Batch: 54, Loss: 0.6564319133758545, Accuracy: 0.7705078125\n",
      "Batch: 55, Loss: 0.7774141430854797, Accuracy: 0.7353515625\n",
      "Batch: 56, Loss: 0.7396957874298096, Accuracy: 0.748046875\n",
      "Batch: 57, Loss: 0.6968610286712646, Accuracy: 0.7734375\n",
      "Batch: 58, Loss: 0.7700178623199463, Accuracy: 0.759765625\n",
      "Batch: 59, Loss: 0.6656558513641357, Accuracy: 0.7802734375\n",
      "Batch: 60, Loss: 0.6217297315597534, Accuracy: 0.7861328125\n",
      "Batch: 61, Loss: 0.7025500535964966, Accuracy: 0.765625\n",
      "Batch: 62, Loss: 0.65833580493927, Accuracy: 0.7744140625\n",
      "Batch: 63, Loss: 0.7077716588973999, Accuracy: 0.7646484375\n",
      "Batch: 64, Loss: 0.6862963438034058, Accuracy: 0.767578125\n",
      "Batch: 65, Loss: 0.6693372130393982, Accuracy: 0.7744140625\n",
      "Batch: 66, Loss: 0.7083714604377747, Accuracy: 0.771484375\n",
      "Batch: 67, Loss: 0.7957608699798584, Accuracy: 0.744140625\n",
      "Batch: 68, Loss: 0.8137949705123901, Accuracy: 0.734375\n",
      "Batch: 69, Loss: 0.7255141139030457, Accuracy: 0.755859375\n",
      "Batch: 70, Loss: 0.6722636222839355, Accuracy: 0.7890625\n",
      "Batch: 71, Loss: 0.7118582725524902, Accuracy: 0.7548828125\n",
      "Batch: 72, Loss: 0.6003513336181641, Accuracy: 0.7998046875\n",
      "Batch: 73, Loss: 0.6082698106765747, Accuracy: 0.8037109375\n",
      "Batch: 74, Loss: 0.5954423546791077, Accuracy: 0.8203125\n",
      "Batch: 75, Loss: 0.6149016618728638, Accuracy: 0.7880859375\n",
      "Batch: 76, Loss: 0.6829099655151367, Accuracy: 0.783203125\n",
      "Batch: 77, Loss: 0.6309834718704224, Accuracy: 0.7890625\n",
      "Batch: 78, Loss: 0.6786445379257202, Accuracy: 0.7763671875\n",
      "Batch: 79, Loss: 0.5844434499740601, Accuracy: 0.81640625\n",
      "Batch: 80, Loss: 0.6384292840957642, Accuracy: 0.7890625\n",
      "Batch: 81, Loss: 0.7686827182769775, Accuracy: 0.73046875\n",
      "Batch: 82, Loss: 0.7113983631134033, Accuracy: 0.7587890625\n",
      "Batch: 83, Loss: 0.6073318123817444, Accuracy: 0.796875\n",
      "Batch: 84, Loss: 0.649299144744873, Accuracy: 0.7958984375\n",
      "Batch: 85, Loss: 0.6412994861602783, Accuracy: 0.79296875\n",
      "Batch: 86, Loss: 0.7658840417861938, Accuracy: 0.7587890625\n",
      "Batch: 87, Loss: 0.6250993013381958, Accuracy: 0.7998046875\n",
      "Batch: 88, Loss: 0.734408974647522, Accuracy: 0.767578125\n",
      "Batch: 89, Loss: 0.706533670425415, Accuracy: 0.7646484375\n",
      "Batch: 90, Loss: 0.6382298469543457, Accuracy: 0.779296875\n",
      "Batch: 91, Loss: 0.635010838508606, Accuracy: 0.794921875\n",
      "Batch: 92, Loss: 0.6783139705657959, Accuracy: 0.7666015625\n",
      "Batch: 93, Loss: 0.679984450340271, Accuracy: 0.763671875\n",
      "Batch: 94, Loss: 0.7133610248565674, Accuracy: 0.7705078125\n",
      "Batch: 95, Loss: 0.7101775407791138, Accuracy: 0.7490234375\n",
      "Batch: 97, Loss: 0.54109787940979, Accuracy: 0.810546875\n",
      "Batch: 98, Loss: 0.6455816030502319, Accuracy: 0.7978515625\n",
      "Batch: 99, Loss: 0.6736717224121094, Accuracy: 0.77734375\n",
      "Batch: 100, Loss: 0.703087568283081, Accuracy: 0.78515625\n",
      "Batch: 101, Loss: 0.6964294910430908, Accuracy: 0.7734375\n",
      "Batch: 102, Loss: 0.6427577137947083, Accuracy: 0.79296875\n",
      "Batch: 103, Loss: 0.681610643863678, Accuracy: 0.791015625\n",
      "Batch: 104, Loss: 0.6200793385505676, Accuracy: 0.798828125\n",
      "Batch: 105, Loss: 0.7240098714828491, Accuracy: 0.763671875\n",
      "Batch: 106, Loss: 0.6342357397079468, Accuracy: 0.7958984375\n",
      "Batch: 107, Loss: 0.6879938840866089, Accuracy: 0.7802734375\n",
      "Batch: 108, Loss: 0.6719284057617188, Accuracy: 0.7666015625\n",
      "Batch: 109, Loss: 0.7347729206085205, Accuracy: 0.759765625\n",
      "Batch: 110, Loss: 0.6558253765106201, Accuracy: 0.7822265625\n",
      "Batch: 111, Loss: 0.7113273739814758, Accuracy: 0.7626953125\n",
      "Batch: 112, Loss: 0.6806068420410156, Accuracy: 0.7841796875\n",
      "Batch: 113, Loss: 0.6833080649375916, Accuracy: 0.78125\n",
      "Batch: 114, Loss: 0.7523685097694397, Accuracy: 0.7587890625\n",
      "Batch: 115, Loss: 0.814834475517273, Accuracy: 0.7412109375\n",
      "Batch: 116, Loss: 0.7202115058898926, Accuracy: 0.76953125\n",
      "Batch: 117, Loss: 0.7147141695022583, Accuracy: 0.77734375\n",
      "Batch: 118, Loss: 0.5607448816299438, Accuracy: 0.8251953125\n",
      "Batch: 119, Loss: 0.536909282207489, Accuracy: 0.81640625\n",
      "Batch: 120, Loss: 0.6951877474784851, Accuracy: 0.7802734375\n",
      "Batch: 121, Loss: 0.6990540027618408, Accuracy: 0.7578125\n",
      "Batch: 122, Loss: 0.6692999005317688, Accuracy: 0.7880859375\n",
      "Batch: 123, Loss: 0.6609244346618652, Accuracy: 0.783203125\n",
      "Batch: 124, Loss: 0.7333171963691711, Accuracy: 0.75390625\n",
      "Batch: 125, Loss: 0.7421624660491943, Accuracy: 0.76171875\n",
      "Batch: 126, Loss: 0.7052038908004761, Accuracy: 0.7666015625\n",
      "Batch: 127, Loss: 0.6200282573699951, Accuracy: 0.798828125\n",
      "Batch: 128, Loss: 0.7663887143135071, Accuracy: 0.7626953125\n",
      "Batch: 129, Loss: 0.6263343095779419, Accuracy: 0.7919921875\n",
      "Batch: 130, Loss: 0.8038108348846436, Accuracy: 0.728515625\n",
      "Batch: 131, Loss: 0.641065776348114, Accuracy: 0.7724609375\n",
      "Batch: 132, Loss: 0.7404623031616211, Accuracy: 0.755859375\n",
      "Batch: 133, Loss: 0.6715759634971619, Accuracy: 0.7666015625\n",
      "Batch: 134, Loss: 0.7371482849121094, Accuracy: 0.748046875\n",
      "Batch: 135, Loss: 0.6245877742767334, Accuracy: 0.794921875\n",
      "Batch: 136, Loss: 0.6807669401168823, Accuracy: 0.771484375\n",
      "Batch: 137, Loss: 0.7082053422927856, Accuracy: 0.755859375\n",
      "Batch: 138, Loss: 0.6257526874542236, Accuracy: 0.7939453125\n",
      "Batch: 139, Loss: 0.6863038539886475, Accuracy: 0.775390625\n",
      "Batch: 140, Loss: 0.6601669788360596, Accuracy: 0.7822265625\n",
      "Batch: 141, Loss: 0.7240786552429199, Accuracy: 0.7578125\n",
      "Batch: 142, Loss: 0.7566757798194885, Accuracy: 0.76953125\n",
      "Batch: 143, Loss: 0.7218225002288818, Accuracy: 0.7744140625\n",
      "Batch: 144, Loss: 0.6925085186958313, Accuracy: 0.7666015625\n",
      "Batch: 145, Loss: 0.6594139933586121, Accuracy: 0.77734375\n",
      "Batch: 146, Loss: 0.7297594547271729, Accuracy: 0.76171875\n",
      "Batch: 147, Loss: 0.7152242660522461, Accuracy: 0.755859375\n",
      "Batch: 148, Loss: 0.7864692807197571, Accuracy: 0.74609375\n",
      "Batch: 149, Loss: 0.6626272201538086, Accuracy: 0.78125\n",
      "Batch: 150, Loss: 0.6927727460861206, Accuracy: 0.76953125\n",
      "Batch: 151, Loss: 0.6155914068222046, Accuracy: 0.79296875\n",
      "Epoch 65/80\n",
      "Batch: 1, Loss: 0.9055880308151245, Accuracy: 0.7138671875\n",
      "Batch: 2, Loss: 0.7698036432266235, Accuracy: 0.73828125\n",
      "Batch: 3, Loss: 0.6862045526504517, Accuracy: 0.7705078125\n",
      "Batch: 4, Loss: 0.6290420293807983, Accuracy: 0.798828125\n",
      "Batch: 5, Loss: 0.6519415378570557, Accuracy: 0.78515625\n",
      "Batch: 6, Loss: 0.6966369152069092, Accuracy: 0.7646484375\n",
      "Batch: 7, Loss: 0.7339349389076233, Accuracy: 0.744140625\n",
      "Batch: 8, Loss: 0.6763110756874084, Accuracy: 0.7744140625\n",
      "Batch: 9, Loss: 0.6476995944976807, Accuracy: 0.7861328125\n",
      "Batch: 10, Loss: 0.6389755010604858, Accuracy: 0.771484375\n",
      "Batch: 11, Loss: 0.7896949052810669, Accuracy: 0.7177734375\n",
      "Batch: 12, Loss: 0.7490988969802856, Accuracy: 0.7470703125\n",
      "Batch: 13, Loss: 0.5579526424407959, Accuracy: 0.81640625\n",
      "Batch: 14, Loss: 0.7292405366897583, Accuracy: 0.763671875\n",
      "Batch: 15, Loss: 0.6266650557518005, Accuracy: 0.794921875\n",
      "Batch: 16, Loss: 0.6694743633270264, Accuracy: 0.787109375\n",
      "Batch: 17, Loss: 0.6922382116317749, Accuracy: 0.767578125\n",
      "Batch: 18, Loss: 0.6973657608032227, Accuracy: 0.7744140625\n",
      "Batch: 19, Loss: 0.7095237970352173, Accuracy: 0.7783203125\n",
      "Batch: 20, Loss: 0.6133551597595215, Accuracy: 0.8076171875\n",
      "Batch: 21, Loss: 0.6292901635169983, Accuracy: 0.794921875\n",
      "Batch: 22, Loss: 0.7749598026275635, Accuracy: 0.755859375\n",
      "Batch: 23, Loss: 0.7176364660263062, Accuracy: 0.7548828125\n",
      "Batch: 24, Loss: 0.7295594215393066, Accuracy: 0.75390625\n",
      "Batch: 25, Loss: 0.6774526834487915, Accuracy: 0.7880859375\n",
      "Batch: 26, Loss: 0.5953353643417358, Accuracy: 0.8037109375\n",
      "Batch: 27, Loss: 0.6319167017936707, Accuracy: 0.791015625\n",
      "Batch: 28, Loss: 0.6890738010406494, Accuracy: 0.76171875\n",
      "Batch: 29, Loss: 0.6576631665229797, Accuracy: 0.78125\n",
      "Batch: 30, Loss: 0.6026370525360107, Accuracy: 0.80078125\n",
      "Batch: 31, Loss: 0.6239652037620544, Accuracy: 0.7998046875\n",
      "Batch: 32, Loss: 0.6415555477142334, Accuracy: 0.7861328125\n",
      "Batch: 33, Loss: 0.7321014404296875, Accuracy: 0.7666015625\n",
      "Batch: 34, Loss: 0.7593932747840881, Accuracy: 0.744140625\n",
      "Batch: 35, Loss: 0.7087740898132324, Accuracy: 0.763671875\n",
      "Batch: 36, Loss: 0.7263436317443848, Accuracy: 0.759765625\n",
      "Batch: 37, Loss: 0.6946895122528076, Accuracy: 0.783203125\n",
      "Batch: 40, Loss: 0.6421477794647217, Accuracy: 0.783203125\n",
      "Batch: 41, Loss: 0.6446606516838074, Accuracy: 0.7861328125\n",
      "Batch: 42, Loss: 0.519744873046875, Accuracy: 0.8291015625\n",
      "Batch: 43, Loss: 0.7016760110855103, Accuracy: 0.7607421875\n",
      "Batch: 44, Loss: 0.6989316940307617, Accuracy: 0.76953125\n",
      "Batch: 45, Loss: 0.602493166923523, Accuracy: 0.7978515625\n",
      "Batch: 46, Loss: 0.6173155903816223, Accuracy: 0.794921875\n",
      "Batch: 47, Loss: 0.6774764657020569, Accuracy: 0.7998046875\n",
      "Batch: 48, Loss: 0.6338589787483215, Accuracy: 0.77734375\n",
      "Batch: 49, Loss: 0.7134323120117188, Accuracy: 0.7822265625\n",
      "Batch: 50, Loss: 0.6811676025390625, Accuracy: 0.7744140625\n",
      "Batch: 51, Loss: 0.7015711069107056, Accuracy: 0.7646484375\n",
      "Batch: 52, Loss: 0.688896894454956, Accuracy: 0.7861328125\n",
      "Batch: 53, Loss: 0.6333611011505127, Accuracy: 0.806640625\n",
      "Batch: 54, Loss: 0.6539566516876221, Accuracy: 0.794921875\n",
      "Batch: 55, Loss: 0.7966489791870117, Accuracy: 0.7353515625\n",
      "Batch: 56, Loss: 0.7364131212234497, Accuracy: 0.771484375\n",
      "Batch: 57, Loss: 0.7141231894493103, Accuracy: 0.7548828125\n",
      "Batch: 58, Loss: 0.7887399196624756, Accuracy: 0.76171875\n",
      "Batch: 59, Loss: 0.6528986692428589, Accuracy: 0.7841796875\n",
      "Batch: 60, Loss: 0.6463185548782349, Accuracy: 0.779296875\n",
      "Batch: 61, Loss: 0.7285993099212646, Accuracy: 0.763671875\n",
      "Batch: 62, Loss: 0.6406333446502686, Accuracy: 0.7783203125\n",
      "Batch: 63, Loss: 0.694993257522583, Accuracy: 0.7783203125\n",
      "Batch: 64, Loss: 0.6911814212799072, Accuracy: 0.767578125\n",
      "Batch: 65, Loss: 0.6968672275543213, Accuracy: 0.7705078125\n",
      "Batch: 66, Loss: 0.6932994723320007, Accuracy: 0.7734375\n",
      "Batch: 67, Loss: 0.7632558345794678, Accuracy: 0.7548828125\n",
      "Batch: 68, Loss: 0.8081489205360413, Accuracy: 0.736328125\n",
      "Batch: 69, Loss: 0.709433913230896, Accuracy: 0.76953125\n",
      "Batch: 70, Loss: 0.6770629286766052, Accuracy: 0.7861328125\n",
      "Batch: 71, Loss: 0.7369658350944519, Accuracy: 0.7470703125\n",
      "Batch: 72, Loss: 0.6318390965461731, Accuracy: 0.7822265625\n",
      "Batch: 73, Loss: 0.6238687634468079, Accuracy: 0.8017578125\n",
      "Batch: 74, Loss: 0.5865126848220825, Accuracy: 0.818359375\n",
      "Batch: 75, Loss: 0.6317355632781982, Accuracy: 0.80078125\n",
      "Batch: 76, Loss: 0.6621531844139099, Accuracy: 0.77734375\n",
      "Batch: 77, Loss: 0.6147059202194214, Accuracy: 0.7978515625\n",
      "Batch: 78, Loss: 0.6123096346855164, Accuracy: 0.8017578125\n",
      "Batch: 79, Loss: 0.6036279201507568, Accuracy: 0.8046875\n",
      "Batch: 80, Loss: 0.6137363910675049, Accuracy: 0.7978515625\n",
      "Batch: 81, Loss: 0.7359147071838379, Accuracy: 0.7470703125\n",
      "Batch: 82, Loss: 0.6813424825668335, Accuracy: 0.7724609375\n",
      "Batch: 83, Loss: 0.5719805955886841, Accuracy: 0.8076171875\n",
      "Batch: 84, Loss: 0.648180365562439, Accuracy: 0.78125\n",
      "Batch: 85, Loss: 0.6092543601989746, Accuracy: 0.8037109375\n",
      "Batch: 86, Loss: 0.7540688514709473, Accuracy: 0.7626953125\n",
      "Batch: 87, Loss: 0.6254669427871704, Accuracy: 0.8017578125\n",
      "Batch: 88, Loss: 0.6902502775192261, Accuracy: 0.765625\n",
      "Batch: 89, Loss: 0.6707260608673096, Accuracy: 0.791015625\n",
      "Batch: 90, Loss: 0.6363441944122314, Accuracy: 0.7900390625\n",
      "Batch: 91, Loss: 0.6592806577682495, Accuracy: 0.7802734375\n",
      "Batch: 92, Loss: 0.6996780633926392, Accuracy: 0.7626953125\n",
      "Batch: 93, Loss: 0.699566125869751, Accuracy: 0.7734375\n",
      "Batch: 94, Loss: 0.6873065233230591, Accuracy: 0.7802734375\n",
      "Batch: 95, Loss: 0.7023919224739075, Accuracy: 0.7626953125\n",
      "Batch: 96, Loss: 0.6675010323524475, Accuracy: 0.7744140625\n",
      "Batch: 97, Loss: 0.5574933886528015, Accuracy: 0.8134765625\n",
      "Batch: 98, Loss: 0.6696915626525879, Accuracy: 0.77734375\n",
      "Batch: 99, Loss: 0.6552732586860657, Accuracy: 0.7841796875\n",
      "Batch: 100, Loss: 0.6754096746444702, Accuracy: 0.7802734375\n",
      "Batch: 101, Loss: 0.6964578628540039, Accuracy: 0.7666015625\n",
      "Batch: 102, Loss: 0.6565910577774048, Accuracy: 0.7900390625\n",
      "Batch: 103, Loss: 0.6925328969955444, Accuracy: 0.7763671875\n",
      "Batch: 104, Loss: 0.6670883893966675, Accuracy: 0.779296875\n",
      "Batch: 105, Loss: 0.7272136807441711, Accuracy: 0.76953125\n",
      "Batch: 106, Loss: 0.6416878700256348, Accuracy: 0.779296875\n",
      "Batch: 107, Loss: 0.6777700185775757, Accuracy: 0.7783203125\n",
      "Batch: 108, Loss: 0.6643968224525452, Accuracy: 0.771484375\n",
      "Batch: 109, Loss: 0.7168396711349487, Accuracy: 0.76953125\n",
      "Batch: 110, Loss: 0.6521207094192505, Accuracy: 0.7861328125\n",
      "Batch: 111, Loss: 0.6888155937194824, Accuracy: 0.7685546875\n",
      "Batch: 112, Loss: 0.6739298105239868, Accuracy: 0.7958984375\n",
      "Batch: 113, Loss: 0.6747081279754639, Accuracy: 0.7705078125\n",
      "Batch: 114, Loss: 0.7571538686752319, Accuracy: 0.7548828125\n",
      "Batch: 115, Loss: 0.7788033485412598, Accuracy: 0.75\n",
      "Batch: 116, Loss: 0.7212189435958862, Accuracy: 0.77734375\n",
      "Batch: 117, Loss: 0.6742051243782043, Accuracy: 0.794921875\n",
      "Batch: 118, Loss: 0.5911856889724731, Accuracy: 0.8046875\n",
      "Batch: 119, Loss: 0.5349966287612915, Accuracy: 0.82421875\n",
      "Batch: 120, Loss: 0.6837329268455505, Accuracy: 0.77734375\n",
      "Batch: 121, Loss: 0.6981409788131714, Accuracy: 0.7724609375\n",
      "Batch: 122, Loss: 0.6692448258399963, Accuracy: 0.76953125\n",
      "Batch: 123, Loss: 0.6189620494842529, Accuracy: 0.80078125\n",
      "Batch: 124, Loss: 0.6870342493057251, Accuracy: 0.78125\n",
      "Batch: 125, Loss: 0.7713205218315125, Accuracy: 0.75390625\n",
      "Batch: 126, Loss: 0.7218387126922607, Accuracy: 0.75390625\n",
      "Batch: 127, Loss: 0.5929248332977295, Accuracy: 0.8173828125\n",
      "Batch: 128, Loss: 0.7288111448287964, Accuracy: 0.7841796875\n",
      "Batch: 130, Loss: 0.7892791628837585, Accuracy: 0.7392578125\n",
      "Batch: 131, Loss: 0.6450409889221191, Accuracy: 0.78125\n",
      "Batch: 132, Loss: 0.7203792929649353, Accuracy: 0.771484375\n",
      "Batch: 133, Loss: 0.6426940560340881, Accuracy: 0.7880859375\n",
      "Batch: 134, Loss: 0.7178247570991516, Accuracy: 0.748046875\n",
      "Batch: 135, Loss: 0.6403736472129822, Accuracy: 0.77734375\n",
      "Batch: 136, Loss: 0.694318413734436, Accuracy: 0.7578125\n",
      "Batch: 137, Loss: 0.7096028923988342, Accuracy: 0.75\n",
      "Batch: 138, Loss: 0.6187952756881714, Accuracy: 0.7744140625\n",
      "Batch: 139, Loss: 0.6428390741348267, Accuracy: 0.77734375\n",
      "Batch: 140, Loss: 0.6531354188919067, Accuracy: 0.7890625\n",
      "Batch: 141, Loss: 0.7065885066986084, Accuracy: 0.771484375\n",
      "Batch: 142, Loss: 0.7458465695381165, Accuracy: 0.7685546875\n",
      "Batch: 143, Loss: 0.6774870157241821, Accuracy: 0.7744140625\n",
      "Batch: 144, Loss: 0.6923271417617798, Accuracy: 0.7744140625\n",
      "Batch: 145, Loss: 0.6728045344352722, Accuracy: 0.7587890625\n",
      "Batch: 146, Loss: 0.6789112091064453, Accuracy: 0.7822265625\n",
      "Batch: 147, Loss: 0.7371533513069153, Accuracy: 0.763671875\n",
      "Batch: 148, Loss: 0.7733518481254578, Accuracy: 0.73828125\n",
      "Batch: 149, Loss: 0.6738004088401794, Accuracy: 0.76171875\n",
      "Batch: 150, Loss: 0.7082249522209167, Accuracy: 0.76171875\n",
      "Batch: 151, Loss: 0.5913197994232178, Accuracy: 0.8037109375\n",
      "Epoch 66/80\n",
      "Batch: 1, Loss: 0.8665157556533813, Accuracy: 0.7021484375\n",
      "Batch: 2, Loss: 0.7395209074020386, Accuracy: 0.7373046875\n",
      "Batch: 3, Loss: 0.6670178174972534, Accuracy: 0.76953125\n",
      "Batch: 4, Loss: 0.610772430896759, Accuracy: 0.8154296875\n",
      "Batch: 5, Loss: 0.6793791055679321, Accuracy: 0.7783203125\n",
      "Batch: 6, Loss: 0.716965913772583, Accuracy: 0.751953125\n",
      "Batch: 7, Loss: 0.7117280960083008, Accuracy: 0.7578125\n",
      "Batch: 8, Loss: 0.6252763867378235, Accuracy: 0.791015625\n",
      "Batch: 9, Loss: 0.6457485556602478, Accuracy: 0.7939453125\n",
      "Batch: 10, Loss: 0.6100231409072876, Accuracy: 0.787109375\n",
      "Batch: 11, Loss: 0.7757787108421326, Accuracy: 0.744140625\n",
      "Batch: 12, Loss: 0.7307450771331787, Accuracy: 0.751953125\n",
      "Batch: 13, Loss: 0.5594668388366699, Accuracy: 0.8125\n",
      "Batch: 14, Loss: 0.7210080623626709, Accuracy: 0.771484375\n",
      "Batch: 15, Loss: 0.6438270211219788, Accuracy: 0.7822265625\n",
      "Batch: 16, Loss: 0.6619089841842651, Accuracy: 0.787109375\n",
      "Batch: 17, Loss: 0.6973207592964172, Accuracy: 0.7685546875\n",
      "Batch: 18, Loss: 0.7072907090187073, Accuracy: 0.7587890625\n",
      "Batch: 19, Loss: 0.6990741491317749, Accuracy: 0.759765625\n",
      "Batch: 20, Loss: 0.6145360469818115, Accuracy: 0.794921875\n",
      "Batch: 21, Loss: 0.6371147632598877, Accuracy: 0.78515625\n",
      "Batch: 22, Loss: 0.7643799185752869, Accuracy: 0.7509765625\n",
      "Batch: 23, Loss: 0.7198072671890259, Accuracy: 0.755859375\n",
      "Batch: 26, Loss: 0.5744361877441406, Accuracy: 0.8193359375\n",
      "Batch: 27, Loss: 0.603863000869751, Accuracy: 0.7880859375\n",
      "Batch: 28, Loss: 0.6867417097091675, Accuracy: 0.7763671875\n",
      "Batch: 29, Loss: 0.6599627733230591, Accuracy: 0.7978515625\n",
      "Batch: 30, Loss: 0.6006020307540894, Accuracy: 0.8232421875\n",
      "Batch: 31, Loss: 0.5881531238555908, Accuracy: 0.80859375\n",
      "Batch: 32, Loss: 0.6091567277908325, Accuracy: 0.794921875\n",
      "Batch: 33, Loss: 0.7268157601356506, Accuracy: 0.76953125\n",
      "Batch: 34, Loss: 0.7488030791282654, Accuracy: 0.74609375\n",
      "Batch: 35, Loss: 0.7369165420532227, Accuracy: 0.75390625\n",
      "Batch: 36, Loss: 0.7214429974555969, Accuracy: 0.7841796875\n",
      "Batch: 37, Loss: 0.6677349209785461, Accuracy: 0.783203125\n",
      "Batch: 38, Loss: 0.6671090126037598, Accuracy: 0.7705078125\n",
      "Batch: 39, Loss: 0.6760376691818237, Accuracy: 0.779296875\n",
      "Batch: 40, Loss: 0.6669004559516907, Accuracy: 0.78515625\n",
      "Batch: 41, Loss: 0.6233308911323547, Accuracy: 0.80078125\n",
      "Batch: 42, Loss: 0.505792498588562, Accuracy: 0.83203125\n",
      "Batch: 43, Loss: 0.6880295276641846, Accuracy: 0.7568359375\n",
      "Batch: 44, Loss: 0.677592933177948, Accuracy: 0.767578125\n",
      "Batch: 45, Loss: 0.603524923324585, Accuracy: 0.8056640625\n",
      "Batch: 46, Loss: 0.624787449836731, Accuracy: 0.798828125\n",
      "Batch: 47, Loss: 0.6745730638504028, Accuracy: 0.7939453125\n",
      "Batch: 48, Loss: 0.6013839244842529, Accuracy: 0.8037109375\n",
      "Batch: 49, Loss: 0.7147939205169678, Accuracy: 0.7587890625\n",
      "Batch: 50, Loss: 0.7073614597320557, Accuracy: 0.765625\n",
      "Batch: 51, Loss: 0.6814721822738647, Accuracy: 0.7724609375\n",
      "Batch: 52, Loss: 0.6634856462478638, Accuracy: 0.7919921875\n",
      "Batch: 53, Loss: 0.6084673404693604, Accuracy: 0.8076171875\n",
      "Batch: 54, Loss: 0.6744521856307983, Accuracy: 0.771484375\n",
      "Batch: 55, Loss: 0.7915533781051636, Accuracy: 0.7412109375\n",
      "Batch: 56, Loss: 0.7722905278205872, Accuracy: 0.744140625\n",
      "Batch: 57, Loss: 0.7111634016036987, Accuracy: 0.7666015625\n",
      "Batch: 58, Loss: 0.7524846196174622, Accuracy: 0.7607421875\n",
      "Batch: 59, Loss: 0.6598196029663086, Accuracy: 0.779296875\n",
      "Batch: 60, Loss: 0.6301308870315552, Accuracy: 0.796875\n",
      "Batch: 61, Loss: 0.7056246995925903, Accuracy: 0.77734375\n",
      "Batch: 62, Loss: 0.6874898076057434, Accuracy: 0.767578125\n",
      "Batch: 63, Loss: 0.6781529188156128, Accuracy: 0.7724609375\n",
      "Batch: 64, Loss: 0.6766554117202759, Accuracy: 0.78125\n",
      "Batch: 65, Loss: 0.6756571531295776, Accuracy: 0.7822265625\n",
      "Batch: 66, Loss: 0.7078617811203003, Accuracy: 0.77734375\n",
      "Batch: 67, Loss: 0.7460819482803345, Accuracy: 0.765625\n",
      "Batch: 68, Loss: 0.8144081830978394, Accuracy: 0.732421875\n",
      "Batch: 69, Loss: 0.6999201774597168, Accuracy: 0.7548828125\n",
      "Batch: 70, Loss: 0.6483057141304016, Accuracy: 0.7861328125\n",
      "Batch: 71, Loss: 0.707897424697876, Accuracy: 0.763671875\n",
      "Batch: 72, Loss: 0.6422608494758606, Accuracy: 0.7861328125\n",
      "Batch: 74, Loss: 0.6094249486923218, Accuracy: 0.806640625\n",
      "Batch: 75, Loss: 0.6510390043258667, Accuracy: 0.7841796875\n",
      "Batch: 76, Loss: 0.6977050304412842, Accuracy: 0.77734375\n",
      "Batch: 77, Loss: 0.6191143989562988, Accuracy: 0.7919921875\n",
      "Batch: 78, Loss: 0.6296042203903198, Accuracy: 0.7890625\n",
      "Batch: 79, Loss: 0.593409538269043, Accuracy: 0.8154296875\n",
      "Batch: 80, Loss: 0.6537449359893799, Accuracy: 0.7802734375\n",
      "Batch: 81, Loss: 0.7155152559280396, Accuracy: 0.75\n",
      "Batch: 82, Loss: 0.6752922534942627, Accuracy: 0.7744140625\n",
      "Batch: 83, Loss: 0.5807409286499023, Accuracy: 0.8134765625\n",
      "Batch: 84, Loss: 0.6289247274398804, Accuracy: 0.802734375\n",
      "Batch: 85, Loss: 0.6551811099052429, Accuracy: 0.77734375\n",
      "Batch: 86, Loss: 0.7576632499694824, Accuracy: 0.771484375\n",
      "Batch: 87, Loss: 0.6213778257369995, Accuracy: 0.7958984375\n",
      "Batch: 88, Loss: 0.6965740919113159, Accuracy: 0.775390625\n",
      "Batch: 89, Loss: 0.6831287145614624, Accuracy: 0.7685546875\n",
      "Batch: 90, Loss: 0.6428688168525696, Accuracy: 0.7958984375\n",
      "Batch: 91, Loss: 0.6661405563354492, Accuracy: 0.775390625\n",
      "Batch: 92, Loss: 0.7120278477668762, Accuracy: 0.7548828125\n",
      "Batch: 93, Loss: 0.6631916165351868, Accuracy: 0.7724609375\n",
      "Batch: 94, Loss: 0.7017776370048523, Accuracy: 0.765625\n",
      "Batch: 95, Loss: 0.7147531509399414, Accuracy: 0.73828125\n",
      "Batch: 96, Loss: 0.6589307188987732, Accuracy: 0.7587890625\n",
      "Batch: 97, Loss: 0.5512596368789673, Accuracy: 0.806640625\n",
      "Batch: 98, Loss: 0.6250495910644531, Accuracy: 0.80078125\n",
      "Batch: 99, Loss: 0.6569608449935913, Accuracy: 0.787109375\n",
      "Batch: 100, Loss: 0.6947185397148132, Accuracy: 0.783203125\n",
      "Batch: 101, Loss: 0.6980578899383545, Accuracy: 0.7666015625\n",
      "Batch: 102, Loss: 0.6619057655334473, Accuracy: 0.7890625\n",
      "Batch: 103, Loss: 0.6799960136413574, Accuracy: 0.7861328125\n",
      "Batch: 104, Loss: 0.6205393075942993, Accuracy: 0.78515625\n",
      "Batch: 105, Loss: 0.7389024496078491, Accuracy: 0.7685546875\n",
      "Batch: 106, Loss: 0.6306488513946533, Accuracy: 0.7783203125\n",
      "Batch: 107, Loss: 0.6550215482711792, Accuracy: 0.7822265625\n",
      "Batch: 108, Loss: 0.6563435196876526, Accuracy: 0.78125\n",
      "Batch: 109, Loss: 0.7058594226837158, Accuracy: 0.7685546875\n",
      "Batch: 110, Loss: 0.6609869599342346, Accuracy: 0.7861328125\n",
      "Batch: 111, Loss: 0.7035320997238159, Accuracy: 0.78125\n",
      "Batch: 112, Loss: 0.6497126817703247, Accuracy: 0.7802734375\n",
      "Batch: 113, Loss: 0.6933491230010986, Accuracy: 0.763671875\n",
      "Batch: 114, Loss: 0.7501552104949951, Accuracy: 0.755859375\n",
      "Batch: 115, Loss: 0.8210123181343079, Accuracy: 0.75\n",
      "Batch: 116, Loss: 0.7423966526985168, Accuracy: 0.7548828125\n",
      "Batch: 119, Loss: 0.5748175382614136, Accuracy: 0.810546875\n",
      "Batch: 120, Loss: 0.7039324045181274, Accuracy: 0.78515625\n",
      "Batch: 121, Loss: 0.6821264624595642, Accuracy: 0.779296875\n",
      "Batch: 122, Loss: 0.6487970352172852, Accuracy: 0.78515625\n",
      "Batch: 123, Loss: 0.6239070892333984, Accuracy: 0.783203125\n",
      "Batch: 124, Loss: 0.6700047850608826, Accuracy: 0.78515625\n",
      "Batch: 125, Loss: 0.7504433989524841, Accuracy: 0.7646484375\n",
      "Batch: 126, Loss: 0.7157100439071655, Accuracy: 0.7734375\n",
      "Batch: 127, Loss: 0.5895739197731018, Accuracy: 0.8125\n",
      "Batch: 128, Loss: 0.7208435535430908, Accuracy: 0.779296875\n",
      "Batch: 129, Loss: 0.6005334854125977, Accuracy: 0.79296875\n",
      "Batch: 130, Loss: 0.7811823487281799, Accuracy: 0.7265625\n",
      "Batch: 131, Loss: 0.6520906090736389, Accuracy: 0.7841796875\n",
      "Batch: 132, Loss: 0.704773485660553, Accuracy: 0.7685546875\n",
      "Batch: 133, Loss: 0.6667978167533875, Accuracy: 0.7998046875\n",
      "Batch: 134, Loss: 0.7106688022613525, Accuracy: 0.7578125\n",
      "Batch: 135, Loss: 0.626469612121582, Accuracy: 0.80078125\n",
      "Batch: 136, Loss: 0.6760021448135376, Accuracy: 0.7734375\n",
      "Batch: 137, Loss: 0.6813803911209106, Accuracy: 0.767578125\n",
      "Batch: 138, Loss: 0.6263833045959473, Accuracy: 0.7890625\n",
      "Batch: 139, Loss: 0.6863516569137573, Accuracy: 0.7685546875\n",
      "Batch: 140, Loss: 0.6840648651123047, Accuracy: 0.765625\n",
      "Batch: 141, Loss: 0.7069069147109985, Accuracy: 0.775390625\n",
      "Batch: 142, Loss: 0.7568724751472473, Accuracy: 0.76171875\n",
      "Batch: 143, Loss: 0.6778185963630676, Accuracy: 0.77734375\n",
      "Batch: 144, Loss: 0.6917734146118164, Accuracy: 0.7568359375\n",
      "Batch: 145, Loss: 0.6656802892684937, Accuracy: 0.7626953125\n",
      "Batch: 146, Loss: 0.6804330348968506, Accuracy: 0.7763671875\n",
      "Batch: 147, Loss: 0.721723198890686, Accuracy: 0.765625\n",
      "Batch: 148, Loss: 0.7565574049949646, Accuracy: 0.7470703125\n",
      "Batch: 149, Loss: 0.651826024055481, Accuracy: 0.783203125\n",
      "Batch: 150, Loss: 0.6541374921798706, Accuracy: 0.7705078125\n",
      "Batch: 151, Loss: 0.616143524646759, Accuracy: 0.7978515625\n",
      "Epoch 67/80\n",
      "Batch: 1, Loss: 0.8529098033905029, Accuracy: 0.71875\n",
      "Batch: 2, Loss: 0.7736436724662781, Accuracy: 0.7236328125\n",
      "Batch: 3, Loss: 0.6554702520370483, Accuracy: 0.78515625\n",
      "Batch: 4, Loss: 0.6072524785995483, Accuracy: 0.80859375\n",
      "Batch: 5, Loss: 0.6367548108100891, Accuracy: 0.798828125\n",
      "Batch: 6, Loss: 0.6870850920677185, Accuracy: 0.7763671875\n",
      "Batch: 7, Loss: 0.7264379262924194, Accuracy: 0.74609375\n",
      "Batch: 8, Loss: 0.6376978754997253, Accuracy: 0.7783203125\n",
      "Batch: 9, Loss: 0.6250406503677368, Accuracy: 0.8056640625\n",
      "Batch: 12, Loss: 0.729787290096283, Accuracy: 0.7724609375\n",
      "Batch: 13, Loss: 0.521579921245575, Accuracy: 0.830078125\n",
      "Batch: 14, Loss: 0.7264019846916199, Accuracy: 0.7587890625\n",
      "Batch: 15, Loss: 0.6205002069473267, Accuracy: 0.7978515625\n",
      "Batch: 16, Loss: 0.6551731824874878, Accuracy: 0.7939453125\n",
      "Batch: 17, Loss: 0.6915861368179321, Accuracy: 0.7763671875\n",
      "Batch: 18, Loss: 0.6843996644020081, Accuracy: 0.76953125\n",
      "Batch: 19, Loss: 0.6637124419212341, Accuracy: 0.798828125\n",
      "Batch: 20, Loss: 0.5721021890640259, Accuracy: 0.8203125\n",
      "Batch: 21, Loss: 0.6215354204177856, Accuracy: 0.7958984375\n",
      "Batch: 22, Loss: 0.7390950918197632, Accuracy: 0.7734375\n",
      "Batch: 23, Loss: 0.6893045902252197, Accuracy: 0.7626953125\n",
      "Batch: 24, Loss: 0.6896213293075562, Accuracy: 0.767578125\n",
      "Batch: 25, Loss: 0.6263359785079956, Accuracy: 0.7958984375\n",
      "Batch: 26, Loss: 0.5695056915283203, Accuracy: 0.80078125\n",
      "Batch: 27, Loss: 0.6298742294311523, Accuracy: 0.7783203125\n",
      "Batch: 28, Loss: 0.6915355920791626, Accuracy: 0.771484375\n",
      "Batch: 29, Loss: 0.6467813849449158, Accuracy: 0.783203125\n",
      "Batch: 30, Loss: 0.5981873273849487, Accuracy: 0.8134765625\n",
      "Batch: 31, Loss: 0.6013660430908203, Accuracy: 0.8046875\n",
      "Batch: 32, Loss: 0.642428994178772, Accuracy: 0.7841796875\n",
      "Batch: 33, Loss: 0.706303596496582, Accuracy: 0.767578125\n",
      "Batch: 34, Loss: 0.7533157467842102, Accuracy: 0.7509765625\n",
      "Batch: 35, Loss: 0.7129518389701843, Accuracy: 0.779296875\n",
      "Batch: 36, Loss: 0.6975218653678894, Accuracy: 0.783203125\n",
      "Batch: 37, Loss: 0.6717996597290039, Accuracy: 0.7685546875\n",
      "Batch: 38, Loss: 0.6894658803939819, Accuracy: 0.763671875\n",
      "Batch: 39, Loss: 0.7174546718597412, Accuracy: 0.775390625\n",
      "Batch: 40, Loss: 0.6698038578033447, Accuracy: 0.765625\n",
      "Batch: 41, Loss: 0.608108639717102, Accuracy: 0.798828125\n",
      "Batch: 42, Loss: 0.5171334743499756, Accuracy: 0.8291015625\n",
      "Batch: 43, Loss: 0.6791726350784302, Accuracy: 0.7646484375\n",
      "Batch: 44, Loss: 0.6783483028411865, Accuracy: 0.7705078125\n",
      "Batch: 45, Loss: 0.5847316980361938, Accuracy: 0.802734375\n",
      "Batch: 46, Loss: 0.6165713667869568, Accuracy: 0.7919921875\n",
      "Batch: 47, Loss: 0.6660963296890259, Accuracy: 0.783203125\n",
      "Batch: 48, Loss: 0.5972303152084351, Accuracy: 0.8056640625\n",
      "Batch: 49, Loss: 0.6888942718505859, Accuracy: 0.7763671875\n",
      "Batch: 50, Loss: 0.7008910775184631, Accuracy: 0.76953125\n",
      "Batch: 51, Loss: 0.6934911608695984, Accuracy: 0.78515625\n",
      "Batch: 52, Loss: 0.6551913619041443, Accuracy: 0.798828125\n",
      "Batch: 53, Loss: 0.6355334520339966, Accuracy: 0.78515625\n",
      "Batch: 54, Loss: 0.6601012945175171, Accuracy: 0.78515625\n",
      "Batch: 55, Loss: 0.7496253252029419, Accuracy: 0.7470703125\n",
      "Batch: 56, Loss: 0.7350578308105469, Accuracy: 0.755859375\n",
      "Batch: 57, Loss: 0.6788644790649414, Accuracy: 0.7763671875\n",
      "Batch: 58, Loss: 0.7815665006637573, Accuracy: 0.7451171875\n",
      "Batch: 59, Loss: 0.6800435185432434, Accuracy: 0.779296875\n",
      "Batch: 60, Loss: 0.6368244290351868, Accuracy: 0.7919921875\n",
      "Batch: 61, Loss: 0.73847895860672, Accuracy: 0.7578125\n",
      "Batch: 62, Loss: 0.6574738025665283, Accuracy: 0.7841796875\n",
      "Batch: 63, Loss: 0.6814616322517395, Accuracy: 0.779296875\n",
      "Batch: 64, Loss: 0.676155686378479, Accuracy: 0.7666015625\n",
      "Batch: 65, Loss: 0.6786726117134094, Accuracy: 0.783203125\n",
      "Batch: 66, Loss: 0.6786584854125977, Accuracy: 0.7939453125\n",
      "Batch: 67, Loss: 0.7467058897018433, Accuracy: 0.7724609375\n",
      "Batch: 68, Loss: 0.7670790553092957, Accuracy: 0.7548828125\n",
      "Batch: 69, Loss: 0.7219593524932861, Accuracy: 0.7685546875\n",
      "Batch: 70, Loss: 0.6841191053390503, Accuracy: 0.7861328125\n",
      "Batch: 71, Loss: 0.7254596948623657, Accuracy: 0.751953125\n",
      "Batch: 72, Loss: 0.6164054870605469, Accuracy: 0.79296875\n",
      "Batch: 73, Loss: 0.6157736778259277, Accuracy: 0.802734375\n",
      "Batch: 74, Loss: 0.5843029022216797, Accuracy: 0.818359375\n",
      "Batch: 75, Loss: 0.5995072722434998, Accuracy: 0.79296875\n",
      "Batch: 76, Loss: 0.6669658422470093, Accuracy: 0.7763671875\n",
      "Batch: 77, Loss: 0.6056748032569885, Accuracy: 0.7978515625\n",
      "Batch: 78, Loss: 0.6136975288391113, Accuracy: 0.798828125\n",
      "Batch: 79, Loss: 0.5873948335647583, Accuracy: 0.80859375\n",
      "Batch: 80, Loss: 0.6250990629196167, Accuracy: 0.7861328125\n",
      "Batch: 81, Loss: 0.759048581123352, Accuracy: 0.732421875\n",
      "Batch: 82, Loss: 0.6768863797187805, Accuracy: 0.7685546875\n",
      "Batch: 83, Loss: 0.5858777165412903, Accuracy: 0.8046875\n",
      "Batch: 84, Loss: 0.6506142616271973, Accuracy: 0.791015625\n",
      "Batch: 85, Loss: 0.675208330154419, Accuracy: 0.77734375\n",
      "Batch: 86, Loss: 0.7369007468223572, Accuracy: 0.7470703125\n",
      "Batch: 87, Loss: 0.6313762068748474, Accuracy: 0.8017578125\n",
      "Batch: 88, Loss: 0.6760406494140625, Accuracy: 0.7822265625\n",
      "Batch: 89, Loss: 0.6845204830169678, Accuracy: 0.7900390625\n",
      "Batch: 90, Loss: 0.6228916645050049, Accuracy: 0.7861328125\n",
      "Batch: 91, Loss: 0.6527040004730225, Accuracy: 0.7724609375\n",
      "Batch: 92, Loss: 0.6842800378799438, Accuracy: 0.771484375\n",
      "Batch: 93, Loss: 0.6429535150527954, Accuracy: 0.783203125\n",
      "Batch: 94, Loss: 0.6822586059570312, Accuracy: 0.7724609375\n",
      "Batch: 95, Loss: 0.7348672747612, Accuracy: 0.740234375\n",
      "Batch: 96, Loss: 0.6377120018005371, Accuracy: 0.7900390625\n",
      "Batch: 97, Loss: 0.569092869758606, Accuracy: 0.80078125\n",
      "Batch: 98, Loss: 0.6629289984703064, Accuracy: 0.7890625\n",
      "Batch: 99, Loss: 0.6665938496589661, Accuracy: 0.7841796875\n",
      "Batch: 100, Loss: 0.6637904644012451, Accuracy: 0.7822265625\n",
      "Batch: 101, Loss: 0.6970412135124207, Accuracy: 0.7734375\n",
      "Batch: 104, Loss: 0.6202357411384583, Accuracy: 0.7919921875\n",
      "Batch: 105, Loss: 0.7025752663612366, Accuracy: 0.763671875\n",
      "Batch: 106, Loss: 0.6098554730415344, Accuracy: 0.7900390625\n",
      "Batch: 107, Loss: 0.6752905249595642, Accuracy: 0.78515625\n",
      "Batch: 108, Loss: 0.6385554075241089, Accuracy: 0.7998046875\n",
      "Batch: 109, Loss: 0.7527011036872864, Accuracy: 0.74609375\n",
      "Batch: 110, Loss: 0.6133673191070557, Accuracy: 0.791015625\n",
      "Batch: 111, Loss: 0.6947402954101562, Accuracy: 0.78125\n",
      "Batch: 112, Loss: 0.6490107774734497, Accuracy: 0.7841796875\n",
      "Batch: 113, Loss: 0.6515798568725586, Accuracy: 0.7822265625\n",
      "Batch: 114, Loss: 0.7427380084991455, Accuracy: 0.744140625\n",
      "Batch: 115, Loss: 0.7529850602149963, Accuracy: 0.767578125\n",
      "Batch: 116, Loss: 0.7115987539291382, Accuracy: 0.7861328125\n",
      "Batch: 117, Loss: 0.7051615715026855, Accuracy: 0.7587890625\n",
      "Batch: 118, Loss: 0.558583676815033, Accuracy: 0.8193359375\n",
      "Batch: 119, Loss: 0.5451680421829224, Accuracy: 0.80859375\n",
      "Batch: 120, Loss: 0.70326828956604, Accuracy: 0.7724609375\n",
      "Batch: 121, Loss: 0.7015115022659302, Accuracy: 0.771484375\n",
      "Batch: 122, Loss: 0.65491783618927, Accuracy: 0.78515625\n",
      "Batch: 123, Loss: 0.6129995584487915, Accuracy: 0.794921875\n",
      "Batch: 124, Loss: 0.6662358641624451, Accuracy: 0.787109375\n",
      "Batch: 125, Loss: 0.7297634482383728, Accuracy: 0.763671875\n",
      "Batch: 126, Loss: 0.7182331085205078, Accuracy: 0.7646484375\n",
      "Batch: 127, Loss: 0.611526370048523, Accuracy: 0.7998046875\n",
      "Batch: 128, Loss: 0.7307693958282471, Accuracy: 0.7919921875\n",
      "Batch: 129, Loss: 0.5958765149116516, Accuracy: 0.8076171875\n",
      "Batch: 130, Loss: 0.7601224780082703, Accuracy: 0.7548828125\n",
      "Batch: 131, Loss: 0.660976231098175, Accuracy: 0.783203125\n",
      "Batch: 132, Loss: 0.7354896664619446, Accuracy: 0.763671875\n",
      "Batch: 133, Loss: 0.6461855173110962, Accuracy: 0.7978515625\n",
      "Batch: 134, Loss: 0.7078254222869873, Accuracy: 0.76953125\n",
      "Batch: 135, Loss: 0.6138232350349426, Accuracy: 0.802734375\n",
      "Batch: 136, Loss: 0.6907154321670532, Accuracy: 0.77734375\n",
      "Batch: 137, Loss: 0.6862533092498779, Accuracy: 0.7587890625\n",
      "Batch: 138, Loss: 0.5780270099639893, Accuracy: 0.8046875\n",
      "Batch: 139, Loss: 0.6357285380363464, Accuracy: 0.78515625\n",
      "Batch: 140, Loss: 0.6545950174331665, Accuracy: 0.783203125\n",
      "Batch: 141, Loss: 0.7177683115005493, Accuracy: 0.7578125\n",
      "Batch: 142, Loss: 0.7382673621177673, Accuracy: 0.7578125\n",
      "Batch: 143, Loss: 0.6864303350448608, Accuracy: 0.775390625\n",
      "Batch: 144, Loss: 0.6702378392219543, Accuracy: 0.7724609375\n",
      "Batch: 145, Loss: 0.6606376767158508, Accuracy: 0.7841796875\n",
      "Batch: 146, Loss: 0.7188901305198669, Accuracy: 0.7626953125\n",
      "Batch: 148, Loss: 0.7749629616737366, Accuracy: 0.7451171875\n",
      "Batch: 149, Loss: 0.6529569625854492, Accuracy: 0.775390625\n",
      "Batch: 150, Loss: 0.6820520162582397, Accuracy: 0.767578125\n",
      "Batch: 151, Loss: 0.607797384262085, Accuracy: 0.8095703125\n",
      "Epoch 68/80\n",
      "Batch: 1, Loss: 0.8899204730987549, Accuracy: 0.716796875\n",
      "Batch: 2, Loss: 0.7530862092971802, Accuracy: 0.744140625\n",
      "Batch: 3, Loss: 0.6602869629859924, Accuracy: 0.767578125\n",
      "Batch: 4, Loss: 0.5946711897850037, Accuracy: 0.818359375\n",
      "Batch: 5, Loss: 0.6619600057601929, Accuracy: 0.779296875\n",
      "Batch: 6, Loss: 0.6914869546890259, Accuracy: 0.7607421875\n",
      "Batch: 7, Loss: 0.711718738079071, Accuracy: 0.7470703125\n",
      "Batch: 8, Loss: 0.6593916416168213, Accuracy: 0.77734375\n",
      "Batch: 9, Loss: 0.642671525478363, Accuracy: 0.77734375\n",
      "Batch: 10, Loss: 0.6187529563903809, Accuracy: 0.802734375\n",
      "Batch: 11, Loss: 0.7556931376457214, Accuracy: 0.734375\n",
      "Batch: 12, Loss: 0.7458695769309998, Accuracy: 0.7666015625\n",
      "Batch: 13, Loss: 0.5444443225860596, Accuracy: 0.8154296875\n",
      "Batch: 14, Loss: 0.7273999452590942, Accuracy: 0.7470703125\n",
      "Batch: 15, Loss: 0.6224124431610107, Accuracy: 0.7978515625\n",
      "Batch: 16, Loss: 0.6578444838523865, Accuracy: 0.7900390625\n",
      "Batch: 17, Loss: 0.6595628261566162, Accuracy: 0.7900390625\n",
      "Batch: 18, Loss: 0.6720103025436401, Accuracy: 0.7802734375\n",
      "Batch: 19, Loss: 0.6644827127456665, Accuracy: 0.7822265625\n",
      "Batch: 20, Loss: 0.598374605178833, Accuracy: 0.8056640625\n",
      "Batch: 21, Loss: 0.6173720359802246, Accuracy: 0.78515625\n",
      "Batch: 22, Loss: 0.7318324446678162, Accuracy: 0.7626953125\n",
      "Batch: 23, Loss: 0.7029092907905579, Accuracy: 0.765625\n",
      "Batch: 24, Loss: 0.6864361763000488, Accuracy: 0.775390625\n",
      "Batch: 25, Loss: 0.665497899055481, Accuracy: 0.79296875\n",
      "Batch: 26, Loss: 0.5577750205993652, Accuracy: 0.8154296875\n",
      "Batch: 27, Loss: 0.6079217195510864, Accuracy: 0.79296875\n",
      "Batch: 28, Loss: 0.6826273202896118, Accuracy: 0.76953125\n",
      "Batch: 29, Loss: 0.6389169692993164, Accuracy: 0.7763671875\n",
      "Batch: 30, Loss: 0.5780504941940308, Accuracy: 0.8212890625\n",
      "Batch: 31, Loss: 0.571060299873352, Accuracy: 0.810546875\n",
      "Batch: 32, Loss: 0.5897635221481323, Accuracy: 0.80078125\n",
      "Batch: 33, Loss: 0.7171934843063354, Accuracy: 0.7734375\n",
      "Batch: 34, Loss: 0.7628113031387329, Accuracy: 0.748046875\n",
      "Batch: 35, Loss: 0.6979113817214966, Accuracy: 0.7646484375\n",
      "Batch: 36, Loss: 0.688600480556488, Accuracy: 0.7802734375\n",
      "Batch: 37, Loss: 0.6510048508644104, Accuracy: 0.787109375\n",
      "Batch: 38, Loss: 0.6732684373855591, Accuracy: 0.7646484375\n",
      "Batch: 39, Loss: 0.6887826919555664, Accuracy: 0.7783203125\n",
      "Batch: 40, Loss: 0.6404983401298523, Accuracy: 0.7890625\n",
      "Batch: 41, Loss: 0.5899435877799988, Accuracy: 0.7998046875\n",
      "Batch: 42, Loss: 0.5246525406837463, Accuracy: 0.830078125\n",
      "Batch: 43, Loss: 0.672687828540802, Accuracy: 0.7763671875\n",
      "Batch: 44, Loss: 0.6778910756111145, Accuracy: 0.7802734375\n",
      "Batch: 45, Loss: 0.5788771510124207, Accuracy: 0.8046875\n",
      "Batch: 46, Loss: 0.6113075017929077, Accuracy: 0.80859375\n",
      "Batch: 47, Loss: 0.6456955671310425, Accuracy: 0.7939453125\n",
      "Batch: 48, Loss: 0.6324349641799927, Accuracy: 0.7880859375\n",
      "Batch: 49, Loss: 0.7106325626373291, Accuracy: 0.771484375\n",
      "Batch: 50, Loss: 0.647772490978241, Accuracy: 0.796875\n",
      "Batch: 51, Loss: 0.6576501131057739, Accuracy: 0.7900390625\n",
      "Batch: 52, Loss: 0.6547684669494629, Accuracy: 0.787109375\n",
      "Batch: 53, Loss: 0.6020354628562927, Accuracy: 0.798828125\n",
      "Batch: 54, Loss: 0.6290762424468994, Accuracy: 0.7958984375\n",
      "Batch: 55, Loss: 0.7643811106681824, Accuracy: 0.740234375\n",
      "Batch: 56, Loss: 0.7384968996047974, Accuracy: 0.7685546875\n",
      "Batch: 57, Loss: 0.7018771171569824, Accuracy: 0.7587890625\n",
      "Batch: 58, Loss: 0.7326771020889282, Accuracy: 0.77734375\n",
      "Batch: 59, Loss: 0.6354790925979614, Accuracy: 0.791015625\n",
      "Batch: 60, Loss: 0.6237614154815674, Accuracy: 0.80078125\n",
      "Batch: 61, Loss: 0.7266857624053955, Accuracy: 0.771484375\n",
      "Batch: 62, Loss: 0.6328430771827698, Accuracy: 0.79296875\n",
      "Batch: 63, Loss: 0.688352108001709, Accuracy: 0.775390625\n",
      "Batch: 64, Loss: 0.6526787281036377, Accuracy: 0.79296875\n",
      "Batch: 65, Loss: 0.6668179035186768, Accuracy: 0.77734375\n",
      "Batch: 66, Loss: 0.6723594665527344, Accuracy: 0.779296875\n",
      "Batch: 67, Loss: 0.7627190351486206, Accuracy: 0.7705078125\n",
      "Batch: 68, Loss: 0.7685767412185669, Accuracy: 0.75390625\n",
      "Batch: 69, Loss: 0.693864107131958, Accuracy: 0.7666015625\n",
      "Batch: 70, Loss: 0.6928417682647705, Accuracy: 0.783203125\n",
      "Batch: 71, Loss: 0.7143839597702026, Accuracy: 0.7626953125\n",
      "Batch: 72, Loss: 0.6162451505661011, Accuracy: 0.7880859375\n",
      "Batch: 73, Loss: 0.6067314147949219, Accuracy: 0.7978515625\n",
      "Batch: 74, Loss: 0.5733033418655396, Accuracy: 0.8232421875\n",
      "Batch: 75, Loss: 0.6121420860290527, Accuracy: 0.79296875\n",
      "Batch: 76, Loss: 0.6596376299858093, Accuracy: 0.7861328125\n",
      "Batch: 77, Loss: 0.591241717338562, Accuracy: 0.806640625\n",
      "Batch: 78, Loss: 0.604042112827301, Accuracy: 0.806640625\n",
      "Batch: 79, Loss: 0.5838192701339722, Accuracy: 0.81640625\n",
      "Batch: 80, Loss: 0.6205525398254395, Accuracy: 0.7998046875\n",
      "Batch: 81, Loss: 0.7289147973060608, Accuracy: 0.7431640625\n",
      "Batch: 82, Loss: 0.6857786178588867, Accuracy: 0.763671875\n",
      "Batch: 83, Loss: 0.5795032978057861, Accuracy: 0.8134765625\n",
      "Batch: 84, Loss: 0.6518737077713013, Accuracy: 0.783203125\n",
      "Batch: 85, Loss: 0.6481850147247314, Accuracy: 0.7958984375\n",
      "Batch: 86, Loss: 0.7542886734008789, Accuracy: 0.7607421875\n",
      "Batch: 87, Loss: 0.64995938539505, Accuracy: 0.7978515625\n",
      "Batch: 88, Loss: 0.7167035341262817, Accuracy: 0.7705078125\n",
      "Batch: 89, Loss: 0.6555233597755432, Accuracy: 0.7958984375\n",
      "Batch: 90, Loss: 0.6429639458656311, Accuracy: 0.80078125\n",
      "Batch: 91, Loss: 0.6625803709030151, Accuracy: 0.775390625\n",
      "Batch: 94, Loss: 0.7093816995620728, Accuracy: 0.75390625\n",
      "Batch: 95, Loss: 0.7228237390518188, Accuracy: 0.7607421875\n",
      "Batch: 96, Loss: 0.6346553564071655, Accuracy: 0.79296875\n",
      "Batch: 97, Loss: 0.5688256025314331, Accuracy: 0.802734375\n",
      "Batch: 98, Loss: 0.6426486968994141, Accuracy: 0.7861328125\n",
      "Batch: 99, Loss: 0.6535782814025879, Accuracy: 0.7890625\n",
      "Batch: 100, Loss: 0.6947186589241028, Accuracy: 0.779296875\n",
      "Batch: 101, Loss: 0.6818156242370605, Accuracy: 0.7705078125\n",
      "Batch: 102, Loss: 0.6640254259109497, Accuracy: 0.787109375\n",
      "Batch: 103, Loss: 0.6630339026451111, Accuracy: 0.775390625\n",
      "Batch: 104, Loss: 0.6273229122161865, Accuracy: 0.7802734375\n",
      "Batch: 105, Loss: 0.7351603507995605, Accuracy: 0.7578125\n",
      "Batch: 106, Loss: 0.6193181872367859, Accuracy: 0.7861328125\n",
      "Batch: 107, Loss: 0.6684132814407349, Accuracy: 0.775390625\n",
      "Batch: 108, Loss: 0.6203185319900513, Accuracy: 0.8046875\n",
      "Batch: 109, Loss: 0.7563134431838989, Accuracy: 0.7353515625\n",
      "Batch: 110, Loss: 0.6357804536819458, Accuracy: 0.791015625\n",
      "Batch: 111, Loss: 0.6854212880134583, Accuracy: 0.7783203125\n",
      "Batch: 112, Loss: 0.6738249063491821, Accuracy: 0.7822265625\n",
      "Batch: 113, Loss: 0.6549481153488159, Accuracy: 0.775390625\n",
      "Batch: 114, Loss: 0.7470879554748535, Accuracy: 0.75\n",
      "Batch: 115, Loss: 0.7910036444664001, Accuracy: 0.7529296875\n",
      "Batch: 116, Loss: 0.6778625249862671, Accuracy: 0.7841796875\n",
      "Batch: 117, Loss: 0.6633171439170837, Accuracy: 0.7939453125\n",
      "Batch: 118, Loss: 0.559394359588623, Accuracy: 0.8173828125\n",
      "Batch: 119, Loss: 0.5560818314552307, Accuracy: 0.82421875\n",
      "Batch: 120, Loss: 0.6944674253463745, Accuracy: 0.7822265625\n",
      "Batch: 121, Loss: 0.6869293451309204, Accuracy: 0.7744140625\n",
      "Batch: 122, Loss: 0.6445790529251099, Accuracy: 0.7900390625\n",
      "Batch: 123, Loss: 0.5993419885635376, Accuracy: 0.798828125\n",
      "Batch: 124, Loss: 0.6937136650085449, Accuracy: 0.7783203125\n",
      "Batch: 125, Loss: 0.7233362197875977, Accuracy: 0.77734375\n",
      "Batch: 126, Loss: 0.7154009342193604, Accuracy: 0.7763671875\n",
      "Batch: 127, Loss: 0.5770885944366455, Accuracy: 0.828125\n",
      "Batch: 128, Loss: 0.7418436408042908, Accuracy: 0.7939453125\n",
      "Batch: 129, Loss: 0.6271846294403076, Accuracy: 0.7822265625\n",
      "Batch: 130, Loss: 0.7392337322235107, Accuracy: 0.75\n",
      "Batch: 131, Loss: 0.6595888137817383, Accuracy: 0.7802734375\n",
      "Batch: 132, Loss: 0.7024588584899902, Accuracy: 0.7685546875\n",
      "Batch: 133, Loss: 0.6324647068977356, Accuracy: 0.7841796875\n",
      "Batch: 134, Loss: 0.6805208921432495, Accuracy: 0.76953125\n",
      "Batch: 135, Loss: 0.6187953948974609, Accuracy: 0.80078125\n",
      "Batch: 136, Loss: 0.6692085266113281, Accuracy: 0.7666015625\n",
      "Batch: 137, Loss: 0.654990017414093, Accuracy: 0.7626953125\n",
      "Batch: 138, Loss: 0.5910249352455139, Accuracy: 0.7978515625\n",
      "Batch: 139, Loss: 0.6310560703277588, Accuracy: 0.78125\n",
      "Batch: 140, Loss: 0.6729122400283813, Accuracy: 0.775390625\n",
      "Batch: 141, Loss: 0.7197515368461609, Accuracy: 0.7607421875\n",
      "Batch: 143, Loss: 0.6688033938407898, Accuracy: 0.775390625\n",
      "Batch: 144, Loss: 0.6781449317932129, Accuracy: 0.76953125\n",
      "Batch: 145, Loss: 0.6434520483016968, Accuracy: 0.7802734375\n",
      "Batch: 146, Loss: 0.6878566145896912, Accuracy: 0.7802734375\n",
      "Batch: 147, Loss: 0.6815980076789856, Accuracy: 0.78125\n",
      "Batch: 148, Loss: 0.7670148611068726, Accuracy: 0.7451171875\n",
      "Batch: 149, Loss: 0.6590334177017212, Accuracy: 0.7802734375\n",
      "Batch: 150, Loss: 0.6577972173690796, Accuracy: 0.7783203125\n",
      "Batch: 151, Loss: 0.6247622966766357, Accuracy: 0.796875\n",
      "Epoch 69/80\n",
      "Batch: 1, Loss: 0.8929139971733093, Accuracy: 0.716796875\n",
      "Batch: 2, Loss: 0.7560704350471497, Accuracy: 0.7294921875\n",
      "Batch: 3, Loss: 0.6673877835273743, Accuracy: 0.77734375\n",
      "Batch: 4, Loss: 0.6066733002662659, Accuracy: 0.8076171875\n",
      "Batch: 5, Loss: 0.6518412232398987, Accuracy: 0.7724609375\n",
      "Batch: 6, Loss: 0.6929726600646973, Accuracy: 0.7666015625\n",
      "Batch: 7, Loss: 0.6998776793479919, Accuracy: 0.7490234375\n",
      "Batch: 8, Loss: 0.6290658116340637, Accuracy: 0.796875\n",
      "Batch: 9, Loss: 0.6269394159317017, Accuracy: 0.7900390625\n",
      "Batch: 10, Loss: 0.5914204716682434, Accuracy: 0.7890625\n",
      "Batch: 11, Loss: 0.7569199800491333, Accuracy: 0.732421875\n",
      "Batch: 12, Loss: 0.7159456014633179, Accuracy: 0.7626953125\n",
      "Batch: 13, Loss: 0.5373495221138, Accuracy: 0.8193359375\n",
      "Batch: 14, Loss: 0.725887656211853, Accuracy: 0.759765625\n",
      "Batch: 15, Loss: 0.5963168144226074, Accuracy: 0.81640625\n",
      "Batch: 16, Loss: 0.6627210378646851, Accuracy: 0.7783203125\n",
      "Batch: 17, Loss: 0.6864012479782104, Accuracy: 0.765625\n",
      "Batch: 18, Loss: 0.6782950162887573, Accuracy: 0.7763671875\n",
      "Batch: 19, Loss: 0.6951595544815063, Accuracy: 0.7763671875\n",
      "Batch: 20, Loss: 0.5795481204986572, Accuracy: 0.8125\n",
      "Batch: 21, Loss: 0.607193112373352, Accuracy: 0.7978515625\n",
      "Batch: 22, Loss: 0.7526886463165283, Accuracy: 0.765625\n",
      "Batch: 23, Loss: 0.6525613069534302, Accuracy: 0.78125\n",
      "Batch: 24, Loss: 0.6899372339248657, Accuracy: 0.7763671875\n",
      "Batch: 25, Loss: 0.6323360204696655, Accuracy: 0.8056640625\n",
      "Batch: 26, Loss: 0.6046650409698486, Accuracy: 0.8056640625\n",
      "Batch: 27, Loss: 0.5848378539085388, Accuracy: 0.8046875\n",
      "Batch: 28, Loss: 0.6768089532852173, Accuracy: 0.775390625\n",
      "Batch: 29, Loss: 0.6386492252349854, Accuracy: 0.7939453125\n",
      "Batch: 30, Loss: 0.6021065711975098, Accuracy: 0.8056640625\n",
      "Batch: 31, Loss: 0.559674084186554, Accuracy: 0.8115234375\n",
      "Batch: 32, Loss: 0.5832047462463379, Accuracy: 0.7978515625\n",
      "Batch: 33, Loss: 0.7015397548675537, Accuracy: 0.765625\n",
      "Batch: 34, Loss: 0.751702070236206, Accuracy: 0.7490234375\n",
      "Batch: 35, Loss: 0.7097541093826294, Accuracy: 0.7666015625\n",
      "Batch: 36, Loss: 0.7265859842300415, Accuracy: 0.7734375\n",
      "Batch: 37, Loss: 0.6903226375579834, Accuracy: 0.7734375\n",
      "Batch: 38, Loss: 0.696214497089386, Accuracy: 0.763671875\n",
      "Batch: 41, Loss: 0.6056027412414551, Accuracy: 0.7998046875\n",
      "Batch: 42, Loss: 0.519425630569458, Accuracy: 0.8232421875\n",
      "Batch: 43, Loss: 0.6687651872634888, Accuracy: 0.7724609375\n",
      "Batch: 44, Loss: 0.6935053467750549, Accuracy: 0.7666015625\n",
      "Batch: 45, Loss: 0.5963743925094604, Accuracy: 0.794921875\n",
      "Batch: 46, Loss: 0.6094945669174194, Accuracy: 0.7890625\n",
      "Batch: 47, Loss: 0.6558427214622498, Accuracy: 0.7919921875\n",
      "Batch: 48, Loss: 0.6215187311172485, Accuracy: 0.8037109375\n",
      "Batch: 49, Loss: 0.6980072259902954, Accuracy: 0.7900390625\n",
      "Batch: 50, Loss: 0.6704241633415222, Accuracy: 0.7861328125\n",
      "Batch: 51, Loss: 0.6760152578353882, Accuracy: 0.76953125\n",
      "Batch: 52, Loss: 0.6648861169815063, Accuracy: 0.7705078125\n",
      "Batch: 53, Loss: 0.5958030223846436, Accuracy: 0.796875\n",
      "Batch: 54, Loss: 0.6584939956665039, Accuracy: 0.783203125\n",
      "Batch: 55, Loss: 0.738084614276886, Accuracy: 0.7412109375\n",
      "Batch: 56, Loss: 0.7337269186973572, Accuracy: 0.763671875\n",
      "Batch: 57, Loss: 0.6643192172050476, Accuracy: 0.779296875\n",
      "Batch: 58, Loss: 0.7658349275588989, Accuracy: 0.748046875\n",
      "Batch: 59, Loss: 0.6567876935005188, Accuracy: 0.794921875\n",
      "Batch: 60, Loss: 0.6489297747612, Accuracy: 0.78515625\n",
      "Batch: 61, Loss: 0.7185262441635132, Accuracy: 0.7802734375\n",
      "Batch: 62, Loss: 0.6508294343948364, Accuracy: 0.7861328125\n",
      "Batch: 63, Loss: 0.6840368509292603, Accuracy: 0.7744140625\n",
      "Batch: 64, Loss: 0.6629952192306519, Accuracy: 0.7841796875\n",
      "Batch: 65, Loss: 0.6586692333221436, Accuracy: 0.7763671875\n",
      "Batch: 66, Loss: 0.6689044833183289, Accuracy: 0.779296875\n",
      "Batch: 67, Loss: 0.7277134656906128, Accuracy: 0.767578125\n",
      "Batch: 68, Loss: 0.7747780084609985, Accuracy: 0.7470703125\n",
      "Batch: 69, Loss: 0.6833567023277283, Accuracy: 0.7705078125\n",
      "Batch: 70, Loss: 0.6698629260063171, Accuracy: 0.7841796875\n",
      "Batch: 71, Loss: 0.7167899012565613, Accuracy: 0.74609375\n",
      "Batch: 72, Loss: 0.619973361492157, Accuracy: 0.7919921875\n",
      "Batch: 73, Loss: 0.6284666657447815, Accuracy: 0.80078125\n",
      "Batch: 74, Loss: 0.6120293140411377, Accuracy: 0.8056640625\n",
      "Batch: 75, Loss: 0.5993781685829163, Accuracy: 0.79296875\n",
      "Batch: 76, Loss: 0.627505898475647, Accuracy: 0.7998046875\n",
      "Batch: 77, Loss: 0.6206417083740234, Accuracy: 0.8017578125\n",
      "Batch: 78, Loss: 0.6177369356155396, Accuracy: 0.798828125\n",
      "Batch: 79, Loss: 0.5911778211593628, Accuracy: 0.82421875\n",
      "Batch: 80, Loss: 0.6093758344650269, Accuracy: 0.7998046875\n",
      "Batch: 81, Loss: 0.710828423500061, Accuracy: 0.75\n",
      "Batch: 82, Loss: 0.6717586517333984, Accuracy: 0.775390625\n",
      "Batch: 83, Loss: 0.5961476564407349, Accuracy: 0.8017578125\n",
      "Batch: 84, Loss: 0.6308812499046326, Accuracy: 0.79296875\n",
      "Batch: 86, Loss: 0.7348722219467163, Accuracy: 0.7626953125\n",
      "Batch: 87, Loss: 0.6186879277229309, Accuracy: 0.798828125\n",
      "Batch: 88, Loss: 0.7253216505050659, Accuracy: 0.7607421875\n",
      "Batch: 89, Loss: 0.6454423666000366, Accuracy: 0.7958984375\n",
      "Batch: 90, Loss: 0.6341185569763184, Accuracy: 0.7939453125\n",
      "Batch: 91, Loss: 0.657822847366333, Accuracy: 0.7900390625\n",
      "Batch: 92, Loss: 0.635299563407898, Accuracy: 0.7802734375\n",
      "Batch: 93, Loss: 0.6558640003204346, Accuracy: 0.7666015625\n",
      "Batch: 94, Loss: 0.6856104135513306, Accuracy: 0.7587890625\n",
      "Batch: 95, Loss: 0.6905816197395325, Accuracy: 0.7734375\n",
      "Batch: 96, Loss: 0.677043080329895, Accuracy: 0.7705078125\n",
      "Batch: 97, Loss: 0.5795812606811523, Accuracy: 0.8095703125\n",
      "Batch: 98, Loss: 0.6314020156860352, Accuracy: 0.78515625\n",
      "Batch: 99, Loss: 0.6715355515480042, Accuracy: 0.787109375\n",
      "Batch: 100, Loss: 0.6479405760765076, Accuracy: 0.7802734375\n",
      "Batch: 101, Loss: 0.6779720187187195, Accuracy: 0.75\n",
      "Batch: 102, Loss: 0.6363087892532349, Accuracy: 0.78515625\n",
      "Batch: 103, Loss: 0.6523538827896118, Accuracy: 0.796875\n",
      "Batch: 104, Loss: 0.6306948661804199, Accuracy: 0.7880859375\n",
      "Batch: 105, Loss: 0.6875373721122742, Accuracy: 0.765625\n",
      "Batch: 106, Loss: 0.5915023684501648, Accuracy: 0.802734375\n",
      "Batch: 107, Loss: 0.6681816577911377, Accuracy: 0.791015625\n",
      "Batch: 108, Loss: 0.6169919967651367, Accuracy: 0.798828125\n",
      "Batch: 109, Loss: 0.7394442558288574, Accuracy: 0.7548828125\n",
      "Batch: 110, Loss: 0.6148349046707153, Accuracy: 0.7958984375\n",
      "Batch: 111, Loss: 0.6666944622993469, Accuracy: 0.7861328125\n",
      "Batch: 112, Loss: 0.642200231552124, Accuracy: 0.7939453125\n",
      "Batch: 113, Loss: 0.6613032221794128, Accuracy: 0.763671875\n",
      "Batch: 114, Loss: 0.731212854385376, Accuracy: 0.763671875\n",
      "Batch: 115, Loss: 0.7740254402160645, Accuracy: 0.7431640625\n",
      "Batch: 116, Loss: 0.687135636806488, Accuracy: 0.77734375\n",
      "Batch: 117, Loss: 0.6752927303314209, Accuracy: 0.783203125\n",
      "Batch: 118, Loss: 0.5923477411270142, Accuracy: 0.814453125\n",
      "Batch: 119, Loss: 0.5507799983024597, Accuracy: 0.81640625\n",
      "Batch: 120, Loss: 0.6816012859344482, Accuracy: 0.783203125\n",
      "Batch: 121, Loss: 0.7027976512908936, Accuracy: 0.7783203125\n",
      "Batch: 122, Loss: 0.642909049987793, Accuracy: 0.7900390625\n",
      "Batch: 123, Loss: 0.594586968421936, Accuracy: 0.80859375\n",
      "Batch: 124, Loss: 0.6706655621528625, Accuracy: 0.78125\n",
      "Batch: 125, Loss: 0.7330555319786072, Accuracy: 0.759765625\n",
      "Batch: 126, Loss: 0.6765984296798706, Accuracy: 0.7841796875\n",
      "Batch: 127, Loss: 0.5592443943023682, Accuracy: 0.8369140625\n",
      "Batch: 128, Loss: 0.7578486204147339, Accuracy: 0.76953125\n",
      "Batch: 129, Loss: 0.6061065196990967, Accuracy: 0.80078125\n",
      "Batch: 130, Loss: 0.7539071440696716, Accuracy: 0.75\n",
      "Batch: 133, Loss: 0.6384803056716919, Accuracy: 0.78515625\n",
      "Batch: 134, Loss: 0.701597273349762, Accuracy: 0.76171875\n",
      "Batch: 135, Loss: 0.6122641563415527, Accuracy: 0.806640625\n",
      "Batch: 136, Loss: 0.6796880960464478, Accuracy: 0.77734375\n",
      "Batch: 137, Loss: 0.6698026657104492, Accuracy: 0.7705078125\n",
      "Batch: 138, Loss: 0.58412766456604, Accuracy: 0.806640625\n",
      "Batch: 139, Loss: 0.6462372541427612, Accuracy: 0.7841796875\n",
      "Batch: 140, Loss: 0.6761742234230042, Accuracy: 0.76953125\n",
      "Batch: 141, Loss: 0.7061959505081177, Accuracy: 0.7626953125\n",
      "Batch: 142, Loss: 0.724952757358551, Accuracy: 0.7626953125\n",
      "Batch: 143, Loss: 0.6428737640380859, Accuracy: 0.791015625\n",
      "Batch: 144, Loss: 0.6780778765678406, Accuracy: 0.7880859375\n",
      "Batch: 145, Loss: 0.6284849047660828, Accuracy: 0.7890625\n",
      "Batch: 146, Loss: 0.6953715682029724, Accuracy: 0.7783203125\n",
      "Batch: 147, Loss: 0.6850653886795044, Accuracy: 0.775390625\n",
      "Batch: 148, Loss: 0.7627378702163696, Accuracy: 0.7490234375\n",
      "Batch: 149, Loss: 0.6187252998352051, Accuracy: 0.8076171875\n",
      "Batch: 150, Loss: 0.6686990261077881, Accuracy: 0.78515625\n",
      "Batch: 151, Loss: 0.6138936877250671, Accuracy: 0.8095703125\n",
      "Epoch 70/80\n",
      "Batch: 1, Loss: 0.8804609775543213, Accuracy: 0.7255859375\n",
      "Batch: 2, Loss: 0.7499719858169556, Accuracy: 0.734375\n",
      "Batch: 3, Loss: 0.6856999397277832, Accuracy: 0.7841796875\n",
      "Batch: 4, Loss: 0.6126967668533325, Accuracy: 0.8134765625\n",
      "Batch: 5, Loss: 0.6477678418159485, Accuracy: 0.7802734375\n",
      "Batch: 6, Loss: 0.6830445528030396, Accuracy: 0.7724609375\n",
      "Batch: 7, Loss: 0.7135972380638123, Accuracy: 0.75390625\n",
      "Batch: 8, Loss: 0.6290819644927979, Accuracy: 0.779296875\n",
      "Batch: 9, Loss: 0.6520690321922302, Accuracy: 0.7890625\n",
      "Batch: 10, Loss: 0.6029295921325684, Accuracy: 0.79296875\n",
      "Batch: 11, Loss: 0.7000730633735657, Accuracy: 0.7666015625\n",
      "Batch: 12, Loss: 0.6793107986450195, Accuracy: 0.7685546875\n",
      "Batch: 13, Loss: 0.5388601422309875, Accuracy: 0.8310546875\n",
      "Batch: 14, Loss: 0.6948165893554688, Accuracy: 0.7744140625\n",
      "Batch: 15, Loss: 0.609125018119812, Accuracy: 0.7978515625\n",
      "Batch: 16, Loss: 0.6400580406188965, Accuracy: 0.7939453125\n",
      "Batch: 17, Loss: 0.6792317628860474, Accuracy: 0.78515625\n",
      "Batch: 18, Loss: 0.6868160367012024, Accuracy: 0.765625\n",
      "Batch: 19, Loss: 0.6682188510894775, Accuracy: 0.79296875\n",
      "Batch: 20, Loss: 0.5803409814834595, Accuracy: 0.814453125\n",
      "Batch: 21, Loss: 0.5939462780952454, Accuracy: 0.8017578125\n",
      "Batch: 22, Loss: 0.7578149437904358, Accuracy: 0.751953125\n",
      "Batch: 23, Loss: 0.6941548585891724, Accuracy: 0.763671875\n",
      "Batch: 24, Loss: 0.6659002304077148, Accuracy: 0.763671875\n",
      "Batch: 25, Loss: 0.6636437177658081, Accuracy: 0.779296875\n",
      "Batch: 26, Loss: 0.5997600555419922, Accuracy: 0.7998046875\n",
      "Batch: 27, Loss: 0.6163312196731567, Accuracy: 0.7939453125\n",
      "Batch: 28, Loss: 0.7172942757606506, Accuracy: 0.763671875\n",
      "Batch: 29, Loss: 0.608959436416626, Accuracy: 0.7998046875\n",
      "Batch: 30, Loss: 0.5672943592071533, Accuracy: 0.8203125\n",
      "Batch: 31, Loss: 0.5697408318519592, Accuracy: 0.8125\n",
      "Batch: 32, Loss: 0.6114844083786011, Accuracy: 0.794921875\n",
      "Batch: 33, Loss: 0.7125203609466553, Accuracy: 0.771484375\n",
      "Batch: 34, Loss: 0.6933630704879761, Accuracy: 0.7666015625\n",
      "Batch: 35, Loss: 0.6898738741874695, Accuracy: 0.7880859375\n",
      "Batch: 36, Loss: 0.7241529226303101, Accuracy: 0.771484375\n",
      "Batch: 37, Loss: 0.6716051697731018, Accuracy: 0.7734375\n",
      "Batch: 38, Loss: 0.6669008731842041, Accuracy: 0.7783203125\n",
      "Batch: 39, Loss: 0.6891170740127563, Accuracy: 0.779296875\n",
      "Batch: 40, Loss: 0.6325422525405884, Accuracy: 0.796875\n",
      "Batch: 41, Loss: 0.6075286865234375, Accuracy: 0.7880859375\n",
      "Batch: 42, Loss: 0.5177026391029358, Accuracy: 0.8291015625\n",
      "Batch: 43, Loss: 0.6640257239341736, Accuracy: 0.7783203125\n",
      "Batch: 44, Loss: 0.6760228872299194, Accuracy: 0.779296875\n",
      "Batch: 45, Loss: 0.5640500783920288, Accuracy: 0.8154296875\n",
      "Batch: 46, Loss: 0.5915096998214722, Accuracy: 0.8134765625\n",
      "Batch: 47, Loss: 0.6554533243179321, Accuracy: 0.796875\n",
      "Batch: 48, Loss: 0.5819265842437744, Accuracy: 0.806640625\n",
      "Batch: 49, Loss: 0.6999991536140442, Accuracy: 0.779296875\n",
      "Batch: 50, Loss: 0.6795046925544739, Accuracy: 0.771484375\n",
      "Batch: 51, Loss: 0.6748246550559998, Accuracy: 0.7724609375\n",
      "Batch: 52, Loss: 0.6903623342514038, Accuracy: 0.7724609375\n",
      "Batch: 53, Loss: 0.5945894122123718, Accuracy: 0.8076171875\n",
      "Batch: 54, Loss: 0.6501049995422363, Accuracy: 0.7880859375\n",
      "Batch: 55, Loss: 0.7425696849822998, Accuracy: 0.751953125\n",
      "Batch: 56, Loss: 0.7274854183197021, Accuracy: 0.759765625\n",
      "Batch: 57, Loss: 0.6887734532356262, Accuracy: 0.775390625\n",
      "Batch: 58, Loss: 0.7295632362365723, Accuracy: 0.7783203125\n",
      "Batch: 59, Loss: 0.6411312222480774, Accuracy: 0.7900390625\n",
      "Batch: 60, Loss: 0.6105635166168213, Accuracy: 0.7919921875\n",
      "Batch: 61, Loss: 0.7194325923919678, Accuracy: 0.779296875\n",
      "Batch: 62, Loss: 0.6205471158027649, Accuracy: 0.7890625\n",
      "Batch: 63, Loss: 0.6771053075790405, Accuracy: 0.7724609375\n",
      "Batch: 64, Loss: 0.666405200958252, Accuracy: 0.7861328125\n",
      "Batch: 65, Loss: 0.6776343584060669, Accuracy: 0.787109375\n",
      "Batch: 66, Loss: 0.6705405712127686, Accuracy: 0.779296875\n",
      "Batch: 67, Loss: 0.7593793272972107, Accuracy: 0.7587890625\n",
      "Batch: 68, Loss: 0.7609433531761169, Accuracy: 0.7646484375\n",
      "Batch: 69, Loss: 0.6597142219543457, Accuracy: 0.7763671875\n",
      "Batch: 70, Loss: 0.6229158639907837, Accuracy: 0.802734375\n",
      "Batch: 74, Loss: 0.5758401155471802, Accuracy: 0.818359375\n",
      "Batch: 75, Loss: 0.6152088642120361, Accuracy: 0.7958984375\n",
      "Batch: 76, Loss: 0.6869888305664062, Accuracy: 0.765625\n",
      "Batch: 77, Loss: 0.6243289709091187, Accuracy: 0.814453125\n",
      "Batch: 78, Loss: 0.5866706371307373, Accuracy: 0.8134765625\n",
      "Batch: 79, Loss: 0.5611289143562317, Accuracy: 0.82421875\n",
      "Batch: 80, Loss: 0.6409643888473511, Accuracy: 0.78125\n",
      "Batch: 81, Loss: 0.6855125427246094, Accuracy: 0.751953125\n",
      "Batch: 82, Loss: 0.6846541166305542, Accuracy: 0.7666015625\n",
      "Batch: 83, Loss: 0.5759769678115845, Accuracy: 0.8134765625\n",
      "Batch: 84, Loss: 0.6261385083198547, Accuracy: 0.7880859375\n",
      "Batch: 85, Loss: 0.6354705095291138, Accuracy: 0.7998046875\n",
      "Batch: 86, Loss: 0.7364284992218018, Accuracy: 0.7626953125\n",
      "Batch: 87, Loss: 0.5883967280387878, Accuracy: 0.796875\n",
      "Batch: 88, Loss: 0.7086573839187622, Accuracy: 0.7802734375\n",
      "Batch: 89, Loss: 0.6598449349403381, Accuracy: 0.787109375\n",
      "Batch: 90, Loss: 0.6336367130279541, Accuracy: 0.7900390625\n",
      "Batch: 91, Loss: 0.6286096572875977, Accuracy: 0.783203125\n",
      "Batch: 92, Loss: 0.6713905930519104, Accuracy: 0.765625\n",
      "Batch: 93, Loss: 0.6491433382034302, Accuracy: 0.7890625\n",
      "Batch: 94, Loss: 0.692233681678772, Accuracy: 0.7646484375\n",
      "Batch: 95, Loss: 0.7090801000595093, Accuracy: 0.7578125\n",
      "Batch: 96, Loss: 0.6230736374855042, Accuracy: 0.7919921875\n",
      "Batch: 97, Loss: 0.515190601348877, Accuracy: 0.8271484375\n",
      "Batch: 98, Loss: 0.6417184472084045, Accuracy: 0.7822265625\n",
      "Batch: 99, Loss: 0.6616620421409607, Accuracy: 0.7841796875\n",
      "Batch: 100, Loss: 0.694002091884613, Accuracy: 0.765625\n",
      "Batch: 101, Loss: 0.6840638518333435, Accuracy: 0.76953125\n",
      "Batch: 102, Loss: 0.6578329801559448, Accuracy: 0.77734375\n",
      "Batch: 103, Loss: 0.681810200214386, Accuracy: 0.7763671875\n",
      "Batch: 104, Loss: 0.6231556534767151, Accuracy: 0.7958984375\n",
      "Batch: 105, Loss: 0.7149100303649902, Accuracy: 0.7666015625\n",
      "Batch: 106, Loss: 0.5863693356513977, Accuracy: 0.8115234375\n",
      "Batch: 107, Loss: 0.6571428775787354, Accuracy: 0.78125\n",
      "Batch: 108, Loss: 0.6377815008163452, Accuracy: 0.7861328125\n",
      "Batch: 109, Loss: 0.7314502596855164, Accuracy: 0.7548828125\n",
      "Batch: 110, Loss: 0.6094247698783875, Accuracy: 0.7900390625\n",
      "Batch: 111, Loss: 0.6598718762397766, Accuracy: 0.7998046875\n",
      "Batch: 112, Loss: 0.6637829542160034, Accuracy: 0.779296875\n",
      "Batch: 113, Loss: 0.6669858694076538, Accuracy: 0.7890625\n",
      "Batch: 114, Loss: 0.746952474117279, Accuracy: 0.765625\n",
      "Batch: 115, Loss: 0.7738879323005676, Accuracy: 0.751953125\n",
      "Batch: 116, Loss: 0.7110586166381836, Accuracy: 0.7724609375\n",
      "Batch: 120, Loss: 0.69884192943573, Accuracy: 0.771484375\n",
      "Batch: 121, Loss: 0.7119725346565247, Accuracy: 0.771484375\n",
      "Batch: 122, Loss: 0.620500922203064, Accuracy: 0.802734375\n",
      "Batch: 123, Loss: 0.6079200506210327, Accuracy: 0.80078125\n",
      "Batch: 124, Loss: 0.6805810928344727, Accuracy: 0.7822265625\n",
      "Batch: 125, Loss: 0.7398129105567932, Accuracy: 0.7763671875\n",
      "Batch: 126, Loss: 0.669723391532898, Accuracy: 0.76953125\n",
      "Batch: 127, Loss: 0.5969785451889038, Accuracy: 0.8125\n",
      "Batch: 128, Loss: 0.7126669883728027, Accuracy: 0.77734375\n",
      "Batch: 129, Loss: 0.607876181602478, Accuracy: 0.7890625\n",
      "Batch: 130, Loss: 0.7799297571182251, Accuracy: 0.7451171875\n",
      "Batch: 131, Loss: 0.6415330171585083, Accuracy: 0.779296875\n",
      "Batch: 132, Loss: 0.6579833030700684, Accuracy: 0.7919921875\n",
      "Batch: 133, Loss: 0.6140549778938293, Accuracy: 0.7890625\n",
      "Batch: 134, Loss: 0.6431319117546082, Accuracy: 0.7763671875\n",
      "Batch: 135, Loss: 0.6185859441757202, Accuracy: 0.794921875\n",
      "Batch: 136, Loss: 0.6844918131828308, Accuracy: 0.76953125\n",
      "Batch: 137, Loss: 0.6665712594985962, Accuracy: 0.7734375\n",
      "Batch: 138, Loss: 0.6177917718887329, Accuracy: 0.7880859375\n",
      "Batch: 139, Loss: 0.6464669704437256, Accuracy: 0.779296875\n",
      "Batch: 140, Loss: 0.6626099348068237, Accuracy: 0.771484375\n",
      "Batch: 141, Loss: 0.6771294474601746, Accuracy: 0.7744140625\n",
      "Batch: 142, Loss: 0.7224764227867126, Accuracy: 0.7802734375\n",
      "Batch: 143, Loss: 0.626187801361084, Accuracy: 0.783203125\n",
      "Batch: 144, Loss: 0.6781109571456909, Accuracy: 0.7783203125\n",
      "Batch: 145, Loss: 0.5974748134613037, Accuracy: 0.7958984375\n",
      "Batch: 146, Loss: 0.6698389649391174, Accuracy: 0.775390625\n",
      "Batch: 147, Loss: 0.6815677881240845, Accuracy: 0.7802734375\n",
      "Batch: 148, Loss: 0.7221689224243164, Accuracy: 0.734375\n",
      "Batch: 149, Loss: 0.6507304310798645, Accuracy: 0.7880859375\n",
      "Batch: 150, Loss: 0.6688523888587952, Accuracy: 0.7783203125\n",
      "Batch: 151, Loss: 0.5960602760314941, Accuracy: 0.8046875\n",
      "Saved Weights at epoch 70 to file Weights_70.h5\n",
      "Epoch 71/80\n",
      "Batch: 1, Loss: 0.8419359922409058, Accuracy: 0.7294921875\n",
      "Batch: 2, Loss: 0.7069644331932068, Accuracy: 0.74609375\n",
      "Batch: 3, Loss: 0.6527217626571655, Accuracy: 0.791015625\n",
      "Batch: 4, Loss: 0.5839771032333374, Accuracy: 0.8154296875\n",
      "Batch: 5, Loss: 0.6427874565124512, Accuracy: 0.7841796875\n",
      "Batch: 6, Loss: 0.6714723110198975, Accuracy: 0.7705078125\n",
      "Batch: 7, Loss: 0.6800378561019897, Accuracy: 0.76171875\n",
      "Batch: 8, Loss: 0.6329662799835205, Accuracy: 0.775390625\n",
      "Batch: 9, Loss: 0.6253520250320435, Accuracy: 0.78125\n",
      "Batch: 10, Loss: 0.5863431692123413, Accuracy: 0.8095703125\n",
      "Batch: 11, Loss: 0.7382001876831055, Accuracy: 0.7548828125\n",
      "Batch: 12, Loss: 0.6916773319244385, Accuracy: 0.7626953125\n",
      "Batch: 13, Loss: 0.5304077863693237, Accuracy: 0.810546875\n",
      "Batch: 14, Loss: 0.6925036907196045, Accuracy: 0.775390625\n",
      "Batch: 15, Loss: 0.5852365493774414, Accuracy: 0.8037109375\n",
      "Batch: 16, Loss: 0.6453734636306763, Accuracy: 0.8017578125\n",
      "Batch: 17, Loss: 0.6494563221931458, Accuracy: 0.76953125\n",
      "Batch: 18, Loss: 0.6677435636520386, Accuracy: 0.77734375\n",
      "Batch: 19, Loss: 0.6522752642631531, Accuracy: 0.7841796875\n",
      "Batch: 20, Loss: 0.5677783489227295, Accuracy: 0.8154296875\n",
      "Batch: 21, Loss: 0.6250625848770142, Accuracy: 0.794921875\n",
      "Batch: 22, Loss: 0.7199498414993286, Accuracy: 0.791015625\n",
      "Batch: 23, Loss: 0.6693724393844604, Accuracy: 0.78125\n",
      "Batch: 24, Loss: 0.6809971332550049, Accuracy: 0.7666015625\n",
      "Batch: 25, Loss: 0.6507357358932495, Accuracy: 0.7919921875\n",
      "Batch: 26, Loss: 0.560154378414154, Accuracy: 0.8037109375\n",
      "Batch: 27, Loss: 0.5981168150901794, Accuracy: 0.7958984375\n",
      "Batch: 28, Loss: 0.6623137593269348, Accuracy: 0.7744140625\n",
      "Batch: 29, Loss: 0.6337035298347473, Accuracy: 0.7958984375\n",
      "Batch: 30, Loss: 0.5767918229103088, Accuracy: 0.814453125\n",
      "Batch: 31, Loss: 0.5555849075317383, Accuracy: 0.8154296875\n",
      "Batch: 32, Loss: 0.5986120104789734, Accuracy: 0.787109375\n",
      "Batch: 33, Loss: 0.7126302719116211, Accuracy: 0.791015625\n",
      "Batch: 34, Loss: 0.7049593329429626, Accuracy: 0.763671875\n",
      "Batch: 35, Loss: 0.6852900385856628, Accuracy: 0.7861328125\n",
      "Batch: 36, Loss: 0.7067771553993225, Accuracy: 0.7861328125\n",
      "Batch: 37, Loss: 0.6626731157302856, Accuracy: 0.78515625\n",
      "Batch: 38, Loss: 0.6504960060119629, Accuracy: 0.7861328125\n",
      "Batch: 39, Loss: 0.6865487098693848, Accuracy: 0.7783203125\n",
      "Batch: 40, Loss: 0.6453819870948792, Accuracy: 0.783203125\n",
      "Batch: 41, Loss: 0.6060513257980347, Accuracy: 0.7900390625\n",
      "Batch: 42, Loss: 0.5103051662445068, Accuracy: 0.8349609375\n",
      "Batch: 43, Loss: 0.6740565299987793, Accuracy: 0.7734375\n",
      "Batch: 44, Loss: 0.6527784466743469, Accuracy: 0.7724609375\n",
      "Batch: 45, Loss: 0.5921168923377991, Accuracy: 0.8017578125\n",
      "Batch: 46, Loss: 0.5908846855163574, Accuracy: 0.8017578125\n",
      "Batch: 47, Loss: 0.6322270631790161, Accuracy: 0.7978515625\n",
      "Batch: 48, Loss: 0.5732080936431885, Accuracy: 0.8017578125\n",
      "Batch: 49, Loss: 0.6677203178405762, Accuracy: 0.7763671875\n",
      "Batch: 50, Loss: 0.6621605753898621, Accuracy: 0.787109375\n",
      "Batch: 51, Loss: 0.6661878824234009, Accuracy: 0.7802734375\n",
      "Batch: 52, Loss: 0.6463301181793213, Accuracy: 0.7841796875\n",
      "Batch: 53, Loss: 0.608329713344574, Accuracy: 0.794921875\n",
      "Batch: 54, Loss: 0.6323267221450806, Accuracy: 0.796875\n",
      "Batch: 55, Loss: 0.735474705696106, Accuracy: 0.7470703125\n",
      "Batch: 56, Loss: 0.7216770052909851, Accuracy: 0.7509765625\n",
      "Batch: 57, Loss: 0.6788468360900879, Accuracy: 0.7724609375\n",
      "Batch: 58, Loss: 0.7107999324798584, Accuracy: 0.7783203125\n",
      "Batch: 59, Loss: 0.652032732963562, Accuracy: 0.7880859375\n",
      "Batch: 60, Loss: 0.6333795785903931, Accuracy: 0.7880859375\n",
      "Batch: 61, Loss: 0.7029929161071777, Accuracy: 0.771484375\n",
      "Batch: 62, Loss: 0.6302361488342285, Accuracy: 0.77734375\n",
      "Batch: 63, Loss: 0.6686657667160034, Accuracy: 0.7861328125\n",
      "Batch: 64, Loss: 0.6654045581817627, Accuracy: 0.787109375\n",
      "Batch: 65, Loss: 0.6361104249954224, Accuracy: 0.798828125\n",
      "Batch: 66, Loss: 0.6654189229011536, Accuracy: 0.7724609375\n",
      "Batch: 67, Loss: 0.7636978626251221, Accuracy: 0.765625\n",
      "Batch: 68, Loss: 0.7695950865745544, Accuracy: 0.7490234375\n",
      "Batch: 69, Loss: 0.6721516251564026, Accuracy: 0.775390625\n",
      "Batch: 70, Loss: 0.6574740409851074, Accuracy: 0.7919921875\n",
      "Batch: 71, Loss: 0.6876091361045837, Accuracy: 0.7587890625\n",
      "Batch: 72, Loss: 0.600425124168396, Accuracy: 0.798828125\n",
      "Batch: 73, Loss: 0.5912083983421326, Accuracy: 0.8046875\n",
      "Batch: 74, Loss: 0.5581191182136536, Accuracy: 0.8232421875\n",
      "Batch: 75, Loss: 0.5929056406021118, Accuracy: 0.80859375\n",
      "Batch: 76, Loss: 0.6581414937973022, Accuracy: 0.77734375\n",
      "Batch: 77, Loss: 0.6189597249031067, Accuracy: 0.8017578125\n",
      "Batch: 78, Loss: 0.6029749512672424, Accuracy: 0.8017578125\n",
      "Batch: 79, Loss: 0.545405387878418, Accuracy: 0.828125\n",
      "Batch: 80, Loss: 0.6336196660995483, Accuracy: 0.787109375\n",
      "Batch: 81, Loss: 0.7167078256607056, Accuracy: 0.751953125\n",
      "Batch: 82, Loss: 0.6840142011642456, Accuracy: 0.7666015625\n",
      "Batch: 83, Loss: 0.5813853740692139, Accuracy: 0.8134765625\n",
      "Batch: 84, Loss: 0.6268651485443115, Accuracy: 0.7861328125\n",
      "Batch: 85, Loss: 0.6288084387779236, Accuracy: 0.794921875\n",
      "Batch: 86, Loss: 0.7138159871101379, Accuracy: 0.7763671875\n",
      "Batch: 87, Loss: 0.6001458764076233, Accuracy: 0.810546875\n",
      "Batch: 88, Loss: 0.7123187184333801, Accuracy: 0.771484375\n",
      "Batch: 89, Loss: 0.6486718654632568, Accuracy: 0.7939453125\n",
      "Batch: 90, Loss: 0.6152051687240601, Accuracy: 0.8046875\n",
      "Batch: 91, Loss: 0.6140010356903076, Accuracy: 0.7919921875\n",
      "Batch: 92, Loss: 0.6594667434692383, Accuracy: 0.7841796875\n",
      "Batch: 93, Loss: 0.6610850691795349, Accuracy: 0.7890625\n",
      "Batch: 94, Loss: 0.673086404800415, Accuracy: 0.7744140625\n",
      "Batch: 95, Loss: 0.6778914332389832, Accuracy: 0.7724609375\n",
      "Batch: 96, Loss: 0.6275869011878967, Accuracy: 0.79296875\n",
      "Batch: 97, Loss: 0.5167298913002014, Accuracy: 0.822265625\n",
      "Batch: 98, Loss: 0.637040913105011, Accuracy: 0.798828125\n",
      "Batch: 99, Loss: 0.6484943628311157, Accuracy: 0.783203125\n",
      "Batch: 100, Loss: 0.6816381216049194, Accuracy: 0.779296875\n",
      "Batch: 101, Loss: 0.6561668515205383, Accuracy: 0.78125\n",
      "Batch: 102, Loss: 0.6655867099761963, Accuracy: 0.7734375\n",
      "Batch: 103, Loss: 0.6441318988800049, Accuracy: 0.7890625\n",
      "Batch: 104, Loss: 0.6050258874893188, Accuracy: 0.7998046875\n",
      "Batch: 105, Loss: 0.7182159423828125, Accuracy: 0.76171875\n",
      "Batch: 106, Loss: 0.6063421368598938, Accuracy: 0.7958984375\n",
      "Batch: 108, Loss: 0.6217633485794067, Accuracy: 0.791015625\n",
      "Batch: 109, Loss: 0.7262264490127563, Accuracy: 0.76171875\n",
      "Batch: 110, Loss: 0.6389772891998291, Accuracy: 0.78515625\n",
      "Batch: 111, Loss: 0.6928743124008179, Accuracy: 0.783203125\n",
      "Batch: 112, Loss: 0.6805111765861511, Accuracy: 0.783203125\n",
      "Batch: 113, Loss: 0.6488274931907654, Accuracy: 0.787109375\n",
      "Batch: 114, Loss: 0.7175441980361938, Accuracy: 0.7724609375\n",
      "Batch: 115, Loss: 0.7606487274169922, Accuracy: 0.7626953125\n",
      "Batch: 116, Loss: 0.6501381397247314, Accuracy: 0.7939453125\n",
      "Batch: 117, Loss: 0.6946613788604736, Accuracy: 0.779296875\n",
      "Batch: 118, Loss: 0.5782982110977173, Accuracy: 0.818359375\n",
      "Batch: 119, Loss: 0.5368843674659729, Accuracy: 0.83203125\n",
      "Batch: 120, Loss: 0.66225266456604, Accuracy: 0.7822265625\n",
      "Batch: 121, Loss: 0.6926603317260742, Accuracy: 0.7822265625\n",
      "Batch: 122, Loss: 0.6416769027709961, Accuracy: 0.79296875\n",
      "Batch: 123, Loss: 0.5883186459541321, Accuracy: 0.79296875\n",
      "Batch: 124, Loss: 0.6535598039627075, Accuracy: 0.7802734375\n",
      "Batch: 125, Loss: 0.7466751337051392, Accuracy: 0.7529296875\n",
      "Batch: 126, Loss: 0.680404007434845, Accuracy: 0.78125\n",
      "Batch: 127, Loss: 0.5723272562026978, Accuracy: 0.833984375\n",
      "Batch: 128, Loss: 0.7132396697998047, Accuracy: 0.7783203125\n",
      "Batch: 129, Loss: 0.5818503499031067, Accuracy: 0.796875\n",
      "Batch: 130, Loss: 0.7579784393310547, Accuracy: 0.755859375\n",
      "Batch: 131, Loss: 0.6477047801017761, Accuracy: 0.7919921875\n",
      "Batch: 132, Loss: 0.6758499145507812, Accuracy: 0.7783203125\n",
      "Batch: 133, Loss: 0.5973465442657471, Accuracy: 0.7978515625\n",
      "Batch: 134, Loss: 0.6872355937957764, Accuracy: 0.767578125\n",
      "Batch: 135, Loss: 0.5973999500274658, Accuracy: 0.8115234375\n",
      "Batch: 136, Loss: 0.6423850059509277, Accuracy: 0.7841796875\n",
      "Batch: 137, Loss: 0.6512835025787354, Accuracy: 0.767578125\n",
      "Batch: 138, Loss: 0.5807627439498901, Accuracy: 0.794921875\n",
      "Batch: 139, Loss: 0.6364165544509888, Accuracy: 0.7890625\n",
      "Batch: 140, Loss: 0.6498371958732605, Accuracy: 0.77734375\n",
      "Batch: 141, Loss: 0.7067983150482178, Accuracy: 0.7822265625\n",
      "Batch: 142, Loss: 0.7064485549926758, Accuracy: 0.7763671875\n",
      "Batch: 143, Loss: 0.636288583278656, Accuracy: 0.791015625\n",
      "Batch: 144, Loss: 0.6970758438110352, Accuracy: 0.7705078125\n",
      "Batch: 145, Loss: 0.6353374719619751, Accuracy: 0.7802734375\n",
      "Batch: 146, Loss: 0.6816277503967285, Accuracy: 0.7802734375\n",
      "Batch: 147, Loss: 0.6836709976196289, Accuracy: 0.7861328125\n",
      "Batch: 148, Loss: 0.7349728941917419, Accuracy: 0.767578125\n",
      "Batch: 149, Loss: 0.6257672309875488, Accuracy: 0.8046875\n",
      "Batch: 150, Loss: 0.6701120138168335, Accuracy: 0.767578125\n",
      "Batch: 151, Loss: 0.6101604104042053, Accuracy: 0.8017578125\n",
      "Epoch 72/80\n",
      "Batch: 4, Loss: 0.6008005142211914, Accuracy: 0.8125\n",
      "Batch: 5, Loss: 0.6391744613647461, Accuracy: 0.787109375\n",
      "Batch: 6, Loss: 0.6867233514785767, Accuracy: 0.765625\n",
      "Batch: 7, Loss: 0.6780418157577515, Accuracy: 0.765625\n",
      "Batch: 8, Loss: 0.6445765495300293, Accuracy: 0.78515625\n",
      "Batch: 9, Loss: 0.6136912107467651, Accuracy: 0.7958984375\n",
      "Batch: 10, Loss: 0.5984107255935669, Accuracy: 0.794921875\n",
      "Batch: 11, Loss: 0.7151088714599609, Accuracy: 0.7529296875\n",
      "Batch: 12, Loss: 0.7114109992980957, Accuracy: 0.7666015625\n",
      "Batch: 13, Loss: 0.5356383323669434, Accuracy: 0.8125\n",
      "Batch: 14, Loss: 0.7030866146087646, Accuracy: 0.767578125\n",
      "Batch: 15, Loss: 0.5700852274894714, Accuracy: 0.81640625\n",
      "Batch: 16, Loss: 0.6374448537826538, Accuracy: 0.8037109375\n",
      "Batch: 17, Loss: 0.6646304130554199, Accuracy: 0.77734375\n",
      "Batch: 18, Loss: 0.6620722413063049, Accuracy: 0.78125\n",
      "Batch: 19, Loss: 0.6498464345932007, Accuracy: 0.7939453125\n",
      "Batch: 20, Loss: 0.5606592297554016, Accuracy: 0.8232421875\n",
      "Batch: 21, Loss: 0.6293507218360901, Accuracy: 0.775390625\n",
      "Batch: 22, Loss: 0.7407049536705017, Accuracy: 0.7529296875\n",
      "Batch: 23, Loss: 0.6351518630981445, Accuracy: 0.7900390625\n",
      "Batch: 24, Loss: 0.6752806901931763, Accuracy: 0.7841796875\n",
      "Batch: 25, Loss: 0.668692946434021, Accuracy: 0.7783203125\n",
      "Batch: 26, Loss: 0.6074033975601196, Accuracy: 0.7939453125\n",
      "Batch: 27, Loss: 0.5828589200973511, Accuracy: 0.8076171875\n",
      "Batch: 28, Loss: 0.6648274660110474, Accuracy: 0.78125\n",
      "Batch: 29, Loss: 0.6469196677207947, Accuracy: 0.79296875\n",
      "Batch: 30, Loss: 0.5921789407730103, Accuracy: 0.814453125\n",
      "Batch: 31, Loss: 0.5951399207115173, Accuracy: 0.8076171875\n",
      "Batch: 32, Loss: 0.6031216382980347, Accuracy: 0.79296875\n",
      "Batch: 33, Loss: 0.6762479543685913, Accuracy: 0.7861328125\n",
      "Batch: 34, Loss: 0.6965005993843079, Accuracy: 0.771484375\n",
      "Batch: 35, Loss: 0.7039393782615662, Accuracy: 0.759765625\n",
      "Batch: 36, Loss: 0.7076925039291382, Accuracy: 0.7861328125\n",
      "Batch: 37, Loss: 0.6609842777252197, Accuracy: 0.787109375\n",
      "Batch: 38, Loss: 0.6555655002593994, Accuracy: 0.76953125\n",
      "Batch: 39, Loss: 0.6443968415260315, Accuracy: 0.7841796875\n",
      "Batch: 40, Loss: 0.6323897838592529, Accuracy: 0.791015625\n",
      "Batch: 41, Loss: 0.6006866693496704, Accuracy: 0.7939453125\n",
      "Batch: 42, Loss: 0.5039702653884888, Accuracy: 0.8310546875\n",
      "Batch: 43, Loss: 0.6760938167572021, Accuracy: 0.77734375\n",
      "Batch: 44, Loss: 0.6717219352722168, Accuracy: 0.7734375\n",
      "Batch: 45, Loss: 0.5781930685043335, Accuracy: 0.8056640625\n",
      "Batch: 46, Loss: 0.6019325852394104, Accuracy: 0.8056640625\n",
      "Batch: 47, Loss: 0.5812724232673645, Accuracy: 0.8095703125\n",
      "Batch: 48, Loss: 0.5605291128158569, Accuracy: 0.80859375\n",
      "Batch: 49, Loss: 0.6732030510902405, Accuracy: 0.7822265625\n",
      "Batch: 50, Loss: 0.6416247487068176, Accuracy: 0.78125\n",
      "Batch: 51, Loss: 0.6528677940368652, Accuracy: 0.775390625\n",
      "Batch: 52, Loss: 0.6408963203430176, Accuracy: 0.7900390625\n",
      "Batch: 53, Loss: 0.5990860462188721, Accuracy: 0.8046875\n",
      "Batch: 54, Loss: 0.6373299956321716, Accuracy: 0.7880859375\n",
      "Batch: 55, Loss: 0.7299426794052124, Accuracy: 0.759765625\n",
      "Batch: 56, Loss: 0.7536678314208984, Accuracy: 0.74609375\n",
      "Batch: 57, Loss: 0.6632466316223145, Accuracy: 0.779296875\n",
      "Batch: 58, Loss: 0.7268148064613342, Accuracy: 0.7724609375\n",
      "Batch: 59, Loss: 0.6327698230743408, Accuracy: 0.8056640625\n",
      "Batch: 60, Loss: 0.5941277742385864, Accuracy: 0.80859375\n",
      "Batch: 61, Loss: 0.6965787410736084, Accuracy: 0.7734375\n",
      "Batch: 62, Loss: 0.6055231094360352, Accuracy: 0.7998046875\n",
      "Batch: 63, Loss: 0.6717343926429749, Accuracy: 0.7763671875\n",
      "Batch: 64, Loss: 0.6383647322654724, Accuracy: 0.794921875\n",
      "Batch: 65, Loss: 0.659980058670044, Accuracy: 0.7841796875\n",
      "Batch: 66, Loss: 0.6514894366264343, Accuracy: 0.7890625\n",
      "Batch: 67, Loss: 0.7192443609237671, Accuracy: 0.7734375\n",
      "Batch: 68, Loss: 0.7649058699607849, Accuracy: 0.759765625\n",
      "Batch: 69, Loss: 0.6687124371528625, Accuracy: 0.76953125\n",
      "Batch: 70, Loss: 0.6350533962249756, Accuracy: 0.8046875\n",
      "Batch: 71, Loss: 0.6709827780723572, Accuracy: 0.76171875\n",
      "Batch: 72, Loss: 0.5675113201141357, Accuracy: 0.8095703125\n",
      "Batch: 73, Loss: 0.6034716963768005, Accuracy: 0.8056640625\n",
      "Batch: 74, Loss: 0.5565500259399414, Accuracy: 0.8154296875\n",
      "Batch: 75, Loss: 0.6014500856399536, Accuracy: 0.80078125\n",
      "Batch: 76, Loss: 0.6675881743431091, Accuracy: 0.796875\n",
      "Batch: 77, Loss: 0.5908058285713196, Accuracy: 0.8056640625\n",
      "Batch: 78, Loss: 0.5693604350090027, Accuracy: 0.8125\n",
      "Batch: 79, Loss: 0.5911005735397339, Accuracy: 0.8134765625\n",
      "Batch: 80, Loss: 0.6263326406478882, Accuracy: 0.7958984375\n",
      "Batch: 81, Loss: 0.717505931854248, Accuracy: 0.7421875\n",
      "Batch: 82, Loss: 0.6414709091186523, Accuracy: 0.77734375\n",
      "Batch: 83, Loss: 0.5666577816009521, Accuracy: 0.8173828125\n",
      "Batch: 84, Loss: 0.610824465751648, Accuracy: 0.810546875\n",
      "Batch: 85, Loss: 0.6057162880897522, Accuracy: 0.80859375\n",
      "Batch: 86, Loss: 0.7507357597351074, Accuracy: 0.755859375\n",
      "Batch: 87, Loss: 0.585103452205658, Accuracy: 0.814453125\n",
      "Batch: 88, Loss: 0.6860159635543823, Accuracy: 0.779296875\n",
      "Batch: 89, Loss: 0.6165531873703003, Accuracy: 0.8017578125\n",
      "Batch: 90, Loss: 0.6298117637634277, Accuracy: 0.78515625\n",
      "Batch: 91, Loss: 0.6738046407699585, Accuracy: 0.783203125\n",
      "Batch: 92, Loss: 0.6368293166160583, Accuracy: 0.7841796875\n",
      "Batch: 94, Loss: 0.6605430841445923, Accuracy: 0.76953125\n",
      "Batch: 95, Loss: 0.6871974468231201, Accuracy: 0.7802734375\n",
      "Batch: 96, Loss: 0.628470778465271, Accuracy: 0.791015625\n",
      "Batch: 97, Loss: 0.5369701385498047, Accuracy: 0.8076171875\n",
      "Batch: 98, Loss: 0.6023716926574707, Accuracy: 0.810546875\n",
      "Batch: 99, Loss: 0.6504934430122375, Accuracy: 0.7841796875\n",
      "Batch: 100, Loss: 0.6562737226486206, Accuracy: 0.7958984375\n",
      "Batch: 101, Loss: 0.6768418550491333, Accuracy: 0.7841796875\n",
      "Batch: 102, Loss: 0.6262075901031494, Accuracy: 0.79296875\n",
      "Batch: 103, Loss: 0.6571218967437744, Accuracy: 0.7939453125\n",
      "Batch: 104, Loss: 0.5939195156097412, Accuracy: 0.7998046875\n",
      "Batch: 105, Loss: 0.6820281744003296, Accuracy: 0.7734375\n",
      "Batch: 106, Loss: 0.6153132915496826, Accuracy: 0.7919921875\n",
      "Batch: 107, Loss: 0.6566305756568909, Accuracy: 0.7890625\n",
      "Batch: 108, Loss: 0.6680286526679993, Accuracy: 0.7802734375\n",
      "Batch: 109, Loss: 0.6964839696884155, Accuracy: 0.7724609375\n",
      "Batch: 110, Loss: 0.610135555267334, Accuracy: 0.7919921875\n",
      "Batch: 111, Loss: 0.6601332426071167, Accuracy: 0.79296875\n",
      "Batch: 112, Loss: 0.6206569075584412, Accuracy: 0.791015625\n",
      "Batch: 113, Loss: 0.6470950245857239, Accuracy: 0.7880859375\n",
      "Batch: 114, Loss: 0.7214251756668091, Accuracy: 0.76953125\n",
      "Batch: 115, Loss: 0.7837457656860352, Accuracy: 0.751953125\n",
      "Batch: 116, Loss: 0.6870566606521606, Accuracy: 0.7734375\n",
      "Batch: 117, Loss: 0.6643205285072327, Accuracy: 0.78125\n",
      "Batch: 118, Loss: 0.5629100799560547, Accuracy: 0.8203125\n",
      "Batch: 119, Loss: 0.5339407920837402, Accuracy: 0.8154296875\n",
      "Batch: 120, Loss: 0.6792579889297485, Accuracy: 0.77734375\n",
      "Batch: 121, Loss: 0.6984443068504333, Accuracy: 0.779296875\n",
      "Batch: 122, Loss: 0.6040955781936646, Accuracy: 0.802734375\n",
      "Batch: 123, Loss: 0.604139506816864, Accuracy: 0.8046875\n",
      "Batch: 124, Loss: 0.6457292437553406, Accuracy: 0.7958984375\n",
      "Batch: 125, Loss: 0.7303436994552612, Accuracy: 0.7607421875\n",
      "Batch: 126, Loss: 0.668747067451477, Accuracy: 0.78515625\n",
      "Batch: 127, Loss: 0.5557186603546143, Accuracy: 0.8125\n",
      "Batch: 128, Loss: 0.7059720754623413, Accuracy: 0.78125\n",
      "Batch: 129, Loss: 0.603588342666626, Accuracy: 0.78515625\n",
      "Batch: 130, Loss: 0.7462010383605957, Accuracy: 0.744140625\n",
      "Batch: 131, Loss: 0.6253689527511597, Accuracy: 0.796875\n",
      "Batch: 132, Loss: 0.6951258778572083, Accuracy: 0.7724609375\n",
      "Batch: 133, Loss: 0.6060079336166382, Accuracy: 0.8076171875\n",
      "Batch: 134, Loss: 0.6796775460243225, Accuracy: 0.7685546875\n",
      "Batch: 135, Loss: 0.6115562915802002, Accuracy: 0.8017578125\n",
      "Batch: 136, Loss: 0.6431887149810791, Accuracy: 0.79296875\n",
      "Batch: 137, Loss: 0.6708013415336609, Accuracy: 0.7734375\n",
      "Batch: 138, Loss: 0.582602858543396, Accuracy: 0.8046875\n",
      "Batch: 139, Loss: 0.6266962885856628, Accuracy: 0.7939453125\n",
      "Batch: 142, Loss: 0.6938431262969971, Accuracy: 0.779296875\n",
      "Batch: 143, Loss: 0.6667121648788452, Accuracy: 0.7861328125\n",
      "Batch: 144, Loss: 0.7001487016677856, Accuracy: 0.7666015625\n",
      "Batch: 145, Loss: 0.6101003885269165, Accuracy: 0.7880859375\n",
      "Batch: 146, Loss: 0.6788333058357239, Accuracy: 0.7705078125\n",
      "Batch: 147, Loss: 0.7087728977203369, Accuracy: 0.7705078125\n",
      "Batch: 148, Loss: 0.7402502298355103, Accuracy: 0.744140625\n",
      "Batch: 149, Loss: 0.6202168464660645, Accuracy: 0.7900390625\n",
      "Batch: 150, Loss: 0.6463751792907715, Accuracy: 0.7861328125\n",
      "Batch: 151, Loss: 0.5832843780517578, Accuracy: 0.8134765625\n",
      "Epoch 73/80\n",
      "Batch: 1, Loss: 0.8804336786270142, Accuracy: 0.7099609375\n",
      "Batch: 2, Loss: 0.7145467400550842, Accuracy: 0.7490234375\n",
      "Batch: 3, Loss: 0.6499687433242798, Accuracy: 0.78125\n",
      "Batch: 4, Loss: 0.5690746307373047, Accuracy: 0.8154296875\n",
      "Batch: 5, Loss: 0.6108815670013428, Accuracy: 0.7939453125\n",
      "Batch: 6, Loss: 0.6822428703308105, Accuracy: 0.763671875\n",
      "Batch: 7, Loss: 0.6923422813415527, Accuracy: 0.759765625\n",
      "Batch: 8, Loss: 0.6204428672790527, Accuracy: 0.7841796875\n",
      "Batch: 9, Loss: 0.5906885862350464, Accuracy: 0.806640625\n",
      "Batch: 10, Loss: 0.5925060510635376, Accuracy: 0.7958984375\n",
      "Batch: 11, Loss: 0.7598739862442017, Accuracy: 0.7412109375\n",
      "Batch: 12, Loss: 0.6793458461761475, Accuracy: 0.787109375\n",
      "Batch: 13, Loss: 0.5365779399871826, Accuracy: 0.82421875\n",
      "Batch: 14, Loss: 0.6820516586303711, Accuracy: 0.765625\n",
      "Batch: 15, Loss: 0.5980907678604126, Accuracy: 0.8017578125\n",
      "Batch: 16, Loss: 0.6602740287780762, Accuracy: 0.7861328125\n",
      "Batch: 17, Loss: 0.6424545645713806, Accuracy: 0.787109375\n",
      "Batch: 18, Loss: 0.6596145629882812, Accuracy: 0.7802734375\n",
      "Batch: 19, Loss: 0.6482181549072266, Accuracy: 0.7998046875\n",
      "Batch: 20, Loss: 0.5329960584640503, Accuracy: 0.8271484375\n",
      "Batch: 21, Loss: 0.5902378559112549, Accuracy: 0.80078125\n",
      "Batch: 22, Loss: 0.7490758299827576, Accuracy: 0.7724609375\n",
      "Batch: 23, Loss: 0.6660401821136475, Accuracy: 0.7734375\n",
      "Batch: 24, Loss: 0.6583020091056824, Accuracy: 0.7822265625\n",
      "Batch: 25, Loss: 0.6427916288375854, Accuracy: 0.78125\n",
      "Batch: 26, Loss: 0.576822817325592, Accuracy: 0.8125\n",
      "Batch: 27, Loss: 0.6308677196502686, Accuracy: 0.794921875\n",
      "Batch: 28, Loss: 0.6570601463317871, Accuracy: 0.77734375\n",
      "Batch: 29, Loss: 0.645719051361084, Accuracy: 0.787109375\n",
      "Batch: 30, Loss: 0.5712828636169434, Accuracy: 0.8212890625\n",
      "Batch: 31, Loss: 0.5842206478118896, Accuracy: 0.8017578125\n",
      "Batch: 32, Loss: 0.5993314981460571, Accuracy: 0.7958984375\n",
      "Batch: 33, Loss: 0.691462516784668, Accuracy: 0.7734375\n",
      "Batch: 34, Loss: 0.6964923143386841, Accuracy: 0.775390625\n",
      "Batch: 35, Loss: 0.6829200983047485, Accuracy: 0.7783203125\n",
      "Batch: 36, Loss: 0.7127940058708191, Accuracy: 0.783203125\n",
      "Batch: 37, Loss: 0.6204140186309814, Accuracy: 0.787109375\n",
      "Batch: 38, Loss: 0.6535204648971558, Accuracy: 0.7724609375\n",
      "Batch: 39, Loss: 0.6633083820343018, Accuracy: 0.79296875\n",
      "Batch: 40, Loss: 0.6320856213569641, Accuracy: 0.79296875\n",
      "Batch: 41, Loss: 0.5979095697402954, Accuracy: 0.7958984375\n",
      "Batch: 42, Loss: 0.485452264547348, Accuracy: 0.833984375\n",
      "Batch: 43, Loss: 0.6999313831329346, Accuracy: 0.779296875\n",
      "Batch: 44, Loss: 0.6271560192108154, Accuracy: 0.7841796875\n",
      "Batch: 45, Loss: 0.5851016044616699, Accuracy: 0.8095703125\n",
      "Batch: 46, Loss: 0.6098436117172241, Accuracy: 0.8037109375\n",
      "Batch: 47, Loss: 0.6108886003494263, Accuracy: 0.822265625\n",
      "Batch: 48, Loss: 0.5974470376968384, Accuracy: 0.80078125\n",
      "Batch: 49, Loss: 0.6566808223724365, Accuracy: 0.79296875\n",
      "Batch: 50, Loss: 0.6668524742126465, Accuracy: 0.78125\n",
      "Batch: 51, Loss: 0.6619112491607666, Accuracy: 0.7841796875\n",
      "Batch: 52, Loss: 0.6482285857200623, Accuracy: 0.783203125\n",
      "Batch: 53, Loss: 0.5853972434997559, Accuracy: 0.798828125\n",
      "Batch: 54, Loss: 0.6310616135597229, Accuracy: 0.7890625\n",
      "Batch: 55, Loss: 0.7235908508300781, Accuracy: 0.759765625\n",
      "Batch: 56, Loss: 0.70260089635849, Accuracy: 0.7705078125\n",
      "Batch: 57, Loss: 0.6645569205284119, Accuracy: 0.771484375\n",
      "Batch: 58, Loss: 0.7181745767593384, Accuracy: 0.7587890625\n",
      "Batch: 59, Loss: 0.6119460463523865, Accuracy: 0.806640625\n",
      "Batch: 60, Loss: 0.5913138389587402, Accuracy: 0.794921875\n",
      "Batch: 61, Loss: 0.6906093955039978, Accuracy: 0.7744140625\n",
      "Batch: 62, Loss: 0.6188693046569824, Accuracy: 0.802734375\n",
      "Batch: 63, Loss: 0.6838937997817993, Accuracy: 0.7666015625\n",
      "Batch: 64, Loss: 0.6053187251091003, Accuracy: 0.7919921875\n",
      "Batch: 65, Loss: 0.6453980207443237, Accuracy: 0.78125\n",
      "Batch: 66, Loss: 0.6428897976875305, Accuracy: 0.7939453125\n",
      "Batch: 67, Loss: 0.7140387892723083, Accuracy: 0.771484375\n",
      "Batch: 68, Loss: 0.725350022315979, Accuracy: 0.7666015625\n",
      "Batch: 69, Loss: 0.6848532557487488, Accuracy: 0.775390625\n",
      "Batch: 70, Loss: 0.6483120322227478, Accuracy: 0.7939453125\n",
      "Batch: 71, Loss: 0.7022586464881897, Accuracy: 0.75\n",
      "Batch: 72, Loss: 0.5841546654701233, Accuracy: 0.80859375\n",
      "Batch: 73, Loss: 0.5896911025047302, Accuracy: 0.8095703125\n",
      "Batch: 74, Loss: 0.584844172000885, Accuracy: 0.8017578125\n",
      "Batch: 75, Loss: 0.5814290046691895, Accuracy: 0.81640625\n",
      "Batch: 76, Loss: 0.6592632532119751, Accuracy: 0.783203125\n",
      "Batch: 77, Loss: 0.5936704874038696, Accuracy: 0.8095703125\n",
      "Batch: 78, Loss: 0.5736091136932373, Accuracy: 0.802734375\n",
      "Batch: 79, Loss: 0.5549236536026001, Accuracy: 0.826171875\n",
      "Batch: 80, Loss: 0.6263789534568787, Accuracy: 0.78515625\n",
      "Batch: 81, Loss: 0.6631994247436523, Accuracy: 0.7607421875\n",
      "Batch: 82, Loss: 0.6683455109596252, Accuracy: 0.7822265625\n",
      "Batch: 83, Loss: 0.549315333366394, Accuracy: 0.837890625\n",
      "Batch: 85, Loss: 0.610258162021637, Accuracy: 0.796875\n",
      "Batch: 86, Loss: 0.7172714471817017, Accuracy: 0.765625\n",
      "Batch: 87, Loss: 0.6160286068916321, Accuracy: 0.7978515625\n",
      "Batch: 88, Loss: 0.6831362247467041, Accuracy: 0.77734375\n",
      "Batch: 89, Loss: 0.618848443031311, Accuracy: 0.802734375\n",
      "Batch: 90, Loss: 0.6232678294181824, Accuracy: 0.8134765625\n",
      "Batch: 91, Loss: 0.6441138386726379, Accuracy: 0.7705078125\n",
      "Batch: 92, Loss: 0.6322331428527832, Accuracy: 0.7919921875\n",
      "Batch: 93, Loss: 0.6339315176010132, Accuracy: 0.7841796875\n",
      "Batch: 94, Loss: 0.6542969346046448, Accuracy: 0.7890625\n",
      "Batch: 95, Loss: 0.6638933420181274, Accuracy: 0.79296875\n",
      "Batch: 96, Loss: 0.6072884798049927, Accuracy: 0.802734375\n",
      "Batch: 97, Loss: 0.5001219511032104, Accuracy: 0.8291015625\n",
      "Batch: 98, Loss: 0.6291820406913757, Accuracy: 0.8037109375\n",
      "Batch: 99, Loss: 0.6042356491088867, Accuracy: 0.7890625\n",
      "Batch: 100, Loss: 0.6665928959846497, Accuracy: 0.7783203125\n",
      "Batch: 101, Loss: 0.6454651951789856, Accuracy: 0.7890625\n",
      "Batch: 102, Loss: 0.622304379940033, Accuracy: 0.80078125\n",
      "Batch: 103, Loss: 0.6515829563140869, Accuracy: 0.7744140625\n",
      "Batch: 104, Loss: 0.6039073467254639, Accuracy: 0.8017578125\n",
      "Batch: 105, Loss: 0.690457820892334, Accuracy: 0.7763671875\n",
      "Batch: 106, Loss: 0.6128315329551697, Accuracy: 0.8046875\n",
      "Batch: 107, Loss: 0.6455277800559998, Accuracy: 0.78515625\n",
      "Batch: 108, Loss: 0.593654990196228, Accuracy: 0.7998046875\n",
      "Batch: 109, Loss: 0.7020143270492554, Accuracy: 0.7626953125\n",
      "Batch: 110, Loss: 0.6049405336380005, Accuracy: 0.791015625\n",
      "Batch: 111, Loss: 0.6400753259658813, Accuracy: 0.7880859375\n",
      "Batch: 112, Loss: 0.6511480212211609, Accuracy: 0.7890625\n",
      "Batch: 113, Loss: 0.63344407081604, Accuracy: 0.78515625\n",
      "Batch: 114, Loss: 0.672061562538147, Accuracy: 0.7783203125\n",
      "Batch: 115, Loss: 0.752729594707489, Accuracy: 0.76953125\n",
      "Batch: 116, Loss: 0.6507179737091064, Accuracy: 0.79296875\n",
      "Batch: 117, Loss: 0.6607354879379272, Accuracy: 0.8037109375\n",
      "Batch: 118, Loss: 0.5352867841720581, Accuracy: 0.826171875\n",
      "Batch: 119, Loss: 0.5186867117881775, Accuracy: 0.8232421875\n",
      "Batch: 120, Loss: 0.7002490758895874, Accuracy: 0.78125\n",
      "Batch: 121, Loss: 0.6836500763893127, Accuracy: 0.78125\n",
      "Batch: 122, Loss: 0.6096132397651672, Accuracy: 0.8193359375\n",
      "Batch: 123, Loss: 0.5543996095657349, Accuracy: 0.8193359375\n",
      "Batch: 124, Loss: 0.6253864765167236, Accuracy: 0.80078125\n",
      "Batch: 125, Loss: 0.7140291333198547, Accuracy: 0.765625\n",
      "Batch: 126, Loss: 0.6581072807312012, Accuracy: 0.7958984375\n",
      "Batch: 127, Loss: 0.5677928924560547, Accuracy: 0.8369140625\n",
      "Batch: 129, Loss: 0.5919510126113892, Accuracy: 0.8056640625\n",
      "Batch: 130, Loss: 0.7239537239074707, Accuracy: 0.7548828125\n",
      "Batch: 131, Loss: 0.6439183354377747, Accuracy: 0.787109375\n",
      "Batch: 132, Loss: 0.6703451871871948, Accuracy: 0.7880859375\n",
      "Batch: 133, Loss: 0.6059384346008301, Accuracy: 0.8095703125\n",
      "Batch: 134, Loss: 0.6482789516448975, Accuracy: 0.783203125\n",
      "Batch: 135, Loss: 0.5950347185134888, Accuracy: 0.8076171875\n",
      "Batch: 136, Loss: 0.6388811469078064, Accuracy: 0.794921875\n",
      "Batch: 137, Loss: 0.6523023843765259, Accuracy: 0.7685546875\n",
      "Batch: 138, Loss: 0.5531795024871826, Accuracy: 0.8046875\n",
      "Batch: 139, Loss: 0.616184413433075, Accuracy: 0.775390625\n",
      "Batch: 140, Loss: 0.5946797132492065, Accuracy: 0.7998046875\n",
      "Batch: 141, Loss: 0.6927379369735718, Accuracy: 0.7744140625\n",
      "Batch: 142, Loss: 0.7140685319900513, Accuracy: 0.7763671875\n",
      "Batch: 143, Loss: 0.6360476613044739, Accuracy: 0.787109375\n",
      "Batch: 144, Loss: 0.6514737606048584, Accuracy: 0.7734375\n",
      "Batch: 145, Loss: 0.6123563051223755, Accuracy: 0.7802734375\n",
      "Batch: 146, Loss: 0.6709809899330139, Accuracy: 0.7763671875\n",
      "Batch: 147, Loss: 0.6489454507827759, Accuracy: 0.771484375\n",
      "Batch: 148, Loss: 0.7005574703216553, Accuracy: 0.767578125\n",
      "Batch: 149, Loss: 0.6046090126037598, Accuracy: 0.7998046875\n",
      "Batch: 150, Loss: 0.6479898691177368, Accuracy: 0.7919921875\n",
      "Batch: 151, Loss: 0.5828341841697693, Accuracy: 0.8046875\n",
      "Epoch 74/80\n",
      "Batch: 1, Loss: 0.872406542301178, Accuracy: 0.7265625\n",
      "Batch: 2, Loss: 0.7103959321975708, Accuracy: 0.7587890625\n",
      "Batch: 3, Loss: 0.6723493337631226, Accuracy: 0.7841796875\n",
      "Batch: 4, Loss: 0.558601975440979, Accuracy: 0.8193359375\n",
      "Batch: 5, Loss: 0.5989831686019897, Accuracy: 0.794921875\n",
      "Batch: 6, Loss: 0.6406798958778381, Accuracy: 0.783203125\n",
      "Batch: 7, Loss: 0.6848853230476379, Accuracy: 0.751953125\n",
      "Batch: 8, Loss: 0.6365506649017334, Accuracy: 0.7880859375\n",
      "Batch: 9, Loss: 0.6405835747718811, Accuracy: 0.7958984375\n",
      "Batch: 10, Loss: 0.6081048250198364, Accuracy: 0.7919921875\n",
      "Batch: 11, Loss: 0.7275171279907227, Accuracy: 0.748046875\n",
      "Batch: 12, Loss: 0.7034401297569275, Accuracy: 0.7470703125\n",
      "Batch: 13, Loss: 0.5327327251434326, Accuracy: 0.826171875\n",
      "Batch: 14, Loss: 0.6999019384384155, Accuracy: 0.775390625\n",
      "Batch: 15, Loss: 0.5853376984596252, Accuracy: 0.80859375\n",
      "Batch: 16, Loss: 0.6367919445037842, Accuracy: 0.8095703125\n",
      "Batch: 17, Loss: 0.6334848403930664, Accuracy: 0.7998046875\n",
      "Batch: 18, Loss: 0.6253117918968201, Accuracy: 0.8037109375\n",
      "Batch: 19, Loss: 0.6489186882972717, Accuracy: 0.775390625\n",
      "Batch: 20, Loss: 0.5371938347816467, Accuracy: 0.8212890625\n",
      "Batch: 21, Loss: 0.5747175216674805, Accuracy: 0.80859375\n",
      "Batch: 22, Loss: 0.7460452318191528, Accuracy: 0.775390625\n",
      "Batch: 23, Loss: 0.6666340827941895, Accuracy: 0.7705078125\n",
      "Batch: 24, Loss: 0.6730769872665405, Accuracy: 0.763671875\n",
      "Batch: 25, Loss: 0.6315902471542358, Accuracy: 0.7939453125\n",
      "Batch: 26, Loss: 0.5423557758331299, Accuracy: 0.8115234375\n",
      "Batch: 27, Loss: 0.6150467395782471, Accuracy: 0.7841796875\n",
      "Batch: 28, Loss: 0.6653066873550415, Accuracy: 0.791015625\n",
      "Batch: 29, Loss: 0.6277469992637634, Accuracy: 0.7919921875\n",
      "Batch: 30, Loss: 0.5510550141334534, Accuracy: 0.8251953125\n",
      "Batch: 31, Loss: 0.5603846311569214, Accuracy: 0.837890625\n",
      "Batch: 32, Loss: 0.5880081653594971, Accuracy: 0.8046875\n",
      "Batch: 33, Loss: 0.6947973966598511, Accuracy: 0.7734375\n",
      "Batch: 34, Loss: 0.6972000598907471, Accuracy: 0.7802734375\n",
      "Batch: 35, Loss: 0.6595402956008911, Accuracy: 0.791015625\n",
      "Batch: 36, Loss: 0.657900333404541, Accuracy: 0.791015625\n",
      "Batch: 37, Loss: 0.6760382652282715, Accuracy: 0.77734375\n",
      "Batch: 38, Loss: 0.6160153746604919, Accuracy: 0.7900390625\n",
      "Batch: 39, Loss: 0.6630282402038574, Accuracy: 0.791015625\n",
      "Batch: 40, Loss: 0.6255432367324829, Accuracy: 0.79296875\n",
      "Batch: 41, Loss: 0.6036425232887268, Accuracy: 0.7939453125\n",
      "Batch: 42, Loss: 0.4955354928970337, Accuracy: 0.8310546875\n",
      "Batch: 43, Loss: 0.6541475057601929, Accuracy: 0.77734375\n",
      "Batch: 44, Loss: 0.6446291208267212, Accuracy: 0.7822265625\n",
      "Batch: 45, Loss: 0.5425474047660828, Accuracy: 0.8232421875\n",
      "Batch: 46, Loss: 0.5602251291275024, Accuracy: 0.8173828125\n",
      "Batch: 47, Loss: 0.6161497235298157, Accuracy: 0.8037109375\n",
      "Batch: 48, Loss: 0.5880113840103149, Accuracy: 0.80859375\n",
      "Batch: 49, Loss: 0.7062969207763672, Accuracy: 0.765625\n",
      "Batch: 50, Loss: 0.6593660116195679, Accuracy: 0.791015625\n",
      "Batch: 51, Loss: 0.6577063798904419, Accuracy: 0.7861328125\n",
      "Batch: 52, Loss: 0.6415785551071167, Accuracy: 0.7978515625\n",
      "Batch: 53, Loss: 0.578019380569458, Accuracy: 0.8193359375\n",
      "Batch: 54, Loss: 0.6167641878128052, Accuracy: 0.8017578125\n",
      "Batch: 55, Loss: 0.7379833459854126, Accuracy: 0.7509765625\n",
      "Batch: 56, Loss: 0.6912505030632019, Accuracy: 0.77734375\n",
      "Batch: 57, Loss: 0.6747579574584961, Accuracy: 0.767578125\n",
      "Batch: 58, Loss: 0.7215769290924072, Accuracy: 0.7685546875\n",
      "Batch: 59, Loss: 0.6212151050567627, Accuracy: 0.8046875\n",
      "Batch: 60, Loss: 0.6105530858039856, Accuracy: 0.80078125\n",
      "Batch: 61, Loss: 0.7125058174133301, Accuracy: 0.771484375\n",
      "Batch: 62, Loss: 0.6210648417472839, Accuracy: 0.7890625\n",
      "Batch: 63, Loss: 0.6598098278045654, Accuracy: 0.7880859375\n",
      "Batch: 64, Loss: 0.6286851167678833, Accuracy: 0.7900390625\n",
      "Batch: 65, Loss: 0.641673743724823, Accuracy: 0.77734375\n",
      "Batch: 66, Loss: 0.6465389728546143, Accuracy: 0.796875\n",
      "Batch: 67, Loss: 0.7221893072128296, Accuracy: 0.7685546875\n",
      "Batch: 68, Loss: 0.7372029423713684, Accuracy: 0.76171875\n",
      "Batch: 72, Loss: 0.5660868883132935, Accuracy: 0.8017578125\n",
      "Batch: 73, Loss: 0.5825143456459045, Accuracy: 0.80859375\n",
      "Batch: 74, Loss: 0.5663155913352966, Accuracy: 0.8173828125\n",
      "Batch: 75, Loss: 0.6033361554145813, Accuracy: 0.80859375\n",
      "Batch: 76, Loss: 0.6689367294311523, Accuracy: 0.7978515625\n",
      "Batch: 77, Loss: 0.6106619834899902, Accuracy: 0.798828125\n",
      "Batch: 78, Loss: 0.5804252028465271, Accuracy: 0.822265625\n",
      "Batch: 79, Loss: 0.554252028465271, Accuracy: 0.822265625\n",
      "Batch: 80, Loss: 0.5966231822967529, Accuracy: 0.8056640625\n",
      "Batch: 81, Loss: 0.6651047468185425, Accuracy: 0.7607421875\n",
      "Batch: 82, Loss: 0.6516444683074951, Accuracy: 0.7861328125\n",
      "Batch: 83, Loss: 0.5404839515686035, Accuracy: 0.8271484375\n",
      "Batch: 84, Loss: 0.5867214798927307, Accuracy: 0.8046875\n",
      "Batch: 85, Loss: 0.6475921869277954, Accuracy: 0.7880859375\n",
      "Batch: 86, Loss: 0.7196047902107239, Accuracy: 0.751953125\n",
      "Batch: 87, Loss: 0.6109121441841125, Accuracy: 0.814453125\n",
      "Batch: 88, Loss: 0.6753298044204712, Accuracy: 0.76953125\n",
      "Batch: 89, Loss: 0.6651958227157593, Accuracy: 0.787109375\n",
      "Batch: 90, Loss: 0.5971575975418091, Accuracy: 0.80078125\n",
      "Batch: 91, Loss: 0.6024318933486938, Accuracy: 0.7978515625\n",
      "Batch: 92, Loss: 0.648904025554657, Accuracy: 0.7744140625\n",
      "Batch: 93, Loss: 0.6221696138381958, Accuracy: 0.787109375\n",
      "Batch: 94, Loss: 0.6677345037460327, Accuracy: 0.765625\n",
      "Batch: 95, Loss: 0.6831493377685547, Accuracy: 0.775390625\n",
      "Batch: 96, Loss: 0.6234704852104187, Accuracy: 0.787109375\n",
      "Batch: 97, Loss: 0.5198859572410583, Accuracy: 0.8232421875\n",
      "Batch: 98, Loss: 0.5937100648880005, Accuracy: 0.8125\n",
      "Batch: 99, Loss: 0.6171503067016602, Accuracy: 0.787109375\n",
      "Batch: 100, Loss: 0.667802095413208, Accuracy: 0.7734375\n",
      "Batch: 101, Loss: 0.6622626185417175, Accuracy: 0.7861328125\n",
      "Batch: 102, Loss: 0.6426488757133484, Accuracy: 0.80078125\n",
      "Batch: 103, Loss: 0.6500574350357056, Accuracy: 0.783203125\n",
      "Batch: 104, Loss: 0.5977238416671753, Accuracy: 0.80859375\n",
      "Batch: 105, Loss: 0.714340090751648, Accuracy: 0.767578125\n",
      "Batch: 106, Loss: 0.5960907936096191, Accuracy: 0.8193359375\n",
      "Batch: 107, Loss: 0.6451900005340576, Accuracy: 0.7998046875\n",
      "Batch: 108, Loss: 0.6247578859329224, Accuracy: 0.7978515625\n",
      "Batch: 109, Loss: 0.7003017067909241, Accuracy: 0.775390625\n",
      "Batch: 110, Loss: 0.6446483731269836, Accuracy: 0.7763671875\n",
      "Batch: 111, Loss: 0.6632620096206665, Accuracy: 0.7900390625\n",
      "Batch: 112, Loss: 0.631024956703186, Accuracy: 0.7890625\n",
      "Batch: 116, Loss: 0.6860630512237549, Accuracy: 0.7802734375\n",
      "Batch: 117, Loss: 0.6213038563728333, Accuracy: 0.798828125\n",
      "Batch: 118, Loss: 0.5411081314086914, Accuracy: 0.822265625\n",
      "Batch: 119, Loss: 0.5020982027053833, Accuracy: 0.8349609375\n",
      "Batch: 120, Loss: 0.6694166660308838, Accuracy: 0.787109375\n",
      "Batch: 121, Loss: 0.6985807418823242, Accuracy: 0.765625\n",
      "Batch: 122, Loss: 0.6080307960510254, Accuracy: 0.802734375\n",
      "Batch: 123, Loss: 0.5838432908058167, Accuracy: 0.810546875\n",
      "Batch: 124, Loss: 0.6420878171920776, Accuracy: 0.783203125\n",
      "Batch: 125, Loss: 0.7009292840957642, Accuracy: 0.7802734375\n",
      "Batch: 126, Loss: 0.6611809730529785, Accuracy: 0.7861328125\n",
      "Batch: 127, Loss: 0.545665442943573, Accuracy: 0.822265625\n",
      "Batch: 128, Loss: 0.7008897066116333, Accuracy: 0.80078125\n",
      "Batch: 129, Loss: 0.5586684942245483, Accuracy: 0.81640625\n",
      "Batch: 130, Loss: 0.7006386518478394, Accuracy: 0.76953125\n",
      "Batch: 131, Loss: 0.6100814342498779, Accuracy: 0.7919921875\n",
      "Batch: 132, Loss: 0.6742939949035645, Accuracy: 0.7880859375\n",
      "Batch: 133, Loss: 0.5956246852874756, Accuracy: 0.8115234375\n",
      "Batch: 134, Loss: 0.6397683024406433, Accuracy: 0.7822265625\n",
      "Batch: 135, Loss: 0.6088091731071472, Accuracy: 0.7919921875\n",
      "Batch: 136, Loss: 0.6492372155189514, Accuracy: 0.7783203125\n",
      "Batch: 137, Loss: 0.6588873863220215, Accuracy: 0.7607421875\n",
      "Batch: 138, Loss: 0.5715898275375366, Accuracy: 0.806640625\n",
      "Batch: 139, Loss: 0.643285870552063, Accuracy: 0.7529296875\n",
      "Batch: 140, Loss: 0.6455177068710327, Accuracy: 0.783203125\n",
      "Batch: 141, Loss: 0.6801930069923401, Accuracy: 0.7783203125\n",
      "Batch: 142, Loss: 0.6698963642120361, Accuracy: 0.7802734375\n",
      "Batch: 143, Loss: 0.6528252363204956, Accuracy: 0.79296875\n",
      "Batch: 144, Loss: 0.6509664058685303, Accuracy: 0.78125\n",
      "Batch: 145, Loss: 0.6023363471031189, Accuracy: 0.791015625\n",
      "Batch: 146, Loss: 0.6886056065559387, Accuracy: 0.7626953125\n",
      "Batch: 147, Loss: 0.6460492610931396, Accuracy: 0.7822265625\n",
      "Batch: 148, Loss: 0.7199376821517944, Accuracy: 0.765625\n",
      "Batch: 149, Loss: 0.6276873350143433, Accuracy: 0.7958984375\n",
      "Batch: 150, Loss: 0.6507617235183716, Accuracy: 0.787109375\n",
      "Batch: 151, Loss: 0.6006816625595093, Accuracy: 0.82421875\n",
      "Epoch 75/80\n",
      "Batch: 1, Loss: 0.828222393989563, Accuracy: 0.734375\n",
      "Batch: 2, Loss: 0.7231395244598389, Accuracy: 0.7587890625\n",
      "Batch: 3, Loss: 0.6301695704460144, Accuracy: 0.791015625\n",
      "Batch: 4, Loss: 0.5651870965957642, Accuracy: 0.806640625\n",
      "Batch: 5, Loss: 0.6079974174499512, Accuracy: 0.7958984375\n",
      "Batch: 6, Loss: 0.6601276397705078, Accuracy: 0.78125\n",
      "Batch: 7, Loss: 0.6934924721717834, Accuracy: 0.76171875\n",
      "Batch: 10, Loss: 0.5994659662246704, Accuracy: 0.798828125\n",
      "Batch: 11, Loss: 0.7243825793266296, Accuracy: 0.7509765625\n",
      "Batch: 12, Loss: 0.7000631093978882, Accuracy: 0.76953125\n",
      "Batch: 13, Loss: 0.5346264839172363, Accuracy: 0.8134765625\n",
      "Batch: 14, Loss: 0.6696838140487671, Accuracy: 0.7880859375\n",
      "Batch: 15, Loss: 0.5632166266441345, Accuracy: 0.8193359375\n",
      "Batch: 16, Loss: 0.6147638559341431, Accuracy: 0.8017578125\n",
      "Batch: 17, Loss: 0.6419200897216797, Accuracy: 0.7734375\n",
      "Batch: 18, Loss: 0.656067967414856, Accuracy: 0.7861328125\n",
      "Batch: 19, Loss: 0.6608418226242065, Accuracy: 0.7841796875\n",
      "Batch: 20, Loss: 0.5268470644950867, Accuracy: 0.830078125\n",
      "Batch: 21, Loss: 0.5789484977722168, Accuracy: 0.794921875\n",
      "Batch: 22, Loss: 0.6976926326751709, Accuracy: 0.775390625\n",
      "Batch: 23, Loss: 0.6405036449432373, Accuracy: 0.7802734375\n",
      "Batch: 24, Loss: 0.6645928621292114, Accuracy: 0.7744140625\n",
      "Batch: 25, Loss: 0.6244111061096191, Accuracy: 0.7958984375\n",
      "Batch: 26, Loss: 0.5740652680397034, Accuracy: 0.810546875\n",
      "Batch: 27, Loss: 0.605738639831543, Accuracy: 0.7744140625\n",
      "Batch: 28, Loss: 0.6820014715194702, Accuracy: 0.7734375\n",
      "Batch: 29, Loss: 0.643068790435791, Accuracy: 0.7841796875\n",
      "Batch: 30, Loss: 0.5609331130981445, Accuracy: 0.8271484375\n",
      "Batch: 31, Loss: 0.5940107703208923, Accuracy: 0.796875\n",
      "Batch: 32, Loss: 0.6121325492858887, Accuracy: 0.7861328125\n",
      "Batch: 33, Loss: 0.6731727123260498, Accuracy: 0.7744140625\n",
      "Batch: 34, Loss: 0.6919758319854736, Accuracy: 0.775390625\n",
      "Batch: 35, Loss: 0.6424590945243835, Accuracy: 0.7880859375\n",
      "Batch: 36, Loss: 0.6842421293258667, Accuracy: 0.7861328125\n",
      "Batch: 37, Loss: 0.6430919170379639, Accuracy: 0.791015625\n",
      "Batch: 38, Loss: 0.6379565000534058, Accuracy: 0.79296875\n",
      "Batch: 39, Loss: 0.6662280559539795, Accuracy: 0.7939453125\n",
      "Batch: 40, Loss: 0.6129616498947144, Accuracy: 0.798828125\n",
      "Batch: 41, Loss: 0.6078649759292603, Accuracy: 0.7802734375\n",
      "Batch: 42, Loss: 0.493681401014328, Accuracy: 0.826171875\n",
      "Batch: 43, Loss: 0.6595534682273865, Accuracy: 0.7822265625\n",
      "Batch: 44, Loss: 0.6329822540283203, Accuracy: 0.79296875\n",
      "Batch: 45, Loss: 0.5608400702476501, Accuracy: 0.7998046875\n",
      "Batch: 46, Loss: 0.5765849351882935, Accuracy: 0.810546875\n",
      "Batch: 47, Loss: 0.6085126399993896, Accuracy: 0.810546875\n",
      "Batch: 48, Loss: 0.5694429874420166, Accuracy: 0.8115234375\n",
      "Batch: 49, Loss: 0.6314610838890076, Accuracy: 0.7978515625\n",
      "Batch: 50, Loss: 0.6444608569145203, Accuracy: 0.798828125\n",
      "Batch: 51, Loss: 0.6228208541870117, Accuracy: 0.796875\n",
      "Batch: 54, Loss: 0.6036379337310791, Accuracy: 0.7919921875\n",
      "Batch: 55, Loss: 0.7208526730537415, Accuracy: 0.7646484375\n",
      "Batch: 56, Loss: 0.6801387071609497, Accuracy: 0.7900390625\n",
      "Batch: 57, Loss: 0.6465440988540649, Accuracy: 0.7978515625\n",
      "Batch: 58, Loss: 0.7218731045722961, Accuracy: 0.7822265625\n",
      "Batch: 59, Loss: 0.6070632934570312, Accuracy: 0.80859375\n",
      "Batch: 60, Loss: 0.601669430732727, Accuracy: 0.8076171875\n",
      "Batch: 61, Loss: 0.680490255355835, Accuracy: 0.7763671875\n",
      "Batch: 62, Loss: 0.610796332359314, Accuracy: 0.7822265625\n",
      "Batch: 63, Loss: 0.6503894329071045, Accuracy: 0.78515625\n",
      "Batch: 64, Loss: 0.640296220779419, Accuracy: 0.798828125\n",
      "Batch: 65, Loss: 0.6565003395080566, Accuracy: 0.78125\n",
      "Batch: 66, Loss: 0.6412299871444702, Accuracy: 0.779296875\n",
      "Batch: 67, Loss: 0.7361741065979004, Accuracy: 0.767578125\n",
      "Batch: 68, Loss: 0.734476625919342, Accuracy: 0.7578125\n",
      "Batch: 69, Loss: 0.6609039902687073, Accuracy: 0.779296875\n",
      "Batch: 70, Loss: 0.6104769110679626, Accuracy: 0.8125\n",
      "Batch: 71, Loss: 0.6749650239944458, Accuracy: 0.759765625\n",
      "Batch: 72, Loss: 0.5864603519439697, Accuracy: 0.7890625\n",
      "Batch: 73, Loss: 0.595562219619751, Accuracy: 0.818359375\n",
      "Batch: 74, Loss: 0.549933135509491, Accuracy: 0.8251953125\n",
      "Batch: 75, Loss: 0.6033574342727661, Accuracy: 0.8037109375\n",
      "Batch: 76, Loss: 0.654638409614563, Accuracy: 0.794921875\n",
      "Batch: 77, Loss: 0.5815922021865845, Accuracy: 0.82421875\n",
      "Batch: 78, Loss: 0.5799751877784729, Accuracy: 0.8037109375\n",
      "Batch: 79, Loss: 0.521706759929657, Accuracy: 0.84375\n",
      "Batch: 80, Loss: 0.5843772888183594, Accuracy: 0.7998046875\n",
      "Batch: 81, Loss: 0.6611219644546509, Accuracy: 0.763671875\n",
      "Batch: 82, Loss: 0.6582823991775513, Accuracy: 0.7626953125\n",
      "Batch: 83, Loss: 0.5577283501625061, Accuracy: 0.8056640625\n",
      "Batch: 84, Loss: 0.6075729727745056, Accuracy: 0.814453125\n",
      "Batch: 85, Loss: 0.6449790000915527, Accuracy: 0.7900390625\n",
      "Batch: 86, Loss: 0.710813581943512, Accuracy: 0.7685546875\n",
      "Batch: 87, Loss: 0.5734944343566895, Accuracy: 0.81640625\n",
      "Batch: 88, Loss: 0.6828745603561401, Accuracy: 0.7734375\n",
      "Batch: 89, Loss: 0.6104605793952942, Accuracy: 0.7998046875\n",
      "Batch: 90, Loss: 0.5925679206848145, Accuracy: 0.810546875\n",
      "Batch: 91, Loss: 0.6199603080749512, Accuracy: 0.791015625\n",
      "Batch: 92, Loss: 0.6451537609100342, Accuracy: 0.7802734375\n",
      "Batch: 93, Loss: 0.6508175134658813, Accuracy: 0.77734375\n",
      "Batch: 94, Loss: 0.6618356704711914, Accuracy: 0.7783203125\n",
      "Batch: 96, Loss: 0.606194019317627, Accuracy: 0.7978515625\n",
      "Batch: 97, Loss: 0.5205945372581482, Accuracy: 0.83203125\n",
      "Batch: 98, Loss: 0.588841438293457, Accuracy: 0.806640625\n",
      "Batch: 99, Loss: 0.5966026782989502, Accuracy: 0.794921875\n",
      "Batch: 100, Loss: 0.6523433923721313, Accuracy: 0.7841796875\n",
      "Batch: 101, Loss: 0.6279996037483215, Accuracy: 0.7998046875\n",
      "Batch: 102, Loss: 0.6290144920349121, Accuracy: 0.79296875\n",
      "Batch: 103, Loss: 0.6265774965286255, Accuracy: 0.7939453125\n",
      "Batch: 104, Loss: 0.5872825384140015, Accuracy: 0.806640625\n",
      "Batch: 105, Loss: 0.6402226090431213, Accuracy: 0.7919921875\n",
      "Batch: 106, Loss: 0.5997001528739929, Accuracy: 0.810546875\n",
      "Batch: 107, Loss: 0.6661950349807739, Accuracy: 0.796875\n",
      "Batch: 108, Loss: 0.603683352470398, Accuracy: 0.8017578125\n",
      "Batch: 109, Loss: 0.7163437604904175, Accuracy: 0.75390625\n",
      "Batch: 110, Loss: 0.5882407426834106, Accuracy: 0.7919921875\n",
      "Batch: 111, Loss: 0.6391528844833374, Accuracy: 0.802734375\n",
      "Batch: 112, Loss: 0.6436703205108643, Accuracy: 0.794921875\n",
      "Batch: 113, Loss: 0.5993705987930298, Accuracy: 0.7939453125\n",
      "Batch: 114, Loss: 0.688579261302948, Accuracy: 0.7802734375\n",
      "Batch: 115, Loss: 0.7422847747802734, Accuracy: 0.74609375\n",
      "Batch: 116, Loss: 0.636400580406189, Accuracy: 0.783203125\n",
      "Batch: 117, Loss: 0.636216938495636, Accuracy: 0.791015625\n",
      "Batch: 118, Loss: 0.5446267127990723, Accuracy: 0.82421875\n",
      "Batch: 119, Loss: 0.5231121182441711, Accuracy: 0.8212890625\n",
      "Batch: 120, Loss: 0.6450439095497131, Accuracy: 0.77734375\n",
      "Batch: 121, Loss: 0.6871517300605774, Accuracy: 0.7685546875\n",
      "Batch: 122, Loss: 0.582943320274353, Accuracy: 0.8134765625\n",
      "Batch: 123, Loss: 0.5774909257888794, Accuracy: 0.810546875\n",
      "Batch: 124, Loss: 0.6610798835754395, Accuracy: 0.7802734375\n",
      "Batch: 125, Loss: 0.73027503490448, Accuracy: 0.765625\n",
      "Batch: 126, Loss: 0.6725318431854248, Accuracy: 0.7880859375\n",
      "Batch: 127, Loss: 0.5583556890487671, Accuracy: 0.818359375\n",
      "Batch: 128, Loss: 0.7280833721160889, Accuracy: 0.775390625\n",
      "Batch: 129, Loss: 0.5636581778526306, Accuracy: 0.8095703125\n",
      "Batch: 130, Loss: 0.7185471057891846, Accuracy: 0.767578125\n",
      "Batch: 131, Loss: 0.604284405708313, Accuracy: 0.7958984375\n",
      "Batch: 132, Loss: 0.6793167591094971, Accuracy: 0.783203125\n",
      "Batch: 133, Loss: 0.6174170970916748, Accuracy: 0.7861328125\n",
      "Batch: 134, Loss: 0.6559628844261169, Accuracy: 0.78125\n",
      "Batch: 135, Loss: 0.5980303287506104, Accuracy: 0.80859375\n",
      "Batch: 136, Loss: 0.6454965472221375, Accuracy: 0.77734375\n",
      "Batch: 137, Loss: 0.655784547328949, Accuracy: 0.779296875\n",
      "Batch: 138, Loss: 0.5976755619049072, Accuracy: 0.7958984375\n",
      "Batch: 139, Loss: 0.6122485399246216, Accuracy: 0.79296875\n",
      "Batch: 140, Loss: 0.6495159268379211, Accuracy: 0.7724609375\n",
      "Batch: 141, Loss: 0.694362998008728, Accuracy: 0.77734375\n",
      "Batch: 142, Loss: 0.6676559448242188, Accuracy: 0.7744140625\n",
      "Batch: 143, Loss: 0.6247949600219727, Accuracy: 0.7939453125\n",
      "Batch: 144, Loss: 0.6786683201789856, Accuracy: 0.7734375\n",
      "Batch: 145, Loss: 0.6198335886001587, Accuracy: 0.78125\n",
      "Batch: 146, Loss: 0.6724136471748352, Accuracy: 0.78125\n",
      "Batch: 147, Loss: 0.6558086276054382, Accuracy: 0.791015625\n",
      "Batch: 148, Loss: 0.6970210671424866, Accuracy: 0.7578125\n",
      "Batch: 149, Loss: 0.6103893518447876, Accuracy: 0.798828125\n",
      "Batch: 150, Loss: 0.6328631639480591, Accuracy: 0.79296875\n",
      "Batch: 151, Loss: 0.5796129703521729, Accuracy: 0.8115234375\n",
      "Epoch 76/80\n",
      "Batch: 1, Loss: 0.8390021324157715, Accuracy: 0.740234375\n",
      "Batch: 2, Loss: 0.7102428674697876, Accuracy: 0.7607421875\n",
      "Batch: 3, Loss: 0.6644066572189331, Accuracy: 0.791015625\n",
      "Batch: 4, Loss: 0.5951685905456543, Accuracy: 0.8056640625\n",
      "Batch: 5, Loss: 0.6314003467559814, Accuracy: 0.7822265625\n",
      "Batch: 6, Loss: 0.6689807176589966, Accuracy: 0.7646484375\n",
      "Batch: 7, Loss: 0.7018268704414368, Accuracy: 0.755859375\n",
      "Batch: 8, Loss: 0.6221011877059937, Accuracy: 0.7880859375\n",
      "Batch: 9, Loss: 0.5946897864341736, Accuracy: 0.8046875\n",
      "Batch: 10, Loss: 0.5987348556518555, Accuracy: 0.7939453125\n",
      "Batch: 11, Loss: 0.7089159488677979, Accuracy: 0.759765625\n",
      "Batch: 12, Loss: 0.6646557450294495, Accuracy: 0.7685546875\n",
      "Batch: 13, Loss: 0.5366572141647339, Accuracy: 0.8154296875\n",
      "Batch: 14, Loss: 0.7093294262886047, Accuracy: 0.7626953125\n",
      "Batch: 15, Loss: 0.6058444976806641, Accuracy: 0.8095703125\n",
      "Batch: 16, Loss: 0.6126676797866821, Accuracy: 0.7998046875\n",
      "Batch: 17, Loss: 0.646101176738739, Accuracy: 0.791015625\n",
      "Batch: 18, Loss: 0.6517606973648071, Accuracy: 0.7958984375\n",
      "Batch: 19, Loss: 0.6347161531448364, Accuracy: 0.7939453125\n",
      "Batch: 20, Loss: 0.5615620613098145, Accuracy: 0.8134765625\n",
      "Batch: 21, Loss: 0.5763888359069824, Accuracy: 0.796875\n",
      "Batch: 22, Loss: 0.7080976963043213, Accuracy: 0.7724609375\n",
      "Batch: 23, Loss: 0.6841071844100952, Accuracy: 0.7578125\n",
      "Batch: 24, Loss: 0.6663479804992676, Accuracy: 0.7734375\n",
      "Batch: 25, Loss: 0.6484301090240479, Accuracy: 0.798828125\n",
      "Batch: 26, Loss: 0.5681784749031067, Accuracy: 0.8115234375\n",
      "Batch: 27, Loss: 0.6011877655982971, Accuracy: 0.7841796875\n",
      "Batch: 28, Loss: 0.6765114068984985, Accuracy: 0.7705078125\n",
      "Batch: 29, Loss: 0.6203105449676514, Accuracy: 0.8154296875\n",
      "Batch: 30, Loss: 0.5768125057220459, Accuracy: 0.818359375\n",
      "Batch: 31, Loss: 0.5544596910476685, Accuracy: 0.8193359375\n",
      "Batch: 32, Loss: 0.5762208700180054, Accuracy: 0.8095703125\n",
      "Batch: 33, Loss: 0.697149395942688, Accuracy: 0.7822265625\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_dir, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.669647</td>\n",
       "      <td>0.284180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.846643</td>\n",
       "      <td>0.505859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.550365</td>\n",
       "      <td>0.552734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.423734</td>\n",
       "      <td>0.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.316762</td>\n",
       "      <td>0.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.283447</td>\n",
       "      <td>0.610352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.196602</td>\n",
       "      <td>0.627930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.147893</td>\n",
       "      <td>0.645508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.083460</td>\n",
       "      <td>0.652344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.070172</td>\n",
       "      <td>0.669922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.064165</td>\n",
       "      <td>0.662109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.030042</td>\n",
       "      <td>0.672852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.978791</td>\n",
       "      <td>0.692383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.943226</td>\n",
       "      <td>0.701172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.957304</td>\n",
       "      <td>0.689453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.927884</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.917587</td>\n",
       "      <td>0.708984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.888347</td>\n",
       "      <td>0.716797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.899699</td>\n",
       "      <td>0.717773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.875614</td>\n",
       "      <td>0.727539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.864747</td>\n",
       "      <td>0.725586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.839909</td>\n",
       "      <td>0.736328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.848150</td>\n",
       "      <td>0.732422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.828648</td>\n",
       "      <td>0.738281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.831119</td>\n",
       "      <td>0.725586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.817901</td>\n",
       "      <td>0.738281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.820173</td>\n",
       "      <td>0.739258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.810007</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.791974</td>\n",
       "      <td>0.746094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>0.660615</td>\n",
       "      <td>0.794922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>0.679564</td>\n",
       "      <td>0.784180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>0.652342</td>\n",
       "      <td>0.786133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>0.642869</td>\n",
       "      <td>0.778320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>0.638352</td>\n",
       "      <td>0.785156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>0.645752</td>\n",
       "      <td>0.793945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>0.648446</td>\n",
       "      <td>0.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>0.627221</td>\n",
       "      <td>0.790039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>0.647230</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>0.635407</td>\n",
       "      <td>0.803711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>0.633044</td>\n",
       "      <td>0.791992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>0.623323</td>\n",
       "      <td>0.798828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>0.603054</td>\n",
       "      <td>0.795898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>0.615591</td>\n",
       "      <td>0.792969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>0.591320</td>\n",
       "      <td>0.803711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>0.616144</td>\n",
       "      <td>0.797852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>0.607797</td>\n",
       "      <td>0.809570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>0.624762</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>0.613894</td>\n",
       "      <td>0.809570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>0.596060</td>\n",
       "      <td>0.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>0.610160</td>\n",
       "      <td>0.801758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>0.583284</td>\n",
       "      <td>0.813477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>0.582834</td>\n",
       "      <td>0.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>0.600682</td>\n",
       "      <td>0.824219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>0.579613</td>\n",
       "      <td>0.811523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>0.599393</td>\n",
       "      <td>0.808594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>0.578175</td>\n",
       "      <td>0.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>0.564189</td>\n",
       "      <td>0.826172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>0.553327</td>\n",
       "      <td>0.822266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch      Loss  Accuracy\n",
       "0       1  2.669647  0.284180\n",
       "1       2  1.846643  0.505859\n",
       "2       3  1.550365  0.552734\n",
       "3       4  1.423734  0.578125\n",
       "4       5  1.316762  0.601562\n",
       "5       6  1.283447  0.610352\n",
       "6       7  1.196602  0.627930\n",
       "7       8  1.147893  0.645508\n",
       "8       9  1.083460  0.652344\n",
       "9      10  1.070172  0.669922\n",
       "10     11  1.064165  0.662109\n",
       "11     12  1.030042  0.672852\n",
       "12     13  0.996910  0.687500\n",
       "13     14  0.978791  0.692383\n",
       "14     15  0.943226  0.701172\n",
       "15     16  0.957304  0.689453\n",
       "16     17  0.927884  0.703125\n",
       "17     18  0.917587  0.708984\n",
       "18     19  0.888347  0.716797\n",
       "19     20  0.899699  0.717773\n",
       "20     21  0.875614  0.727539\n",
       "21     22  0.864747  0.725586\n",
       "22     23  0.839909  0.736328\n",
       "23     24  0.848150  0.732422\n",
       "24     25  0.828648  0.738281\n",
       "25     26  0.831119  0.725586\n",
       "26     27  0.817901  0.738281\n",
       "27     28  0.820173  0.739258\n",
       "28     29  0.810007  0.734375\n",
       "29     30  0.791974  0.746094\n",
       "..    ...       ...       ...\n",
       "50     51  0.660615  0.794922\n",
       "51     52  0.679564  0.784180\n",
       "52     53  0.652342  0.786133\n",
       "53     54  0.642869  0.778320\n",
       "54     55  0.638352  0.785156\n",
       "55     56  0.645752  0.793945\n",
       "56     57  0.648446  0.789062\n",
       "57     58  0.627221  0.790039\n",
       "58     59  0.647230  0.796875\n",
       "59     60  0.635407  0.803711\n",
       "60     61  0.633044  0.791992\n",
       "61     62  0.623323  0.798828\n",
       "62     63  0.603054  0.795898\n",
       "63     64  0.615591  0.792969\n",
       "64     65  0.591320  0.803711\n",
       "65     66  0.616144  0.797852\n",
       "66     67  0.607797  0.809570\n",
       "67     68  0.624762  0.796875\n",
       "68     69  0.613894  0.809570\n",
       "69     70  0.596060  0.804688\n",
       "70     71  0.610160  0.801758\n",
       "71     72  0.583284  0.813477\n",
       "72     73  0.582834  0.804688\n",
       "73     74  0.600682  0.824219\n",
       "74     75  0.579613  0.811523\n",
       "75     76  0.599393  0.808594\n",
       "76     77  0.578175  0.816406\n",
       "77     78  0.564189  0.826172\n",
       "78     79  0.553327  0.822266\n",
       "79     80  0.585043  0.818359\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(log_dir)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
