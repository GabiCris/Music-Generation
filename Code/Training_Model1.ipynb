{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize paths for data input and weights output\n",
    "data_dir = \"../Data/\"\n",
    "data_file = \"Notting_OneillQuart\"\n",
    "save_weights_dir = '../Trained_Weights/Weights_Notting_Oneill/'\n",
    "log_dir = \"../Data/log_Notting_Oneill.csv\"\n",
    "charToIndex_json = \"char_to_index.json\"\n",
    "# Parameters\n",
    "BATCH_SIZE = 32\n",
    "SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the batches\n",
    "def get_batches(chars, unique_chars):\n",
    "    char_no = chars.shape[0] # number of characters in the data\n",
    "    batch_chars = int(char_no / BATCH_SIZE)\n",
    "    \n",
    "    # outer loop iterates every time a new batch is created\n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, SEQ_LENGTH):\n",
    "        # number of batches wil be char_no/(BATCH_SIZE * SEQ_LENGTH)\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))  \n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))\n",
    "        # iterates over rows in a batch\n",
    "        for batch_row in range(0, BATCH_SIZE):\n",
    "            # iterates over columns in a batch\n",
    "            for i in range(0, SEQ_LENGTH): \n",
    "                X[batch_row, i] = chars[batch_row * batch_chars + start + i]\n",
    "                Y[batch_row, i, chars[batch_row * batch_chars + start + i + 1]] = 1\n",
    "                # by 1 we mark that the next character in the sequence is the correct one\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # inputs have to be the same length which is achieved when creating batches\n",
    "    # input dimension will be the number of unique characters in the training data\n",
    "    # output-dimention needs more validation - 8?\n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 16, batch_input_shape = (batch_size, seq_length))) \n",
    "    \n",
    "    # Using keras Dropout to prevent overfitting\n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(128, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, epochs = 80):\n",
    "    \n",
    "    # Mapping all unique characters to an index\n",
    "    char_to_index = {char: x for (x, char) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Unique characters in the training data = {}\".format(len(char_to_index)))  \n",
    "    # Saved the mapping in a json file\n",
    "    with open(os.path.join(data_dir, charToIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {x: char for (char, x) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    # Build the model\n",
    "    model = build_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    # multi-class classification problem - using Categorical Cross entropy as loss function\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Number of characters = \" + str(characters.shape[0]))\n",
    "    \n",
    "    # saving training data for furture logging\n",
    "    saved_epoch, loss, accuracy = [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        last_epoch_loss, last_epoch_accuracy = 0, 0\n",
    "        saved_epoch.append(epoch+1)\n",
    "        \n",
    "        # reading the batches one by one and training the model on each one\n",
    "        for i, (x, y) in enumerate(get_batches(characters, unique_chars)):\n",
    "            last_epoch_loss, last_epoch_accuracy = model.train_on_batch(x, y) \n",
    "            print(\"Batch No.: {}, Loss: {}, Accuracy: {}\".format(i+1, last_epoch_loss, last_epoch_accuracy))\n",
    "        loss.append(last_epoch_loss)\n",
    "        accuracy.append(last_epoch_accuracy)\n",
    "        \n",
    "        # Saving the computed weights each 10th epoch\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(save_weights_dir):\n",
    "                os.makedirs(save_weights_dir)\n",
    "            model.save_weights(os.path.join(save_weights_dir, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved weights computed at epoch {} to Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    # Logging the training data into a DataFrame structure to be saved to file after each training\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = saved_epoch\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(log_dir, index = False)\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    pyplot.plot(accuracy, saved_epoch)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters in the training data = 93\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (32, 128, 16)             1488      \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (32, 128, 256)            279552    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (32, 128, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (32, 128, 128)            197120    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (32, 128, 128)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (32, 128, 93)             11997     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (32, 128, 93)             0         \n",
      "=================================================================\n",
      "Total params: 490,157\n",
      "Trainable params: 490,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Number of characters = 1085327\n",
      "Epoch 1/80\n",
      "Batch No.: 1, Loss: 4.5326313972473145, Accuracy: 0.009033203125\n",
      "Batch No.: 2, Loss: 4.5288591384887695, Accuracy: 0.141357421875\n",
      "Batch No.: 3, Loss: 4.52301549911499, Accuracy: 0.148681640625\n",
      "Batch No.: 4, Loss: 4.512088775634766, Accuracy: 0.163818359375\n",
      "Batch No.: 5, Loss: 4.495737552642822, Accuracy: 0.158203125\n",
      "Batch No.: 6, Loss: 4.470858573913574, Accuracy: 0.142578125\n",
      "Batch No.: 7, Loss: 4.370989799499512, Accuracy: 0.15625\n",
      "Batch No.: 8, Loss: 4.153503894805908, Accuracy: 0.156982421875\n",
      "Batch No.: 9, Loss: 4.170000076293945, Accuracy: 0.12939453125\n",
      "Batch No.: 10, Loss: 3.8316783905029297, Accuracy: 0.163818359375\n",
      "Batch No.: 11, Loss: 3.8208189010620117, Accuracy: 0.175048828125\n",
      "Batch No.: 12, Loss: 3.973637342453003, Accuracy: 0.13134765625\n",
      "Batch No.: 13, Loss: 3.8291406631469727, Accuracy: 0.149658203125\n",
      "Batch No.: 15, Loss: 3.7949376106262207, Accuracy: 0.154052734375\n",
      "Batch No.: 16, Loss: 3.853851318359375, Accuracy: 0.136474609375\n",
      "Batch No.: 17, Loss: 3.692598581314087, Accuracy: 0.15185546875\n",
      "Batch No.: 18, Loss: 3.723227024078369, Accuracy: 0.15380859375\n",
      "Batch No.: 19, Loss: 3.884523391723633, Accuracy: 0.140625\n",
      "Batch No.: 20, Loss: 3.716610908508301, Accuracy: 0.154052734375\n",
      "Batch No.: 21, Loss: 3.6499009132385254, Accuracy: 0.162109375\n",
      "Batch No.: 22, Loss: 3.7879016399383545, Accuracy: 0.140625\n",
      "Batch No.: 23, Loss: 3.7966742515563965, Accuracy: 0.138671875\n",
      "Batch No.: 24, Loss: 3.655609130859375, Accuracy: 0.151611328125\n",
      "Batch No.: 25, Loss: 3.70068359375, Accuracy: 0.16064453125\n",
      "Batch No.: 26, Loss: 3.7832446098327637, Accuracy: 0.144775390625\n",
      "Batch No.: 27, Loss: 3.6725406646728516, Accuracy: 0.14697265625\n",
      "Batch No.: 28, Loss: 3.7706809043884277, Accuracy: 0.14208984375\n",
      "Batch No.: 29, Loss: 3.7895708084106445, Accuracy: 0.1416015625\n",
      "Batch No.: 30, Loss: 3.5932698249816895, Accuracy: 0.15087890625\n",
      "Batch No.: 31, Loss: 3.7561469078063965, Accuracy: 0.14599609375\n",
      "Batch No.: 32, Loss: 3.85231614112854, Accuracy: 0.138427734375\n",
      "Batch No.: 33, Loss: 3.6480846405029297, Accuracy: 0.15380859375\n",
      "Batch No.: 34, Loss: 3.6254472732543945, Accuracy: 0.165283203125\n",
      "Batch No.: 35, Loss: 3.8296236991882324, Accuracy: 0.138916015625\n",
      "Batch No.: 36, Loss: 3.7265851497650146, Accuracy: 0.1455078125\n",
      "Batch No.: 37, Loss: 3.588277578353882, Accuracy: 0.1630859375\n",
      "Batch No.: 38, Loss: 3.846097946166992, Accuracy: 0.130859375\n",
      "Batch No.: 39, Loss: 3.7112226486206055, Accuracy: 0.1474609375\n",
      "Batch No.: 40, Loss: 3.651251792907715, Accuracy: 0.154541015625\n",
      "Batch No.: 41, Loss: 3.7022581100463867, Accuracy: 0.146240234375\n",
      "Batch No.: 42, Loss: 3.7099995613098145, Accuracy: 0.14697265625\n",
      "Batch No.: 43, Loss: 3.727487087249756, Accuracy: 0.151611328125\n",
      "Batch No.: 44, Loss: 3.6275272369384766, Accuracy: 0.15576171875\n",
      "Batch No.: 45, Loss: 3.712033748626709, Accuracy: 0.139404296875\n",
      "Batch No.: 46, Loss: 3.64793062210083, Accuracy: 0.15673828125\n",
      "Batch No.: 47, Loss: 3.682506561279297, Accuracy: 0.1513671875\n",
      "Batch No.: 48, Loss: 3.7480268478393555, Accuracy: 0.14501953125\n",
      "Batch No.: 49, Loss: 3.6651101112365723, Accuracy: 0.165771484375\n",
      "Batch No.: 50, Loss: 3.6666080951690674, Accuracy: 0.15478515625\n",
      "Batch No.: 51, Loss: 3.756401777267456, Accuracy: 0.135498046875\n",
      "Batch No.: 52, Loss: 3.707261562347412, Accuracy: 0.14794921875\n",
      "Batch No.: 53, Loss: 3.6871845722198486, Accuracy: 0.154541015625\n",
      "Batch No.: 54, Loss: 3.6027002334594727, Accuracy: 0.16162109375\n",
      "Batch No.: 55, Loss: 3.71641206741333, Accuracy: 0.1533203125\n",
      "Batch No.: 56, Loss: 3.7889766693115234, Accuracy: 0.145263671875\n",
      "Batch No.: 57, Loss: 3.7264914512634277, Accuracy: 0.14501953125\n",
      "Batch No.: 58, Loss: 3.642331600189209, Accuracy: 0.16357421875\n",
      "Batch No.: 61, Loss: 3.710866928100586, Accuracy: 0.150634765625\n",
      "Batch No.: 62, Loss: 3.698676109313965, Accuracy: 0.14404296875\n",
      "Batch No.: 63, Loss: 3.7392547130584717, Accuracy: 0.143798828125\n",
      "Batch No.: 64, Loss: 3.6955442428588867, Accuracy: 0.1484375\n",
      "Batch No.: 65, Loss: 3.6824965476989746, Accuracy: 0.1533203125\n",
      "Batch No.: 66, Loss: 3.7572035789489746, Accuracy: 0.14453125\n",
      "Batch No.: 67, Loss: 3.725290536880493, Accuracy: 0.144287109375\n",
      "Batch No.: 68, Loss: 3.6254003047943115, Accuracy: 0.155029296875\n",
      "Batch No.: 69, Loss: 3.6694083213806152, Accuracy: 0.151123046875\n",
      "Batch No.: 70, Loss: 3.731428861618042, Accuracy: 0.143310546875\n",
      "Batch No.: 71, Loss: 3.728179454803467, Accuracy: 0.137939453125\n",
      "Batch No.: 72, Loss: 3.7157859802246094, Accuracy: 0.144287109375\n",
      "Batch No.: 73, Loss: 3.61269211769104, Accuracy: 0.1494140625\n",
      "Batch No.: 74, Loss: 3.7141456604003906, Accuracy: 0.139892578125\n",
      "Batch No.: 75, Loss: 3.6706719398498535, Accuracy: 0.156982421875\n",
      "Batch No.: 76, Loss: 3.63472318649292, Accuracy: 0.15380859375\n",
      "Batch No.: 77, Loss: 3.6918957233428955, Accuracy: 0.151611328125\n",
      "Batch No.: 78, Loss: 3.702401638031006, Accuracy: 0.14794921875\n",
      "Batch No.: 79, Loss: 3.6642441749572754, Accuracy: 0.1455078125\n",
      "Batch No.: 80, Loss: 3.6754255294799805, Accuracy: 0.144287109375\n",
      "Batch No.: 81, Loss: 3.6682181358337402, Accuracy: 0.148681640625\n",
      "Batch No.: 82, Loss: 3.7124876976013184, Accuracy: 0.1455078125\n",
      "Batch No.: 84, Loss: 3.6148464679718018, Accuracy: 0.155517578125\n",
      "Batch No.: 85, Loss: 3.773871421813965, Accuracy: 0.143798828125\n",
      "Batch No.: 86, Loss: 3.754507541656494, Accuracy: 0.134033203125\n",
      "Batch No.: 87, Loss: 3.5332040786743164, Accuracy: 0.1748046875\n",
      "Batch No.: 88, Loss: 3.648739814758301, Accuracy: 0.158203125\n",
      "Batch No.: 89, Loss: 3.666586399078369, Accuracy: 0.149169921875\n",
      "Batch No.: 90, Loss: 3.632580280303955, Accuracy: 0.16162109375\n",
      "Batch No.: 91, Loss: 3.674351692199707, Accuracy: 0.15185546875\n",
      "Batch No.: 92, Loss: 3.70479679107666, Accuracy: 0.1416015625\n",
      "Batch No.: 93, Loss: 3.6788082122802734, Accuracy: 0.1611328125\n",
      "Batch No.: 94, Loss: 3.705486297607422, Accuracy: 0.163330078125\n",
      "Batch No.: 95, Loss: 3.690115451812744, Accuracy: 0.150634765625\n",
      "Batch No.: 96, Loss: 3.6806161403656006, Accuracy: 0.15771484375\n",
      "Batch No.: 97, Loss: 3.639233112335205, Accuracy: 0.16064453125\n",
      "Batch No.: 98, Loss: 3.6862874031066895, Accuracy: 0.145263671875\n",
      "Batch No.: 99, Loss: 3.681511402130127, Accuracy: 0.154541015625\n",
      "Batch No.: 100, Loss: 3.7485971450805664, Accuracy: 0.14404296875\n",
      "Batch No.: 101, Loss: 3.7817695140838623, Accuracy: 0.134765625\n",
      "Batch No.: 102, Loss: 3.5630173683166504, Accuracy: 0.153564453125\n",
      "Batch No.: 103, Loss: 3.6967711448669434, Accuracy: 0.14453125\n",
      "Batch No.: 104, Loss: 3.7081546783447266, Accuracy: 0.144775390625\n",
      "Batch No.: 105, Loss: 3.6584744453430176, Accuracy: 0.14892578125\n",
      "Batch No.: 106, Loss: 3.7567105293273926, Accuracy: 0.137939453125\n",
      "Batch No.: 107, Loss: 3.704463005065918, Accuracy: 0.144775390625\n",
      "Batch No.: 108, Loss: 3.6445846557617188, Accuracy: 0.144287109375\n",
      "Batch No.: 109, Loss: 3.6674599647521973, Accuracy: 0.135009765625\n",
      "Batch No.: 110, Loss: 3.716987133026123, Accuracy: 0.136474609375\n",
      "Batch No.: 111, Loss: 3.658708095550537, Accuracy: 0.146484375\n",
      "Batch No.: 112, Loss: 3.74648380279541, Accuracy: 0.126220703125\n",
      "Batch No.: 113, Loss: 3.6768181324005127, Accuracy: 0.1318359375\n",
      "Batch No.: 114, Loss: 3.764508008956909, Accuracy: 0.13720703125\n",
      "Batch No.: 115, Loss: 3.792118549346924, Accuracy: 0.1259765625\n",
      "Batch No.: 116, Loss: 3.6035044193267822, Accuracy: 0.150390625\n",
      "Batch No.: 117, Loss: 3.6973819732666016, Accuracy: 0.144775390625\n",
      "Batch No.: 118, Loss: 3.61537766456604, Accuracy: 0.15185546875\n",
      "Batch No.: 119, Loss: 3.6765077114105225, Accuracy: 0.148681640625\n",
      "Batch No.: 120, Loss: 3.685797929763794, Accuracy: 0.14599609375\n",
      "Batch No.: 121, Loss: 3.7342593669891357, Accuracy: 0.14306640625\n",
      "Batch No.: 122, Loss: 3.6512773036956787, Accuracy: 0.156005859375\n",
      "Batch No.: 123, Loss: 3.717372417449951, Accuracy: 0.151123046875\n",
      "Batch No.: 124, Loss: 3.710033893585205, Accuracy: 0.154052734375\n",
      "Batch No.: 125, Loss: 3.670743703842163, Accuracy: 0.15234375\n",
      "Batch No.: 126, Loss: 3.7097008228302, Accuracy: 0.156005859375\n",
      "Batch No.: 127, Loss: 3.7007834911346436, Accuracy: 0.13525390625\n",
      "Batch No.: 128, Loss: 3.7067322731018066, Accuracy: 0.147705078125\n",
      "Batch No.: 129, Loss: 3.6973021030426025, Accuracy: 0.14794921875\n",
      "Batch No.: 130, Loss: 3.837273597717285, Accuracy: 0.131591796875\n",
      "Batch No.: 131, Loss: 3.6260180473327637, Accuracy: 0.15234375\n",
      "Batch No.: 132, Loss: 3.636667013168335, Accuracy: 0.1513671875\n",
      "Batch No.: 133, Loss: 3.8000731468200684, Accuracy: 0.132080078125\n",
      "Batch No.: 134, Loss: 3.705019950866699, Accuracy: 0.15234375\n",
      "Batch No.: 135, Loss: 3.6210274696350098, Accuracy: 0.155517578125\n",
      "Batch No.: 136, Loss: 3.744717597961426, Accuracy: 0.14013671875\n",
      "Batch No.: 137, Loss: 3.7224137783050537, Accuracy: 0.13671875\n",
      "Batch No.: 138, Loss: 3.6207478046417236, Accuracy: 0.14794921875\n",
      "Batch No.: 139, Loss: 3.6952881813049316, Accuracy: 0.134765625\n",
      "Batch No.: 140, Loss: 3.6935465335845947, Accuracy: 0.143310546875\n",
      "Batch No.: 141, Loss: 3.7510147094726562, Accuracy: 0.14404296875\n",
      "Batch No.: 142, Loss: 3.749643087387085, Accuracy: 0.132568359375\n",
      "Batch No.: 143, Loss: 3.778897523880005, Accuracy: 0.141357421875\n",
      "Batch No.: 144, Loss: 3.647012710571289, Accuracy: 0.154541015625\n",
      "Batch No.: 145, Loss: 3.6969077587127686, Accuracy: 0.14892578125\n",
      "Batch No.: 146, Loss: 3.675413131713867, Accuracy: 0.146240234375\n",
      "Batch No.: 147, Loss: 3.599438428878784, Accuracy: 0.16162109375\n",
      "Batch No.: 148, Loss: 3.780728816986084, Accuracy: 0.140380859375\n",
      "Batch No.: 149, Loss: 3.6690502166748047, Accuracy: 0.150146484375\n",
      "Batch No.: 150, Loss: 3.5841002464294434, Accuracy: 0.163330078125\n",
      "Batch No.: 151, Loss: 3.7308075428009033, Accuracy: 0.154296875\n",
      "Batch No.: 152, Loss: 3.7124969959259033, Accuracy: 0.1513671875\n",
      "Batch No.: 153, Loss: 3.6808700561523438, Accuracy: 0.15234375\n",
      "Batch No.: 154, Loss: 3.6470389366149902, Accuracy: 0.155517578125\n",
      "Batch No.: 155, Loss: 3.649549722671509, Accuracy: 0.15380859375\n",
      "Batch No.: 156, Loss: 3.634615898132324, Accuracy: 0.146240234375\n",
      "Batch No.: 157, Loss: 3.681781768798828, Accuracy: 0.149658203125\n",
      "Batch No.: 158, Loss: 3.644545555114746, Accuracy: 0.158935546875\n",
      "Batch No.: 159, Loss: 3.7307324409484863, Accuracy: 0.14111328125\n",
      "Batch No.: 160, Loss: 3.672276735305786, Accuracy: 0.14208984375\n",
      "Batch No.: 161, Loss: 3.66788387298584, Accuracy: 0.142578125\n",
      "Batch No.: 162, Loss: 3.743323802947998, Accuracy: 0.134033203125\n",
      "Batch No.: 163, Loss: 3.723565101623535, Accuracy: 0.137451171875\n",
      "Batch No.: 164, Loss: 3.6029224395751953, Accuracy: 0.156494140625\n",
      "Batch No.: 165, Loss: 3.7138800621032715, Accuracy: 0.145751953125\n",
      "Batch No.: 166, Loss: 3.713589668273926, Accuracy: 0.1533203125\n",
      "Batch No.: 167, Loss: 3.5884897708892822, Accuracy: 0.164306640625\n",
      "Batch No.: 168, Loss: 3.766324520111084, Accuracy: 0.135498046875\n",
      "Batch No.: 169, Loss: 3.6880340576171875, Accuracy: 0.144775390625\n",
      "Batch No.: 170, Loss: 3.6171493530273438, Accuracy: 0.1572265625\n",
      "Batch No.: 171, Loss: 3.795814037322998, Accuracy: 0.138671875\n",
      "Batch No.: 172, Loss: 3.720968008041382, Accuracy: 0.1416015625\n",
      "Batch No.: 173, Loss: 3.5627379417419434, Accuracy: 0.16796875\n",
      "Batch No.: 174, Loss: 3.675961494445801, Accuracy: 0.16015625\n",
      "Batch No.: 175, Loss: 3.8087191581726074, Accuracy: 0.135009765625\n",
      "Batch No.: 176, Loss: 3.6022727489471436, Accuracy: 0.15771484375\n",
      "Batch No.: 177, Loss: 3.704838752746582, Accuracy: 0.151123046875\n",
      "Batch No.: 178, Loss: 3.684262275695801, Accuracy: 0.146728515625\n",
      "Batch No.: 179, Loss: 3.5591588020324707, Accuracy: 0.167236328125\n",
      "Batch No.: 180, Loss: 3.625295639038086, Accuracy: 0.154296875\n",
      "Batch No.: 181, Loss: 3.6215548515319824, Accuracy: 0.1591796875\n",
      "Batch No.: 252, Loss: 3.275798797607422, Accuracy: 0.16259765625\n",
      "Batch No.: 253, Loss: 3.3064041137695312, Accuracy: 0.1650390625\n",
      "Batch No.: 254, Loss: 3.270961284637451, Accuracy: 0.17236328125\n",
      "Batch No.: 255, Loss: 3.2900643348693848, Accuracy: 0.1728515625\n",
      "Batch No.: 256, Loss: 3.308685541152954, Accuracy: 0.172607421875\n",
      "Batch No.: 257, Loss: 3.162484645843506, Accuracy: 0.180908203125\n",
      "Batch No.: 258, Loss: 3.311675548553467, Accuracy: 0.157470703125\n",
      "Batch No.: 259, Loss: 3.3260045051574707, Accuracy: 0.154541015625\n",
      "Batch No.: 260, Loss: 3.2141714096069336, Accuracy: 0.16845703125\n",
      "Batch No.: 261, Loss: 3.2525758743286133, Accuracy: 0.174072265625\n",
      "Batch No.: 262, Loss: 3.308887004852295, Accuracy: 0.1591796875\n",
      "Batch No.: 263, Loss: 3.2864344120025635, Accuracy: 0.160400390625\n",
      "Batch No.: 264, Loss: 3.3207345008850098, Accuracy: 0.156005859375\n",
      "Epoch 2/80\n",
      "Batch No.: 1, Loss: 3.230295181274414, Accuracy: 0.17578125\n",
      "Batch No.: 2, Loss: 3.3046646118164062, Accuracy: 0.16357421875\n",
      "Batch No.: 3, Loss: 3.2576208114624023, Accuracy: 0.169189453125\n",
      "Batch No.: 4, Loss: 3.1894352436065674, Accuracy: 0.18603515625\n",
      "Batch No.: 5, Loss: 3.2349066734313965, Accuracy: 0.183837890625\n",
      "Batch No.: 6, Loss: 3.3581957817077637, Accuracy: 0.1650390625\n",
      "Batch No.: 7, Loss: 3.2019779682159424, Accuracy: 0.181884765625\n",
      "Batch No.: 8, Loss: 3.2360124588012695, Accuracy: 0.17724609375\n",
      "Batch No.: 9, Loss: 3.3814563751220703, Accuracy: 0.1533203125\n",
      "Batch No.: 10, Loss: 3.176769733428955, Accuracy: 0.18359375\n",
      "Batch No.: 11, Loss: 3.1851353645324707, Accuracy: 0.209716796875\n",
      "Batch No.: 12, Loss: 3.3060367107391357, Accuracy: 0.166259765625\n",
      "Batch No.: 13, Loss: 3.1929047107696533, Accuracy: 0.18212890625\n",
      "Batch No.: 14, Loss: 3.166696071624756, Accuracy: 0.19287109375\n",
      "Batch No.: 15, Loss: 3.2192740440368652, Accuracy: 0.189697265625\n",
      "Batch No.: 16, Loss: 3.2289891242980957, Accuracy: 0.18212890625\n",
      "Batch No.: 17, Loss: 3.162724018096924, Accuracy: 0.19091796875\n",
      "Batch No.: 18, Loss: 3.2140815258026123, Accuracy: 0.194091796875\n",
      "Batch No.: 19, Loss: 3.2446720600128174, Accuracy: 0.1982421875\n",
      "Batch No.: 20, Loss: 3.1739814281463623, Accuracy: 0.200927734375\n",
      "Batch No.: 21, Loss: 3.1267576217651367, Accuracy: 0.207763671875\n",
      "Batch No.: 22, Loss: 3.208214282989502, Accuracy: 0.193359375\n",
      "Batch No.: 23, Loss: 3.2171449661254883, Accuracy: 0.185546875\n",
      "Batch No.: 24, Loss: 3.1296026706695557, Accuracy: 0.189697265625\n",
      "Batch No.: 25, Loss: 3.191112995147705, Accuracy: 0.20458984375\n",
      "Batch No.: 26, Loss: 3.1694040298461914, Accuracy: 0.198486328125\n",
      "Batch No.: 27, Loss: 3.161129951477051, Accuracy: 0.186767578125\n",
      "Batch No.: 28, Loss: 3.2011687755584717, Accuracy: 0.195068359375\n",
      "Batch No.: 29, Loss: 3.2117931842803955, Accuracy: 0.192138671875\n",
      "Batch No.: 30, Loss: 3.0850467681884766, Accuracy: 0.203369140625\n",
      "Batch No.: 31, Loss: 3.1738734245300293, Accuracy: 0.191650390625\n",
      "Batch No.: 32, Loss: 3.23614239692688, Accuracy: 0.18017578125\n",
      "Batch No.: 33, Loss: 3.0646302700042725, Accuracy: 0.2099609375\n",
      "Batch No.: 34, Loss: 3.0680363178253174, Accuracy: 0.22216796875\n",
      "Batch No.: 35, Loss: 3.1890242099761963, Accuracy: 0.1982421875\n",
      "Batch No.: 36, Loss: 3.1351730823516846, Accuracy: 0.206787109375\n",
      "Batch No.: 37, Loss: 3.0481386184692383, Accuracy: 0.22265625\n",
      "Batch No.: 38, Loss: 3.2288546562194824, Accuracy: 0.1865234375\n",
      "Batch No.: 39, Loss: 3.1345677375793457, Accuracy: 0.197509765625\n",
      "Batch No.: 40, Loss: 3.0680274963378906, Accuracy: 0.224365234375\n",
      "Batch No.: 41, Loss: 3.1123244762420654, Accuracy: 0.208984375\n",
      "Batch No.: 42, Loss: 3.1135506629943848, Accuracy: 0.208251953125\n",
      "Batch No.: 43, Loss: 3.1397252082824707, Accuracy: 0.2099609375\n",
      "Batch No.: 44, Loss: 3.0589027404785156, Accuracy: 0.215576171875\n",
      "Batch No.: 45, Loss: 3.0643210411071777, Accuracy: 0.210693359375\n",
      "Batch No.: 46, Loss: 3.054295301437378, Accuracy: 0.225830078125\n",
      "Batch No.: 47, Loss: 3.121995210647583, Accuracy: 0.20849609375\n",
      "Batch No.: 48, Loss: 3.125258207321167, Accuracy: 0.20068359375\n",
      "Batch No.: 49, Loss: 3.004121780395508, Accuracy: 0.239501953125\n",
      "Batch No.: 50, Loss: 3.0814452171325684, Accuracy: 0.209228515625\n",
      "Batch No.: 51, Loss: 3.11930775642395, Accuracy: 0.2001953125\n",
      "Batch No.: 52, Loss: 3.0679149627685547, Accuracy: 0.21728515625\n",
      "Batch No.: 53, Loss: 3.0371313095092773, Accuracy: 0.220947265625\n",
      "Batch No.: 54, Loss: 3.008436441421509, Accuracy: 0.226806640625\n",
      "Batch No.: 55, Loss: 3.080465316772461, Accuracy: 0.22314453125\n",
      "Batch No.: 56, Loss: 3.1076669692993164, Accuracy: 0.212890625\n",
      "Batch No.: 57, Loss: 3.0767178535461426, Accuracy: 0.212646484375\n",
      "Batch No.: 58, Loss: 2.993900775909424, Accuracy: 0.23876953125\n",
      "Batch No.: 59, Loss: 3.015880584716797, Accuracy: 0.21630859375\n",
      "Batch No.: 60, Loss: 3.0580344200134277, Accuracy: 0.214111328125\n",
      "Batch No.: 61, Loss: 3.0478615760803223, Accuracy: 0.22021484375\n",
      "Batch No.: 62, Loss: 3.029853582382202, Accuracy: 0.21484375\n",
      "Batch No.: 63, Loss: 3.052371025085449, Accuracy: 0.212646484375\n",
      "Batch No.: 64, Loss: 3.0512495040893555, Accuracy: 0.212158203125\n",
      "Batch No.: 65, Loss: 3.0376315116882324, Accuracy: 0.223876953125\n",
      "Batch No.: 66, Loss: 3.0458717346191406, Accuracy: 0.223876953125\n",
      "Batch No.: 67, Loss: 3.0303878784179688, Accuracy: 0.22216796875\n",
      "Batch No.: 68, Loss: 3.0264859199523926, Accuracy: 0.223388671875\n",
      "Batch No.: 69, Loss: 2.97104811668396, Accuracy: 0.234619140625\n",
      "Batch No.: 70, Loss: 3.0141959190368652, Accuracy: 0.218994140625\n",
      "Batch No.: 71, Loss: 3.0660946369171143, Accuracy: 0.204345703125\n",
      "Batch No.: 72, Loss: 3.063016414642334, Accuracy: 0.216064453125\n",
      "Batch No.: 73, Loss: 3.0152242183685303, Accuracy: 0.218505859375\n",
      "Batch No.: 74, Loss: 3.008255958557129, Accuracy: 0.223388671875\n",
      "Batch No.: 75, Loss: 2.97450590133667, Accuracy: 0.243408203125\n",
      "Batch No.: 76, Loss: 2.9282209873199463, Accuracy: 0.23193359375\n",
      "Batch No.: 77, Loss: 2.9873874187469482, Accuracy: 0.23681640625\n",
      "Batch No.: 78, Loss: 2.952638626098633, Accuracy: 0.236083984375\n",
      "Batch No.: 79, Loss: 2.969937801361084, Accuracy: 0.224609375\n",
      "Batch No.: 80, Loss: 2.972301959991455, Accuracy: 0.2265625\n",
      "Batch No.: 81, Loss: 2.9646620750427246, Accuracy: 0.233154296875\n",
      "Batch No.: 82, Loss: 2.931175708770752, Accuracy: 0.236328125\n",
      "Batch No.: 83, Loss: 2.952411651611328, Accuracy: 0.223388671875\n",
      "Batch No.: 84, Loss: 2.952340602874756, Accuracy: 0.22607421875\n",
      "Batch No.: 85, Loss: 3.0187935829162598, Accuracy: 0.226318359375\n",
      "Batch No.: 86, Loss: 2.9716196060180664, Accuracy: 0.22998046875\n",
      "Batch No.: 87, Loss: 2.821715831756592, Accuracy: 0.262939453125\n",
      "Batch No.: 88, Loss: 2.895322561264038, Accuracy: 0.2529296875\n",
      "Batch No.: 89, Loss: 2.909031867980957, Accuracy: 0.23486328125\n",
      "Batch No.: 90, Loss: 2.8297314643859863, Accuracy: 0.267333984375\n",
      "Batch No.: 91, Loss: 2.881117343902588, Accuracy: 0.239501953125\n",
      "Batch No.: 92, Loss: 2.941713333129883, Accuracy: 0.2333984375\n",
      "Batch No.: 93, Loss: 2.893935441970825, Accuracy: 0.26123046875\n",
      "Batch No.: 94, Loss: 2.9371964931488037, Accuracy: 0.254150390625\n",
      "Batch No.: 95, Loss: 2.967747688293457, Accuracy: 0.2392578125\n",
      "Batch No.: 96, Loss: 2.9109010696411133, Accuracy: 0.2578125\n",
      "Batch No.: 97, Loss: 2.912735939025879, Accuracy: 0.256103515625\n",
      "Batch No.: 98, Loss: 2.900550127029419, Accuracy: 0.24267578125\n",
      "Batch No.: 99, Loss: 2.897233009338379, Accuracy: 0.260009765625\n",
      "Batch No.: 100, Loss: 2.9751498699188232, Accuracy: 0.240478515625\n",
      "Batch No.: 101, Loss: 2.9891998767852783, Accuracy: 0.227783203125\n",
      "Batch No.: 102, Loss: 2.869762420654297, Accuracy: 0.243408203125\n",
      "Batch No.: 103, Loss: 2.924583911895752, Accuracy: 0.2509765625\n",
      "Batch No.: 104, Loss: 2.9195990562438965, Accuracy: 0.2490234375\n",
      "Batch No.: 105, Loss: 2.861780881881714, Accuracy: 0.254150390625\n",
      "Batch No.: 106, Loss: 2.96183443069458, Accuracy: 0.222900390625\n",
      "Batch No.: 107, Loss: 2.876055955886841, Accuracy: 0.2607421875\n",
      "Batch No.: 108, Loss: 2.8649120330810547, Accuracy: 0.2392578125\n",
      "Batch No.: 109, Loss: 2.889498710632324, Accuracy: 0.24169921875\n",
      "Batch No.: 110, Loss: 2.8798105716705322, Accuracy: 0.24755859375\n",
      "Batch No.: 111, Loss: 2.832289695739746, Accuracy: 0.25927734375\n",
      "Batch No.: 112, Loss: 2.8970422744750977, Accuracy: 0.247802734375\n",
      "Batch No.: 113, Loss: 2.923053741455078, Accuracy: 0.235595703125\n",
      "Batch No.: 114, Loss: 2.9940600395202637, Accuracy: 0.232177734375\n",
      "Batch No.: 115, Loss: 2.948543071746826, Accuracy: 0.23583984375\n",
      "Batch No.: 116, Loss: 2.8318915367126465, Accuracy: 0.27099609375\n",
      "Batch No.: 117, Loss: 2.827383041381836, Accuracy: 0.2724609375\n",
      "Batch No.: 118, Loss: 2.8290047645568848, Accuracy: 0.257080078125\n",
      "Batch No.: 119, Loss: 2.839012622833252, Accuracy: 0.26611328125\n",
      "Batch No.: 120, Loss: 2.8413712978363037, Accuracy: 0.25634765625\n",
      "Batch No.: 121, Loss: 2.869962692260742, Accuracy: 0.247802734375\n",
      "Batch No.: 122, Loss: 2.8485159873962402, Accuracy: 0.25390625\n",
      "Batch No.: 123, Loss: 2.9172613620758057, Accuracy: 0.249267578125\n",
      "Batch No.: 124, Loss: 2.8730244636535645, Accuracy: 0.259521484375\n",
      "Batch No.: 125, Loss: 2.89560604095459, Accuracy: 0.25146484375\n",
      "Batch No.: 126, Loss: 2.866032600402832, Accuracy: 0.268798828125\n",
      "Batch No.: 127, Loss: 2.9133105278015137, Accuracy: 0.2392578125\n",
      "Batch No.: 128, Loss: 2.893221139907837, Accuracy: 0.25146484375\n",
      "Batch No.: 129, Loss: 2.9314985275268555, Accuracy: 0.250244140625\n",
      "Batch No.: 130, Loss: 2.9954471588134766, Accuracy: 0.232177734375\n",
      "Batch No.: 131, Loss: 2.866445541381836, Accuracy: 0.23974609375\n",
      "Batch No.: 132, Loss: 2.8852570056915283, Accuracy: 0.2412109375\n",
      "Batch No.: 133, Loss: 2.9703564643859863, Accuracy: 0.244140625\n",
      "Batch No.: 134, Loss: 2.8941543102264404, Accuracy: 0.263427734375\n",
      "Batch No.: 135, Loss: 2.7791714668273926, Accuracy: 0.269287109375\n",
      "Batch No.: 136, Loss: 2.8249990940093994, Accuracy: 0.260009765625\n",
      "Batch No.: 137, Loss: 2.9090652465820312, Accuracy: 0.247802734375\n",
      "Batch No.: 138, Loss: 2.801370143890381, Accuracy: 0.2607421875\n",
      "Batch No.: 139, Loss: 2.8581900596618652, Accuracy: 0.255859375\n",
      "Batch No.: 140, Loss: 2.7905917167663574, Accuracy: 0.26806640625\n",
      "Batch No.: 141, Loss: 2.9002881050109863, Accuracy: 0.26953125\n",
      "Batch No.: 142, Loss: 2.9379687309265137, Accuracy: 0.23388671875\n",
      "Batch No.: 143, Loss: 2.8819420337677, Accuracy: 0.26171875\n",
      "Batch No.: 144, Loss: 2.82991361618042, Accuracy: 0.280029296875\n",
      "Batch No.: 145, Loss: 2.7661423683166504, Accuracy: 0.2978515625\n",
      "Batch No.: 146, Loss: 2.756382465362549, Accuracy: 0.288330078125\n",
      "Batch No.: 147, Loss: 2.708822727203369, Accuracy: 0.2958984375\n",
      "Batch No.: 148, Loss: 2.8120789527893066, Accuracy: 0.279296875\n",
      "Batch No.: 149, Loss: 2.748725414276123, Accuracy: 0.286376953125\n",
      "Batch No.: 150, Loss: 2.694091796875, Accuracy: 0.290283203125\n",
      "Batch No.: 151, Loss: 2.772336721420288, Accuracy: 0.2900390625\n",
      "Batch No.: 152, Loss: 2.7649803161621094, Accuracy: 0.277587890625\n",
      "Batch No.: 153, Loss: 2.7849254608154297, Accuracy: 0.2763671875\n",
      "Batch No.: 154, Loss: 2.693732261657715, Accuracy: 0.298583984375\n",
      "Batch No.: 155, Loss: 2.6745643615722656, Accuracy: 0.31298828125\n",
      "Batch No.: 156, Loss: 2.754584789276123, Accuracy: 0.2880859375\n",
      "Batch No.: 157, Loss: 2.6844911575317383, Accuracy: 0.296142578125\n",
      "Batch No.: 158, Loss: 2.7240281105041504, Accuracy: 0.2919921875\n",
      "Batch No.: 159, Loss: 2.7685327529907227, Accuracy: 0.281005859375\n",
      "Batch No.: 160, Loss: 2.6994423866271973, Accuracy: 0.294921875\n",
      "Batch No.: 161, Loss: 2.737053632736206, Accuracy: 0.289306640625\n",
      "Batch No.: 162, Loss: 2.800386905670166, Accuracy: 0.272216796875\n",
      "Batch No.: 163, Loss: 2.725921154022217, Accuracy: 0.2978515625\n",
      "Batch No.: 164, Loss: 2.6649835109710693, Accuracy: 0.300537109375\n",
      "Batch No.: 165, Loss: 2.688011407852173, Accuracy: 0.314453125\n",
      "Batch No.: 166, Loss: 2.7301807403564453, Accuracy: 0.2998046875\n",
      "Batch No.: 167, Loss: 2.6983838081359863, Accuracy: 0.300048828125\n",
      "Batch No.: 168, Loss: 2.706613302230835, Accuracy: 0.29931640625\n",
      "Batch No.: 169, Loss: 2.707904100418091, Accuracy: 0.297119140625\n",
      "Batch No.: 170, Loss: 2.6752607822418213, Accuracy: 0.30517578125\n",
      "Batch No.: 171, Loss: 2.755788803100586, Accuracy: 0.302734375\n",
      "Batch No.: 172, Loss: 2.7259976863861084, Accuracy: 0.29345703125\n",
      "Batch No.: 173, Loss: 2.625580072402954, Accuracy: 0.31396484375\n",
      "Batch No.: 174, Loss: 2.679337978363037, Accuracy: 0.316650390625\n",
      "Batch No.: 175, Loss: 2.6491754055023193, Accuracy: 0.31005859375\n",
      "Batch No.: 176, Loss: 2.660938262939453, Accuracy: 0.3056640625\n",
      "Batch No.: 177, Loss: 2.7081990242004395, Accuracy: 0.309814453125\n",
      "Batch No.: 178, Loss: 2.699251174926758, Accuracy: 0.30517578125\n",
      "Batch No.: 179, Loss: 2.621335983276367, Accuracy: 0.32958984375\n",
      "Batch No.: 180, Loss: 2.6544318199157715, Accuracy: 0.310791015625\n",
      "Batch No.: 181, Loss: 2.611668348312378, Accuracy: 0.322021484375\n",
      "Batch No.: 182, Loss: 2.626296043395996, Accuracy: 0.31201171875\n",
      "Batch No.: 183, Loss: 2.6270298957824707, Accuracy: 0.31884765625\n",
      "Batch No.: 184, Loss: 2.6243340969085693, Accuracy: 0.311767578125\n",
      "Batch No.: 185, Loss: 2.6225991249084473, Accuracy: 0.31982421875\n",
      "Batch No.: 186, Loss: 2.6206231117248535, Accuracy: 0.30810546875\n",
      "Batch No.: 187, Loss: 2.580875873565674, Accuracy: 0.32470703125\n",
      "Batch No.: 188, Loss: 2.7070233821868896, Accuracy: 0.303466796875\n",
      "Batch No.: 189, Loss: 2.634500503540039, Accuracy: 0.322998046875\n",
      "Batch No.: 190, Loss: 2.655327320098877, Accuracy: 0.29541015625\n",
      "Batch No.: 191, Loss: 2.602571964263916, Accuracy: 0.325927734375\n",
      "Batch No.: 192, Loss: 2.5493736267089844, Accuracy: 0.338623046875\n",
      "Batch No.: 193, Loss: 2.4770760536193848, Accuracy: 0.334716796875\n",
      "Batch No.: 194, Loss: 2.5234267711639404, Accuracy: 0.342041015625\n",
      "Batch No.: 195, Loss: 2.5250046253204346, Accuracy: 0.3505859375\n",
      "Batch No.: 196, Loss: 2.5278728008270264, Accuracy: 0.33544921875\n",
      "Batch No.: 197, Loss: 2.533177137374878, Accuracy: 0.334716796875\n",
      "Batch No.: 198, Loss: 2.5309739112854004, Accuracy: 0.347900390625\n",
      "Batch No.: 199, Loss: 2.552361011505127, Accuracy: 0.333984375\n",
      "Batch No.: 200, Loss: 2.544663906097412, Accuracy: 0.341796875\n",
      "Batch No.: 201, Loss: 2.5396676063537598, Accuracy: 0.352294921875\n",
      "Batch No.: 202, Loss: 2.57401180267334, Accuracy: 0.31689453125\n",
      "Batch No.: 203, Loss: 2.5378174781799316, Accuracy: 0.336181640625\n",
      "Batch No.: 204, Loss: 2.4590609073638916, Accuracy: 0.35693359375\n",
      "Batch No.: 205, Loss: 2.5488433837890625, Accuracy: 0.335693359375\n",
      "Batch No.: 206, Loss: 2.5740456581115723, Accuracy: 0.332763671875\n",
      "Batch No.: 207, Loss: 2.519253730773926, Accuracy: 0.34814453125\n",
      "Batch No.: 208, Loss: 2.57098388671875, Accuracy: 0.331787109375\n",
      "Batch No.: 209, Loss: 2.531337022781372, Accuracy: 0.347412109375\n",
      "Batch No.: 210, Loss: 2.5946178436279297, Accuracy: 0.33251953125\n",
      "Batch No.: 211, Loss: 2.5231471061706543, Accuracy: 0.34228515625\n",
      "Batch No.: 212, Loss: 2.5666723251342773, Accuracy: 0.346923828125\n",
      "Batch No.: 213, Loss: 2.4946508407592773, Accuracy: 0.349609375\n",
      "Batch No.: 214, Loss: 2.5052990913391113, Accuracy: 0.3427734375\n",
      "Batch No.: 215, Loss: 2.513705015182495, Accuracy: 0.349365234375\n",
      "Batch No.: 216, Loss: 2.508880615234375, Accuracy: 0.3466796875\n",
      "Batch No.: 217, Loss: 2.5823934078216553, Accuracy: 0.331787109375\n",
      "Batch No.: 218, Loss: 2.555896282196045, Accuracy: 0.334228515625\n",
      "Batch No.: 219, Loss: 2.5168581008911133, Accuracy: 0.348388671875\n",
      "Batch No.: 220, Loss: 2.5483555793762207, Accuracy: 0.338623046875\n",
      "Batch No.: 221, Loss: 2.539207696914673, Accuracy: 0.347900390625\n",
      "Batch No.: 222, Loss: 2.432220458984375, Accuracy: 0.367431640625\n",
      "Batch No.: 223, Loss: 2.4260120391845703, Accuracy: 0.376220703125\n",
      "Batch No.: 224, Loss: 2.4610824584960938, Accuracy: 0.3642578125\n",
      "Batch No.: 225, Loss: 2.4403584003448486, Accuracy: 0.35498046875\n",
      "Batch No.: 226, Loss: 2.3788390159606934, Accuracy: 0.3818359375\n",
      "Batch No.: 227, Loss: 2.416041851043701, Accuracy: 0.37353515625\n",
      "Batch No.: 228, Loss: 2.466585636138916, Accuracy: 0.361083984375\n",
      "Batch No.: 229, Loss: 2.4304537773132324, Accuracy: 0.35888671875\n",
      "Batch No.: 230, Loss: 2.505586624145508, Accuracy: 0.34521484375\n",
      "Batch No.: 231, Loss: 2.4945390224456787, Accuracy: 0.341796875\n",
      "Batch No.: 232, Loss: 2.5154709815979004, Accuracy: 0.34326171875\n",
      "Batch No.: 233, Loss: 2.3742308616638184, Accuracy: 0.373046875\n",
      "Batch No.: 234, Loss: 2.4770822525024414, Accuracy: 0.347412109375\n",
      "Batch No.: 235, Loss: 2.5596461296081543, Accuracy: 0.347900390625\n",
      "Batch No.: 236, Loss: 2.3879237174987793, Accuracy: 0.37158203125\n",
      "Batch No.: 237, Loss: 2.496804714202881, Accuracy: 0.34619140625\n",
      "Batch No.: 238, Loss: 2.51188325881958, Accuracy: 0.349365234375\n",
      "Batch No.: 239, Loss: 2.435311794281006, Accuracy: 0.369140625\n",
      "Batch No.: 240, Loss: 2.4250240325927734, Accuracy: 0.365478515625\n",
      "Batch No.: 241, Loss: 2.454777956008911, Accuracy: 0.365234375\n",
      "Batch No.: 242, Loss: 2.388127565383911, Accuracy: 0.3720703125\n",
      "Batch No.: 243, Loss: 2.4669432640075684, Accuracy: 0.350341796875\n",
      "Batch No.: 244, Loss: 2.471689224243164, Accuracy: 0.345458984375\n",
      "Batch No.: 245, Loss: 2.407090663909912, Accuracy: 0.35986328125\n",
      "Batch No.: 246, Loss: 2.4430997371673584, Accuracy: 0.34765625\n",
      "Batch No.: 247, Loss: 2.406555414199829, Accuracy: 0.368896484375\n",
      "Batch No.: 248, Loss: 2.40445613861084, Accuracy: 0.368896484375\n",
      "Batch No.: 249, Loss: 2.4689860343933105, Accuracy: 0.36083984375\n",
      "Batch No.: 250, Loss: 2.39280366897583, Accuracy: 0.377197265625\n",
      "Batch No.: 251, Loss: 2.3670010566711426, Accuracy: 0.373779296875\n",
      "Batch No.: 252, Loss: 2.341524124145508, Accuracy: 0.390869140625\n",
      "Batch No.: 253, Loss: 2.348193645477295, Accuracy: 0.383056640625\n",
      "Batch No.: 254, Loss: 2.3529553413391113, Accuracy: 0.3798828125\n",
      "Batch No.: 255, Loss: 2.384371757507324, Accuracy: 0.385009765625\n",
      "Batch No.: 256, Loss: 2.353688955307007, Accuracy: 0.400634765625\n",
      "Batch No.: 257, Loss: 2.349928140640259, Accuracy: 0.380859375\n",
      "Batch No.: 258, Loss: 2.414397716522217, Accuracy: 0.371337890625\n",
      "Batch No.: 259, Loss: 2.3708584308624268, Accuracy: 0.372314453125\n",
      "Batch No.: 260, Loss: 2.4168436527252197, Accuracy: 0.351318359375\n",
      "Batch No.: 261, Loss: 2.4146008491516113, Accuracy: 0.357421875\n",
      "Batch No.: 262, Loss: 2.3425228595733643, Accuracy: 0.366943359375\n",
      "Batch No.: 263, Loss: 2.45975399017334, Accuracy: 0.351806640625\n",
      "Batch No.: 264, Loss: 2.3749380111694336, Accuracy: 0.38330078125\n",
      "Epoch 3/80\n",
      "Batch No.: 1, Loss: 2.490546941757202, Accuracy: 0.35546875\n",
      "Batch No.: 2, Loss: 2.399911880493164, Accuracy: 0.365966796875\n",
      "Batch No.: 3, Loss: 2.3437390327453613, Accuracy: 0.373291015625\n",
      "Batch No.: 4, Loss: 2.3028595447540283, Accuracy: 0.38671875\n",
      "Batch No.: 5, Loss: 2.376615047454834, Accuracy: 0.365478515625\n",
      "Batch No.: 6, Loss: 2.4400744438171387, Accuracy: 0.360107421875\n",
      "Batch No.: 7, Loss: 2.3410041332244873, Accuracy: 0.380615234375\n",
      "Batch No.: 8, Loss: 2.413633108139038, Accuracy: 0.36474609375\n",
      "Batch No.: 9, Loss: 2.362321376800537, Accuracy: 0.387939453125\n",
      "Batch No.: 10, Loss: 2.3596043586730957, Accuracy: 0.369384765625\n",
      "Batch No.: 11, Loss: 2.278684616088867, Accuracy: 0.407470703125\n",
      "Batch No.: 12, Loss: 2.3795371055603027, Accuracy: 0.38232421875\n",
      "Batch No.: 13, Loss: 2.346466541290283, Accuracy: 0.37939453125\n",
      "Batch No.: 14, Loss: 2.348937749862671, Accuracy: 0.36865234375\n",
      "Batch No.: 15, Loss: 2.394930839538574, Accuracy: 0.369873046875\n",
      "Batch No.: 16, Loss: 2.272312879562378, Accuracy: 0.402099609375\n",
      "Batch No.: 17, Loss: 2.375784397125244, Accuracy: 0.36279296875\n",
      "Batch No.: 18, Loss: 2.3942949771881104, Accuracy: 0.362060546875\n",
      "Batch No.: 19, Loss: 2.320023775100708, Accuracy: 0.3916015625\n",
      "Batch No.: 20, Loss: 2.3978514671325684, Accuracy: 0.362548828125\n",
      "Batch No.: 21, Loss: 2.369302749633789, Accuracy: 0.366455078125\n",
      "Batch No.: 22, Loss: 2.3449127674102783, Accuracy: 0.390869140625\n",
      "Batch No.: 23, Loss: 2.3548178672790527, Accuracy: 0.376220703125\n",
      "Batch No.: 24, Loss: 2.3858389854431152, Accuracy: 0.3603515625\n",
      "Batch No.: 25, Loss: 2.409994602203369, Accuracy: 0.36474609375\n",
      "Batch No.: 26, Loss: 2.311755895614624, Accuracy: 0.38232421875\n",
      "Batch No.: 27, Loss: 2.357896566390991, Accuracy: 0.374755859375\n",
      "Batch No.: 28, Loss: 2.339388370513916, Accuracy: 0.386474609375\n",
      "Batch No.: 29, Loss: 2.3215880393981934, Accuracy: 0.38330078125\n",
      "Batch No.: 30, Loss: 2.3168625831604004, Accuracy: 0.376953125\n",
      "Batch No.: 31, Loss: 2.3476617336273193, Accuracy: 0.378662109375\n",
      "Batch No.: 32, Loss: 2.308591842651367, Accuracy: 0.396240234375\n",
      "Batch No.: 33, Loss: 2.256646156311035, Accuracy: 0.3974609375\n",
      "Batch No.: 34, Loss: 2.3154191970825195, Accuracy: 0.37451171875\n",
      "Batch No.: 35, Loss: 2.2377102375030518, Accuracy: 0.41552734375\n",
      "Batch No.: 36, Loss: 2.3088579177856445, Accuracy: 0.385498046875\n",
      "Batch No.: 37, Loss: 2.283777952194214, Accuracy: 0.384521484375\n",
      "Batch No.: 38, Loss: 2.3341431617736816, Accuracy: 0.392333984375\n",
      "Batch No.: 39, Loss: 2.244126796722412, Accuracy: 0.40625\n",
      "Batch No.: 40, Loss: 2.217498779296875, Accuracy: 0.4091796875\n",
      "Batch No.: 41, Loss: 2.2620716094970703, Accuracy: 0.398193359375\n",
      "Batch No.: 42, Loss: 2.2378387451171875, Accuracy: 0.406982421875\n",
      "Batch No.: 43, Loss: 2.2535343170166016, Accuracy: 0.41064453125\n",
      "Batch No.: 44, Loss: 2.313222885131836, Accuracy: 0.379150390625\n",
      "Batch No.: 45, Loss: 2.1827168464660645, Accuracy: 0.4208984375\n",
      "Batch No.: 46, Loss: 2.242934226989746, Accuracy: 0.4033203125\n",
      "Batch No.: 47, Loss: 2.2505412101745605, Accuracy: 0.39453125\n",
      "Batch No.: 48, Loss: 2.3096301555633545, Accuracy: 0.388671875\n",
      "Batch No.: 49, Loss: 2.1693320274353027, Accuracy: 0.418212890625\n",
      "Batch No.: 50, Loss: 2.29118013381958, Accuracy: 0.386962890625\n",
      "Batch No.: 51, Loss: 2.300112724304199, Accuracy: 0.38720703125\n",
      "Batch No.: 52, Loss: 2.254864454269409, Accuracy: 0.392333984375\n",
      "Batch No.: 53, Loss: 2.2723891735076904, Accuracy: 0.38916015625\n",
      "Batch No.: 54, Loss: 2.3084449768066406, Accuracy: 0.38818359375\n",
      "Batch No.: 55, Loss: 2.2766642570495605, Accuracy: 0.39404296875\n",
      "Batch No.: 56, Loss: 2.231557607650757, Accuracy: 0.420166015625\n",
      "Batch No.: 57, Loss: 2.265714406967163, Accuracy: 0.393798828125\n",
      "Batch No.: 58, Loss: 2.18259334564209, Accuracy: 0.3994140625\n",
      "Batch No.: 59, Loss: 2.165250778198242, Accuracy: 0.416259765625\n",
      "Batch No.: 60, Loss: 2.253915309906006, Accuracy: 0.398193359375\n",
      "Batch No.: 61, Loss: 2.2553510665893555, Accuracy: 0.394775390625\n",
      "Batch No.: 62, Loss: 2.2115838527679443, Accuracy: 0.412353515625\n",
      "Batch No.: 63, Loss: 2.233311891555786, Accuracy: 0.4033203125\n",
      "Batch No.: 64, Loss: 2.245044469833374, Accuracy: 0.40087890625\n",
      "Batch No.: 65, Loss: 2.230372905731201, Accuracy: 0.409423828125\n",
      "Batch No.: 66, Loss: 2.2248687744140625, Accuracy: 0.4140625\n",
      "Batch No.: 67, Loss: 2.1678013801574707, Accuracy: 0.426025390625\n",
      "Batch No.: 68, Loss: 2.291752576828003, Accuracy: 0.37744140625\n",
      "Batch No.: 69, Loss: 2.1425442695617676, Accuracy: 0.42822265625\n",
      "Batch No.: 70, Loss: 2.1519999504089355, Accuracy: 0.41796875\n",
      "Batch No.: 71, Loss: 2.2485995292663574, Accuracy: 0.39794921875\n",
      "Batch No.: 72, Loss: 2.240022659301758, Accuracy: 0.40380859375\n",
      "Batch No.: 73, Loss: 2.3294248580932617, Accuracy: 0.37939453125\n",
      "Batch No.: 74, Loss: 2.1635167598724365, Accuracy: 0.435546875\n",
      "Batch No.: 75, Loss: 2.2108869552612305, Accuracy: 0.41552734375\n",
      "Batch No.: 76, Loss: 2.130544662475586, Accuracy: 0.426025390625\n",
      "Batch No.: 77, Loss: 2.220473289489746, Accuracy: 0.412109375\n",
      "Batch No.: 78, Loss: 2.1048481464385986, Accuracy: 0.432373046875\n",
      "Batch No.: 79, Loss: 2.1812305450439453, Accuracy: 0.415771484375\n",
      "Batch No.: 80, Loss: 2.204061508178711, Accuracy: 0.4140625\n",
      "Batch No.: 81, Loss: 2.2007908821105957, Accuracy: 0.405517578125\n",
      "Batch No.: 82, Loss: 2.143270492553711, Accuracy: 0.417724609375\n",
      "Batch No.: 83, Loss: 2.1338186264038086, Accuracy: 0.420654296875\n",
      "Batch No.: 84, Loss: 2.2517027854919434, Accuracy: 0.384765625\n",
      "Batch No.: 85, Loss: 2.20941424369812, Accuracy: 0.4189453125\n",
      "Batch No.: 86, Loss: 2.112335681915283, Accuracy: 0.43310546875\n",
      "Batch No.: 87, Loss: 2.1358730792999268, Accuracy: 0.413818359375\n",
      "Batch No.: 88, Loss: 2.158470869064331, Accuracy: 0.430419921875\n",
      "Batch No.: 89, Loss: 2.102558135986328, Accuracy: 0.42529296875\n",
      "Batch No.: 90, Loss: 2.0740270614624023, Accuracy: 0.449462890625\n",
      "Batch No.: 91, Loss: 2.0662999153137207, Accuracy: 0.4423828125\n",
      "Batch No.: 92, Loss: 2.197730779647827, Accuracy: 0.405517578125\n",
      "Batch No.: 93, Loss: 2.119114875793457, Accuracy: 0.445556640625\n",
      "Batch No.: 94, Loss: 2.1536173820495605, Accuracy: 0.429931640625\n",
      "Batch No.: 95, Loss: 2.2222115993499756, Accuracy: 0.406005859375\n",
      "Batch No.: 96, Loss: 2.1605310440063477, Accuracy: 0.423095703125\n",
      "Batch No.: 97, Loss: 2.179403066635132, Accuracy: 0.41943359375\n",
      "Batch No.: 98, Loss: 2.1276025772094727, Accuracy: 0.431396484375\n",
      "Batch No.: 99, Loss: 2.1647958755493164, Accuracy: 0.421630859375\n",
      "Batch No.: 100, Loss: 2.2185888290405273, Accuracy: 0.408203125\n",
      "Batch No.: 101, Loss: 2.197237014770508, Accuracy: 0.42724609375\n",
      "Batch No.: 102, Loss: 2.230245351791382, Accuracy: 0.3916015625\n",
      "Batch No.: 103, Loss: 2.1523799896240234, Accuracy: 0.424072265625\n",
      "Batch No.: 104, Loss: 2.1820998191833496, Accuracy: 0.427001953125\n",
      "Batch No.: 105, Loss: 2.111332416534424, Accuracy: 0.440673828125\n",
      "Batch No.: 106, Loss: 2.187617301940918, Accuracy: 0.413818359375\n",
      "Batch No.: 107, Loss: 2.135296106338501, Accuracy: 0.42529296875\n",
      "Batch No.: 108, Loss: 2.124955892562866, Accuracy: 0.428466796875\n",
      "Batch No.: 109, Loss: 2.15205454826355, Accuracy: 0.42822265625\n",
      "Batch No.: 110, Loss: 2.1142325401306152, Accuracy: 0.431396484375\n",
      "Batch No.: 111, Loss: 2.1031911373138428, Accuracy: 0.427734375\n",
      "Batch No.: 112, Loss: 2.0779201984405518, Accuracy: 0.451904296875\n",
      "Batch No.: 113, Loss: 2.179840564727783, Accuracy: 0.410400390625\n",
      "Batch No.: 114, Loss: 2.2543892860412598, Accuracy: 0.404052734375\n",
      "Batch No.: 115, Loss: 2.1160755157470703, Accuracy: 0.43798828125\n",
      "Batch No.: 116, Loss: 2.147437572479248, Accuracy: 0.426025390625\n",
      "Batch No.: 117, Loss: 2.0408194065093994, Accuracy: 0.45703125\n",
      "Batch No.: 118, Loss: 2.0958216190338135, Accuracy: 0.4384765625\n",
      "Batch No.: 119, Loss: 2.054013252258301, Accuracy: 0.44775390625\n",
      "Batch No.: 120, Loss: 2.1029984951019287, Accuracy: 0.4345703125\n",
      "Batch No.: 121, Loss: 2.1285061836242676, Accuracy: 0.427490234375\n",
      "Batch No.: 122, Loss: 2.100883722305298, Accuracy: 0.434326171875\n",
      "Batch No.: 123, Loss: 2.2236108779907227, Accuracy: 0.41015625\n",
      "Batch No.: 124, Loss: 2.1261954307556152, Accuracy: 0.432373046875\n",
      "Batch No.: 125, Loss: 2.1866395473480225, Accuracy: 0.41162109375\n",
      "Batch No.: 126, Loss: 2.06904935836792, Accuracy: 0.45654296875\n",
      "Batch No.: 127, Loss: 2.081526279449463, Accuracy: 0.445556640625\n",
      "Batch No.: 128, Loss: 2.1362838745117188, Accuracy: 0.428955078125\n",
      "Batch No.: 129, Loss: 2.229301929473877, Accuracy: 0.40625\n",
      "Batch No.: 130, Loss: 2.0732126235961914, Accuracy: 0.468505859375\n",
      "Batch No.: 131, Loss: 2.2219326496124268, Accuracy: 0.403076171875\n",
      "Batch No.: 132, Loss: 2.2164688110351562, Accuracy: 0.404541015625\n",
      "Batch No.: 133, Loss: 2.085226058959961, Accuracy: 0.46142578125\n",
      "Batch No.: 134, Loss: 2.062285900115967, Accuracy: 0.4609375\n",
      "Batch No.: 135, Loss: 2.1159000396728516, Accuracy: 0.428466796875\n",
      "Batch No.: 136, Loss: 2.0051350593566895, Accuracy: 0.4697265625\n",
      "Batch No.: 137, Loss: 2.1137070655822754, Accuracy: 0.442138671875\n",
      "Batch No.: 138, Loss: 2.1140198707580566, Accuracy: 0.4306640625\n",
      "Batch No.: 139, Loss: 2.1210174560546875, Accuracy: 0.434814453125\n",
      "Batch No.: 140, Loss: 2.032606840133667, Accuracy: 0.454345703125\n",
      "Batch No.: 141, Loss: 2.123213291168213, Accuracy: 0.44580078125\n",
      "Batch No.: 142, Loss: 2.1266345977783203, Accuracy: 0.446044921875\n",
      "Batch No.: 143, Loss: 2.07621431350708, Accuracy: 0.456298828125\n",
      "Batch No.: 144, Loss: 2.0987069606781006, Accuracy: 0.431884765625\n",
      "Batch No.: 145, Loss: 1.9991693496704102, Accuracy: 0.466796875\n",
      "Batch No.: 146, Loss: 1.972023367881775, Accuracy: 0.482177734375\n",
      "Batch No.: 147, Loss: 1.9647457599639893, Accuracy: 0.4697265625\n",
      "Batch No.: 148, Loss: 1.9966152906417847, Accuracy: 0.479736328125\n",
      "Batch No.: 149, Loss: 1.9950685501098633, Accuracy: 0.462646484375\n",
      "Batch No.: 150, Loss: 2.066591739654541, Accuracy: 0.44287109375\n",
      "Batch No.: 151, Loss: 2.0008838176727295, Accuracy: 0.470947265625\n",
      "Batch No.: 152, Loss: 1.9936116933822632, Accuracy: 0.46923828125\n",
      "Batch No.: 153, Loss: 2.0637335777282715, Accuracy: 0.447021484375\n",
      "Batch No.: 154, Loss: 1.9861030578613281, Accuracy: 0.462890625\n",
      "Batch No.: 155, Loss: 1.8633108139038086, Accuracy: 0.501953125\n",
      "Batch No.: 156, Loss: 2.054553985595703, Accuracy: 0.450439453125\n",
      "Batch No.: 157, Loss: 1.9429091215133667, Accuracy: 0.477783203125\n",
      "Batch No.: 158, Loss: 2.020211696624756, Accuracy: 0.4580078125\n",
      "Batch No.: 159, Loss: 2.0208425521850586, Accuracy: 0.460693359375\n",
      "Batch No.: 160, Loss: 2.0362966060638428, Accuracy: 0.453125\n",
      "Batch No.: 161, Loss: 2.0470852851867676, Accuracy: 0.449462890625\n",
      "Batch No.: 162, Loss: 2.0807604789733887, Accuracy: 0.454345703125\n",
      "Batch No.: 163, Loss: 1.997342586517334, Accuracy: 0.468505859375\n",
      "Batch No.: 164, Loss: 2.0217537879943848, Accuracy: 0.44189453125\n",
      "Batch No.: 165, Loss: 1.9234641790390015, Accuracy: 0.482177734375\n",
      "Batch No.: 166, Loss: 1.9996893405914307, Accuracy: 0.4677734375\n",
      "Batch No.: 167, Loss: 2.1440842151641846, Accuracy: 0.4267578125\n",
      "Batch No.: 168, Loss: 1.948453664779663, Accuracy: 0.4912109375\n",
      "Batch No.: 169, Loss: 2.015249252319336, Accuracy: 0.467041015625\n",
      "Batch No.: 170, Loss: 2.069322347640991, Accuracy: 0.4462890625\n",
      "Batch No.: 171, Loss: 2.045168399810791, Accuracy: 0.4736328125\n",
      "Batch No.: 172, Loss: 1.973403811454773, Accuracy: 0.4892578125\n",
      "Batch No.: 173, Loss: 2.001314401626587, Accuracy: 0.460693359375\n",
      "Batch No.: 174, Loss: 2.045262336730957, Accuracy: 0.459228515625\n",
      "Batch No.: 175, Loss: 1.8523839712142944, Accuracy: 0.516357421875\n",
      "Batch No.: 176, Loss: 2.008388042449951, Accuracy: 0.458740234375\n",
      "Batch No.: 177, Loss: 1.9981440305709839, Accuracy: 0.474853515625\n",
      "Batch No.: 178, Loss: 1.9504988193511963, Accuracy: 0.486083984375\n",
      "Batch No.: 179, Loss: 2.0137922763824463, Accuracy: 0.46337890625\n",
      "Batch No.: 180, Loss: 1.9610586166381836, Accuracy: 0.4814453125\n",
      "Batch No.: 181, Loss: 1.8974409103393555, Accuracy: 0.50537109375\n",
      "Batch No.: 182, Loss: 1.996105670928955, Accuracy: 0.4609375\n",
      "Batch No.: 183, Loss: 1.9429606199264526, Accuracy: 0.489990234375\n",
      "Batch No.: 184, Loss: 1.945070505142212, Accuracy: 0.486572265625\n",
      "Batch No.: 185, Loss: 2.0086417198181152, Accuracy: 0.4638671875\n",
      "Batch No.: 186, Loss: 1.9056501388549805, Accuracy: 0.4892578125\n",
      "Batch No.: 187, Loss: 1.9068329334259033, Accuracy: 0.487548828125\n",
      "Batch No.: 188, Loss: 2.0771126747131348, Accuracy: 0.44775390625\n",
      "Batch No.: 189, Loss: 1.8996895551681519, Accuracy: 0.49951171875\n",
      "Batch No.: 190, Loss: 2.1077003479003906, Accuracy: 0.43798828125\n",
      "Batch No.: 191, Loss: 1.954456090927124, Accuracy: 0.484375\n",
      "Batch No.: 192, Loss: 1.8011847734451294, Accuracy: 0.53759765625\n",
      "Batch No.: 193, Loss: 1.9473521709442139, Accuracy: 0.468505859375\n",
      "Batch No.: 194, Loss: 1.861975908279419, Accuracy: 0.5009765625\n",
      "Batch No.: 195, Loss: 1.8092436790466309, Accuracy: 0.52001953125\n",
      "Batch No.: 196, Loss: 1.9487354755401611, Accuracy: 0.474365234375\n",
      "Batch No.: 197, Loss: 1.8643341064453125, Accuracy: 0.49755859375\n",
      "Batch No.: 198, Loss: 1.798323631286621, Accuracy: 0.525390625\n",
      "Batch No.: 199, Loss: 1.9976190328598022, Accuracy: 0.466552734375\n",
      "Batch No.: 200, Loss: 1.8594849109649658, Accuracy: 0.5\n",
      "Batch No.: 201, Loss: 1.8759444952011108, Accuracy: 0.505615234375\n",
      "Batch No.: 202, Loss: 1.9398301839828491, Accuracy: 0.482666015625\n",
      "Batch No.: 203, Loss: 1.9056017398834229, Accuracy: 0.49462890625\n",
      "Batch No.: 204, Loss: 1.7943651676177979, Accuracy: 0.5205078125\n",
      "Batch No.: 205, Loss: 1.9620037078857422, Accuracy: 0.46826171875\n",
      "Batch No.: 206, Loss: 1.896733045578003, Accuracy: 0.503173828125\n",
      "Batch No.: 207, Loss: 1.8285117149353027, Accuracy: 0.509765625\n",
      "Batch No.: 208, Loss: 1.9845610857009888, Accuracy: 0.4716796875\n",
      "Batch No.: 209, Loss: 1.9045783281326294, Accuracy: 0.49267578125\n",
      "Batch No.: 210, Loss: 1.9517170190811157, Accuracy: 0.486328125\n",
      "Batch No.: 211, Loss: 1.941360354423523, Accuracy: 0.473876953125\n",
      "Batch No.: 212, Loss: 1.916130781173706, Accuracy: 0.4970703125\n",
      "Batch No.: 213, Loss: 1.8551068305969238, Accuracy: 0.496337890625\n",
      "Batch No.: 214, Loss: 1.9168586730957031, Accuracy: 0.4951171875\n",
      "Batch No.: 215, Loss: 1.9635114669799805, Accuracy: 0.47509765625\n",
      "Batch No.: 216, Loss: 1.8476850986480713, Accuracy: 0.501708984375\n",
      "Batch No.: 217, Loss: 1.889575719833374, Accuracy: 0.483154296875\n",
      "Batch No.: 218, Loss: 1.9856698513031006, Accuracy: 0.467041015625\n",
      "Batch No.: 219, Loss: 1.9453403949737549, Accuracy: 0.47998046875\n",
      "Batch No.: 220, Loss: 1.9571961164474487, Accuracy: 0.47802734375\n",
      "Batch No.: 221, Loss: 1.933715581893921, Accuracy: 0.4814453125\n",
      "Batch No.: 222, Loss: 1.8564807176589966, Accuracy: 0.49951171875\n",
      "Batch No.: 223, Loss: 1.8271808624267578, Accuracy: 0.5078125\n",
      "Batch No.: 224, Loss: 1.8189775943756104, Accuracy: 0.51953125\n",
      "Batch No.: 225, Loss: 1.904007911682129, Accuracy: 0.48046875\n",
      "Batch No.: 226, Loss: 1.7737611532211304, Accuracy: 0.532958984375\n",
      "Batch No.: 227, Loss: 1.806248664855957, Accuracy: 0.51953125\n",
      "Batch No.: 228, Loss: 1.97184157371521, Accuracy: 0.46630859375\n",
      "Batch No.: 229, Loss: 1.8484387397766113, Accuracy: 0.4970703125\n",
      "Batch No.: 230, Loss: 1.8648617267608643, Accuracy: 0.498779296875\n",
      "Batch No.: 231, Loss: 1.9447968006134033, Accuracy: 0.471923828125\n",
      "Batch No.: 232, Loss: 1.9832100868225098, Accuracy: 0.47314453125\n",
      "Batch No.: 233, Loss: 1.7780917882919312, Accuracy: 0.518798828125\n",
      "Batch No.: 234, Loss: 1.9211714267730713, Accuracy: 0.479736328125\n",
      "Batch No.: 235, Loss: 1.9317022562026978, Accuracy: 0.48828125\n",
      "Batch No.: 236, Loss: 1.7606278657913208, Accuracy: 0.52294921875\n",
      "Batch No.: 237, Loss: 1.9894386529922485, Accuracy: 0.463134765625\n",
      "Batch No.: 238, Loss: 1.866064190864563, Accuracy: 0.49853515625\n",
      "Batch No.: 239, Loss: 1.8177490234375, Accuracy: 0.5185546875\n",
      "Batch No.: 240, Loss: 1.909853458404541, Accuracy: 0.478515625\n",
      "Batch No.: 241, Loss: 1.9019640684127808, Accuracy: 0.489990234375\n",
      "Batch No.: 242, Loss: 1.7658817768096924, Accuracy: 0.527587890625\n",
      "Batch No.: 243, Loss: 1.943938136100769, Accuracy: 0.476806640625\n",
      "Batch No.: 244, Loss: 1.9730241298675537, Accuracy: 0.470947265625\n",
      "Batch No.: 245, Loss: 1.7969622611999512, Accuracy: 0.517333984375\n",
      "Batch No.: 246, Loss: 1.8523845672607422, Accuracy: 0.4892578125\n",
      "Batch No.: 247, Loss: 1.8953466415405273, Accuracy: 0.48583984375\n",
      "Batch No.: 248, Loss: 1.828988790512085, Accuracy: 0.502197265625\n",
      "Batch No.: 249, Loss: 1.9513695240020752, Accuracy: 0.4775390625\n",
      "Batch No.: 250, Loss: 1.8808510303497314, Accuracy: 0.489990234375\n",
      "Batch No.: 251, Loss: 1.8518425226211548, Accuracy: 0.488525390625\n",
      "Batch No.: 252, Loss: 1.7517168521881104, Accuracy: 0.5341796875\n",
      "Batch No.: 253, Loss: 1.7896634340286255, Accuracy: 0.513671875\n",
      "Batch No.: 254, Loss: 1.7818845510482788, Accuracy: 0.51806640625\n",
      "Batch No.: 255, Loss: 1.8468825817108154, Accuracy: 0.502197265625\n",
      "Batch No.: 256, Loss: 1.8160827159881592, Accuracy: 0.5283203125\n",
      "Batch No.: 257, Loss: 1.8937733173370361, Accuracy: 0.48583984375\n",
      "Batch No.: 258, Loss: 1.8658125400543213, Accuracy: 0.494384765625\n",
      "Batch No.: 259, Loss: 1.7868276834487915, Accuracy: 0.523193359375\n",
      "Batch No.: 260, Loss: 1.917839527130127, Accuracy: 0.474365234375\n",
      "Batch No.: 261, Loss: 1.932182788848877, Accuracy: 0.4736328125\n",
      "Batch No.: 262, Loss: 1.7528780698776245, Accuracy: 0.523193359375\n",
      "Batch No.: 263, Loss: 1.9476467370986938, Accuracy: 0.4638671875\n",
      "Batch No.: 264, Loss: 1.8015353679656982, Accuracy: 0.516357421875\n",
      "Epoch 4/80\n",
      "Batch No.: 1, Loss: 2.0684332847595215, Accuracy: 0.453369140625\n",
      "Batch No.: 2, Loss: 1.8258607387542725, Accuracy: 0.498046875\n",
      "Batch No.: 3, Loss: 1.796745777130127, Accuracy: 0.493896484375\n",
      "Batch No.: 4, Loss: 1.7796882390975952, Accuracy: 0.5068359375\n",
      "Batch No.: 5, Loss: 1.8377618789672852, Accuracy: 0.491943359375\n",
      "Batch No.: 6, Loss: 1.8530354499816895, Accuracy: 0.4990234375\n",
      "Batch No.: 7, Loss: 1.825770616531372, Accuracy: 0.491455078125\n",
      "Batch No.: 8, Loss: 1.950401782989502, Accuracy: 0.45654296875\n",
      "Batch No.: 9, Loss: 1.6309432983398438, Accuracy: 0.56640625\n",
      "Batch No.: 10, Loss: 1.8665486574172974, Accuracy: 0.480712890625\n",
      "Batch No.: 11, Loss: 1.7871273756027222, Accuracy: 0.5068359375\n",
      "Batch No.: 12, Loss: 1.7508201599121094, Accuracy: 0.531005859375\n",
      "Batch No.: 13, Loss: 1.8299684524536133, Accuracy: 0.503662109375\n",
      "Batch No.: 14, Loss: 1.8522794246673584, Accuracy: 0.49267578125\n",
      "Batch No.: 15, Loss: 1.882129192352295, Accuracy: 0.491455078125\n",
      "Batch No.: 16, Loss: 1.6962387561798096, Accuracy: 0.541015625\n",
      "Batch No.: 17, Loss: 1.8819866180419922, Accuracy: 0.4853515625\n",
      "Batch No.: 18, Loss: 1.8943877220153809, Accuracy: 0.4775390625\n",
      "Batch No.: 19, Loss: 1.7348324060440063, Accuracy: 0.5302734375\n",
      "Batch No.: 20, Loss: 1.8332161903381348, Accuracy: 0.505126953125\n",
      "Batch No.: 21, Loss: 1.8855781555175781, Accuracy: 0.48486328125\n",
      "Batch No.: 22, Loss: 1.7938714027404785, Accuracy: 0.52587890625\n",
      "Batch No.: 23, Loss: 1.7894923686981201, Accuracy: 0.50732421875\n",
      "Batch No.: 24, Loss: 1.9448118209838867, Accuracy: 0.472412109375\n",
      "Batch No.: 25, Loss: 1.9436012506484985, Accuracy: 0.475341796875\n",
      "Batch No.: 26, Loss: 1.7423412799835205, Accuracy: 0.534423828125\n",
      "Batch No.: 27, Loss: 1.864728331565857, Accuracy: 0.483642578125\n",
      "Batch No.: 28, Loss: 1.8169018030166626, Accuracy: 0.4990234375\n",
      "Batch No.: 29, Loss: 1.7553997039794922, Accuracy: 0.52001953125\n",
      "Batch No.: 30, Loss: 1.8943572044372559, Accuracy: 0.4794921875\n",
      "Batch No.: 31, Loss: 1.8421330451965332, Accuracy: 0.4892578125\n",
      "Batch No.: 32, Loss: 1.7292890548706055, Accuracy: 0.5390625\n",
      "Batch No.: 33, Loss: 1.7586994171142578, Accuracy: 0.513916015625\n",
      "Batch No.: 34, Loss: 1.8565573692321777, Accuracy: 0.480712890625\n",
      "Batch No.: 35, Loss: 1.6672366857528687, Accuracy: 0.544677734375\n",
      "Batch No.: 36, Loss: 1.8041696548461914, Accuracy: 0.511962890625\n",
      "Batch No.: 37, Loss: 1.8861982822418213, Accuracy: 0.478271484375\n",
      "Batch No.: 38, Loss: 1.7912709712982178, Accuracy: 0.509521484375\n",
      "Batch No.: 39, Loss: 1.7315467596054077, Accuracy: 0.5244140625\n",
      "Batch No.: 40, Loss: 1.7510356903076172, Accuracy: 0.523681640625\n",
      "Batch No.: 41, Loss: 1.7869012355804443, Accuracy: 0.50732421875\n",
      "Batch No.: 42, Loss: 1.7558274269104004, Accuracy: 0.5234375\n",
      "Batch No.: 43, Loss: 1.7325431108474731, Accuracy: 0.53662109375\n",
      "Batch No.: 44, Loss: 1.8630051612854004, Accuracy: 0.493408203125\n",
      "Batch No.: 45, Loss: 1.7063438892364502, Accuracy: 0.5322265625\n",
      "Batch No.: 46, Loss: 1.7880744934082031, Accuracy: 0.5087890625\n",
      "Batch No.: 47, Loss: 1.8032283782958984, Accuracy: 0.504638671875\n",
      "Batch No.: 48, Loss: 1.7991483211517334, Accuracy: 0.506591796875\n",
      "Batch No.: 49, Loss: 1.732729434967041, Accuracy: 0.533447265625\n",
      "Batch No.: 50, Loss: 1.82672119140625, Accuracy: 0.50048828125\n",
      "Batch No.: 51, Loss: 1.7979052066802979, Accuracy: 0.510498046875\n",
      "Batch No.: 52, Loss: 1.790905237197876, Accuracy: 0.51171875\n",
      "Batch No.: 53, Loss: 1.7722210884094238, Accuracy: 0.5185546875\n",
      "Batch No.: 54, Loss: 1.9018995761871338, Accuracy: 0.477783203125\n",
      "Batch No.: 55, Loss: 1.823596715927124, Accuracy: 0.509521484375\n",
      "Batch No.: 56, Loss: 1.7164539098739624, Accuracy: 0.54248046875\n",
      "Batch No.: 57, Loss: 1.807116985321045, Accuracy: 0.50048828125\n",
      "Batch No.: 58, Loss: 1.7270922660827637, Accuracy: 0.516845703125\n",
      "Batch No.: 59, Loss: 1.7281179428100586, Accuracy: 0.518310546875\n",
      "Batch No.: 60, Loss: 1.7888482809066772, Accuracy: 0.5146484375\n",
      "Batch No.: 61, Loss: 1.7871668338775635, Accuracy: 0.51708984375\n",
      "Batch No.: 62, Loss: 1.784195899963379, Accuracy: 0.517578125\n",
      "Batch No.: 63, Loss: 1.7700903415679932, Accuracy: 0.524169921875\n",
      "Batch No.: 64, Loss: 1.792589545249939, Accuracy: 0.5048828125\n",
      "Batch No.: 65, Loss: 1.7969536781311035, Accuracy: 0.5068359375\n",
      "Batch No.: 66, Loss: 1.7643214464187622, Accuracy: 0.5205078125\n",
      "Batch No.: 67, Loss: 1.6946555376052856, Accuracy: 0.540771484375\n",
      "Batch No.: 68, Loss: 1.8707003593444824, Accuracy: 0.4873046875\n",
      "Batch No.: 69, Loss: 1.7371556758880615, Accuracy: 0.5244140625\n",
      "Batch No.: 70, Loss: 1.6849889755249023, Accuracy: 0.55224609375\n",
      "Batch No.: 71, Loss: 1.8171207904815674, Accuracy: 0.501708984375\n",
      "Batch No.: 72, Loss: 1.8168710470199585, Accuracy: 0.511962890625\n",
      "Batch No.: 73, Loss: 1.9092166423797607, Accuracy: 0.48388671875\n",
      "Batch No.: 74, Loss: 1.711179494857788, Accuracy: 0.540283203125\n",
      "Batch No.: 75, Loss: 1.783498764038086, Accuracy: 0.52197265625\n",
      "Batch No.: 76, Loss: 1.6900979280471802, Accuracy: 0.541748046875\n",
      "Batch No.: 77, Loss: 1.7796199321746826, Accuracy: 0.51611328125\n",
      "Batch No.: 78, Loss: 1.6598418951034546, Accuracy: 0.5498046875\n",
      "Batch No.: 79, Loss: 1.7331537008285522, Accuracy: 0.526611328125\n",
      "Batch No.: 80, Loss: 1.7619447708129883, Accuracy: 0.522705078125\n",
      "Batch No.: 81, Loss: 1.7807185649871826, Accuracy: 0.509765625\n",
      "Batch No.: 82, Loss: 1.740736484527588, Accuracy: 0.53125\n",
      "Batch No.: 83, Loss: 1.673026204109192, Accuracy: 0.544677734375\n",
      "Batch No.: 84, Loss: 1.846153736114502, Accuracy: 0.48681640625\n",
      "Batch No.: 85, Loss: 1.7879173755645752, Accuracy: 0.524658203125\n",
      "Batch No.: 86, Loss: 1.6336431503295898, Accuracy: 0.55908203125\n",
      "Batch No.: 87, Loss: 1.7302234172821045, Accuracy: 0.521484375\n",
      "Batch No.: 88, Loss: 1.7442023754119873, Accuracy: 0.5263671875\n",
      "Batch No.: 89, Loss: 1.6434437036514282, Accuracy: 0.550537109375\n",
      "Batch No.: 90, Loss: 1.6543574333190918, Accuracy: 0.546875\n",
      "Batch No.: 91, Loss: 1.6105120182037354, Accuracy: 0.557373046875\n",
      "Batch No.: 92, Loss: 1.7835179567337036, Accuracy: 0.510498046875\n",
      "Batch No.: 93, Loss: 1.6779029369354248, Accuracy: 0.544921875\n",
      "Batch No.: 94, Loss: 1.7455966472625732, Accuracy: 0.52099609375\n",
      "Batch No.: 95, Loss: 1.8278864622116089, Accuracy: 0.496337890625\n",
      "Batch No.: 96, Loss: 1.7196674346923828, Accuracy: 0.53515625\n",
      "Batch No.: 97, Loss: 1.7803709506988525, Accuracy: 0.51171875\n",
      "Batch No.: 98, Loss: 1.6972405910491943, Accuracy: 0.542724609375\n",
      "Batch No.: 99, Loss: 1.7629272937774658, Accuracy: 0.51708984375\n",
      "Batch No.: 100, Loss: 1.8361181020736694, Accuracy: 0.49462890625\n",
      "Batch No.: 101, Loss: 1.7021639347076416, Accuracy: 0.550048828125\n",
      "Batch No.: 102, Loss: 1.860731840133667, Accuracy: 0.4814453125\n",
      "Batch No.: 103, Loss: 1.7446305751800537, Accuracy: 0.533203125\n",
      "Batch No.: 104, Loss: 1.7521038055419922, Accuracy: 0.53369140625\n",
      "Batch No.: 105, Loss: 1.7261803150177002, Accuracy: 0.522216796875\n",
      "Batch No.: 106, Loss: 1.7642635107040405, Accuracy: 0.5107421875\n",
      "Batch No.: 107, Loss: 1.7293319702148438, Accuracy: 0.525390625\n",
      "Batch No.: 108, Loss: 1.7353019714355469, Accuracy: 0.52490234375\n",
      "Batch No.: 109, Loss: 1.7278283834457397, Accuracy: 0.531494140625\n",
      "Batch No.: 110, Loss: 1.6856796741485596, Accuracy: 0.53515625\n",
      "Batch No.: 111, Loss: 1.692579746246338, Accuracy: 0.528076171875\n",
      "Batch No.: 112, Loss: 1.646891474723816, Accuracy: 0.561279296875\n",
      "Batch No.: 113, Loss: 1.7890751361846924, Accuracy: 0.505126953125\n",
      "Batch No.: 114, Loss: 1.863821268081665, Accuracy: 0.50244140625\n",
      "Batch No.: 115, Loss: 1.6696231365203857, Accuracy: 0.550048828125\n",
      "Batch No.: 116, Loss: 1.796903371810913, Accuracy: 0.49462890625\n",
      "Batch No.: 117, Loss: 1.636429786682129, Accuracy: 0.55419921875\n",
      "Batch No.: 118, Loss: 1.705665111541748, Accuracy: 0.535888671875\n",
      "Batch No.: 119, Loss: 1.6611648797988892, Accuracy: 0.5400390625\n",
      "Batch No.: 120, Loss: 1.73483407497406, Accuracy: 0.52685546875\n",
      "Batch No.: 121, Loss: 1.7293323278427124, Accuracy: 0.536376953125\n",
      "Batch No.: 122, Loss: 1.726061224937439, Accuracy: 0.52392578125\n",
      "Batch No.: 123, Loss: 1.8002797365188599, Accuracy: 0.51513671875\n",
      "Batch No.: 124, Loss: 1.7393866777420044, Accuracy: 0.51904296875\n",
      "Batch No.: 125, Loss: 1.7796517610549927, Accuracy: 0.51171875\n",
      "Batch No.: 126, Loss: 1.6788549423217773, Accuracy: 0.54052734375\n",
      "Batch No.: 127, Loss: 1.6898167133331299, Accuracy: 0.53271484375\n",
      "Batch No.: 128, Loss: 1.726042628288269, Accuracy: 0.53173828125\n",
      "Batch No.: 129, Loss: 1.8880033493041992, Accuracy: 0.494873046875\n",
      "Batch No.: 130, Loss: 1.663992166519165, Accuracy: 0.56396484375\n",
      "Batch No.: 131, Loss: 1.8651463985443115, Accuracy: 0.486328125\n",
      "Batch No.: 132, Loss: 1.8698195219039917, Accuracy: 0.493896484375\n",
      "Batch No.: 133, Loss: 1.6916100978851318, Accuracy: 0.55615234375\n",
      "Batch No.: 134, Loss: 1.6820751428604126, Accuracy: 0.546142578125\n",
      "Batch No.: 135, Loss: 1.7489595413208008, Accuracy: 0.5087890625\n",
      "Batch No.: 136, Loss: 1.6059895753860474, Accuracy: 0.56201171875\n",
      "Batch No.: 137, Loss: 1.7455201148986816, Accuracy: 0.527099609375\n",
      "Batch No.: 138, Loss: 1.7681148052215576, Accuracy: 0.51220703125\n",
      "Batch No.: 139, Loss: 1.722078561782837, Accuracy: 0.532958984375\n",
      "Batch No.: 140, Loss: 1.6678029298782349, Accuracy: 0.540283203125\n",
      "Batch No.: 141, Loss: 1.7503774166107178, Accuracy: 0.525146484375\n",
      "Batch No.: 142, Loss: 1.7378861904144287, Accuracy: 0.5234375\n",
      "Batch No.: 143, Loss: 1.661971926689148, Accuracy: 0.552978515625\n",
      "Batch No.: 144, Loss: 1.7504966259002686, Accuracy: 0.519287109375\n",
      "Batch No.: 145, Loss: 1.6273980140686035, Accuracy: 0.5498046875\n",
      "Batch No.: 146, Loss: 1.6004489660263062, Accuracy: 0.553955078125\n",
      "Batch No.: 147, Loss: 1.627828598022461, Accuracy: 0.551513671875\n",
      "Batch No.: 148, Loss: 1.6143513917922974, Accuracy: 0.5615234375\n",
      "Batch No.: 149, Loss: 1.6339235305786133, Accuracy: 0.54345703125\n",
      "Batch No.: 150, Loss: 1.7320151329040527, Accuracy: 0.51416015625\n",
      "Batch No.: 151, Loss: 1.6281120777130127, Accuracy: 0.5556640625\n",
      "Batch No.: 152, Loss: 1.6248371601104736, Accuracy: 0.546630859375\n",
      "Batch No.: 153, Loss: 1.694283127784729, Accuracy: 0.526611328125\n",
      "Batch No.: 154, Loss: 1.6320950984954834, Accuracy: 0.539794921875\n",
      "Batch No.: 155, Loss: 1.4988627433776855, Accuracy: 0.58642578125\n",
      "Batch No.: 156, Loss: 1.6974892616271973, Accuracy: 0.53076171875\n",
      "Batch No.: 157, Loss: 1.5659235715866089, Accuracy: 0.564208984375\n",
      "Batch No.: 158, Loss: 1.6806492805480957, Accuracy: 0.531494140625\n",
      "Batch No.: 159, Loss: 1.6490857601165771, Accuracy: 0.552978515625\n",
      "Batch No.: 160, Loss: 1.7150535583496094, Accuracy: 0.528564453125\n",
      "Batch No.: 161, Loss: 1.7009427547454834, Accuracy: 0.536376953125\n",
      "Batch No.: 162, Loss: 1.6971466541290283, Accuracy: 0.5390625\n",
      "Batch No.: 163, Loss: 1.61057710647583, Accuracy: 0.55126953125\n",
      "Batch No.: 164, Loss: 1.7026469707489014, Accuracy: 0.515869140625\n",
      "Batch No.: 165, Loss: 1.574157476425171, Accuracy: 0.57177734375\n",
      "Batch No.: 166, Loss: 1.641780972480774, Accuracy: 0.554443359375\n",
      "Batch No.: 167, Loss: 1.8308465480804443, Accuracy: 0.49609375\n",
      "Batch No.: 168, Loss: 1.6125742197036743, Accuracy: 0.566650390625\n",
      "Batch No.: 169, Loss: 1.648940920829773, Accuracy: 0.542724609375\n",
      "Batch No.: 170, Loss: 1.7429851293563843, Accuracy: 0.511962890625\n",
      "Batch No.: 171, Loss: 1.7269926071166992, Accuracy: 0.547119140625\n",
      "Batch No.: 172, Loss: 1.5793827772140503, Accuracy: 0.57080078125\n",
      "Batch No.: 173, Loss: 1.6849616765975952, Accuracy: 0.52734375\n",
      "Batch No.: 174, Loss: 1.7306902408599854, Accuracy: 0.536865234375\n",
      "Batch No.: 175, Loss: 1.503668189048767, Accuracy: 0.592529296875\n",
      "Batch No.: 176, Loss: 1.673912763595581, Accuracy: 0.53857421875\n",
      "Batch No.: 177, Loss: 1.6720688343048096, Accuracy: 0.548828125\n",
      "Batch No.: 178, Loss: 1.598435401916504, Accuracy: 0.566650390625\n",
      "Batch No.: 179, Loss: 1.6699352264404297, Accuracy: 0.54052734375\n",
      "Batch No.: 180, Loss: 1.64300537109375, Accuracy: 0.54443359375\n",
      "Batch No.: 181, Loss: 1.5401196479797363, Accuracy: 0.577880859375\n",
      "Batch No.: 182, Loss: 1.6730246543884277, Accuracy: 0.5283203125\n",
      "Batch No.: 183, Loss: 1.6030282974243164, Accuracy: 0.558349609375\n",
      "Batch No.: 184, Loss: 1.5841343402862549, Accuracy: 0.5673828125\n",
      "Batch No.: 185, Loss: 1.6880613565444946, Accuracy: 0.532958984375\n",
      "Batch No.: 186, Loss: 1.5396076440811157, Accuracy: 0.5693359375\n",
      "Batch No.: 187, Loss: 1.5836613178253174, Accuracy: 0.556396484375\n",
      "Batch No.: 188, Loss: 1.7736575603485107, Accuracy: 0.50830078125\n",
      "Batch No.: 189, Loss: 1.559382677078247, Accuracy: 0.581298828125\n",
      "Batch No.: 190, Loss: 1.796452283859253, Accuracy: 0.503173828125\n",
      "Batch No.: 191, Loss: 1.6748285293579102, Accuracy: 0.54345703125\n",
      "Batch No.: 192, Loss: 1.4666032791137695, Accuracy: 0.60791015625\n",
      "Batch No.: 193, Loss: 1.6895687580108643, Accuracy: 0.521728515625\n",
      "Batch No.: 194, Loss: 1.5627210140228271, Accuracy: 0.574462890625\n",
      "Batch No.: 195, Loss: 1.477760672569275, Accuracy: 0.596923828125\n",
      "Batch No.: 196, Loss: 1.6884112358093262, Accuracy: 0.52392578125\n",
      "Batch No.: 84, Loss: 0.6838061213493347, Accuracy: 0.7783203125\n",
      "Batch No.: 85, Loss: 0.659714937210083, Accuracy: 0.79443359375\n",
      "Batch No.: 86, Loss: 0.5793941020965576, Accuracy: 0.81298828125\n",
      "Batch No.: 87, Loss: 0.596668004989624, Accuracy: 0.809326171875\n",
      "Batch No.: 88, Loss: 0.6414429545402527, Accuracy: 0.796142578125\n",
      "Batch No.: 89, Loss: 0.5962640047073364, Accuracy: 0.81103515625\n",
      "Batch No.: 90, Loss: 0.6158075928688049, Accuracy: 0.8076171875\n",
      "Batch No.: 91, Loss: 0.621094286441803, Accuracy: 0.807373046875\n",
      "Batch No.: 92, Loss: 0.6343848705291748, Accuracy: 0.792236328125\n",
      "Batch No.: 93, Loss: 0.6550965309143066, Accuracy: 0.793212890625\n",
      "Batch No.: 94, Loss: 0.6855407953262329, Accuracy: 0.77490234375\n",
      "Batch No.: 95, Loss: 0.7139441967010498, Accuracy: 0.7744140625\n",
      "Batch No.: 96, Loss: 0.6163387298583984, Accuracy: 0.8046875\n",
      "Batch No.: 97, Loss: 0.6569716334342957, Accuracy: 0.78759765625\n",
      "Batch No.: 98, Loss: 0.6668057441711426, Accuracy: 0.794677734375\n",
      "Batch No.: 101, Loss: 0.6049350500106812, Accuracy: 0.807373046875\n",
      "Batch No.: 102, Loss: 0.6866399049758911, Accuracy: 0.774169921875\n",
      "Batch No.: 103, Loss: 0.6589518785476685, Accuracy: 0.796630859375\n",
      "Batch No.: 104, Loss: 0.6359274387359619, Accuracy: 0.800048828125\n",
      "Batch No.: 105, Loss: 0.6903773546218872, Accuracy: 0.779296875\n",
      "Batch No.: 106, Loss: 0.6576406955718994, Accuracy: 0.782470703125\n",
      "Batch No.: 107, Loss: 0.6198076009750366, Accuracy: 0.80078125\n",
      "Batch No.: 108, Loss: 0.6367955803871155, Accuracy: 0.79443359375\n",
      "Batch No.: 109, Loss: 0.6610692739486694, Accuracy: 0.793212890625\n",
      "Batch No.: 110, Loss: 0.6287567019462585, Accuracy: 0.810791015625\n",
      "Batch No.: 111, Loss: 0.6052491664886475, Accuracy: 0.806396484375\n",
      "Batch No.: 112, Loss: 0.5943635702133179, Accuracy: 0.8095703125\n",
      "Batch No.: 113, Loss: 0.6791189312934875, Accuracy: 0.78271484375\n",
      "Batch No.: 114, Loss: 0.6719238758087158, Accuracy: 0.787109375\n",
      "Batch No.: 115, Loss: 0.6620470285415649, Accuracy: 0.78759765625\n",
      "Batch No.: 116, Loss: 0.6990754008293152, Accuracy: 0.778076171875\n",
      "Batch No.: 117, Loss: 0.6206879019737244, Accuracy: 0.8017578125\n",
      "Batch No.: 118, Loss: 0.6406986713409424, Accuracy: 0.794677734375\n",
      "Batch No.: 119, Loss: 0.66492760181427, Accuracy: 0.787353515625\n",
      "Batch No.: 120, Loss: 0.6994821429252625, Accuracy: 0.78271484375\n",
      "Batch No.: 121, Loss: 0.6778792142868042, Accuracy: 0.7841796875\n",
      "Batch No.: 122, Loss: 0.710981011390686, Accuracy: 0.778564453125\n",
      "Batch No.: 123, Loss: 0.7361354827880859, Accuracy: 0.7734375\n",
      "Batch No.: 127, Loss: 0.6407256126403809, Accuracy: 0.797607421875\n",
      "Batch No.: 128, Loss: 0.6511579751968384, Accuracy: 0.796875\n",
      "Batch No.: 129, Loss: 0.7025207281112671, Accuracy: 0.779052734375\n",
      "Batch No.: 130, Loss: 0.6764743328094482, Accuracy: 0.787353515625\n",
      "Batch No.: 131, Loss: 0.6799630522727966, Accuracy: 0.789306640625\n",
      "Batch No.: 132, Loss: 0.7665500640869141, Accuracy: 0.761474609375\n",
      "Batch No.: 133, Loss: 0.6806930899620056, Accuracy: 0.784423828125\n",
      "Batch No.: 134, Loss: 0.6544123888015747, Accuracy: 0.79443359375\n",
      "Batch No.: 135, Loss: 0.6997945308685303, Accuracy: 0.77685546875\n",
      "Batch No.: 136, Loss: 0.6222164630889893, Accuracy: 0.81103515625\n",
      "Batch No.: 137, Loss: 0.6252849102020264, Accuracy: 0.803955078125\n",
      "Batch No.: 138, Loss: 0.6994620561599731, Accuracy: 0.783447265625\n",
      "Batch No.: 139, Loss: 0.6839378476142883, Accuracy: 0.785888671875\n",
      "Batch No.: 140, Loss: 0.6637881994247437, Accuracy: 0.785400390625\n",
      "Batch No.: 141, Loss: 0.7334776520729065, Accuracy: 0.771484375\n",
      "Batch No.: 142, Loss: 0.7744458913803101, Accuracy: 0.760009765625\n",
      "Batch No.: 143, Loss: 0.6740227937698364, Accuracy: 0.788818359375\n",
      "Batch No.: 144, Loss: 0.679892897605896, Accuracy: 0.78662109375\n",
      "Batch No.: 145, Loss: 0.6847730278968811, Accuracy: 0.778564453125\n",
      "Batch No.: 146, Loss: 0.6534769535064697, Accuracy: 0.78564453125\n",
      "Batch No.: 147, Loss: 0.6910080313682556, Accuracy: 0.78662109375\n",
      "Batch No.: 148, Loss: 0.6491380929946899, Accuracy: 0.788818359375\n",
      "Batch No.: 150, Loss: 0.6688439846038818, Accuracy: 0.788330078125\n",
      "Batch No.: 151, Loss: 0.6657838225364685, Accuracy: 0.783935546875\n",
      "Batch No.: 152, Loss: 0.6498811841011047, Accuracy: 0.790771484375\n",
      "Batch No.: 153, Loss: 0.6763250827789307, Accuracy: 0.785400390625\n",
      "Batch No.: 154, Loss: 0.6431000232696533, Accuracy: 0.797119140625\n",
      "Batch No.: 155, Loss: 0.5914510488510132, Accuracy: 0.8154296875\n",
      "Batch No.: 156, Loss: 0.6627985239028931, Accuracy: 0.7861328125\n",
      "Batch No.: 157, Loss: 0.6127132177352905, Accuracy: 0.804931640625\n",
      "Batch No.: 158, Loss: 0.6675483584403992, Accuracy: 0.78759765625\n",
      "Batch No.: 159, Loss: 0.6532723903656006, Accuracy: 0.789306640625\n",
      "Batch No.: 160, Loss: 0.708524227142334, Accuracy: 0.771728515625\n",
      "Batch No.: 161, Loss: 0.6970646381378174, Accuracy: 0.783203125\n",
      "Batch No.: 162, Loss: 0.6849972009658813, Accuracy: 0.7841796875\n",
      "Batch No.: 163, Loss: 0.6121387481689453, Accuracy: 0.806884765625\n",
      "Batch No.: 164, Loss: 0.7105693817138672, Accuracy: 0.76904296875\n",
      "Batch No.: 165, Loss: 0.62733393907547, Accuracy: 0.802734375\n",
      "Batch No.: 166, Loss: 0.6241394281387329, Accuracy: 0.809326171875\n",
      "Batch No.: 167, Loss: 0.7710304260253906, Accuracy: 0.759765625\n",
      "Batch No.: 168, Loss: 0.6624197959899902, Accuracy: 0.791259765625\n",
      "Batch No.: 169, Loss: 0.6575810313224792, Accuracy: 0.789794921875\n",
      "Batch No.: 170, Loss: 0.7598433494567871, Accuracy: 0.7529296875\n",
      "Batch No.: 171, Loss: 0.7214088439941406, Accuracy: 0.778564453125\n",
      "Batch No.: 172, Loss: 0.6778652667999268, Accuracy: 0.787353515625\n",
      "Batch No.: 173, Loss: 0.6891013383865356, Accuracy: 0.7783203125\n",
      "Batch No.: 175, Loss: 0.6233251094818115, Accuracy: 0.798828125\n",
      "Batch No.: 176, Loss: 0.7162191271781921, Accuracy: 0.7724609375\n",
      "Batch No.: 177, Loss: 0.7156771421432495, Accuracy: 0.779296875\n",
      "Batch No.: 178, Loss: 0.6542508006095886, Accuracy: 0.790771484375\n",
      "Batch No.: 179, Loss: 0.666949987411499, Accuracy: 0.7861328125\n",
      "Batch No.: 180, Loss: 0.6920702457427979, Accuracy: 0.78271484375\n",
      "Batch No.: 181, Loss: 0.6221845149993896, Accuracy: 0.802734375\n",
      "Batch No.: 182, Loss: 0.6615058183670044, Accuracy: 0.791015625\n",
      "Batch No.: 183, Loss: 0.635400652885437, Accuracy: 0.795166015625\n",
      "Batch No.: 184, Loss: 0.6585203409194946, Accuracy: 0.7939453125\n",
      "Batch No.: 185, Loss: 0.6851763725280762, Accuracy: 0.78515625\n",
      "Batch No.: 186, Loss: 0.6336649656295776, Accuracy: 0.78955078125\n",
      "Batch No.: 187, Loss: 0.651461124420166, Accuracy: 0.785888671875\n",
      "Batch No.: 188, Loss: 0.7144357562065125, Accuracy: 0.773193359375\n",
      "Batch No.: 189, Loss: 0.6139298677444458, Accuracy: 0.801025390625\n",
      "Batch No.: 190, Loss: 0.7503671646118164, Accuracy: 0.76123046875\n",
      "Batch No.: 191, Loss: 0.7308655977249146, Accuracy: 0.7666015625\n",
      "Batch No.: 192, Loss: 0.5711023807525635, Accuracy: 0.818359375\n",
      "Batch No.: 193, Loss: 0.7208062410354614, Accuracy: 0.77099609375\n",
      "Batch No.: 194, Loss: 0.6774475574493408, Accuracy: 0.77978515625\n",
      "Batch No.: 195, Loss: 0.5709761381149292, Accuracy: 0.8193359375\n",
      "Batch No.: 196, Loss: 0.6689298152923584, Accuracy: 0.787353515625\n",
      "Batch No.: 199, Loss: 0.6759346127510071, Accuracy: 0.78271484375\n",
      "Batch No.: 200, Loss: 0.623126208782196, Accuracy: 0.801025390625\n",
      "Batch No.: 201, Loss: 0.6614447236061096, Accuracy: 0.788330078125\n",
      "Batch No.: 202, Loss: 0.6950404644012451, Accuracy: 0.779541015625\n",
      "Batch No.: 203, Loss: 0.617171585559845, Accuracy: 0.802490234375\n",
      "Batch No.: 204, Loss: 0.6182262897491455, Accuracy: 0.8017578125\n",
      "Batch No.: 205, Loss: 0.6353729963302612, Accuracy: 0.796142578125\n",
      "Batch No.: 206, Loss: 0.6761218905448914, Accuracy: 0.7861328125\n",
      "Batch No.: 207, Loss: 0.6235847473144531, Accuracy: 0.803955078125\n",
      "Batch No.: 208, Loss: 0.740693986415863, Accuracy: 0.766357421875\n",
      "Batch No.: 209, Loss: 0.6582720279693604, Accuracy: 0.792724609375\n",
      "Batch No.: 210, Loss: 0.6320133209228516, Accuracy: 0.806640625\n",
      "Batch No.: 211, Loss: 0.6896263360977173, Accuracy: 0.78271484375\n",
      "Batch No.: 212, Loss: 0.6113277673721313, Accuracy: 0.806884765625\n",
      "Batch No.: 213, Loss: 0.6157572865486145, Accuracy: 0.80029296875\n",
      "Batch No.: 214, Loss: 0.6721977591514587, Accuracy: 0.78125\n",
      "Batch No.: 215, Loss: 0.6658798456192017, Accuracy: 0.789306640625\n",
      "Batch No.: 216, Loss: 0.6174386739730835, Accuracy: 0.79638671875\n",
      "Batch No.: 217, Loss: 0.6374689340591431, Accuracy: 0.797607421875\n",
      "Batch No.: 218, Loss: 0.660279393196106, Accuracy: 0.787353515625\n",
      "Batch No.: 219, Loss: 0.7091296315193176, Accuracy: 0.771728515625\n",
      "Batch No.: 220, Loss: 0.6967475414276123, Accuracy: 0.776123046875\n",
      "Batch No.: 221, Loss: 0.6770837306976318, Accuracy: 0.788818359375\n",
      "Batch No.: 222, Loss: 0.7047467231750488, Accuracy: 0.770263671875\n",
      "Batch No.: 223, Loss: 0.6433655619621277, Accuracy: 0.797119140625\n",
      "Batch No.: 224, Loss: 0.617712140083313, Accuracy: 0.80517578125\n",
      "Batch No.: 225, Loss: 0.6587836742401123, Accuracy: 0.784423828125\n",
      "Batch No.: 226, Loss: 0.6259752511978149, Accuracy: 0.7958984375\n",
      "Batch No.: 227, Loss: 0.5888469219207764, Accuracy: 0.816162109375\n",
      "Batch No.: 228, Loss: 0.7272211313247681, Accuracy: 0.765625\n",
      "Batch No.: 229, Loss: 0.6608355045318604, Accuracy: 0.7841796875\n",
      "Batch No.: 230, Loss: 0.6274524331092834, Accuracy: 0.799072265625\n",
      "Batch No.: 231, Loss: 0.6895042061805725, Accuracy: 0.780517578125\n",
      "Batch No.: 232, Loss: 0.6688517928123474, Accuracy: 0.7919921875\n",
      "Batch No.: 233, Loss: 0.5991451144218445, Accuracy: 0.810302734375\n",
      "Batch No.: 234, Loss: 0.715103030204773, Accuracy: 0.779296875\n",
      "Batch No.: 235, Loss: 0.6560288071632385, Accuracy: 0.792236328125\n",
      "Batch No.: 236, Loss: 0.6609696745872498, Accuracy: 0.7919921875\n",
      "Batch No.: 237, Loss: 0.7358044385910034, Accuracy: 0.7646484375\n",
      "Batch No.: 238, Loss: 0.6653878688812256, Accuracy: 0.794677734375\n",
      "Batch No.: 239, Loss: 0.6296373605728149, Accuracy: 0.8046875\n",
      "Batch No.: 240, Loss: 0.6566325426101685, Accuracy: 0.786376953125\n",
      "Batch No.: 241, Loss: 0.6686398983001709, Accuracy: 0.79150390625\n",
      "Batch No.: 242, Loss: 0.59885573387146, Accuracy: 0.811279296875\n",
      "Batch No.: 243, Loss: 0.6575281620025635, Accuracy: 0.790283203125\n",
      "Batch No.: 244, Loss: 0.6704132556915283, Accuracy: 0.787109375\n",
      "Batch No.: 245, Loss: 0.6009668111801147, Accuracy: 0.807861328125\n",
      "Batch No.: 246, Loss: 0.6104432940483093, Accuracy: 0.810546875\n",
      "Batch No.: 249, Loss: 0.7137659788131714, Accuracy: 0.78173828125\n",
      "Batch No.: 250, Loss: 0.6608502864837646, Accuracy: 0.787841796875\n",
      "Batch No.: 251, Loss: 0.6666481494903564, Accuracy: 0.787109375\n",
      "Batch No.: 252, Loss: 0.6202473044395447, Accuracy: 0.805419921875\n",
      "Batch No.: 253, Loss: 0.635952353477478, Accuracy: 0.802001953125\n",
      "Batch No.: 254, Loss: 0.680600106716156, Accuracy: 0.78271484375\n",
      "Batch No.: 255, Loss: 0.6726770401000977, Accuracy: 0.783935546875\n",
      "Batch No.: 256, Loss: 0.6232426166534424, Accuracy: 0.803466796875\n",
      "Batch No.: 257, Loss: 0.700239896774292, Accuracy: 0.770263671875\n",
      "Batch No.: 258, Loss: 0.6555613279342651, Accuracy: 0.795166015625\n",
      "Batch No.: 259, Loss: 0.5883230566978455, Accuracy: 0.8095703125\n",
      "Batch No.: 260, Loss: 0.6743299961090088, Accuracy: 0.78759765625\n",
      "Batch No.: 261, Loss: 0.6817059516906738, Accuracy: 0.777587890625\n",
      "Batch No.: 262, Loss: 0.5990387797355652, Accuracy: 0.815185546875\n",
      "Batch No.: 263, Loss: 0.7009119987487793, Accuracy: 0.77880859375\n",
      "Batch No.: 264, Loss: 0.5944215655326843, Accuracy: 0.804443359375\n",
      "Epoch 60/80\n",
      "Batch No.: 1, Loss: 1.031065821647644, Accuracy: 0.718994140625\n",
      "Batch No.: 2, Loss: 0.6015087366104126, Accuracy: 0.81005859375\n",
      "Batch No.: 3, Loss: 0.6027949452400208, Accuracy: 0.800537109375\n",
      "Batch No.: 4, Loss: 0.6031786203384399, Accuracy: 0.806396484375\n",
      "Batch No.: 5, Loss: 0.674168586730957, Accuracy: 0.78271484375\n",
      "Batch No.: 6, Loss: 0.5874589085578918, Accuracy: 0.815185546875\n",
      "Batch No.: 7, Loss: 0.616156816482544, Accuracy: 0.796630859375\n",
      "Batch No.: 10, Loss: 0.6226491928100586, Accuracy: 0.80029296875\n",
      "Batch No.: 11, Loss: 0.6211154460906982, Accuracy: 0.8017578125\n",
      "Batch No.: 12, Loss: 0.6340712308883667, Accuracy: 0.80419921875\n",
      "Batch No.: 13, Loss: 0.7034246921539307, Accuracy: 0.7763671875\n",
      "Batch No.: 14, Loss: 0.6530447006225586, Accuracy: 0.790771484375\n",
      "Batch No.: 15, Loss: 0.6731484532356262, Accuracy: 0.781982421875\n",
      "Batch No.: 16, Loss: 0.6068102717399597, Accuracy: 0.80517578125\n",
      "Batch No.: 17, Loss: 0.6648710370063782, Accuracy: 0.789794921875\n",
      "Batch No.: 18, Loss: 0.6806290149688721, Accuracy: 0.785400390625\n",
      "Batch No.: 19, Loss: 0.6137062311172485, Accuracy: 0.800048828125\n",
      "Batch No.: 20, Loss: 0.6249009966850281, Accuracy: 0.803466796875\n",
      "Batch No.: 21, Loss: 0.6969383358955383, Accuracy: 0.78173828125\n",
      "Batch No.: 22, Loss: 0.6206228733062744, Accuracy: 0.803955078125\n",
      "Batch No.: 23, Loss: 0.5660635232925415, Accuracy: 0.82470703125\n",
      "Batch No.: 24, Loss: 0.7186164855957031, Accuracy: 0.7744140625\n",
      "Batch No.: 25, Loss: 0.7341752052307129, Accuracy: 0.769287109375\n",
      "Batch No.: 26, Loss: 0.5657477378845215, Accuracy: 0.817138671875\n",
      "Batch No.: 27, Loss: 0.6704913377761841, Accuracy: 0.791259765625\n",
      "Batch No.: 28, Loss: 0.646733283996582, Accuracy: 0.791748046875\n",
      "Batch No.: 29, Loss: 0.5609986186027527, Accuracy: 0.81884765625\n",
      "Batch No.: 31, Loss: 0.6796294450759888, Accuracy: 0.7822265625\n",
      "Batch No.: 32, Loss: 0.5566672086715698, Accuracy: 0.823974609375\n",
      "Batch No.: 33, Loss: 0.6368870139122009, Accuracy: 0.793701171875\n",
      "Batch No.: 34, Loss: 0.6598035097122192, Accuracy: 0.783447265625\n",
      "Batch No.: 35, Loss: 0.584122896194458, Accuracy: 0.809814453125\n",
      "Batch No.: 36, Loss: 0.638122022151947, Accuracy: 0.79736328125\n",
      "Batch No.: 37, Loss: 0.6758918762207031, Accuracy: 0.78662109375\n",
      "Batch No.: 38, Loss: 0.6670748591423035, Accuracy: 0.790771484375\n",
      "Batch No.: 39, Loss: 0.5947567224502563, Accuracy: 0.80712890625\n",
      "Batch No.: 40, Loss: 0.619568407535553, Accuracy: 0.803466796875\n",
      "Batch No.: 41, Loss: 0.7085280418395996, Accuracy: 0.776611328125\n",
      "Batch No.: 42, Loss: 0.6434948444366455, Accuracy: 0.799072265625\n",
      "Batch No.: 43, Loss: 0.610828161239624, Accuracy: 0.804931640625\n",
      "Batch No.: 44, Loss: 0.6674147844314575, Accuracy: 0.79052734375\n",
      "Batch No.: 45, Loss: 0.6061205267906189, Accuracy: 0.80859375\n",
      "Batch No.: 46, Loss: 0.5925348997116089, Accuracy: 0.81494140625\n",
      "Batch No.: 47, Loss: 0.7010593414306641, Accuracy: 0.782470703125\n",
      "Batch No.: 48, Loss: 0.6081892251968384, Accuracy: 0.801513671875\n",
      "Batch No.: 49, Loss: 0.6440377235412598, Accuracy: 0.79638671875\n",
      "Batch No.: 50, Loss: 0.6769136190414429, Accuracy: 0.786376953125\n",
      "Batch No.: 51, Loss: 0.6418913006782532, Accuracy: 0.7958984375\n",
      "Batch No.: 54, Loss: 0.7087992429733276, Accuracy: 0.76953125\n",
      "Batch No.: 55, Loss: 0.6828547716140747, Accuracy: 0.78515625\n",
      "Batch No.: 56, Loss: 0.6384384632110596, Accuracy: 0.7978515625\n",
      "Batch No.: 57, Loss: 0.662800133228302, Accuracy: 0.79248046875\n",
      "Batch No.: 58, Loss: 0.6041147112846375, Accuracy: 0.805419921875\n",
      "Batch No.: 59, Loss: 0.6472431421279907, Accuracy: 0.794921875\n",
      "Batch No.: 60, Loss: 0.6269103288650513, Accuracy: 0.803955078125\n",
      "Batch No.: 61, Loss: 0.5871759653091431, Accuracy: 0.8154296875\n",
      "Batch No.: 62, Loss: 0.6494410037994385, Accuracy: 0.798095703125\n",
      "Batch No.: 63, Loss: 0.6239901781082153, Accuracy: 0.797607421875\n",
      "Batch No.: 64, Loss: 0.6719949841499329, Accuracy: 0.7880859375\n",
      "Batch No.: 65, Loss: 0.7218393087387085, Accuracy: 0.76953125\n",
      "Batch No.: 66, Loss: 0.5979552268981934, Accuracy: 0.802734375\n",
      "Batch No.: 67, Loss: 0.5908481478691101, Accuracy: 0.814697265625\n",
      "Batch No.: 68, Loss: 0.7098956108093262, Accuracy: 0.779052734375\n",
      "Batch No.: 69, Loss: 0.6677323579788208, Accuracy: 0.781494140625\n",
      "Batch No.: 70, Loss: 0.5928363800048828, Accuracy: 0.811767578125\n",
      "Batch No.: 71, Loss: 0.6895833611488342, Accuracy: 0.780517578125\n",
      "Batch No.: 72, Loss: 0.6407557725906372, Accuracy: 0.800048828125\n",
      "Batch No.: 73, Loss: 0.6505465507507324, Accuracy: 0.79052734375\n",
      "Batch No.: 74, Loss: 0.6587610244750977, Accuracy: 0.793212890625\n",
      "Batch No.: 75, Loss: 0.6423814296722412, Accuracy: 0.796630859375\n",
      "Batch No.: 78, Loss: 0.633658766746521, Accuracy: 0.80322265625\n",
      "Batch No.: 79, Loss: 0.6236816048622131, Accuracy: 0.80615234375\n",
      "Batch No.: 80, Loss: 0.667251467704773, Accuracy: 0.793212890625\n",
      "Batch No.: 81, Loss: 0.6824350357055664, Accuracy: 0.777587890625\n",
      "Batch No.: 82, Loss: 0.6645400524139404, Accuracy: 0.788818359375\n",
      "Batch No.: 83, Loss: 0.6028987169265747, Accuracy: 0.812744140625\n",
      "Batch No.: 84, Loss: 0.7082141637802124, Accuracy: 0.77197265625\n",
      "Batch No.: 85, Loss: 0.6451645493507385, Accuracy: 0.793212890625\n",
      "Batch No.: 86, Loss: 0.5789752006530762, Accuracy: 0.816162109375\n",
      "Batch No.: 87, Loss: 0.5969353318214417, Accuracy: 0.803955078125\n",
      "Batch No.: 88, Loss: 0.6263297200202942, Accuracy: 0.791015625\n",
      "Batch No.: 89, Loss: 0.6056092381477356, Accuracy: 0.814208984375\n",
      "Batch No.: 90, Loss: 0.5865518450737, Accuracy: 0.81005859375\n",
      "Batch No.: 91, Loss: 0.6150592565536499, Accuracy: 0.805419921875\n",
      "Batch No.: 92, Loss: 0.6017758250236511, Accuracy: 0.80517578125\n",
      "Batch No.: 93, Loss: 0.6459633111953735, Accuracy: 0.800048828125\n",
      "Batch No.: 94, Loss: 0.6766379475593567, Accuracy: 0.784423828125\n",
      "Batch No.: 95, Loss: 0.6953495740890503, Accuracy: 0.77880859375\n",
      "Batch No.: 96, Loss: 0.6201422214508057, Accuracy: 0.803955078125\n",
      "Batch No.: 97, Loss: 0.649764895439148, Accuracy: 0.7880859375\n",
      "Batch No.: 98, Loss: 0.662175178527832, Accuracy: 0.7880859375\n",
      "Batch No.: 99, Loss: 0.6638529300689697, Accuracy: 0.785400390625\n",
      "Batch No.: 100, Loss: 0.6498925089836121, Accuracy: 0.79248046875\n",
      "Batch No.: 101, Loss: 0.5857157707214355, Accuracy: 0.8115234375\n",
      "Batch No.: 103, Loss: 0.6781005263328552, Accuracy: 0.78857421875\n",
      "Batch No.: 104, Loss: 0.6349509954452515, Accuracy: 0.8037109375\n",
      "Batch No.: 105, Loss: 0.6878657937049866, Accuracy: 0.77587890625\n",
      "Batch No.: 106, Loss: 0.6506959795951843, Accuracy: 0.78759765625\n",
      "Batch No.: 107, Loss: 0.6322298645973206, Accuracy: 0.800048828125\n",
      "Batch No.: 108, Loss: 0.6297638416290283, Accuracy: 0.79833984375\n",
      "Batch No.: 109, Loss: 0.6716464161872864, Accuracy: 0.785400390625\n",
      "Batch No.: 110, Loss: 0.6281623840332031, Accuracy: 0.801025390625\n",
      "Batch No.: 111, Loss: 0.6178722381591797, Accuracy: 0.808349609375\n",
      "Batch No.: 112, Loss: 0.5928090214729309, Accuracy: 0.81103515625\n",
      "Batch No.: 113, Loss: 0.6667859554290771, Accuracy: 0.79150390625\n",
      "Batch No.: 114, Loss: 0.6650801301002502, Accuracy: 0.794921875\n",
      "Batch No.: 115, Loss: 0.6421530842781067, Accuracy: 0.79833984375\n",
      "Batch No.: 116, Loss: 0.7099566459655762, Accuracy: 0.776123046875\n",
      "Batch No.: 117, Loss: 0.6206045150756836, Accuracy: 0.79638671875\n",
      "Batch No.: 118, Loss: 0.6355004906654358, Accuracy: 0.794677734375\n",
      "Batch No.: 119, Loss: 0.6683427095413208, Accuracy: 0.78662109375\n",
      "Batch No.: 120, Loss: 0.6840356588363647, Accuracy: 0.783203125\n",
      "Batch No.: 121, Loss: 0.6646556854248047, Accuracy: 0.794189453125\n",
      "Batch No.: 122, Loss: 0.7098050117492676, Accuracy: 0.7763671875\n",
      "Batch No.: 123, Loss: 0.7378500699996948, Accuracy: 0.769775390625\n",
      "Batch No.: 124, Loss: 0.6674203276634216, Accuracy: 0.7919921875\n",
      "Batch No.: 125, Loss: 0.6802904605865479, Accuracy: 0.7822265625\n",
      "Batch No.: 127, Loss: 0.626734733581543, Accuracy: 0.8046875\n",
      "Batch No.: 128, Loss: 0.6416398286819458, Accuracy: 0.7958984375\n",
      "Batch No.: 129, Loss: 0.7053844928741455, Accuracy: 0.776123046875\n",
      "Batch No.: 130, Loss: 0.6706759929656982, Accuracy: 0.794677734375\n",
      "Batch No.: 131, Loss: 0.668941855430603, Accuracy: 0.787109375\n",
      "Batch No.: 132, Loss: 0.7702749371528625, Accuracy: 0.762451171875\n",
      "Batch No.: 133, Loss: 0.6610960960388184, Accuracy: 0.7900390625\n",
      "Batch No.: 134, Loss: 0.6456167101860046, Accuracy: 0.794677734375\n",
      "Batch No.: 135, Loss: 0.6981519460678101, Accuracy: 0.775390625\n",
      "Batch No.: 136, Loss: 0.6138210296630859, Accuracy: 0.80615234375\n",
      "Batch No.: 137, Loss: 0.6322288513183594, Accuracy: 0.801025390625\n",
      "Batch No.: 138, Loss: 0.705876350402832, Accuracy: 0.779052734375\n",
      "Batch No.: 139, Loss: 0.6671853065490723, Accuracy: 0.783935546875\n",
      "Batch No.: 140, Loss: 0.6356183886528015, Accuracy: 0.791015625\n",
      "Batch No.: 141, Loss: 0.7186572551727295, Accuracy: 0.77392578125\n",
      "Batch No.: 142, Loss: 0.7781729102134705, Accuracy: 0.7509765625\n",
      "Batch No.: 143, Loss: 0.6484736204147339, Accuracy: 0.802734375\n",
      "Batch No.: 144, Loss: 0.6879639625549316, Accuracy: 0.771484375\n",
      "Batch No.: 145, Loss: 0.6812852621078491, Accuracy: 0.78564453125\n",
      "Batch No.: 146, Loss: 0.6714960336685181, Accuracy: 0.782958984375\n",
      "Batch No.: 147, Loss: 0.6930233240127563, Accuracy: 0.779296875\n",
      "Batch No.: 148, Loss: 0.6311404705047607, Accuracy: 0.796630859375\n",
      "Batch No.: 151, Loss: 0.6584877371788025, Accuracy: 0.78564453125\n",
      "Batch No.: 152, Loss: 0.6366495490074158, Accuracy: 0.801513671875\n",
      "Batch No.: 153, Loss: 0.6799808740615845, Accuracy: 0.78759765625\n",
      "Batch No.: 154, Loss: 0.6540219187736511, Accuracy: 0.7841796875\n",
      "Batch No.: 155, Loss: 0.5932514667510986, Accuracy: 0.8154296875\n",
      "Batch No.: 156, Loss: 0.6548292636871338, Accuracy: 0.7919921875\n",
      "Batch No.: 157, Loss: 0.6229555606842041, Accuracy: 0.79638671875\n",
      "Batch No.: 158, Loss: 0.6619778275489807, Accuracy: 0.781005859375\n",
      "Batch No.: 159, Loss: 0.6492238640785217, Accuracy: 0.793701171875\n",
      "Batch No.: 160, Loss: 0.6937620639801025, Accuracy: 0.778564453125\n",
      "Batch No.: 161, Loss: 0.6766261458396912, Accuracy: 0.79052734375\n",
      "Batch No.: 162, Loss: 0.665526270866394, Accuracy: 0.782958984375\n",
      "Batch No.: 163, Loss: 0.6111780405044556, Accuracy: 0.81005859375\n",
      "Batch No.: 164, Loss: 0.7174631357192993, Accuracy: 0.765869140625\n",
      "Batch No.: 165, Loss: 0.6238870024681091, Accuracy: 0.7978515625\n",
      "Batch No.: 166, Loss: 0.6140270829200745, Accuracy: 0.802978515625\n",
      "Batch No.: 167, Loss: 0.7775140404701233, Accuracy: 0.759521484375\n",
      "Batch No.: 168, Loss: 0.6571437120437622, Accuracy: 0.78955078125\n",
      "Batch No.: 169, Loss: 0.6612317562103271, Accuracy: 0.791259765625\n",
      "Batch No.: 170, Loss: 0.7478835582733154, Accuracy: 0.754150390625\n",
      "Batch No.: 171, Loss: 0.7302066087722778, Accuracy: 0.775390625\n",
      "Batch No.: 172, Loss: 0.6711277365684509, Accuracy: 0.788330078125\n",
      "Batch No.: 174, Loss: 0.6939274072647095, Accuracy: 0.777099609375\n",
      "Batch No.: 175, Loss: 0.6124213337898254, Accuracy: 0.80224609375\n",
      "Batch No.: 176, Loss: 0.7238456010818481, Accuracy: 0.772216796875\n",
      "Batch No.: 177, Loss: 0.6891193389892578, Accuracy: 0.7763671875\n",
      "Batch No.: 178, Loss: 0.6440364122390747, Accuracy: 0.78955078125\n",
      "Batch No.: 179, Loss: 0.6600536108016968, Accuracy: 0.794921875\n",
      "Batch No.: 180, Loss: 0.6744657754898071, Accuracy: 0.784912109375\n",
      "Batch No.: 181, Loss: 0.6249192953109741, Accuracy: 0.800537109375\n",
      "Batch No.: 182, Loss: 0.6668974161148071, Accuracy: 0.7880859375\n",
      "Batch No.: 183, Loss: 0.6323328614234924, Accuracy: 0.80224609375\n",
      "Batch No.: 184, Loss: 0.6525853872299194, Accuracy: 0.791748046875\n",
      "Batch No.: 185, Loss: 0.6860359907150269, Accuracy: 0.783203125\n",
      "Batch No.: 186, Loss: 0.640408992767334, Accuracy: 0.7900390625\n",
      "Batch No.: 187, Loss: 0.6352034211158752, Accuracy: 0.79345703125\n",
      "Batch No.: 188, Loss: 0.7296247482299805, Accuracy: 0.770263671875\n",
      "Batch No.: 189, Loss: 0.5991102457046509, Accuracy: 0.808837890625\n",
      "Batch No.: 190, Loss: 0.7502216100692749, Accuracy: 0.759033203125\n",
      "Batch No.: 191, Loss: 0.7240139245986938, Accuracy: 0.769775390625\n",
      "Batch No.: 192, Loss: 0.5762507319450378, Accuracy: 0.810791015625\n",
      "Batch No.: 193, Loss: 0.7065166234970093, Accuracy: 0.76806640625\n",
      "Batch No.: 194, Loss: 0.6722486019134521, Accuracy: 0.785400390625\n",
      "Batch No.: 195, Loss: 0.5725311040878296, Accuracy: 0.821533203125\n",
      "Batch No.: 196, Loss: 0.6920444965362549, Accuracy: 0.77783203125\n",
      "Batch No.: 197, Loss: 0.6341714262962341, Accuracy: 0.797607421875\n",
      "Batch No.: 199, Loss: 0.6825961470603943, Accuracy: 0.780517578125\n",
      "Batch No.: 200, Loss: 0.6155152320861816, Accuracy: 0.810302734375\n",
      "Batch No.: 201, Loss: 0.6663848161697388, Accuracy: 0.792724609375\n",
      "Batch No.: 202, Loss: 0.6902069449424744, Accuracy: 0.77880859375\n",
      "Batch No.: 203, Loss: 0.6272633075714111, Accuracy: 0.79736328125\n",
      "Batch No.: 204, Loss: 0.6117395162582397, Accuracy: 0.80517578125\n",
      "Batch No.: 205, Loss: 0.628089964389801, Accuracy: 0.801025390625\n",
      "Batch No.: 206, Loss: 0.680678129196167, Accuracy: 0.78662109375\n",
      "Batch No.: 207, Loss: 0.623828649520874, Accuracy: 0.799560546875\n",
      "Batch No.: 208, Loss: 0.7269494533538818, Accuracy: 0.77490234375\n",
      "Batch No.: 209, Loss: 0.647838830947876, Accuracy: 0.79150390625\n",
      "Batch No.: 210, Loss: 0.6224784851074219, Accuracy: 0.801513671875\n",
      "Batch No.: 211, Loss: 0.6997597217559814, Accuracy: 0.774169921875\n",
      "Batch No.: 212, Loss: 0.6317710876464844, Accuracy: 0.799072265625\n",
      "Batch No.: 213, Loss: 0.6103999614715576, Accuracy: 0.80126953125\n",
      "Batch No.: 214, Loss: 0.6798408031463623, Accuracy: 0.78662109375\n",
      "Batch No.: 215, Loss: 0.6737111806869507, Accuracy: 0.78125\n",
      "Batch No.: 216, Loss: 0.614174485206604, Accuracy: 0.806884765625\n",
      "Batch No.: 217, Loss: 0.6369133591651917, Accuracy: 0.794189453125\n",
      "Batch No.: 218, Loss: 0.6546818017959595, Accuracy: 0.79296875\n",
      "Batch No.: 219, Loss: 0.7144774198532104, Accuracy: 0.774658203125\n",
      "Batch No.: 220, Loss: 0.7054128050804138, Accuracy: 0.783203125\n",
      "Batch No.: 224, Loss: 0.6316408514976501, Accuracy: 0.80224609375\n",
      "Batch No.: 225, Loss: 0.6735268831253052, Accuracy: 0.787109375\n",
      "Batch No.: 226, Loss: 0.6370970010757446, Accuracy: 0.797119140625\n",
      "Batch No.: 227, Loss: 0.593267560005188, Accuracy: 0.808837890625\n",
      "Batch No.: 228, Loss: 0.7363128066062927, Accuracy: 0.76025390625\n",
      "Batch No.: 229, Loss: 0.67454993724823, Accuracy: 0.783447265625\n",
      "Batch No.: 230, Loss: 0.6156939268112183, Accuracy: 0.807373046875\n",
      "Batch No.: 231, Loss: 0.6762784719467163, Accuracy: 0.792724609375\n",
      "Batch No.: 232, Loss: 0.6662610173225403, Accuracy: 0.78564453125\n",
      "Batch No.: 233, Loss: 0.6037935614585876, Accuracy: 0.80615234375\n",
      "Batch No.: 234, Loss: 0.7271106839179993, Accuracy: 0.773193359375\n",
      "Batch No.: 235, Loss: 0.659191906452179, Accuracy: 0.798095703125\n",
      "Batch No.: 236, Loss: 0.6643098592758179, Accuracy: 0.789306640625\n",
      "Batch No.: 237, Loss: 0.7326470613479614, Accuracy: 0.76904296875\n",
      "Batch No.: 238, Loss: 0.6802594661712646, Accuracy: 0.7900390625\n",
      "Batch No.: 239, Loss: 0.6220967769622803, Accuracy: 0.804443359375\n",
      "Batch No.: 240, Loss: 0.6484715342521667, Accuracy: 0.791015625\n",
      "Batch No.: 241, Loss: 0.6659603118896484, Accuracy: 0.786865234375\n",
      "Batch No.: 242, Loss: 0.6019036769866943, Accuracy: 0.8095703125\n",
      "Batch No.: 243, Loss: 0.6503949165344238, Accuracy: 0.796875\n",
      "Batch No.: 244, Loss: 0.6773796081542969, Accuracy: 0.779541015625\n",
      "Batch No.: 245, Loss: 0.5754786133766174, Accuracy: 0.81982421875\n",
      "Batch No.: 248, Loss: 0.645471453666687, Accuracy: 0.798583984375\n",
      "Batch No.: 249, Loss: 0.6908484697341919, Accuracy: 0.7841796875\n",
      "Batch No.: 250, Loss: 0.665447473526001, Accuracy: 0.788818359375\n",
      "Batch No.: 251, Loss: 0.6647701263427734, Accuracy: 0.78076171875\n",
      "Batch No.: 252, Loss: 0.6202924847602844, Accuracy: 0.80810546875\n",
      "Batch No.: 253, Loss: 0.6462354063987732, Accuracy: 0.798095703125\n",
      "Batch No.: 254, Loss: 0.6783980131149292, Accuracy: 0.7802734375\n",
      "Batch No.: 255, Loss: 0.6655739545822144, Accuracy: 0.787841796875\n",
      "Batch No.: 256, Loss: 0.6181073784828186, Accuracy: 0.81005859375\n",
      "Batch No.: 257, Loss: 0.6978864669799805, Accuracy: 0.77294921875\n",
      "Batch No.: 258, Loss: 0.6625910997390747, Accuracy: 0.786376953125\n",
      "Batch No.: 259, Loss: 0.5998903512954712, Accuracy: 0.80517578125\n",
      "Batch No.: 260, Loss: 0.6930633783340454, Accuracy: 0.77685546875\n",
      "Batch No.: 261, Loss: 0.6720635890960693, Accuracy: 0.7861328125\n",
      "Batch No.: 262, Loss: 0.5963107943534851, Accuracy: 0.8134765625\n",
      "Batch No.: 263, Loss: 0.6920509338378906, Accuracy: 0.78076171875\n",
      "Batch No.: 264, Loss: 0.5923990607261658, Accuracy: 0.8046875\n",
      "Saved weights computed at epoch 60 to Weights_60.h5\n",
      "Epoch 61/80\n",
      "Batch No.: 1, Loss: 1.0191893577575684, Accuracy: 0.72021484375\n",
      "Batch No.: 2, Loss: 0.5943900346755981, Accuracy: 0.811279296875\n",
      "Batch No.: 3, Loss: 0.6023387908935547, Accuracy: 0.802734375\n",
      "Batch No.: 4, Loss: 0.5943649411201477, Accuracy: 0.8095703125\n",
      "Batch No.: 5, Loss: 0.6615191698074341, Accuracy: 0.78076171875\n",
      "Batch No.: 7, Loss: 0.6206927299499512, Accuracy: 0.796875\n",
      "Batch No.: 8, Loss: 0.6751174926757812, Accuracy: 0.78564453125\n",
      "Batch No.: 9, Loss: 0.5247227549552917, Accuracy: 0.836181640625\n",
      "Batch No.: 10, Loss: 0.6250884532928467, Accuracy: 0.79931640625\n",
      "Batch No.: 11, Loss: 0.6201412677764893, Accuracy: 0.800537109375\n",
      "Batch No.: 12, Loss: 0.63853919506073, Accuracy: 0.802490234375\n",
      "Batch No.: 13, Loss: 0.6792418956756592, Accuracy: 0.785400390625\n",
      "Batch No.: 14, Loss: 0.6406487822532654, Accuracy: 0.789306640625\n",
      "Batch No.: 15, Loss: 0.682130753993988, Accuracy: 0.77978515625\n",
      "Batch No.: 16, Loss: 0.6063335537910461, Accuracy: 0.806396484375\n",
      "Batch No.: 17, Loss: 0.6512945890426636, Accuracy: 0.796142578125\n",
      "Batch No.: 18, Loss: 0.6957746744155884, Accuracy: 0.77978515625\n",
      "Batch No.: 19, Loss: 0.616714596748352, Accuracy: 0.811279296875\n",
      "Batch No.: 20, Loss: 0.6357108354568481, Accuracy: 0.802490234375\n",
      "Batch No.: 21, Loss: 0.6895788908004761, Accuracy: 0.7802734375\n",
      "Batch No.: 22, Loss: 0.6001614928245544, Accuracy: 0.80908203125\n",
      "Batch No.: 23, Loss: 0.5671752691268921, Accuracy: 0.82080078125\n",
      "Batch No.: 24, Loss: 0.7143309712409973, Accuracy: 0.776611328125\n",
      "Batch No.: 25, Loss: 0.7156304121017456, Accuracy: 0.76953125\n",
      "Batch No.: 26, Loss: 0.5762689113616943, Accuracy: 0.812744140625\n",
      "Batch No.: 27, Loss: 0.6710288524627686, Accuracy: 0.790771484375\n",
      "Batch No.: 28, Loss: 0.665108323097229, Accuracy: 0.794189453125\n",
      "Batch No.: 29, Loss: 0.5448519587516785, Accuracy: 0.827392578125\n",
      "Batch No.: 32, Loss: 0.5625499486923218, Accuracy: 0.818603515625\n",
      "Batch No.: 33, Loss: 0.63874351978302, Accuracy: 0.7978515625\n",
      "Batch No.: 34, Loss: 0.6554197072982788, Accuracy: 0.79052734375\n",
      "Batch No.: 35, Loss: 0.5906713008880615, Accuracy: 0.814453125\n",
      "Batch No.: 36, Loss: 0.6312302350997925, Accuracy: 0.800048828125\n",
      "Batch No.: 37, Loss: 0.6808793544769287, Accuracy: 0.781005859375\n",
      "Batch No.: 38, Loss: 0.6590740084648132, Accuracy: 0.798583984375\n",
      "Batch No.: 39, Loss: 0.5833797454833984, Accuracy: 0.812255859375\n",
      "Batch No.: 40, Loss: 0.6456012725830078, Accuracy: 0.790283203125\n",
      "Batch No.: 41, Loss: 0.712500274181366, Accuracy: 0.767822265625\n",
      "Batch No.: 42, Loss: 0.6263896822929382, Accuracy: 0.7998046875\n",
      "Batch No.: 43, Loss: 0.6267428994178772, Accuracy: 0.801025390625\n",
      "Batch No.: 44, Loss: 0.6578378677368164, Accuracy: 0.783203125\n",
      "Batch No.: 45, Loss: 0.6230325698852539, Accuracy: 0.80810546875\n",
      "Batch No.: 46, Loss: 0.5756235122680664, Accuracy: 0.81591796875\n",
      "Batch No.: 47, Loss: 0.6795682907104492, Accuracy: 0.787353515625\n",
      "Batch No.: 48, Loss: 0.5973085165023804, Accuracy: 0.8056640625\n",
      "Batch No.: 49, Loss: 0.6291068196296692, Accuracy: 0.7958984375\n",
      "Batch No.: 50, Loss: 0.666342556476593, Accuracy: 0.782470703125\n",
      "Batch No.: 51, Loss: 0.6541067957878113, Accuracy: 0.795654296875\n",
      "Batch No.: 52, Loss: 0.6426767706871033, Accuracy: 0.796630859375\n",
      "Batch No.: 53, Loss: 0.5985839366912842, Accuracy: 0.810302734375\n",
      "Batch No.: 54, Loss: 0.6957295536994934, Accuracy: 0.7734375\n",
      "Batch No.: 56, Loss: 0.6250050067901611, Accuracy: 0.802978515625\n",
      "Batch No.: 57, Loss: 0.6643720865249634, Accuracy: 0.78466796875\n",
      "Batch No.: 58, Loss: 0.596909761428833, Accuracy: 0.808837890625\n",
      "Batch No.: 59, Loss: 0.6373299360275269, Accuracy: 0.79345703125\n",
      "Batch No.: 60, Loss: 0.6355866193771362, Accuracy: 0.7939453125\n",
      "Batch No.: 61, Loss: 0.6073449850082397, Accuracy: 0.803466796875\n",
      "Batch No.: 62, Loss: 0.6627238392829895, Accuracy: 0.794189453125\n",
      "Batch No.: 63, Loss: 0.6104725003242493, Accuracy: 0.803955078125\n",
      "Batch No.: 64, Loss: 0.6478872299194336, Accuracy: 0.791748046875\n",
      "Batch No.: 65, Loss: 0.7254956364631653, Accuracy: 0.762451171875\n",
      "Batch No.: 66, Loss: 0.6103575229644775, Accuracy: 0.8056640625\n",
      "Batch No.: 67, Loss: 0.6046806573867798, Accuracy: 0.810302734375\n",
      "Batch No.: 68, Loss: 0.6876190900802612, Accuracy: 0.780517578125\n",
      "Batch No.: 69, Loss: 0.6622627973556519, Accuracy: 0.79248046875\n",
      "Batch No.: 70, Loss: 0.5979599356651306, Accuracy: 0.804931640625\n",
      "Batch No.: 71, Loss: 0.6666812896728516, Accuracy: 0.784423828125\n",
      "Batch No.: 72, Loss: 0.63253253698349, Accuracy: 0.806640625\n",
      "Batch No.: 73, Loss: 0.6569795608520508, Accuracy: 0.787841796875\n",
      "Batch No.: 74, Loss: 0.629048764705658, Accuracy: 0.796142578125\n",
      "Batch No.: 75, Loss: 0.6432534456253052, Accuracy: 0.7998046875\n",
      "Batch No.: 76, Loss: 0.6399153470993042, Accuracy: 0.79638671875\n",
      "Batch No.: 77, Loss: 0.6783950328826904, Accuracy: 0.78076171875\n",
      "Batch No.: 80, Loss: 0.6822739243507385, Accuracy: 0.7841796875\n",
      "Batch No.: 81, Loss: 0.6817663908004761, Accuracy: 0.784423828125\n",
      "Batch No.: 82, Loss: 0.6499590873718262, Accuracy: 0.7919921875\n",
      "Batch No.: 83, Loss: 0.5966061353683472, Accuracy: 0.812744140625\n",
      "Batch No.: 84, Loss: 0.6896438598632812, Accuracy: 0.77880859375\n",
      "Batch No.: 85, Loss: 0.6455950140953064, Accuracy: 0.80126953125\n",
      "Batch No.: 86, Loss: 0.584927499294281, Accuracy: 0.813720703125\n",
      "Batch No.: 87, Loss: 0.5872021913528442, Accuracy: 0.8076171875\n",
      "Batch No.: 88, Loss: 0.635898232460022, Accuracy: 0.798583984375\n",
      "Batch No.: 89, Loss: 0.593306303024292, Accuracy: 0.813232421875\n",
      "Batch No.: 90, Loss: 0.6003562808036804, Accuracy: 0.81298828125\n",
      "Batch No.: 91, Loss: 0.6024425029754639, Accuracy: 0.816162109375\n",
      "Batch No.: 92, Loss: 0.6191748976707458, Accuracy: 0.803466796875\n",
      "Batch No.: 93, Loss: 0.649126410484314, Accuracy: 0.794677734375\n",
      "Batch No.: 94, Loss: 0.6767270565032959, Accuracy: 0.7880859375\n",
      "Batch No.: 95, Loss: 0.6987942457199097, Accuracy: 0.78173828125\n",
      "Batch No.: 96, Loss: 0.6113977432250977, Accuracy: 0.8037109375\n",
      "Batch No.: 97, Loss: 0.6452479362487793, Accuracy: 0.791015625\n",
      "Batch No.: 98, Loss: 0.6393082141876221, Accuracy: 0.796875\n",
      "Batch No.: 99, Loss: 0.6635127067565918, Accuracy: 0.789794921875\n",
      "Batch No.: 100, Loss: 0.6538069248199463, Accuracy: 0.784912109375\n",
      "Batch No.: 101, Loss: 0.5815843939781189, Accuracy: 0.80908203125\n",
      "Batch No.: 102, Loss: 0.687223494052887, Accuracy: 0.781005859375\n",
      "Batch No.: 105, Loss: 0.6708993911743164, Accuracy: 0.77783203125\n",
      "Batch No.: 106, Loss: 0.6463226079940796, Accuracy: 0.78857421875\n",
      "Batch No.: 107, Loss: 0.6161895990371704, Accuracy: 0.80322265625\n",
      "Batch No.: 108, Loss: 0.624380886554718, Accuracy: 0.802734375\n",
      "Batch No.: 109, Loss: 0.6716419458389282, Accuracy: 0.78564453125\n",
      "Batch No.: 110, Loss: 0.6266741156578064, Accuracy: 0.80029296875\n",
      "Batch No.: 111, Loss: 0.6014179587364197, Accuracy: 0.80517578125\n",
      "Batch No.: 112, Loss: 0.5995837450027466, Accuracy: 0.807861328125\n",
      "Batch No.: 113, Loss: 0.6571499109268188, Accuracy: 0.7841796875\n",
      "Batch No.: 114, Loss: 0.6724162697792053, Accuracy: 0.784423828125\n",
      "Batch No.: 115, Loss: 0.6450971364974976, Accuracy: 0.802978515625\n",
      "Batch No.: 116, Loss: 0.7047237157821655, Accuracy: 0.783447265625\n",
      "Batch No.: 117, Loss: 0.6229342222213745, Accuracy: 0.79931640625\n",
      "Batch No.: 118, Loss: 0.6365750432014465, Accuracy: 0.79736328125\n",
      "Batch No.: 119, Loss: 0.6485945582389832, Accuracy: 0.7958984375\n",
      "Batch No.: 120, Loss: 0.6741873025894165, Accuracy: 0.78564453125\n",
      "Batch No.: 121, Loss: 0.6733591556549072, Accuracy: 0.792724609375\n",
      "Batch No.: 122, Loss: 0.6990930438041687, Accuracy: 0.77197265625\n",
      "Batch No.: 123, Loss: 0.7284243106842041, Accuracy: 0.774169921875\n",
      "Batch No.: 124, Loss: 0.6574693322181702, Accuracy: 0.790771484375\n",
      "Batch No.: 125, Loss: 0.6864148378372192, Accuracy: 0.7783203125\n",
      "Batch No.: 126, Loss: 0.645928144454956, Accuracy: 0.7939453125\n",
      "Batch No.: 127, Loss: 0.6267569661140442, Accuracy: 0.80712890625\n",
      "Batch No.: 130, Loss: 0.66032874584198, Accuracy: 0.796630859375\n",
      "Batch No.: 131, Loss: 0.6867740154266357, Accuracy: 0.78515625\n",
      "Batch No.: 132, Loss: 0.7589086294174194, Accuracy: 0.760986328125\n",
      "Batch No.: 133, Loss: 0.6623329520225525, Accuracy: 0.7939453125\n",
      "Batch No.: 134, Loss: 0.6391414403915405, Accuracy: 0.798828125\n",
      "Batch No.: 135, Loss: 0.6920479536056519, Accuracy: 0.78125\n",
      "Batch No.: 136, Loss: 0.6302468776702881, Accuracy: 0.80322265625\n",
      "Batch No.: 137, Loss: 0.6336345672607422, Accuracy: 0.79736328125\n",
      "Batch No.: 138, Loss: 0.7039620280265808, Accuracy: 0.7763671875\n",
      "Batch No.: 139, Loss: 0.6668040156364441, Accuracy: 0.792236328125\n",
      "Batch No.: 140, Loss: 0.6549383401870728, Accuracy: 0.78662109375\n",
      "Batch No.: 141, Loss: 0.72150719165802, Accuracy: 0.77880859375\n",
      "Batch No.: 142, Loss: 0.7696548700332642, Accuracy: 0.759521484375\n",
      "Batch No.: 143, Loss: 0.6575418710708618, Accuracy: 0.790283203125\n",
      "Batch No.: 144, Loss: 0.6918531656265259, Accuracy: 0.77978515625\n",
      "Batch No.: 145, Loss: 0.6777148246765137, Accuracy: 0.783203125\n",
      "Batch No.: 146, Loss: 0.6662288904190063, Accuracy: 0.77783203125\n",
      "Batch No.: 147, Loss: 0.6770206689834595, Accuracy: 0.78369140625\n",
      "Batch No.: 148, Loss: 0.6324464678764343, Accuracy: 0.795654296875\n",
      "Batch No.: 149, Loss: 0.6527395844459534, Accuracy: 0.794677734375\n",
      "Batch No.: 150, Loss: 0.6957875490188599, Accuracy: 0.779052734375\n",
      "Batch No.: 153, Loss: 0.6696408987045288, Accuracy: 0.78515625\n",
      "Batch No.: 154, Loss: 0.640694260597229, Accuracy: 0.786376953125\n",
      "Batch No.: 155, Loss: 0.5871483087539673, Accuracy: 0.810546875\n",
      "Batch No.: 156, Loss: 0.6712963581085205, Accuracy: 0.785400390625\n",
      "Batch No.: 157, Loss: 0.6175001859664917, Accuracy: 0.8017578125\n",
      "Batch No.: 158, Loss: 0.6648398637771606, Accuracy: 0.79150390625\n",
      "Batch No.: 159, Loss: 0.6660740971565247, Accuracy: 0.785400390625\n",
      "Batch No.: 160, Loss: 0.6840642094612122, Accuracy: 0.77734375\n",
      "Batch No.: 161, Loss: 0.6892184615135193, Accuracy: 0.779052734375\n",
      "Batch No.: 162, Loss: 0.6928607821464539, Accuracy: 0.777587890625\n",
      "Batch No.: 163, Loss: 0.631342351436615, Accuracy: 0.796142578125\n",
      "Batch No.: 164, Loss: 0.715975284576416, Accuracy: 0.770263671875\n",
      "Batch No.: 165, Loss: 0.6327608227729797, Accuracy: 0.79931640625\n",
      "Batch No.: 166, Loss: 0.6096276640892029, Accuracy: 0.80615234375\n",
      "Batch No.: 167, Loss: 0.7628814578056335, Accuracy: 0.76220703125\n",
      "Batch No.: 168, Loss: 0.6549965143203735, Accuracy: 0.786865234375\n",
      "Batch No.: 169, Loss: 0.6624886989593506, Accuracy: 0.78564453125\n",
      "Batch No.: 170, Loss: 0.7435866594314575, Accuracy: 0.763427734375\n",
      "Batch No.: 171, Loss: 0.7306053042411804, Accuracy: 0.7802734375\n",
      "Batch No.: 172, Loss: 0.6772714257240295, Accuracy: 0.792236328125\n",
      "Batch No.: 173, Loss: 0.6905901432037354, Accuracy: 0.77294921875\n",
      "Batch No.: 174, Loss: 0.70023512840271, Accuracy: 0.783447265625\n",
      "Batch No.: 175, Loss: 0.6115125417709351, Accuracy: 0.80859375\n",
      "Batch No.: 176, Loss: 0.7217893004417419, Accuracy: 0.77099609375\n",
      "Batch No.: 177, Loss: 0.6877329349517822, Accuracy: 0.781982421875\n",
      "Batch No.: 178, Loss: 0.6431090235710144, Accuracy: 0.793212890625\n",
      "Batch No.: 179, Loss: 0.6469339728355408, Accuracy: 0.796875\n",
      "Batch No.: 180, Loss: 0.683404803276062, Accuracy: 0.7890625\n",
      "Batch No.: 181, Loss: 0.6196273565292358, Accuracy: 0.806884765625\n",
      "Batch No.: 182, Loss: 0.6705609560012817, Accuracy: 0.78662109375\n",
      "Batch No.: 183, Loss: 0.624485969543457, Accuracy: 0.7998046875\n",
      "Batch No.: 184, Loss: 0.6565306186676025, Accuracy: 0.795654296875\n",
      "Batch No.: 185, Loss: 0.6894313097000122, Accuracy: 0.783447265625\n",
      "Batch No.: 186, Loss: 0.636669397354126, Accuracy: 0.790771484375\n",
      "Batch No.: 187, Loss: 0.6355253458023071, Accuracy: 0.794189453125\n",
      "Batch No.: 188, Loss: 0.7266618609428406, Accuracy: 0.7734375\n",
      "Batch No.: 189, Loss: 0.601273238658905, Accuracy: 0.8056640625\n",
      "Batch No.: 190, Loss: 0.7416237592697144, Accuracy: 0.764892578125\n",
      "Batch No.: 191, Loss: 0.7143906354904175, Accuracy: 0.7734375\n",
      "Batch No.: 192, Loss: 0.5497359037399292, Accuracy: 0.827880859375\n",
      "Batch No.: 193, Loss: 0.6940504312515259, Accuracy: 0.773193359375\n",
      "Batch No.: 194, Loss: 0.6763315200805664, Accuracy: 0.78466796875\n",
      "Batch No.: 195, Loss: 0.5820397138595581, Accuracy: 0.815185546875\n",
      "Batch No.: 196, Loss: 0.6716760993003845, Accuracy: 0.78515625\n",
      "Batch No.: 197, Loss: 0.6212084293365479, Accuracy: 0.798095703125\n",
      "Batch No.: 198, Loss: 0.5710808634757996, Accuracy: 0.809814453125\n",
      "Batch No.: 199, Loss: 0.6845543384552002, Accuracy: 0.77783203125\n",
      "Batch No.: 200, Loss: 0.6073057651519775, Accuracy: 0.8134765625\n",
      "Batch No.: 201, Loss: 0.6594643592834473, Accuracy: 0.790771484375\n",
      "Batch No.: 202, Loss: 0.6941485404968262, Accuracy: 0.780029296875\n",
      "Batch No.: 203, Loss: 0.6184515953063965, Accuracy: 0.800048828125\n",
      "Batch No.: 204, Loss: 0.6014071702957153, Accuracy: 0.805419921875\n",
      "Batch No.: 205, Loss: 0.6106325387954712, Accuracy: 0.804931640625\n",
      "Batch No.: 206, Loss: 0.6755852699279785, Accuracy: 0.7841796875\n",
      "Batch No.: 207, Loss: 0.6230230331420898, Accuracy: 0.80322265625\n",
      "Batch No.: 208, Loss: 0.7235422134399414, Accuracy: 0.77099609375\n",
      "Batch No.: 209, Loss: 0.6476603746414185, Accuracy: 0.799072265625\n",
      "Batch No.: 210, Loss: 0.6117599010467529, Accuracy: 0.80517578125\n",
      "Batch No.: 211, Loss: 0.6931658983230591, Accuracy: 0.776123046875\n",
      "Batch No.: 212, Loss: 0.6214503645896912, Accuracy: 0.80615234375\n",
      "Batch No.: 213, Loss: 0.600553035736084, Accuracy: 0.808349609375\n",
      "Batch No.: 214, Loss: 0.6565374732017517, Accuracy: 0.78759765625\n",
      "Batch No.: 215, Loss: 0.6711733937263489, Accuracy: 0.7890625\n",
      "Batch No.: 216, Loss: 0.6034120917320251, Accuracy: 0.803955078125\n",
      "Batch No.: 217, Loss: 0.651275634765625, Accuracy: 0.7978515625\n",
      "Batch No.: 218, Loss: 0.6499281525611877, Accuracy: 0.79541015625\n",
      "Batch No.: 219, Loss: 0.700953483581543, Accuracy: 0.7763671875\n",
      "Batch No.: 220, Loss: 0.6844869256019592, Accuracy: 0.7783203125\n",
      "Batch No.: 221, Loss: 0.6709271669387817, Accuracy: 0.786865234375\n",
      "Batch No.: 222, Loss: 0.6931551694869995, Accuracy: 0.779296875\n",
      "Batch No.: 223, Loss: 0.6478054523468018, Accuracy: 0.79443359375\n",
      "Batch No.: 224, Loss: 0.6244360208511353, Accuracy: 0.800048828125\n",
      "Batch No.: 225, Loss: 0.647421658039093, Accuracy: 0.791259765625\n",
      "Batch No.: 226, Loss: 0.6199694871902466, Accuracy: 0.801025390625\n",
      "Batch No.: 227, Loss: 0.6005529165267944, Accuracy: 0.812744140625\n",
      "Batch No.: 228, Loss: 0.7222909927368164, Accuracy: 0.768798828125\n",
      "Batch No.: 229, Loss: 0.6567350029945374, Accuracy: 0.79248046875\n",
      "Batch No.: 230, Loss: 0.604629635810852, Accuracy: 0.801513671875\n",
      "Batch No.: 231, Loss: 0.6768958568572998, Accuracy: 0.785400390625\n",
      "Batch No.: 232, Loss: 0.6679645776748657, Accuracy: 0.7939453125\n",
      "Batch No.: 233, Loss: 0.6062865257263184, Accuracy: 0.8037109375\n",
      "Batch No.: 234, Loss: 0.714930534362793, Accuracy: 0.77587890625\n",
      "Batch No.: 235, Loss: 0.6441982984542847, Accuracy: 0.7978515625\n",
      "Batch No.: 236, Loss: 0.6478051543235779, Accuracy: 0.7939453125\n",
      "Batch No.: 237, Loss: 0.7456039786338806, Accuracy: 0.765625\n",
      "Batch No.: 238, Loss: 0.6494221687316895, Accuracy: 0.793212890625\n",
      "Batch No.: 239, Loss: 0.6111919283866882, Accuracy: 0.79931640625\n",
      "Batch No.: 240, Loss: 0.6653929948806763, Accuracy: 0.787841796875\n",
      "Batch No.: 241, Loss: 0.6588220000267029, Accuracy: 0.789306640625\n",
      "Batch No.: 242, Loss: 0.5956167578697205, Accuracy: 0.803955078125\n",
      "Batch No.: 243, Loss: 0.6615574359893799, Accuracy: 0.787353515625\n",
      "Batch No.: 244, Loss: 0.6764103174209595, Accuracy: 0.784423828125\n",
      "Batch No.: 245, Loss: 0.5837850570678711, Accuracy: 0.812744140625\n",
      "Batch No.: 246, Loss: 0.6008166074752808, Accuracy: 0.810546875\n",
      "Batch No.: 247, Loss: 0.6380788087844849, Accuracy: 0.794189453125\n",
      "Batch No.: 248, Loss: 0.6633807420730591, Accuracy: 0.793212890625\n",
      "Batch No.: 250, Loss: 0.6486820578575134, Accuracy: 0.79248046875\n",
      "Batch No.: 251, Loss: 0.6466892957687378, Accuracy: 0.79345703125\n",
      "Batch No.: 252, Loss: 0.6044290661811829, Accuracy: 0.81201171875\n",
      "Batch No.: 253, Loss: 0.6400570273399353, Accuracy: 0.79541015625\n",
      "Batch No.: 254, Loss: 0.658063530921936, Accuracy: 0.786865234375\n",
      "Batch No.: 255, Loss: 0.6683381199836731, Accuracy: 0.784423828125\n",
      "Batch No.: 256, Loss: 0.6112759113311768, Accuracy: 0.8037109375\n",
      "Batch No.: 257, Loss: 0.6861012578010559, Accuracy: 0.7783203125\n",
      "Batch No.: 258, Loss: 0.6428648829460144, Accuracy: 0.79638671875\n",
      "Batch No.: 259, Loss: 0.5943832993507385, Accuracy: 0.80810546875\n",
      "Batch No.: 260, Loss: 0.6835165023803711, Accuracy: 0.78955078125\n",
      "Batch No.: 261, Loss: 0.6691900491714478, Accuracy: 0.783935546875\n",
      "Batch No.: 262, Loss: 0.585756778717041, Accuracy: 0.812744140625\n",
      "Batch No.: 263, Loss: 0.6844384670257568, Accuracy: 0.78369140625\n",
      "Batch No.: 264, Loss: 0.5901859998703003, Accuracy: 0.802978515625\n",
      "Epoch 62/80\n",
      "Batch No.: 1, Loss: 1.0315814018249512, Accuracy: 0.718505859375\n",
      "Batch No.: 2, Loss: 0.5827736854553223, Accuracy: 0.813720703125\n",
      "Batch No.: 3, Loss: 0.5821316242218018, Accuracy: 0.8115234375\n",
      "Batch No.: 4, Loss: 0.5924249887466431, Accuracy: 0.809814453125\n",
      "Batch No.: 5, Loss: 0.6566991806030273, Accuracy: 0.786376953125\n",
      "Batch No.: 6, Loss: 0.5872162580490112, Accuracy: 0.810791015625\n",
      "Batch No.: 7, Loss: 0.6084187030792236, Accuracy: 0.80419921875\n",
      "Batch No.: 8, Loss: 0.6670045256614685, Accuracy: 0.784912109375\n",
      "Batch No.: 9, Loss: 0.5022393465042114, Accuracy: 0.839111328125\n",
      "Batch No.: 13, Loss: 0.6689611673355103, Accuracy: 0.786865234375\n",
      "Batch No.: 14, Loss: 0.6485726237297058, Accuracy: 0.790283203125\n",
      "Batch No.: 15, Loss: 0.6691403985023499, Accuracy: 0.790283203125\n",
      "Batch No.: 16, Loss: 0.6025591492652893, Accuracy: 0.808349609375\n",
      "Batch No.: 17, Loss: 0.6571513414382935, Accuracy: 0.78515625\n",
      "Batch No.: 18, Loss: 0.6756625175476074, Accuracy: 0.779296875\n",
      "Batch No.: 19, Loss: 0.5957384705543518, Accuracy: 0.80615234375\n",
      "Batch No.: 20, Loss: 0.6077786684036255, Accuracy: 0.803466796875\n",
      "Batch No.: 21, Loss: 0.679883599281311, Accuracy: 0.7802734375\n",
      "Batch No.: 22, Loss: 0.6151638031005859, Accuracy: 0.803955078125\n",
      "Batch No.: 23, Loss: 0.5636163949966431, Accuracy: 0.821533203125\n",
      "Batch No.: 24, Loss: 0.7187989354133606, Accuracy: 0.771728515625\n",
      "Batch No.: 25, Loss: 0.7115639448165894, Accuracy: 0.77294921875\n",
      "Batch No.: 26, Loss: 0.5635236501693726, Accuracy: 0.820068359375\n",
      "Batch No.: 27, Loss: 0.6781533360481262, Accuracy: 0.78759765625\n",
      "Batch No.: 28, Loss: 0.6473458409309387, Accuracy: 0.795166015625\n",
      "Batch No.: 29, Loss: 0.5442714691162109, Accuracy: 0.817138671875\n",
      "Batch No.: 30, Loss: 0.7058802843093872, Accuracy: 0.77099609375\n",
      "Batch No.: 31, Loss: 0.6744285821914673, Accuracy: 0.785400390625\n",
      "Batch No.: 32, Loss: 0.5479588508605957, Accuracy: 0.8271484375\n",
      "Batch No.: 33, Loss: 0.6282349824905396, Accuracy: 0.79150390625\n",
      "Batch No.: 34, Loss: 0.6690845489501953, Accuracy: 0.78369140625\n",
      "Batch No.: 35, Loss: 0.5892248153686523, Accuracy: 0.807861328125\n",
      "Batch No.: 36, Loss: 0.6220541000366211, Accuracy: 0.79345703125\n",
      "Batch No.: 37, Loss: 0.669651985168457, Accuracy: 0.78466796875\n",
      "Batch No.: 38, Loss: 0.668622612953186, Accuracy: 0.7900390625\n",
      "Batch No.: 39, Loss: 0.5782430171966553, Accuracy: 0.815673828125\n",
      "Batch No.: 40, Loss: 0.6428655385971069, Accuracy: 0.79248046875\n",
      "Batch No.: 41, Loss: 0.6922526359558105, Accuracy: 0.783203125\n",
      "Batch No.: 42, Loss: 0.6219736933708191, Accuracy: 0.80419921875\n",
      "Batch No.: 43, Loss: 0.6202436685562134, Accuracy: 0.800537109375\n",
      "Batch No.: 44, Loss: 0.6618063449859619, Accuracy: 0.790283203125\n",
      "Batch No.: 45, Loss: 0.6197871565818787, Accuracy: 0.8017578125\n",
      "Batch No.: 46, Loss: 0.58968186378479, Accuracy: 0.813720703125\n",
      "Batch No.: 47, Loss: 0.6907349824905396, Accuracy: 0.7802734375\n",
      "Batch No.: 48, Loss: 0.6040298342704773, Accuracy: 0.8017578125\n",
      "Batch No.: 49, Loss: 0.644274115562439, Accuracy: 0.78955078125\n",
      "Batch No.: 50, Loss: 0.6675374507904053, Accuracy: 0.794189453125\n",
      "Batch No.: 51, Loss: 0.635476291179657, Accuracy: 0.79736328125\n",
      "Batch No.: 52, Loss: 0.6436092853546143, Accuracy: 0.796630859375\n",
      "Batch No.: 53, Loss: 0.6056873798370361, Accuracy: 0.807373046875\n",
      "Batch No.: 54, Loss: 0.7070547342300415, Accuracy: 0.771484375\n",
      "Batch No.: 55, Loss: 0.6693606376647949, Accuracy: 0.791259765625\n",
      "Batch No.: 56, Loss: 0.6182130575180054, Accuracy: 0.801513671875\n",
      "Batch No.: 57, Loss: 0.6598457098007202, Accuracy: 0.791259765625\n",
      "Batch No.: 58, Loss: 0.601403534412384, Accuracy: 0.8095703125\n",
      "Batch No.: 60, Loss: 0.6423958539962769, Accuracy: 0.7978515625\n",
      "Batch No.: 61, Loss: 0.6097966432571411, Accuracy: 0.80615234375\n",
      "Batch No.: 62, Loss: 0.6490603685379028, Accuracy: 0.79296875\n",
      "Batch No.: 63, Loss: 0.6129074692726135, Accuracy: 0.804443359375\n",
      "Batch No.: 64, Loss: 0.6601783037185669, Accuracy: 0.78662109375\n",
      "Batch No.: 65, Loss: 0.7285455465316772, Accuracy: 0.76171875\n",
      "Batch No.: 66, Loss: 0.5992804169654846, Accuracy: 0.814697265625\n",
      "Batch No.: 67, Loss: 0.5821760892868042, Accuracy: 0.816162109375\n",
      "Batch No.: 68, Loss: 0.6871998310089111, Accuracy: 0.78173828125\n",
      "Batch No.: 69, Loss: 0.6661543250083923, Accuracy: 0.7890625\n",
      "Batch No.: 70, Loss: 0.5851932764053345, Accuracy: 0.810546875\n",
      "Batch No.: 71, Loss: 0.6808673739433289, Accuracy: 0.784423828125\n",
      "Batch No.: 72, Loss: 0.6435205340385437, Accuracy: 0.792724609375\n",
      "Batch No.: 73, Loss: 0.6590208411216736, Accuracy: 0.78857421875\n",
      "Batch No.: 74, Loss: 0.6295671463012695, Accuracy: 0.79345703125\n",
      "Batch No.: 75, Loss: 0.6399167776107788, Accuracy: 0.79248046875\n",
      "Batch No.: 76, Loss: 0.6408634185791016, Accuracy: 0.79345703125\n",
      "Batch No.: 77, Loss: 0.6638715267181396, Accuracy: 0.792724609375\n",
      "Batch No.: 78, Loss: 0.6259242296218872, Accuracy: 0.802490234375\n",
      "Batch No.: 79, Loss: 0.6218774914741516, Accuracy: 0.805908203125\n",
      "Batch No.: 80, Loss: 0.6703991889953613, Accuracy: 0.78564453125\n",
      "Batch No.: 81, Loss: 0.6743147373199463, Accuracy: 0.78759765625\n",
      "Batch No.: 83, Loss: 0.5906459093093872, Accuracy: 0.815673828125\n",
      "Batch No.: 84, Loss: 0.6769095659255981, Accuracy: 0.785400390625\n",
      "Batch No.: 85, Loss: 0.6443219184875488, Accuracy: 0.800048828125\n",
      "Batch No.: 86, Loss: 0.5928077101707458, Accuracy: 0.8076171875\n",
      "Batch No.: 87, Loss: 0.5809667110443115, Accuracy: 0.814453125\n",
      "Batch No.: 88, Loss: 0.6225625276565552, Accuracy: 0.800537109375\n",
      "Batch No.: 89, Loss: 0.606209397315979, Accuracy: 0.8076171875\n",
      "Batch No.: 90, Loss: 0.5899940729141235, Accuracy: 0.816650390625\n",
      "Batch No.: 91, Loss: 0.6174883842468262, Accuracy: 0.812255859375\n",
      "Batch No.: 92, Loss: 0.5970978736877441, Accuracy: 0.8037109375\n",
      "Batch No.: 93, Loss: 0.6472808122634888, Accuracy: 0.7958984375\n",
      "Batch No.: 94, Loss: 0.6537145376205444, Accuracy: 0.794677734375\n",
      "Batch No.: 95, Loss: 0.6722754240036011, Accuracy: 0.7880859375\n",
      "Batch No.: 96, Loss: 0.5980739593505859, Accuracy: 0.808837890625\n",
      "Batch No.: 97, Loss: 0.6345709562301636, Accuracy: 0.79736328125\n",
      "Batch No.: 98, Loss: 0.6439521312713623, Accuracy: 0.803466796875\n",
      "Batch No.: 99, Loss: 0.6719533801078796, Accuracy: 0.782470703125\n",
      "Batch No.: 100, Loss: 0.6558239459991455, Accuracy: 0.7900390625\n",
      "Batch No.: 101, Loss: 0.5878295302391052, Accuracy: 0.810546875\n",
      "Batch No.: 102, Loss: 0.6787976026535034, Accuracy: 0.783203125\n",
      "Batch No.: 103, Loss: 0.6516638994216919, Accuracy: 0.7919921875\n",
      "Batch No.: 104, Loss: 0.6377793550491333, Accuracy: 0.802978515625\n",
      "Batch No.: 105, Loss: 0.6792534589767456, Accuracy: 0.78515625\n",
      "Batch No.: 106, Loss: 0.6666194200515747, Accuracy: 0.7783203125\n",
      "Batch No.: 107, Loss: 0.622286319732666, Accuracy: 0.802978515625\n",
      "Batch No.: 108, Loss: 0.6275496482849121, Accuracy: 0.797607421875\n",
      "Batch No.: 109, Loss: 0.6729857921600342, Accuracy: 0.781494140625\n",
      "Batch No.: 110, Loss: 0.6219753623008728, Accuracy: 0.800048828125\n",
      "Batch No.: 111, Loss: 0.625523567199707, Accuracy: 0.80126953125\n",
      "Batch No.: 112, Loss: 0.5900337100028992, Accuracy: 0.814208984375\n",
      "Batch No.: 113, Loss: 0.6666864156723022, Accuracy: 0.784423828125\n",
      "Batch No.: 114, Loss: 0.6626821756362915, Accuracy: 0.787841796875\n",
      "Batch No.: 115, Loss: 0.6409523487091064, Accuracy: 0.796630859375\n",
      "Batch No.: 116, Loss: 0.6926422119140625, Accuracy: 0.78369140625\n",
      "Batch No.: 117, Loss: 0.6020864844322205, Accuracy: 0.811767578125\n",
      "Batch No.: 118, Loss: 0.6369606256484985, Accuracy: 0.7939453125\n",
      "Batch No.: 119, Loss: 0.649242103099823, Accuracy: 0.790771484375\n",
      "Batch No.: 120, Loss: 0.6820191740989685, Accuracy: 0.785888671875\n",
      "Batch No.: 121, Loss: 0.6540499329566956, Accuracy: 0.7919921875\n",
      "Batch No.: 122, Loss: 0.6987468004226685, Accuracy: 0.778564453125\n",
      "Batch No.: 123, Loss: 0.7236112952232361, Accuracy: 0.7744140625\n",
      "Batch No.: 124, Loss: 0.6658191680908203, Accuracy: 0.78662109375\n",
      "Batch No.: 125, Loss: 0.6788387298583984, Accuracy: 0.7861328125\n",
      "Batch No.: 126, Loss: 0.6503286361694336, Accuracy: 0.784912109375\n",
      "Batch No.: 127, Loss: 0.6350738406181335, Accuracy: 0.79296875\n",
      "Batch No.: 128, Loss: 0.6205605268478394, Accuracy: 0.8056640625\n",
      "Batch No.: 130, Loss: 0.6818109154701233, Accuracy: 0.784423828125\n",
      "Batch No.: 131, Loss: 0.6637579202651978, Accuracy: 0.785400390625\n",
      "Batch No.: 132, Loss: 0.7336001396179199, Accuracy: 0.76953125\n",
      "Batch No.: 133, Loss: 0.6434138417243958, Accuracy: 0.798583984375\n",
      "Batch No.: 134, Loss: 0.6506539583206177, Accuracy: 0.793701171875\n",
      "Batch No.: 135, Loss: 0.6962496638298035, Accuracy: 0.77294921875\n",
      "Batch No.: 136, Loss: 0.6152709126472473, Accuracy: 0.805419921875\n",
      "Batch No.: 137, Loss: 0.6237043142318726, Accuracy: 0.80712890625\n",
      "Batch No.: 138, Loss: 0.6924616098403931, Accuracy: 0.77978515625\n",
      "Batch No.: 139, Loss: 0.6629257202148438, Accuracy: 0.795654296875\n",
      "Batch No.: 140, Loss: 0.6564274430274963, Accuracy: 0.7841796875\n",
      "Batch No.: 141, Loss: 0.7295413017272949, Accuracy: 0.776123046875\n",
      "Batch No.: 142, Loss: 0.7826979160308838, Accuracy: 0.752197265625\n",
      "Batch No.: 143, Loss: 0.644957423210144, Accuracy: 0.79345703125\n",
      "Batch No.: 144, Loss: 0.6825286149978638, Accuracy: 0.777099609375\n",
      "Batch No.: 145, Loss: 0.6840155124664307, Accuracy: 0.775146484375\n",
      "Batch No.: 146, Loss: 0.6390414237976074, Accuracy: 0.790771484375\n",
      "Batch No.: 147, Loss: 0.6902139186859131, Accuracy: 0.77685546875\n",
      "Batch No.: 148, Loss: 0.6341948509216309, Accuracy: 0.79736328125\n",
      "Batch No.: 149, Loss: 0.64986252784729, Accuracy: 0.791015625\n",
      "Batch No.: 150, Loss: 0.6798133254051208, Accuracy: 0.779541015625\n",
      "Batch No.: 151, Loss: 0.6544969081878662, Accuracy: 0.780517578125\n",
      "Batch No.: 153, Loss: 0.6779513359069824, Accuracy: 0.78369140625\n",
      "Batch No.: 154, Loss: 0.6346938610076904, Accuracy: 0.79736328125\n",
      "Batch No.: 155, Loss: 0.5860188603401184, Accuracy: 0.81103515625\n",
      "Batch No.: 156, Loss: 0.6704398393630981, Accuracy: 0.789306640625\n",
      "Batch No.: 157, Loss: 0.6228138208389282, Accuracy: 0.80517578125\n",
      "Batch No.: 158, Loss: 0.6589876413345337, Accuracy: 0.789306640625\n",
      "Batch No.: 159, Loss: 0.6668668985366821, Accuracy: 0.78515625\n",
      "Batch No.: 160, Loss: 0.6851189732551575, Accuracy: 0.784423828125\n",
      "Batch No.: 161, Loss: 0.6829550266265869, Accuracy: 0.783935546875\n",
      "Batch No.: 162, Loss: 0.6681181192398071, Accuracy: 0.784423828125\n",
      "Batch No.: 163, Loss: 0.6116786003112793, Accuracy: 0.8017578125\n",
      "Batch No.: 164, Loss: 0.7169450521469116, Accuracy: 0.770263671875\n",
      "Batch No.: 165, Loss: 0.6363827586174011, Accuracy: 0.80908203125\n",
      "Batch No.: 166, Loss: 0.6261172294616699, Accuracy: 0.805908203125\n",
      "Batch No.: 167, Loss: 0.7595843076705933, Accuracy: 0.76318359375\n",
      "Batch No.: 168, Loss: 0.6364669799804688, Accuracy: 0.791748046875\n",
      "Batch No.: 169, Loss: 0.666427731513977, Accuracy: 0.7939453125\n",
      "Batch No.: 170, Loss: 0.7553309798240662, Accuracy: 0.75927734375\n",
      "Batch No.: 171, Loss: 0.7208017706871033, Accuracy: 0.777099609375\n",
      "Batch No.: 172, Loss: 0.6512537002563477, Accuracy: 0.795654296875\n",
      "Batch No.: 173, Loss: 0.6966794729232788, Accuracy: 0.778076171875\n",
      "Batch No.: 174, Loss: 0.6913589239120483, Accuracy: 0.787841796875\n",
      "Batch No.: 176, Loss: 0.7267131805419922, Accuracy: 0.76953125\n",
      "Batch No.: 177, Loss: 0.691773533821106, Accuracy: 0.7802734375\n",
      "Batch No.: 178, Loss: 0.6342780590057373, Accuracy: 0.797607421875\n",
      "Batch No.: 179, Loss: 0.661723792552948, Accuracy: 0.787841796875\n",
      "Batch No.: 180, Loss: 0.6862175464630127, Accuracy: 0.783203125\n",
      "Batch No.: 181, Loss: 0.6237707734107971, Accuracy: 0.805908203125\n",
      "Batch No.: 182, Loss: 0.6532206535339355, Accuracy: 0.791015625\n",
      "Batch No.: 183, Loss: 0.6192100048065186, Accuracy: 0.801025390625\n",
      "Batch No.: 184, Loss: 0.632577657699585, Accuracy: 0.804931640625\n",
      "Batch No.: 185, Loss: 0.6742676496505737, Accuracy: 0.790283203125\n",
      "Batch No.: 186, Loss: 0.6325880289077759, Accuracy: 0.7861328125\n",
      "Batch No.: 187, Loss: 0.6212565898895264, Accuracy: 0.791015625\n",
      "Batch No.: 188, Loss: 0.7371045351028442, Accuracy: 0.7607421875\n",
      "Batch No.: 189, Loss: 0.6066614389419556, Accuracy: 0.804931640625\n",
      "Batch No.: 190, Loss: 0.7408819198608398, Accuracy: 0.769287109375\n",
      "Batch No.: 191, Loss: 0.7231858968734741, Accuracy: 0.770751953125\n",
      "Batch No.: 192, Loss: 0.5683877468109131, Accuracy: 0.818603515625\n",
      "Batch No.: 193, Loss: 0.7074522972106934, Accuracy: 0.7646484375\n",
      "Batch No.: 194, Loss: 0.6694637537002563, Accuracy: 0.78955078125\n",
      "Batch No.: 195, Loss: 0.5550744533538818, Accuracy: 0.82275390625\n",
      "Batch No.: 196, Loss: 0.663648247718811, Accuracy: 0.788818359375\n",
      "Batch No.: 197, Loss: 0.6183966398239136, Accuracy: 0.8017578125\n",
      "Batch No.: 198, Loss: 0.5703770518302917, Accuracy: 0.81298828125\n",
      "Batch No.: 200, Loss: 0.6081684827804565, Accuracy: 0.8037109375\n",
      "Batch No.: 201, Loss: 0.6575658321380615, Accuracy: 0.78955078125\n",
      "Batch No.: 202, Loss: 0.6825073957443237, Accuracy: 0.778564453125\n",
      "Batch No.: 203, Loss: 0.6147304773330688, Accuracy: 0.8037109375\n",
      "Batch No.: 204, Loss: 0.6020461320877075, Accuracy: 0.804931640625\n",
      "Batch No.: 205, Loss: 0.6379829049110413, Accuracy: 0.79541015625\n",
      "Batch No.: 206, Loss: 0.6717005968093872, Accuracy: 0.78759765625\n",
      "Batch No.: 207, Loss: 0.6083642840385437, Accuracy: 0.802978515625\n",
      "Batch No.: 208, Loss: 0.7097799181938171, Accuracy: 0.772216796875\n",
      "Batch No.: 209, Loss: 0.6511756181716919, Accuracy: 0.789306640625\n",
      "Batch No.: 210, Loss: 0.5971992015838623, Accuracy: 0.81298828125\n",
      "Batch No.: 211, Loss: 0.6796216368675232, Accuracy: 0.78271484375\n",
      "Batch No.: 212, Loss: 0.6060067415237427, Accuracy: 0.80859375\n",
      "Batch No.: 213, Loss: 0.6083643436431885, Accuracy: 0.798828125\n",
      "Batch No.: 214, Loss: 0.6641805768013, Accuracy: 0.791748046875\n",
      "Batch No.: 215, Loss: 0.6491019129753113, Accuracy: 0.79736328125\n",
      "Batch No.: 216, Loss: 0.6033211946487427, Accuracy: 0.802734375\n",
      "Batch No.: 217, Loss: 0.6651016473770142, Accuracy: 0.788330078125\n",
      "Batch No.: 218, Loss: 0.6406370401382446, Accuracy: 0.793701171875\n",
      "Batch No.: 219, Loss: 0.7024130821228027, Accuracy: 0.779296875\n",
      "Batch No.: 220, Loss: 0.6737021207809448, Accuracy: 0.783447265625\n",
      "Batch No.: 221, Loss: 0.6762624979019165, Accuracy: 0.779296875\n",
      "Batch No.: 222, Loss: 0.7052604556083679, Accuracy: 0.77587890625\n",
      "Batch No.: 223, Loss: 0.6606957912445068, Accuracy: 0.78955078125\n",
      "Batch No.: 224, Loss: 0.6217024326324463, Accuracy: 0.806396484375\n",
      "Batch No.: 225, Loss: 0.6587408781051636, Accuracy: 0.790771484375\n",
      "Batch No.: 226, Loss: 0.6129668354988098, Accuracy: 0.80126953125\n",
      "Batch No.: 227, Loss: 0.5974510312080383, Accuracy: 0.80908203125\n",
      "Batch No.: 228, Loss: 0.7294919490814209, Accuracy: 0.769775390625\n",
      "Batch No.: 229, Loss: 0.6729402542114258, Accuracy: 0.78515625\n",
      "Batch No.: 230, Loss: 0.6201058030128479, Accuracy: 0.802734375\n",
      "Batch No.: 231, Loss: 0.6705319881439209, Accuracy: 0.7822265625\n",
      "Batch No.: 232, Loss: 0.657827615737915, Accuracy: 0.79296875\n",
      "Batch No.: 233, Loss: 0.5916668176651001, Accuracy: 0.810791015625\n",
      "Batch No.: 234, Loss: 0.7042661905288696, Accuracy: 0.77880859375\n",
      "Batch No.: 235, Loss: 0.6590881943702698, Accuracy: 0.797607421875\n",
      "Batch No.: 236, Loss: 0.6721138954162598, Accuracy: 0.784912109375\n",
      "Batch No.: 237, Loss: 0.7253627777099609, Accuracy: 0.7685546875\n",
      "Batch No.: 238, Loss: 0.6464750170707703, Accuracy: 0.794677734375\n",
      "Batch No.: 239, Loss: 0.6179238557815552, Accuracy: 0.807861328125\n",
      "Batch No.: 240, Loss: 0.6666713356971741, Accuracy: 0.783203125\n",
      "Batch No.: 241, Loss: 0.6569201946258545, Accuracy: 0.79150390625\n",
      "Batch No.: 242, Loss: 0.6064434051513672, Accuracy: 0.804931640625\n",
      "Batch No.: 243, Loss: 0.6538673639297485, Accuracy: 0.7880859375\n",
      "Batch No.: 244, Loss: 0.6808911561965942, Accuracy: 0.778076171875\n",
      "Batch No.: 245, Loss: 0.6017714738845825, Accuracy: 0.80712890625\n",
      "Batch No.: 246, Loss: 0.621698796749115, Accuracy: 0.798828125\n",
      "Batch No.: 247, Loss: 0.6597250699996948, Accuracy: 0.792724609375\n",
      "Batch No.: 248, Loss: 0.6585776805877686, Accuracy: 0.794189453125\n",
      "Batch No.: 249, Loss: 0.7187188863754272, Accuracy: 0.77294921875\n",
      "Batch No.: 250, Loss: 0.6732603311538696, Accuracy: 0.78564453125\n",
      "Batch No.: 251, Loss: 0.6776043176651001, Accuracy: 0.783935546875\n",
      "Batch No.: 252, Loss: 0.6195188760757446, Accuracy: 0.809814453125\n",
      "Batch No.: 253, Loss: 0.632927656173706, Accuracy: 0.798828125\n",
      "Batch No.: 254, Loss: 0.6702368259429932, Accuracy: 0.779296875\n",
      "Batch No.: 255, Loss: 0.6751183271408081, Accuracy: 0.78662109375\n",
      "Batch No.: 256, Loss: 0.6257225275039673, Accuracy: 0.80224609375\n",
      "Batch No.: 257, Loss: 0.7234096527099609, Accuracy: 0.76611328125\n",
      "Batch No.: 258, Loss: 0.6648338437080383, Accuracy: 0.78857421875\n",
      "Batch No.: 259, Loss: 0.5987465381622314, Accuracy: 0.802978515625\n",
      "Batch No.: 260, Loss: 0.6961047053337097, Accuracy: 0.7822265625\n",
      "Batch No.: 261, Loss: 0.6816524863243103, Accuracy: 0.78369140625\n",
      "Batch No.: 262, Loss: 0.5879091620445251, Accuracy: 0.811767578125\n",
      "Batch No.: 263, Loss: 0.6785621643066406, Accuracy: 0.78369140625\n",
      "Batch No.: 264, Loss: 0.6019468307495117, Accuracy: 0.801025390625\n",
      "Epoch 63/80\n",
      "Batch No.: 43, Loss: 0.6165224313735962, Accuracy: 0.805419921875\n",
      "Batch No.: 44, Loss: 0.6636309623718262, Accuracy: 0.79052734375\n",
      "Batch No.: 45, Loss: 0.618411660194397, Accuracy: 0.798583984375\n",
      "Batch No.: 46, Loss: 0.6095243692398071, Accuracy: 0.802001953125\n",
      "Batch No.: 47, Loss: 0.6873823404312134, Accuracy: 0.775146484375\n",
      "Batch No.: 48, Loss: 0.5937868356704712, Accuracy: 0.805419921875\n",
      "Batch No.: 49, Loss: 0.640302300453186, Accuracy: 0.7978515625\n",
      "Batch No.: 50, Loss: 0.6702093482017517, Accuracy: 0.78955078125\n",
      "Batch No.: 51, Loss: 0.6501888036727905, Accuracy: 0.791259765625\n",
      "Batch No.: 52, Loss: 0.640384316444397, Accuracy: 0.7978515625\n",
      "Batch No.: 53, Loss: 0.6025388240814209, Accuracy: 0.80859375\n",
      "Batch No.: 54, Loss: 0.6845350861549377, Accuracy: 0.771728515625\n",
      "Batch No.: 55, Loss: 0.6705219745635986, Accuracy: 0.78759765625\n",
      "Batch No.: 56, Loss: 0.6329997777938843, Accuracy: 0.799560546875\n",
      "Batch No.: 57, Loss: 0.6591790914535522, Accuracy: 0.786865234375\n",
      "Batch No.: 58, Loss: 0.6058211922645569, Accuracy: 0.7998046875\n",
      "Batch No.: 59, Loss: 0.6301157474517822, Accuracy: 0.78857421875\n",
      "Batch No.: 60, Loss: 0.6423187255859375, Accuracy: 0.79296875\n",
      "Batch No.: 61, Loss: 0.5946347713470459, Accuracy: 0.81396484375\n",
      "Batch No.: 62, Loss: 0.6641981601715088, Accuracy: 0.791259765625\n",
      "Batch No.: 63, Loss: 0.6093446016311646, Accuracy: 0.80029296875\n",
      "Batch No.: 64, Loss: 0.6876183152198792, Accuracy: 0.7861328125\n",
      "Batch No.: 65, Loss: 0.7170569896697998, Accuracy: 0.763427734375\n",
      "Batch No.: 66, Loss: 0.604401707649231, Accuracy: 0.803466796875\n",
      "Batch No.: 67, Loss: 0.5963311195373535, Accuracy: 0.8095703125\n",
      "Batch No.: 68, Loss: 0.6821821928024292, Accuracy: 0.7841796875\n",
      "Batch No.: 69, Loss: 0.650619387626648, Accuracy: 0.7978515625\n",
      "Batch No.: 70, Loss: 0.5940946936607361, Accuracy: 0.8154296875\n",
      "Batch No.: 71, Loss: 0.6727960109710693, Accuracy: 0.785400390625\n",
      "Batch No.: 72, Loss: 0.6297050714492798, Accuracy: 0.8046875\n",
      "Batch No.: 73, Loss: 0.6533244848251343, Accuracy: 0.7890625\n",
      "Batch No.: 74, Loss: 0.6225837469100952, Accuracy: 0.804931640625\n",
      "Batch No.: 75, Loss: 0.634320855140686, Accuracy: 0.791259765625\n",
      "Batch No.: 76, Loss: 0.6397724151611328, Accuracy: 0.798583984375\n",
      "Batch No.: 77, Loss: 0.6635771989822388, Accuracy: 0.79296875\n",
      "Batch No.: 78, Loss: 0.6464877724647522, Accuracy: 0.793701171875\n",
      "Batch No.: 79, Loss: 0.6331087350845337, Accuracy: 0.802490234375\n",
      "Batch No.: 80, Loss: 0.6748553514480591, Accuracy: 0.791015625\n",
      "Batch No.: 81, Loss: 0.66904616355896, Accuracy: 0.78564453125\n",
      "Batch No.: 82, Loss: 0.6512569785118103, Accuracy: 0.7978515625\n",
      "Batch No.: 83, Loss: 0.5854775905609131, Accuracy: 0.81494140625\n",
      "Batch No.: 84, Loss: 0.6803320646286011, Accuracy: 0.780029296875\n",
      "Batch No.: 85, Loss: 0.6517944931983948, Accuracy: 0.8017578125\n",
      "Batch No.: 86, Loss: 0.5802408456802368, Accuracy: 0.81396484375\n",
      "Batch No.: 87, Loss: 0.6131995916366577, Accuracy: 0.803466796875\n",
      "Batch No.: 88, Loss: 0.6241849660873413, Accuracy: 0.79736328125\n",
      "Batch No.: 89, Loss: 0.5940638184547424, Accuracy: 0.814697265625\n",
      "Batch No.: 90, Loss: 0.5753850936889648, Accuracy: 0.81787109375\n",
      "Batch No.: 91, Loss: 0.605003297328949, Accuracy: 0.80712890625\n",
      "Batch No.: 92, Loss: 0.5952332615852356, Accuracy: 0.8154296875\n",
      "Batch No.: 93, Loss: 0.6391456723213196, Accuracy: 0.793212890625\n",
      "Batch No.: 94, Loss: 0.6561315059661865, Accuracy: 0.789794921875\n",
      "Batch No.: 95, Loss: 0.6844601035118103, Accuracy: 0.781982421875\n",
      "Batch No.: 96, Loss: 0.6031233668327332, Accuracy: 0.805419921875\n",
      "Batch No.: 97, Loss: 0.6559804677963257, Accuracy: 0.79296875\n",
      "Batch No.: 98, Loss: 0.664929211139679, Accuracy: 0.796875\n",
      "Batch No.: 99, Loss: 0.6720826625823975, Accuracy: 0.789306640625\n",
      "Batch No.: 100, Loss: 0.6379880309104919, Accuracy: 0.791015625\n",
      "Batch No.: 101, Loss: 0.5900216698646545, Accuracy: 0.812744140625\n",
      "Batch No.: 102, Loss: 0.679986834526062, Accuracy: 0.787109375\n",
      "Batch No.: 103, Loss: 0.6440272331237793, Accuracy: 0.788818359375\n",
      "Batch No.: 104, Loss: 0.6400350332260132, Accuracy: 0.8017578125\n",
      "Batch No.: 105, Loss: 0.6748348474502563, Accuracy: 0.783203125\n",
      "Batch No.: 106, Loss: 0.651267945766449, Accuracy: 0.786865234375\n",
      "Batch No.: 107, Loss: 0.6277656555175781, Accuracy: 0.802734375\n",
      "Batch No.: 108, Loss: 0.625054121017456, Accuracy: 0.802978515625\n",
      "Batch No.: 109, Loss: 0.6573649644851685, Accuracy: 0.796142578125\n",
      "Batch No.: 110, Loss: 0.6388239860534668, Accuracy: 0.7958984375\n",
      "Batch No.: 111, Loss: 0.6148914098739624, Accuracy: 0.7998046875\n",
      "Batch No.: 112, Loss: 0.5874486565589905, Accuracy: 0.816162109375\n",
      "Batch No.: 113, Loss: 0.6742929220199585, Accuracy: 0.77978515625\n",
      "Batch No.: 114, Loss: 0.6696010828018188, Accuracy: 0.789306640625\n",
      "Batch No.: 115, Loss: 0.6463850140571594, Accuracy: 0.795166015625\n",
      "Batch No.: 116, Loss: 0.7100370526313782, Accuracy: 0.77392578125\n",
      "Batch No.: 117, Loss: 0.6101115942001343, Accuracy: 0.801513671875\n",
      "Batch No.: 118, Loss: 0.6213012337684631, Accuracy: 0.8037109375\n",
      "Batch No.: 119, Loss: 0.6530253887176514, Accuracy: 0.79052734375\n",
      "Batch No.: 120, Loss: 0.6810058355331421, Accuracy: 0.782470703125\n",
      "Batch No.: 121, Loss: 0.6657510995864868, Accuracy: 0.78564453125\n",
      "Batch No.: 122, Loss: 0.6849435567855835, Accuracy: 0.78271484375\n",
      "Batch No.: 123, Loss: 0.712130069732666, Accuracy: 0.774658203125\n",
      "Batch No.: 124, Loss: 0.6501622796058655, Accuracy: 0.7900390625\n",
      "Batch No.: 125, Loss: 0.6976138353347778, Accuracy: 0.78076171875\n",
      "Batch No.: 126, Loss: 0.6436272859573364, Accuracy: 0.79345703125\n",
      "Batch No.: 127, Loss: 0.6217939853668213, Accuracy: 0.810791015625\n",
      "Batch No.: 128, Loss: 0.6290603280067444, Accuracy: 0.7958984375\n",
      "Batch No.: 129, Loss: 0.6846058964729309, Accuracy: 0.7861328125\n",
      "Batch No.: 130, Loss: 0.6863112449645996, Accuracy: 0.791748046875\n",
      "Batch No.: 131, Loss: 0.6690521836280823, Accuracy: 0.779541015625\n",
      "Batch No.: 132, Loss: 0.7493675947189331, Accuracy: 0.77099609375\n",
      "Batch No.: 133, Loss: 0.6530930399894714, Accuracy: 0.793701171875\n",
      "Batch No.: 134, Loss: 0.6235198974609375, Accuracy: 0.794677734375\n",
      "Batch No.: 135, Loss: 0.7054525017738342, Accuracy: 0.77587890625\n",
      "Batch No.: 136, Loss: 0.5961328744888306, Accuracy: 0.811279296875\n",
      "Batch No.: 137, Loss: 0.6301739811897278, Accuracy: 0.802978515625\n",
      "Batch No.: 138, Loss: 0.6985929012298584, Accuracy: 0.779296875\n",
      "Batch No.: 139, Loss: 0.6641635894775391, Accuracy: 0.7939453125\n",
      "Batch No.: 140, Loss: 0.6593040227890015, Accuracy: 0.7841796875\n",
      "Batch No.: 141, Loss: 0.7031972408294678, Accuracy: 0.7822265625\n",
      "Batch No.: 142, Loss: 0.7684499025344849, Accuracy: 0.75390625\n",
      "Batch No.: 143, Loss: 0.643330991268158, Accuracy: 0.798095703125\n",
      "Batch No.: 144, Loss: 0.6726783514022827, Accuracy: 0.7861328125\n",
      "Batch No.: 145, Loss: 0.6502299904823303, Accuracy: 0.7861328125\n",
      "Batch No.: 146, Loss: 0.6329463720321655, Accuracy: 0.800537109375\n",
      "Batch No.: 147, Loss: 0.6664925217628479, Accuracy: 0.78271484375\n",
      "Batch No.: 148, Loss: 0.6322848796844482, Accuracy: 0.797119140625\n",
      "Batch No.: 149, Loss: 0.6522334814071655, Accuracy: 0.787353515625\n",
      "Batch No.: 150, Loss: 0.6925568580627441, Accuracy: 0.772216796875\n",
      "Batch No.: 151, Loss: 0.6374521255493164, Accuracy: 0.791259765625\n",
      "Batch No.: 152, Loss: 0.6431430578231812, Accuracy: 0.800537109375\n",
      "Batch No.: 153, Loss: 0.6647578477859497, Accuracy: 0.783447265625\n",
      "Batch No.: 154, Loss: 0.6470745801925659, Accuracy: 0.794189453125\n",
      "Batch No.: 155, Loss: 0.577253520488739, Accuracy: 0.817626953125\n",
      "Batch No.: 156, Loss: 0.6521120071411133, Accuracy: 0.7890625\n",
      "Batch No.: 157, Loss: 0.6199288964271545, Accuracy: 0.800537109375\n",
      "Batch No.: 158, Loss: 0.653346061706543, Accuracy: 0.7880859375\n",
      "Batch No.: 159, Loss: 0.6529156565666199, Accuracy: 0.79248046875\n",
      "Batch No.: 160, Loss: 0.6788330078125, Accuracy: 0.786865234375\n",
      "Batch No.: 161, Loss: 0.6757658123970032, Accuracy: 0.78564453125\n",
      "Batch No.: 162, Loss: 0.6812433004379272, Accuracy: 0.783203125\n",
      "Batch No.: 163, Loss: 0.6095606088638306, Accuracy: 0.802001953125\n",
      "Batch No.: 164, Loss: 0.7148885726928711, Accuracy: 0.765869140625\n",
      "Batch No.: 165, Loss: 0.6326127052307129, Accuracy: 0.79638671875\n",
      "Batch No.: 166, Loss: 0.5865646600723267, Accuracy: 0.81298828125\n",
      "Batch No.: 167, Loss: 0.7583401799201965, Accuracy: 0.7607421875\n",
      "Batch No.: 168, Loss: 0.655548095703125, Accuracy: 0.78857421875\n",
      "Batch No.: 169, Loss: 0.6501133441925049, Accuracy: 0.795166015625\n",
      "Batch No.: 170, Loss: 0.7292627096176147, Accuracy: 0.759033203125\n",
      "Batch No.: 171, Loss: 0.706740140914917, Accuracy: 0.77685546875\n",
      "Batch No.: 172, Loss: 0.6699123382568359, Accuracy: 0.79296875\n",
      "Batch No.: 173, Loss: 0.6671925783157349, Accuracy: 0.781005859375\n",
      "Batch No.: 174, Loss: 0.6883485317230225, Accuracy: 0.781982421875\n",
      "Batch No.: 175, Loss: 0.6005348563194275, Accuracy: 0.81201171875\n",
      "Batch No.: 176, Loss: 0.7169016003608704, Accuracy: 0.7724609375\n",
      "Batch No.: 177, Loss: 0.685472846031189, Accuracy: 0.784912109375\n",
      "Batch No.: 178, Loss: 0.6407904624938965, Accuracy: 0.8056640625\n",
      "Batch No.: 179, Loss: 0.6507393717765808, Accuracy: 0.796875\n",
      "Batch No.: 180, Loss: 0.6817710399627686, Accuracy: 0.78125\n",
      "Batch No.: 181, Loss: 0.6162910461425781, Accuracy: 0.807373046875\n",
      "Batch No.: 182, Loss: 0.6455861330032349, Accuracy: 0.79345703125\n",
      "Batch No.: 183, Loss: 0.6170240640640259, Accuracy: 0.80078125\n",
      "Batch No.: 184, Loss: 0.6373181939125061, Accuracy: 0.7939453125\n",
      "Batch No.: 185, Loss: 0.6749551892280579, Accuracy: 0.788818359375\n",
      "Batch No.: 186, Loss: 0.6184784770011902, Accuracy: 0.802001953125\n",
      "Batch No.: 187, Loss: 0.6294386982917786, Accuracy: 0.801513671875\n",
      "Batch No.: 188, Loss: 0.7193632125854492, Accuracy: 0.774169921875\n",
      "Batch No.: 189, Loss: 0.6158655881881714, Accuracy: 0.79931640625\n",
      "Batch No.: 190, Loss: 0.762197732925415, Accuracy: 0.760009765625\n",
      "Batch No.: 191, Loss: 0.6960639953613281, Accuracy: 0.776123046875\n",
      "Batch No.: 192, Loss: 0.5627435445785522, Accuracy: 0.820068359375\n",
      "Batch No.: 193, Loss: 0.6905454397201538, Accuracy: 0.765869140625\n",
      "Batch No.: 194, Loss: 0.6618282198905945, Accuracy: 0.7880859375\n",
      "Batch No.: 195, Loss: 0.5603882670402527, Accuracy: 0.827392578125\n",
      "Batch No.: 196, Loss: 0.6610150337219238, Accuracy: 0.78564453125\n",
      "Batch No.: 197, Loss: 0.6197046637535095, Accuracy: 0.80126953125\n",
      "Batch No.: 198, Loss: 0.566592276096344, Accuracy: 0.81884765625\n",
      "Batch No.: 199, Loss: 0.6686888933181763, Accuracy: 0.77978515625\n",
      "Batch No.: 200, Loss: 0.6087455749511719, Accuracy: 0.807861328125\n",
      "Batch No.: 201, Loss: 0.666685163974762, Accuracy: 0.792236328125\n",
      "Batch No.: 202, Loss: 0.6783847808837891, Accuracy: 0.786865234375\n",
      "Batch No.: 203, Loss: 0.6314771175384521, Accuracy: 0.79296875\n",
      "Batch No.: 204, Loss: 0.6021732687950134, Accuracy: 0.808837890625\n",
      "Batch No.: 205, Loss: 0.6187881231307983, Accuracy: 0.802978515625\n",
      "Batch No.: 206, Loss: 0.658110499382019, Accuracy: 0.7958984375\n",
      "Batch No.: 207, Loss: 0.6004996299743652, Accuracy: 0.800537109375\n",
      "Batch No.: 208, Loss: 0.7260117530822754, Accuracy: 0.765869140625\n",
      "Batch No.: 209, Loss: 0.6554348468780518, Accuracy: 0.785888671875\n",
      "Batch No.: 210, Loss: 0.6232264041900635, Accuracy: 0.811767578125\n",
      "Batch No.: 211, Loss: 0.6922920942306519, Accuracy: 0.77734375\n",
      "Batch No.: 212, Loss: 0.6119881868362427, Accuracy: 0.808349609375\n",
      "Batch No.: 213, Loss: 0.6023709774017334, Accuracy: 0.812255859375\n",
      "Batch No.: 214, Loss: 0.665942907333374, Accuracy: 0.786865234375\n",
      "Batch No.: 215, Loss: 0.6740316152572632, Accuracy: 0.793212890625\n",
      "Batch No.: 216, Loss: 0.591968834400177, Accuracy: 0.812744140625\n",
      "Batch No.: 217, Loss: 0.6282581686973572, Accuracy: 0.7998046875\n",
      "Batch No.: 218, Loss: 0.6568812131881714, Accuracy: 0.7841796875\n",
      "Batch No.: 219, Loss: 0.702280580997467, Accuracy: 0.777099609375\n",
      "Batch No.: 220, Loss: 0.6948574781417847, Accuracy: 0.779541015625\n",
      "Batch No.: 221, Loss: 0.6506597399711609, Accuracy: 0.793701171875\n",
      "Batch No.: 222, Loss: 0.702595055103302, Accuracy: 0.77734375\n",
      "Batch No.: 223, Loss: 0.6530843377113342, Accuracy: 0.79638671875\n",
      "Batch No.: 224, Loss: 0.643118143081665, Accuracy: 0.801025390625\n",
      "Batch No.: 225, Loss: 0.6547548174858093, Accuracy: 0.790771484375\n",
      "Batch No.: 226, Loss: 0.6192429065704346, Accuracy: 0.802978515625\n",
      "Batch No.: 227, Loss: 0.578711748123169, Accuracy: 0.813232421875\n",
      "Batch No.: 228, Loss: 0.7353180646896362, Accuracy: 0.7685546875\n",
      "Batch No.: 229, Loss: 0.6583847999572754, Accuracy: 0.794677734375\n",
      "Batch No.: 230, Loss: 0.6090421080589294, Accuracy: 0.808837890625\n",
      "Batch No.: 231, Loss: 0.6768703460693359, Accuracy: 0.78173828125\n",
      "Batch No.: 232, Loss: 0.6686813831329346, Accuracy: 0.793701171875\n",
      "Batch No.: 233, Loss: 0.580193281173706, Accuracy: 0.816650390625\n",
      "Batch No.: 234, Loss: 0.711952269077301, Accuracy: 0.772705078125\n",
      "Batch No.: 235, Loss: 0.6607935428619385, Accuracy: 0.797119140625\n",
      "Batch No.: 236, Loss: 0.6480366587638855, Accuracy: 0.791259765625\n",
      "Batch No.: 237, Loss: 0.7330805063247681, Accuracy: 0.769287109375\n",
      "Batch No.: 238, Loss: 0.649533748626709, Accuracy: 0.790283203125\n",
      "Batch No.: 239, Loss: 0.622259259223938, Accuracy: 0.79833984375\n",
      "Batch No.: 240, Loss: 0.6564475893974304, Accuracy: 0.792236328125\n",
      "Batch No.: 241, Loss: 0.64882493019104, Accuracy: 0.795166015625\n",
      "Batch No.: 242, Loss: 0.5824704170227051, Accuracy: 0.8095703125\n",
      "Batch No.: 243, Loss: 0.66588294506073, Accuracy: 0.7890625\n",
      "Batch No.: 244, Loss: 0.67238450050354, Accuracy: 0.788330078125\n",
      "Batch No.: 245, Loss: 0.5731029510498047, Accuracy: 0.8203125\n",
      "Batch No.: 246, Loss: 0.6145304441452026, Accuracy: 0.812255859375\n",
      "Batch No.: 247, Loss: 0.6248774528503418, Accuracy: 0.79736328125\n",
      "Batch No.: 248, Loss: 0.6324189305305481, Accuracy: 0.802978515625\n",
      "Batch No.: 249, Loss: 0.6861817240715027, Accuracy: 0.78515625\n",
      "Batch No.: 250, Loss: 0.6377527713775635, Accuracy: 0.798095703125\n",
      "Batch No.: 251, Loss: 0.653377115726471, Accuracy: 0.79150390625\n",
      "Batch No.: 252, Loss: 0.6043802499771118, Accuracy: 0.80712890625\n",
      "Batch No.: 253, Loss: 0.6270800828933716, Accuracy: 0.794921875\n",
      "Batch No.: 254, Loss: 0.6462274789810181, Accuracy: 0.796142578125\n",
      "Batch No.: 255, Loss: 0.6547188758850098, Accuracy: 0.7880859375\n",
      "Batch No.: 256, Loss: 0.6191986799240112, Accuracy: 0.8037109375\n",
      "Batch No.: 257, Loss: 0.6835143566131592, Accuracy: 0.774169921875\n",
      "Batch No.: 258, Loss: 0.6459483504295349, Accuracy: 0.7958984375\n",
      "Batch No.: 259, Loss: 0.5885596871376038, Accuracy: 0.80615234375\n",
      "Batch No.: 260, Loss: 0.682921290397644, Accuracy: 0.784912109375\n",
      "Batch No.: 261, Loss: 0.6643707156181335, Accuracy: 0.78955078125\n",
      "Batch No.: 262, Loss: 0.5833432674407959, Accuracy: 0.802978515625\n",
      "Batch No.: 263, Loss: 0.6829156875610352, Accuracy: 0.78271484375\n",
      "Batch No.: 264, Loss: 0.5896636247634888, Accuracy: 0.807373046875\n",
      "Epoch 64/80\n",
      "Batch No.: 1, Loss: 1.0378204584121704, Accuracy: 0.718017578125\n",
      "Batch No.: 2, Loss: 0.5810543298721313, Accuracy: 0.814453125\n",
      "Batch No.: 3, Loss: 0.6066114902496338, Accuracy: 0.80224609375\n",
      "Batch No.: 4, Loss: 0.5910030007362366, Accuracy: 0.809814453125\n",
      "Batch No.: 5, Loss: 0.6600278615951538, Accuracy: 0.787841796875\n",
      "Batch No.: 6, Loss: 0.5728979110717773, Accuracy: 0.821533203125\n",
      "Batch No.: 7, Loss: 0.6115332841873169, Accuracy: 0.793701171875\n",
      "Batch No.: 8, Loss: 0.6665108799934387, Accuracy: 0.788818359375\n",
      "Batch No.: 9, Loss: 0.5102020502090454, Accuracy: 0.837158203125\n",
      "Batch No.: 10, Loss: 0.6176745295524597, Accuracy: 0.802490234375\n",
      "Batch No.: 11, Loss: 0.6001914739608765, Accuracy: 0.802734375\n",
      "Batch No.: 12, Loss: 0.6216174960136414, Accuracy: 0.8056640625\n",
      "Batch No.: 13, Loss: 0.6748591065406799, Accuracy: 0.782470703125\n",
      "Batch No.: 14, Loss: 0.6444892883300781, Accuracy: 0.789306640625\n",
      "Batch No.: 15, Loss: 0.6730973124504089, Accuracy: 0.791259765625\n",
      "Batch No.: 16, Loss: 0.5962579250335693, Accuracy: 0.810791015625\n",
      "Batch No.: 17, Loss: 0.6637358665466309, Accuracy: 0.787109375\n",
      "Batch No.: 18, Loss: 0.6758910417556763, Accuracy: 0.78076171875\n",
      "Batch No.: 19, Loss: 0.5977828502655029, Accuracy: 0.8154296875\n",
      "Batch No.: 20, Loss: 0.6347271203994751, Accuracy: 0.7890625\n",
      "Batch No.: 21, Loss: 0.6883794069290161, Accuracy: 0.77978515625\n",
      "Batch No.: 22, Loss: 0.6033605337142944, Accuracy: 0.809326171875\n",
      "Batch No.: 23, Loss: 0.5623900890350342, Accuracy: 0.82177734375\n",
      "Batch No.: 24, Loss: 0.7198217511177063, Accuracy: 0.77490234375\n",
      "Batch No.: 25, Loss: 0.7132591009140015, Accuracy: 0.781005859375\n",
      "Batch No.: 26, Loss: 0.5593507289886475, Accuracy: 0.821044921875\n",
      "Batch No.: 27, Loss: 0.6668843626976013, Accuracy: 0.790283203125\n",
      "Batch No.: 28, Loss: 0.640714704990387, Accuracy: 0.796875\n",
      "Batch No.: 29, Loss: 0.5550011992454529, Accuracy: 0.814208984375\n",
      "Batch No.: 30, Loss: 0.7007343769073486, Accuracy: 0.771728515625\n",
      "Batch No.: 31, Loss: 0.6776213645935059, Accuracy: 0.791259765625\n",
      "Batch No.: 32, Loss: 0.5645490884780884, Accuracy: 0.82568359375\n",
      "Batch No.: 33, Loss: 0.6186891794204712, Accuracy: 0.80517578125\n",
      "Batch No.: 34, Loss: 0.6555535793304443, Accuracy: 0.787841796875\n",
      "Batch No.: 35, Loss: 0.5899766683578491, Accuracy: 0.804443359375\n",
      "Batch No.: 36, Loss: 0.6206406354904175, Accuracy: 0.801025390625\n",
      "Batch No.: 37, Loss: 0.6663652062416077, Accuracy: 0.781982421875\n",
      "Batch No.: 38, Loss: 0.6564213037490845, Accuracy: 0.794921875\n",
      "Batch No.: 39, Loss: 0.5753449201583862, Accuracy: 0.810546875\n",
      "Batch No.: 40, Loss: 0.6104211807250977, Accuracy: 0.808837890625\n",
      "Batch No.: 41, Loss: 0.7012687921524048, Accuracy: 0.77685546875\n",
      "Batch No.: 42, Loss: 0.6247603893280029, Accuracy: 0.8046875\n",
      "Batch No.: 43, Loss: 0.617809534072876, Accuracy: 0.803955078125\n",
      "Batch No.: 44, Loss: 0.653626024723053, Accuracy: 0.789306640625\n",
      "Batch No.: 45, Loss: 0.6073405146598816, Accuracy: 0.802001953125\n",
      "Batch No.: 46, Loss: 0.5916019082069397, Accuracy: 0.809326171875\n",
      "Batch No.: 47, Loss: 0.6642524003982544, Accuracy: 0.78369140625\n",
      "Batch No.: 48, Loss: 0.5916486382484436, Accuracy: 0.805419921875\n",
      "Batch No.: 49, Loss: 0.6240885257720947, Accuracy: 0.791015625\n",
      "Batch No.: 50, Loss: 0.658362627029419, Accuracy: 0.794677734375\n",
      "Batch No.: 51, Loss: 0.6323589086532593, Accuracy: 0.798583984375\n",
      "Batch No.: 52, Loss: 0.6216254830360413, Accuracy: 0.804443359375\n",
      "Batch No.: 53, Loss: 0.5897870063781738, Accuracy: 0.810791015625\n",
      "Batch No.: 54, Loss: 0.6710689663887024, Accuracy: 0.78076171875\n",
      "Batch No.: 55, Loss: 0.6640662550926208, Accuracy: 0.79541015625\n",
      "Batch No.: 56, Loss: 0.6224141716957092, Accuracy: 0.808837890625\n",
      "Batch No.: 57, Loss: 0.645908772945404, Accuracy: 0.790283203125\n",
      "Batch No.: 58, Loss: 0.6063727736473083, Accuracy: 0.806396484375\n",
      "Batch No.: 59, Loss: 0.641332745552063, Accuracy: 0.7890625\n",
      "Batch No.: 60, Loss: 0.6273102760314941, Accuracy: 0.801025390625\n",
      "Batch No.: 61, Loss: 0.5796284675598145, Accuracy: 0.8125\n",
      "Batch No.: 62, Loss: 0.6584946513175964, Accuracy: 0.788818359375\n",
      "Batch No.: 63, Loss: 0.5913928151130676, Accuracy: 0.810791015625\n",
      "Batch No.: 64, Loss: 0.6399965286254883, Accuracy: 0.794677734375\n",
      "Batch No.: 65, Loss: 0.7097917199134827, Accuracy: 0.76806640625\n",
      "Batch No.: 66, Loss: 0.5952244997024536, Accuracy: 0.810791015625\n",
      "Batch No.: 67, Loss: 0.5939991474151611, Accuracy: 0.807373046875\n",
      "Batch No.: 68, Loss: 0.6987452507019043, Accuracy: 0.777099609375\n",
      "Batch No.: 69, Loss: 0.660481333732605, Accuracy: 0.78955078125\n",
      "Batch No.: 70, Loss: 0.5965486168861389, Accuracy: 0.81103515625\n",
      "Batch No.: 71, Loss: 0.6680537462234497, Accuracy: 0.789794921875\n",
      "Batch No.: 72, Loss: 0.6189132928848267, Accuracy: 0.808349609375\n",
      "Batch No.: 73, Loss: 0.6544798612594604, Accuracy: 0.786376953125\n",
      "Batch No.: 74, Loss: 0.6240065693855286, Accuracy: 0.80517578125\n",
      "Batch No.: 75, Loss: 0.6307480931282043, Accuracy: 0.800537109375\n",
      "Batch No.: 76, Loss: 0.6232413649559021, Accuracy: 0.80224609375\n",
      "Batch No.: 77, Loss: 0.6548547744750977, Accuracy: 0.794677734375\n",
      "Batch No.: 78, Loss: 0.6334636807441711, Accuracy: 0.80126953125\n",
      "Batch No.: 79, Loss: 0.6166567802429199, Accuracy: 0.8056640625\n",
      "Batch No.: 80, Loss: 0.6589971780776978, Accuracy: 0.789794921875\n",
      "Batch No.: 81, Loss: 0.657384991645813, Accuracy: 0.792724609375\n",
      "Batch No.: 82, Loss: 0.6561409831047058, Accuracy: 0.788818359375\n",
      "Batch No.: 83, Loss: 0.5933636426925659, Accuracy: 0.81103515625\n",
      "Batch No.: 84, Loss: 0.6949694156646729, Accuracy: 0.77001953125\n",
      "Batch No.: 85, Loss: 0.6504195928573608, Accuracy: 0.79345703125\n",
      "Batch No.: 86, Loss: 0.569654643535614, Accuracy: 0.818115234375\n",
      "Batch No.: 87, Loss: 0.5908877849578857, Accuracy: 0.806640625\n",
      "Batch No.: 88, Loss: 0.6286033391952515, Accuracy: 0.79638671875\n",
      "Batch No.: 89, Loss: 0.5914638042449951, Accuracy: 0.810791015625\n",
      "Batch No.: 90, Loss: 0.5853627920150757, Accuracy: 0.8125\n",
      "Batch No.: 91, Loss: 0.5998985767364502, Accuracy: 0.805908203125\n",
      "Batch No.: 92, Loss: 0.5932626724243164, Accuracy: 0.806640625\n",
      "Batch No.: 93, Loss: 0.6282164454460144, Accuracy: 0.800537109375\n",
      "Batch No.: 94, Loss: 0.6447876691818237, Accuracy: 0.794677734375\n",
      "Batch No.: 95, Loss: 0.6790503263473511, Accuracy: 0.78515625\n",
      "Batch No.: 96, Loss: 0.5990577936172485, Accuracy: 0.8095703125\n",
      "Batch No.: 97, Loss: 0.6309893131256104, Accuracy: 0.80322265625\n",
      "Batch No.: 98, Loss: 0.6557471752166748, Accuracy: 0.794677734375\n",
      "Batch No.: 99, Loss: 0.6507153511047363, Accuracy: 0.793212890625\n",
      "Batch No.: 100, Loss: 0.6391197443008423, Accuracy: 0.791259765625\n",
      "Batch No.: 101, Loss: 0.5707423686981201, Accuracy: 0.818115234375\n",
      "Batch No.: 102, Loss: 0.6671988368034363, Accuracy: 0.791748046875\n",
      "Batch No.: 103, Loss: 0.6568538546562195, Accuracy: 0.79443359375\n",
      "Batch No.: 104, Loss: 0.6325550079345703, Accuracy: 0.802734375\n",
      "Batch No.: 105, Loss: 0.6764082908630371, Accuracy: 0.781005859375\n",
      "Batch No.: 106, Loss: 0.6387931704521179, Accuracy: 0.7890625\n",
      "Batch No.: 107, Loss: 0.6139044761657715, Accuracy: 0.80419921875\n",
      "Batch No.: 108, Loss: 0.6258218288421631, Accuracy: 0.796875\n",
      "Batch No.: 109, Loss: 0.6504354476928711, Accuracy: 0.801025390625\n",
      "Batch No.: 110, Loss: 0.6101686954498291, Accuracy: 0.80322265625\n",
      "Batch No.: 111, Loss: 0.5970538258552551, Accuracy: 0.809326171875\n",
      "Batch No.: 112, Loss: 0.5760290026664734, Accuracy: 0.818359375\n",
      "Batch No.: 113, Loss: 0.6622833609580994, Accuracy: 0.794921875\n",
      "Batch No.: 114, Loss: 0.6468031406402588, Accuracy: 0.794677734375\n",
      "Batch No.: 115, Loss: 0.6340781450271606, Accuracy: 0.795654296875\n",
      "Batch No.: 116, Loss: 0.6984965801239014, Accuracy: 0.779296875\n",
      "Batch No.: 117, Loss: 0.6040009260177612, Accuracy: 0.80908203125\n",
      "Batch No.: 118, Loss: 0.6423649787902832, Accuracy: 0.795166015625\n",
      "Batch No.: 119, Loss: 0.6412997245788574, Accuracy: 0.7900390625\n",
      "Batch No.: 120, Loss: 0.68489670753479, Accuracy: 0.782958984375\n",
      "Batch No.: 121, Loss: 0.6562786102294922, Accuracy: 0.793701171875\n",
      "Batch No.: 122, Loss: 0.6941876411437988, Accuracy: 0.773681640625\n",
      "Batch No.: 123, Loss: 0.7222393751144409, Accuracy: 0.7705078125\n",
      "Batch No.: 124, Loss: 0.6582533121109009, Accuracy: 0.791015625\n",
      "Batch No.: 125, Loss: 0.6838665008544922, Accuracy: 0.778076171875\n",
      "Batch No.: 126, Loss: 0.646350085735321, Accuracy: 0.792724609375\n",
      "Batch No.: 127, Loss: 0.6238248348236084, Accuracy: 0.803466796875\n",
      "Batch No.: 128, Loss: 0.6299233436584473, Accuracy: 0.80029296875\n",
      "Batch No.: 129, Loss: 0.6820755004882812, Accuracy: 0.775390625\n",
      "Batch No.: 130, Loss: 0.6430878043174744, Accuracy: 0.80224609375\n",
      "Batch No.: 131, Loss: 0.6584166884422302, Accuracy: 0.794189453125\n",
      "Batch No.: 132, Loss: 0.7498105764389038, Accuracy: 0.768310546875\n",
      "Batch No.: 133, Loss: 0.6437500715255737, Accuracy: 0.80078125\n",
      "Batch No.: 134, Loss: 0.631058931350708, Accuracy: 0.79638671875\n",
      "Batch No.: 135, Loss: 0.6776468753814697, Accuracy: 0.77685546875\n",
      "Batch No.: 136, Loss: 0.5947709083557129, Accuracy: 0.812744140625\n",
      "Batch No.: 137, Loss: 0.6077932715415955, Accuracy: 0.807373046875\n",
      "Batch No.: 138, Loss: 0.6822772026062012, Accuracy: 0.783447265625\n",
      "Batch No.: 139, Loss: 0.6601932048797607, Accuracy: 0.793701171875\n",
      "Batch No.: 140, Loss: 0.6444907784461975, Accuracy: 0.799560546875\n",
      "Batch No.: 141, Loss: 0.6925898194313049, Accuracy: 0.78466796875\n",
      "Batch No.: 142, Loss: 0.7768459320068359, Accuracy: 0.751220703125\n",
      "Batch No.: 143, Loss: 0.6557645201683044, Accuracy: 0.79541015625\n",
      "Batch No.: 144, Loss: 0.6561949849128723, Accuracy: 0.7939453125\n",
      "Batch No.: 145, Loss: 0.6709821224212646, Accuracy: 0.784912109375\n",
      "Batch No.: 146, Loss: 0.6304589509963989, Accuracy: 0.797607421875\n",
      "Batch No.: 147, Loss: 0.6825350522994995, Accuracy: 0.780029296875\n",
      "Batch No.: 148, Loss: 0.6316056251525879, Accuracy: 0.7978515625\n",
      "Batch No.: 149, Loss: 0.6395128965377808, Accuracy: 0.788818359375\n",
      "Batch No.: 150, Loss: 0.6774076819419861, Accuracy: 0.782470703125\n",
      "Batch No.: 151, Loss: 0.6415274739265442, Accuracy: 0.795166015625\n",
      "Batch No.: 152, Loss: 0.6457235813140869, Accuracy: 0.791259765625\n",
      "Batch No.: 153, Loss: 0.6681039333343506, Accuracy: 0.78759765625\n",
      "Batch No.: 154, Loss: 0.6397091746330261, Accuracy: 0.7919921875\n",
      "Batch No.: 155, Loss: 0.5896849632263184, Accuracy: 0.80810546875\n",
      "Batch No.: 156, Loss: 0.6539686322212219, Accuracy: 0.795166015625\n",
      "Batch No.: 157, Loss: 0.623064398765564, Accuracy: 0.792724609375\n",
      "Batch No.: 158, Loss: 0.6554181575775146, Accuracy: 0.78662109375\n",
      "Batch No.: 159, Loss: 0.6532782912254333, Accuracy: 0.795166015625\n",
      "Batch No.: 160, Loss: 0.6985002160072327, Accuracy: 0.783935546875\n",
      "Batch No.: 161, Loss: 0.6766344308853149, Accuracy: 0.789306640625\n",
      "Batch No.: 162, Loss: 0.6698620319366455, Accuracy: 0.78466796875\n",
      "Batch No.: 163, Loss: 0.6130242347717285, Accuracy: 0.8076171875\n",
      "Batch No.: 164, Loss: 0.7112231254577637, Accuracy: 0.77099609375\n",
      "Batch No.: 165, Loss: 0.6332511305809021, Accuracy: 0.799072265625\n",
      "Batch No.: 166, Loss: 0.5908588767051697, Accuracy: 0.8134765625\n",
      "Batch No.: 167, Loss: 0.7599484324455261, Accuracy: 0.75634765625\n",
      "Batch No.: 168, Loss: 0.645740270614624, Accuracy: 0.790771484375\n",
      "Batch No.: 169, Loss: 0.6679519414901733, Accuracy: 0.792236328125\n",
      "Batch No.: 170, Loss: 0.7256966233253479, Accuracy: 0.76171875\n",
      "Batch No.: 171, Loss: 0.71515291929245, Accuracy: 0.777099609375\n",
      "Batch No.: 172, Loss: 0.6663589477539062, Accuracy: 0.795654296875\n",
      "Batch No.: 173, Loss: 0.6861896514892578, Accuracy: 0.777099609375\n",
      "Batch No.: 174, Loss: 0.7021242380142212, Accuracy: 0.779296875\n",
      "Batch No.: 175, Loss: 0.6183074116706848, Accuracy: 0.804931640625\n",
      "Batch No.: 176, Loss: 0.7175573706626892, Accuracy: 0.779052734375\n",
      "Batch No.: 177, Loss: 0.6801217198371887, Accuracy: 0.7861328125\n",
      "Batch No.: 178, Loss: 0.6245745420455933, Accuracy: 0.802001953125\n",
      "Batch No.: 179, Loss: 0.6587989330291748, Accuracy: 0.79248046875\n",
      "Batch No.: 180, Loss: 0.6817529201507568, Accuracy: 0.78076171875\n",
      "Batch No.: 181, Loss: 0.5964237451553345, Accuracy: 0.81201171875\n",
      "Batch No.: 182, Loss: 0.6593664884567261, Accuracy: 0.785888671875\n",
      "Batch No.: 183, Loss: 0.6390877366065979, Accuracy: 0.798828125\n",
      "Batch No.: 184, Loss: 0.6351250410079956, Accuracy: 0.802978515625\n",
      "Batch No.: 185, Loss: 0.668313205242157, Accuracy: 0.792724609375\n",
      "Batch No.: 186, Loss: 0.6418308019638062, Accuracy: 0.78759765625\n",
      "Batch No.: 187, Loss: 0.6188833713531494, Accuracy: 0.798095703125\n",
      "Batch No.: 188, Loss: 0.7305912971496582, Accuracy: 0.766357421875\n",
      "Batch No.: 189, Loss: 0.6068003177642822, Accuracy: 0.807861328125\n",
      "Batch No.: 190, Loss: 0.7420817613601685, Accuracy: 0.762939453125\n",
      "Batch No.: 191, Loss: 0.7175055742263794, Accuracy: 0.77392578125\n",
      "Batch No.: 192, Loss: 0.5570265054702759, Accuracy: 0.821533203125\n",
      "Batch No.: 193, Loss: 0.6830661296844482, Accuracy: 0.778076171875\n",
      "Batch No.: 194, Loss: 0.6662213802337646, Accuracy: 0.787841796875\n",
      "Batch No.: 195, Loss: 0.5663506984710693, Accuracy: 0.8203125\n",
      "Batch No.: 196, Loss: 0.67415452003479, Accuracy: 0.787353515625\n",
      "Batch No.: 197, Loss: 0.6432801485061646, Accuracy: 0.795654296875\n",
      "Batch No.: 198, Loss: 0.5722649097442627, Accuracy: 0.813720703125\n",
      "Batch No.: 199, Loss: 0.6680018901824951, Accuracy: 0.7890625\n",
      "Batch No.: 200, Loss: 0.6155905723571777, Accuracy: 0.804931640625\n",
      "Batch No.: 201, Loss: 0.6481271982192993, Accuracy: 0.796630859375\n",
      "Batch No.: 202, Loss: 0.6751141548156738, Accuracy: 0.78515625\n",
      "Batch No.: 203, Loss: 0.601800799369812, Accuracy: 0.8056640625\n",
      "Batch No.: 204, Loss: 0.6051748394966125, Accuracy: 0.8037109375\n",
      "Batch No.: 205, Loss: 0.6275750398635864, Accuracy: 0.80126953125\n",
      "Batch No.: 206, Loss: 0.6648420095443726, Accuracy: 0.79345703125\n",
      "Batch No.: 207, Loss: 0.6310281157493591, Accuracy: 0.798095703125\n",
      "Batch No.: 208, Loss: 0.7199786901473999, Accuracy: 0.771484375\n",
      "Batch No.: 209, Loss: 0.6192196607589722, Accuracy: 0.80078125\n",
      "Batch No.: 210, Loss: 0.6005429029464722, Accuracy: 0.814453125\n",
      "Batch No.: 211, Loss: 0.6914266347885132, Accuracy: 0.776123046875\n",
      "Batch No.: 212, Loss: 0.5991498231887817, Accuracy: 0.81298828125\n",
      "Batch No.: 213, Loss: 0.6077560186386108, Accuracy: 0.804443359375\n",
      "Batch No.: 214, Loss: 0.6608994603157043, Accuracy: 0.789794921875\n",
      "Batch No.: 215, Loss: 0.6613608598709106, Accuracy: 0.796630859375\n",
      "Batch No.: 216, Loss: 0.5981705188751221, Accuracy: 0.806396484375\n",
      "Batch No.: 217, Loss: 0.6231673955917358, Accuracy: 0.794921875\n",
      "Batch No.: 218, Loss: 0.6512116193771362, Accuracy: 0.78662109375\n",
      "Batch No.: 219, Loss: 0.6957089900970459, Accuracy: 0.78466796875\n",
      "Batch No.: 220, Loss: 0.677920937538147, Accuracy: 0.781005859375\n",
      "Batch No.: 221, Loss: 0.6763771772384644, Accuracy: 0.7841796875\n",
      "Batch No.: 222, Loss: 0.7011034488677979, Accuracy: 0.776611328125\n",
      "Batch No.: 223, Loss: 0.6432074308395386, Accuracy: 0.794921875\n",
      "Batch No.: 224, Loss: 0.6196644306182861, Accuracy: 0.804443359375\n",
      "Batch No.: 225, Loss: 0.6615601181983948, Accuracy: 0.78955078125\n",
      "Batch No.: 226, Loss: 0.6158902645111084, Accuracy: 0.80078125\n",
      "Batch No.: 227, Loss: 0.5892091989517212, Accuracy: 0.813720703125\n",
      "Batch No.: 228, Loss: 0.7216640710830688, Accuracy: 0.77392578125\n",
      "Batch No.: 229, Loss: 0.6666611433029175, Accuracy: 0.786376953125\n",
      "Batch No.: 230, Loss: 0.6112618446350098, Accuracy: 0.8037109375\n",
      "Batch No.: 231, Loss: 0.6595672369003296, Accuracy: 0.7890625\n",
      "Batch No.: 232, Loss: 0.653154730796814, Accuracy: 0.79052734375\n",
      "Batch No.: 233, Loss: 0.5757375359535217, Accuracy: 0.8154296875\n",
      "Batch No.: 234, Loss: 0.6916817426681519, Accuracy: 0.786865234375\n",
      "Batch No.: 235, Loss: 0.6461717486381531, Accuracy: 0.802001953125\n",
      "Batch No.: 236, Loss: 0.6390387415885925, Accuracy: 0.795654296875\n",
      "Batch No.: 237, Loss: 0.7277463674545288, Accuracy: 0.764892578125\n",
      "Batch No.: 238, Loss: 0.6360694169998169, Accuracy: 0.798828125\n",
      "Batch No.: 239, Loss: 0.5973302125930786, Accuracy: 0.806396484375\n",
      "Batch No.: 240, Loss: 0.6501297950744629, Accuracy: 0.797119140625\n",
      "Batch No.: 241, Loss: 0.6567304134368896, Accuracy: 0.791259765625\n",
      "Batch No.: 242, Loss: 0.5744298100471497, Accuracy: 0.81494140625\n",
      "Batch No.: 243, Loss: 0.6532410383224487, Accuracy: 0.79443359375\n",
      "Batch No.: 244, Loss: 0.6827487945556641, Accuracy: 0.77587890625\n",
      "Batch No.: 245, Loss: 0.5813099145889282, Accuracy: 0.8154296875\n",
      "Batch No.: 246, Loss: 0.6190923452377319, Accuracy: 0.80419921875\n",
      "Batch No.: 247, Loss: 0.6220180988311768, Accuracy: 0.8037109375\n",
      "Batch No.: 248, Loss: 0.6456482410430908, Accuracy: 0.7958984375\n",
      "Batch No.: 249, Loss: 0.6792881488800049, Accuracy: 0.79150390625\n",
      "Batch No.: 250, Loss: 0.6336742639541626, Accuracy: 0.804443359375\n",
      "Batch No.: 251, Loss: 0.653419017791748, Accuracy: 0.7998046875\n",
      "Batch No.: 252, Loss: 0.5984621047973633, Accuracy: 0.81103515625\n",
      "Batch No.: 253, Loss: 0.6199414134025574, Accuracy: 0.802734375\n",
      "Batch No.: 254, Loss: 0.6463738083839417, Accuracy: 0.791015625\n",
      "Batch No.: 255, Loss: 0.6584808826446533, Accuracy: 0.795654296875\n",
      "Batch No.: 256, Loss: 0.6054600477218628, Accuracy: 0.8076171875\n",
      "Batch No.: 257, Loss: 0.675582230091095, Accuracy: 0.784423828125\n",
      "Batch No.: 258, Loss: 0.6584903597831726, Accuracy: 0.795654296875\n",
      "Batch No.: 259, Loss: 0.5739912390708923, Accuracy: 0.815673828125\n",
      "Batch No.: 260, Loss: 0.6773697137832642, Accuracy: 0.78662109375\n",
      "Batch No.: 261, Loss: 0.6772136688232422, Accuracy: 0.777587890625\n",
      "Batch No.: 262, Loss: 0.5719149112701416, Accuracy: 0.8173828125\n",
      "Batch No.: 263, Loss: 0.6579766273498535, Accuracy: 0.798095703125\n",
      "Batch No.: 264, Loss: 0.583971381187439, Accuracy: 0.80908203125\n",
      "Epoch 65/80\n",
      "Batch No.: 1, Loss: 1.0150423049926758, Accuracy: 0.725830078125\n",
      "Batch No.: 2, Loss: 0.5638700723648071, Accuracy: 0.81591796875\n",
      "Batch No.: 3, Loss: 0.5889648795127869, Accuracy: 0.808349609375\n",
      "Batch No.: 4, Loss: 0.5956716537475586, Accuracy: 0.80908203125\n",
      "Batch No.: 5, Loss: 0.6326624751091003, Accuracy: 0.79541015625\n",
      "Batch No.: 6, Loss: 0.5686460733413696, Accuracy: 0.826171875\n",
      "Batch No.: 7, Loss: 0.5849108695983887, Accuracy: 0.805908203125\n",
      "Batch No.: 8, Loss: 0.6594581007957458, Accuracy: 0.786865234375\n",
      "Batch No.: 9, Loss: 0.5052114725112915, Accuracy: 0.837158203125\n",
      "Batch No.: 10, Loss: 0.6164807677268982, Accuracy: 0.801513671875\n",
      "Batch No.: 11, Loss: 0.6249207258224487, Accuracy: 0.797607421875\n",
      "Batch No.: 12, Loss: 0.6115758419036865, Accuracy: 0.811767578125\n",
      "Batch No.: 13, Loss: 0.6640702486038208, Accuracy: 0.779296875\n",
      "Batch No.: 14, Loss: 0.645387589931488, Accuracy: 0.800048828125\n",
      "Batch No.: 15, Loss: 0.6682479381561279, Accuracy: 0.79150390625\n",
      "Batch No.: 16, Loss: 0.5752463340759277, Accuracy: 0.813232421875\n",
      "Batch No.: 17, Loss: 0.6577087640762329, Accuracy: 0.7958984375\n",
      "Batch No.: 18, Loss: 0.662601113319397, Accuracy: 0.782470703125\n",
      "Batch No.: 19, Loss: 0.5916239619255066, Accuracy: 0.81005859375\n",
      "Batch No.: 20, Loss: 0.6211739778518677, Accuracy: 0.797607421875\n",
      "Batch No.: 21, Loss: 0.6771272420883179, Accuracy: 0.78173828125\n",
      "Batch No.: 22, Loss: 0.5863293409347534, Accuracy: 0.813720703125\n",
      "Batch No.: 23, Loss: 0.5324097871780396, Accuracy: 0.829345703125\n",
      "Batch No.: 24, Loss: 0.7008422613143921, Accuracy: 0.776123046875\n",
      "Batch No.: 25, Loss: 0.7047088146209717, Accuracy: 0.78369140625\n",
      "Batch No.: 26, Loss: 0.5618469715118408, Accuracy: 0.81884765625\n",
      "Batch No.: 27, Loss: 0.6716524362564087, Accuracy: 0.786376953125\n",
      "Batch No.: 28, Loss: 0.6347874402999878, Accuracy: 0.796875\n",
      "Batch No.: 29, Loss: 0.5286267995834351, Accuracy: 0.830078125\n",
      "Batch No.: 30, Loss: 0.6925854086875916, Accuracy: 0.78466796875\n",
      "Batch No.: 31, Loss: 0.654285192489624, Accuracy: 0.790283203125\n",
      "Batch No.: 32, Loss: 0.5449805855751038, Accuracy: 0.825927734375\n",
      "Batch No.: 33, Loss: 0.6065467000007629, Accuracy: 0.806396484375\n",
      "Batch No.: 34, Loss: 0.6361218690872192, Accuracy: 0.79296875\n",
      "Batch No.: 35, Loss: 0.5918273329734802, Accuracy: 0.802001953125\n",
      "Batch No.: 36, Loss: 0.6313490867614746, Accuracy: 0.799072265625\n",
      "Batch No.: 37, Loss: 0.673417329788208, Accuracy: 0.7900390625\n",
      "Batch No.: 38, Loss: 0.6472203135490417, Accuracy: 0.794677734375\n",
      "Batch No.: 39, Loss: 0.5755496025085449, Accuracy: 0.81103515625\n",
      "Batch No.: 40, Loss: 0.6113811731338501, Accuracy: 0.806884765625\n",
      "Batch No.: 41, Loss: 0.687651515007019, Accuracy: 0.788818359375\n",
      "Batch No.: 42, Loss: 0.6082820892333984, Accuracy: 0.807861328125\n",
      "Batch No.: 43, Loss: 0.6135607957839966, Accuracy: 0.8095703125\n",
      "Batch No.: 44, Loss: 0.6337507963180542, Accuracy: 0.7958984375\n",
      "Batch No.: 45, Loss: 0.6176527738571167, Accuracy: 0.8095703125\n",
      "Batch No.: 46, Loss: 0.5848307609558105, Accuracy: 0.8115234375\n",
      "Batch No.: 47, Loss: 0.6772246956825256, Accuracy: 0.778564453125\n",
      "Batch No.: 48, Loss: 0.5918026566505432, Accuracy: 0.807861328125\n",
      "Batch No.: 49, Loss: 0.6263507604598999, Accuracy: 0.799560546875\n",
      "Batch No.: 50, Loss: 0.6600983142852783, Accuracy: 0.7880859375\n",
      "Batch No.: 51, Loss: 0.6315324306488037, Accuracy: 0.803466796875\n",
      "Batch No.: 52, Loss: 0.6264994144439697, Accuracy: 0.8076171875\n",
      "Batch No.: 53, Loss: 0.5921962261199951, Accuracy: 0.81005859375\n",
      "Batch No.: 54, Loss: 0.688885509967804, Accuracy: 0.779052734375\n",
      "Batch No.: 55, Loss: 0.6584414839744568, Accuracy: 0.791748046875\n",
      "Batch No.: 56, Loss: 0.6227152347564697, Accuracy: 0.80859375\n",
      "Batch No.: 57, Loss: 0.6395644545555115, Accuracy: 0.794677734375\n",
      "Batch No.: 58, Loss: 0.5934693813323975, Accuracy: 0.813720703125\n",
      "Batch No.: 59, Loss: 0.6339617371559143, Accuracy: 0.79052734375\n",
      "Batch No.: 60, Loss: 0.6340761780738831, Accuracy: 0.8017578125\n",
      "Batch No.: 61, Loss: 0.5927155613899231, Accuracy: 0.80908203125\n",
      "Batch No.: 62, Loss: 0.6715711355209351, Accuracy: 0.78759765625\n",
      "Batch No.: 63, Loss: 0.6025086045265198, Accuracy: 0.806640625\n",
      "Batch No.: 64, Loss: 0.6390042304992676, Accuracy: 0.80126953125\n",
      "Batch No.: 65, Loss: 0.709686815738678, Accuracy: 0.76025390625\n",
      "Batch No.: 66, Loss: 0.5911111831665039, Accuracy: 0.80810546875\n",
      "Batch No.: 67, Loss: 0.5800941586494446, Accuracy: 0.8125\n",
      "Batch No.: 68, Loss: 0.6797313690185547, Accuracy: 0.781005859375\n",
      "Batch No.: 69, Loss: 0.660833477973938, Accuracy: 0.7880859375\n",
      "Batch No.: 70, Loss: 0.5880060195922852, Accuracy: 0.814697265625\n",
      "Batch No.: 71, Loss: 0.6530894041061401, Accuracy: 0.7919921875\n",
      "Batch No.: 72, Loss: 0.6214497089385986, Accuracy: 0.806884765625\n",
      "Batch No.: 73, Loss: 0.6265810132026672, Accuracy: 0.800048828125\n",
      "Batch No.: 74, Loss: 0.613746702671051, Accuracy: 0.79931640625\n",
      "Batch No.: 75, Loss: 0.6056187152862549, Accuracy: 0.80517578125\n",
      "Batch No.: 76, Loss: 0.6106613278388977, Accuracy: 0.802734375\n",
      "Batch No.: 77, Loss: 0.6553983092308044, Accuracy: 0.789794921875\n",
      "Batch No.: 78, Loss: 0.619633674621582, Accuracy: 0.7978515625\n",
      "Batch No.: 79, Loss: 0.622262716293335, Accuracy: 0.80615234375\n",
      "Batch No.: 80, Loss: 0.663955569267273, Accuracy: 0.786865234375\n",
      "Batch No.: 81, Loss: 0.6480472683906555, Accuracy: 0.79345703125\n",
      "Batch No.: 82, Loss: 0.630528450012207, Accuracy: 0.79638671875\n",
      "Batch No.: 83, Loss: 0.5843664407730103, Accuracy: 0.821533203125\n",
      "Batch No.: 84, Loss: 0.6715880632400513, Accuracy: 0.781005859375\n",
      "Batch No.: 85, Loss: 0.6572538614273071, Accuracy: 0.787109375\n",
      "Batch No.: 86, Loss: 0.555903434753418, Accuracy: 0.81591796875\n",
      "Batch No.: 87, Loss: 0.5853191614151001, Accuracy: 0.81103515625\n",
      "Batch No.: 88, Loss: 0.6391034126281738, Accuracy: 0.79736328125\n",
      "Batch No.: 89, Loss: 0.5873215794563293, Accuracy: 0.811767578125\n",
      "Batch No.: 90, Loss: 0.5820047855377197, Accuracy: 0.813720703125\n",
      "Batch No.: 91, Loss: 0.5887660980224609, Accuracy: 0.82275390625\n",
      "Batch No.: 92, Loss: 0.5804643630981445, Accuracy: 0.80859375\n",
      "Batch No.: 93, Loss: 0.6183618307113647, Accuracy: 0.804931640625\n",
      "Batch No.: 94, Loss: 0.6519134044647217, Accuracy: 0.79150390625\n",
      "Batch No.: 95, Loss: 0.6665704250335693, Accuracy: 0.79541015625\n",
      "Batch No.: 96, Loss: 0.5796281099319458, Accuracy: 0.81298828125\n",
      "Batch No.: 97, Loss: 0.6314269304275513, Accuracy: 0.80517578125\n",
      "Batch No.: 98, Loss: 0.6430627703666687, Accuracy: 0.7958984375\n",
      "Batch No.: 99, Loss: 0.6688435077667236, Accuracy: 0.79443359375\n",
      "Batch No.: 100, Loss: 0.6335119009017944, Accuracy: 0.78857421875\n",
      "Batch No.: 101, Loss: 0.5689822435379028, Accuracy: 0.818359375\n",
      "Batch No.: 102, Loss: 0.6736546754837036, Accuracy: 0.788330078125\n",
      "Batch No.: 103, Loss: 0.6526325345039368, Accuracy: 0.79638671875\n",
      "Batch No.: 104, Loss: 0.6292682886123657, Accuracy: 0.8046875\n",
      "Batch No.: 105, Loss: 0.6722328662872314, Accuracy: 0.787109375\n",
      "Batch No.: 106, Loss: 0.6434329748153687, Accuracy: 0.786865234375\n",
      "Batch No.: 107, Loss: 0.6240776777267456, Accuracy: 0.808349609375\n",
      "Batch No.: 108, Loss: 0.6212470531463623, Accuracy: 0.800537109375\n",
      "Batch No.: 109, Loss: 0.6542724370956421, Accuracy: 0.791015625\n",
      "Batch No.: 110, Loss: 0.6121683120727539, Accuracy: 0.806884765625\n",
      "Batch No.: 111, Loss: 0.613578736782074, Accuracy: 0.802978515625\n",
      "Batch No.: 112, Loss: 0.5763115286827087, Accuracy: 0.811279296875\n",
      "Batch No.: 113, Loss: 0.6673038005828857, Accuracy: 0.787353515625\n",
      "Batch No.: 114, Loss: 0.6568194031715393, Accuracy: 0.79150390625\n",
      "Batch No.: 115, Loss: 0.6318271160125732, Accuracy: 0.797607421875\n",
      "Batch No.: 116, Loss: 0.6897876262664795, Accuracy: 0.78955078125\n",
      "Batch No.: 117, Loss: 0.5867007970809937, Accuracy: 0.808349609375\n",
      "Batch No.: 118, Loss: 0.6367288827896118, Accuracy: 0.79931640625\n",
      "Batch No.: 119, Loss: 0.6402853727340698, Accuracy: 0.797119140625\n",
      "Batch No.: 120, Loss: 0.6661449670791626, Accuracy: 0.7900390625\n",
      "Batch No.: 121, Loss: 0.6577856540679932, Accuracy: 0.796875\n",
      "Batch No.: 122, Loss: 0.6955145001411438, Accuracy: 0.77490234375\n",
      "Batch No.: 123, Loss: 0.6999169588088989, Accuracy: 0.783935546875\n",
      "Batch No.: 124, Loss: 0.6518926024436951, Accuracy: 0.795654296875\n",
      "Batch No.: 125, Loss: 0.6688612699508667, Accuracy: 0.785400390625\n",
      "Batch No.: 126, Loss: 0.6383371949195862, Accuracy: 0.79638671875\n",
      "Batch No.: 127, Loss: 0.6127098202705383, Accuracy: 0.8076171875\n",
      "Batch No.: 128, Loss: 0.6102434992790222, Accuracy: 0.808837890625\n",
      "Batch No.: 129, Loss: 0.686448335647583, Accuracy: 0.784912109375\n",
      "Batch No.: 130, Loss: 0.6715924143791199, Accuracy: 0.78759765625\n",
      "Batch No.: 131, Loss: 0.6607600450515747, Accuracy: 0.790771484375\n",
      "Batch No.: 132, Loss: 0.7349339723587036, Accuracy: 0.765625\n",
      "Batch No.: 133, Loss: 0.6488797068595886, Accuracy: 0.795166015625\n",
      "Batch No.: 134, Loss: 0.6261744499206543, Accuracy: 0.803466796875\n",
      "Batch No.: 135, Loss: 0.6910398006439209, Accuracy: 0.776611328125\n",
      "Batch No.: 136, Loss: 0.5924122333526611, Accuracy: 0.8115234375\n",
      "Batch No.: 137, Loss: 0.6189489960670471, Accuracy: 0.802734375\n",
      "Batch No.: 138, Loss: 0.6690022945404053, Accuracy: 0.7890625\n",
      "Batch No.: 139, Loss: 0.649113655090332, Accuracy: 0.800048828125\n",
      "Batch No.: 140, Loss: 0.6424720287322998, Accuracy: 0.79248046875\n",
      "Batch No.: 141, Loss: 0.7150548696517944, Accuracy: 0.775634765625\n",
      "Batch No.: 142, Loss: 0.7497043013572693, Accuracy: 0.765625\n",
      "Batch No.: 143, Loss: 0.6464028358459473, Accuracy: 0.797607421875\n",
      "Batch No.: 144, Loss: 0.6601532697677612, Accuracy: 0.782958984375\n",
      "Batch No.: 145, Loss: 0.647838830947876, Accuracy: 0.78564453125\n",
      "Batch No.: 146, Loss: 0.6376545429229736, Accuracy: 0.79443359375\n",
      "Batch No.: 147, Loss: 0.6478127241134644, Accuracy: 0.792724609375\n",
      "Batch No.: 148, Loss: 0.6282399892807007, Accuracy: 0.795166015625\n",
      "Batch No.: 149, Loss: 0.6576445698738098, Accuracy: 0.789794921875\n",
      "Batch No.: 150, Loss: 0.668046236038208, Accuracy: 0.79345703125\n",
      "Batch No.: 151, Loss: 0.6534568071365356, Accuracy: 0.792724609375\n",
      "Batch No.: 152, Loss: 0.6308654546737671, Accuracy: 0.795166015625\n",
      "Batch No.: 153, Loss: 0.6537845730781555, Accuracy: 0.78759765625\n",
      "Batch No.: 154, Loss: 0.6268924474716187, Accuracy: 0.791748046875\n",
      "Batch No.: 155, Loss: 0.5823497772216797, Accuracy: 0.814453125\n",
      "Batch No.: 156, Loss: 0.6490585803985596, Accuracy: 0.795654296875\n",
      "Batch No.: 157, Loss: 0.6178964376449585, Accuracy: 0.8046875\n",
      "Batch No.: 158, Loss: 0.6605339050292969, Accuracy: 0.7880859375\n",
      "Batch No.: 159, Loss: 0.6518787145614624, Accuracy: 0.7958984375\n",
      "Batch No.: 160, Loss: 0.6747366786003113, Accuracy: 0.789306640625\n",
      "Batch No.: 161, Loss: 0.6928195953369141, Accuracy: 0.77978515625\n",
      "Batch No.: 162, Loss: 0.6665244102478027, Accuracy: 0.78857421875\n",
      "Batch No.: 163, Loss: 0.6023590564727783, Accuracy: 0.80517578125\n",
      "Batch No.: 164, Loss: 0.7105047106742859, Accuracy: 0.769287109375\n",
      "Batch No.: 165, Loss: 0.6253224611282349, Accuracy: 0.797119140625\n",
      "Batch No.: 166, Loss: 0.5860595107078552, Accuracy: 0.811767578125\n",
      "Batch No.: 167, Loss: 0.7450429797172546, Accuracy: 0.76611328125\n",
      "Batch No.: 168, Loss: 0.630778431892395, Accuracy: 0.795166015625\n",
      "Batch No.: 169, Loss: 0.6505612134933472, Accuracy: 0.786376953125\n",
      "Batch No.: 170, Loss: 0.7525404095649719, Accuracy: 0.75732421875\n",
      "Batch No.: 171, Loss: 0.708662748336792, Accuracy: 0.7763671875\n",
      "Batch No.: 172, Loss: 0.6512213945388794, Accuracy: 0.797607421875\n",
      "Batch No.: 173, Loss: 0.6622528433799744, Accuracy: 0.78173828125\n",
      "Batch No.: 174, Loss: 0.6781863570213318, Accuracy: 0.787109375\n",
      "Batch No.: 175, Loss: 0.6043262481689453, Accuracy: 0.81298828125\n",
      "Batch No.: 176, Loss: 0.6989390850067139, Accuracy: 0.781982421875\n",
      "Batch No.: 177, Loss: 0.6733765006065369, Accuracy: 0.789306640625\n",
      "Batch No.: 178, Loss: 0.631310224533081, Accuracy: 0.80712890625\n",
      "Batch No.: 179, Loss: 0.6381043195724487, Accuracy: 0.79931640625\n",
      "Batch No.: 180, Loss: 0.6858068108558655, Accuracy: 0.78076171875\n",
      "Batch No.: 181, Loss: 0.6119548082351685, Accuracy: 0.807373046875\n",
      "Batch No.: 182, Loss: 0.6416580677032471, Accuracy: 0.7900390625\n",
      "Batch No.: 183, Loss: 0.6208725571632385, Accuracy: 0.7978515625\n",
      "Batch No.: 184, Loss: 0.6393868923187256, Accuracy: 0.799072265625\n",
      "Batch No.: 185, Loss: 0.6769803762435913, Accuracy: 0.791259765625\n",
      "Batch No.: 186, Loss: 0.6296736598014832, Accuracy: 0.797119140625\n",
      "Batch No.: 187, Loss: 0.620884358882904, Accuracy: 0.79345703125\n",
      "Batch No.: 188, Loss: 0.7110809087753296, Accuracy: 0.77880859375\n",
      "Batch No.: 189, Loss: 0.5928530693054199, Accuracy: 0.804443359375\n",
      "Batch No.: 190, Loss: 0.7342605590820312, Accuracy: 0.77001953125\n",
      "Batch No.: 191, Loss: 0.7129155397415161, Accuracy: 0.769775390625\n",
      "Batch No.: 192, Loss: 0.5586518049240112, Accuracy: 0.81884765625\n",
      "Batch No.: 193, Loss: 0.6751376390457153, Accuracy: 0.780029296875\n",
      "Batch No.: 194, Loss: 0.655316948890686, Accuracy: 0.7919921875\n",
      "Batch No.: 195, Loss: 0.5742143392562866, Accuracy: 0.822265625\n",
      "Batch No.: 196, Loss: 0.6513187885284424, Accuracy: 0.790771484375\n",
      "Batch No.: 197, Loss: 0.6275191903114319, Accuracy: 0.7978515625\n",
      "Batch No.: 198, Loss: 0.5644978284835815, Accuracy: 0.816162109375\n",
      "Batch No.: 199, Loss: 0.6774041652679443, Accuracy: 0.78076171875\n",
      "Batch No.: 200, Loss: 0.5978471040725708, Accuracy: 0.81103515625\n",
      "Batch No.: 201, Loss: 0.6363011598587036, Accuracy: 0.79638671875\n",
      "Batch No.: 202, Loss: 0.6639028191566467, Accuracy: 0.78759765625\n",
      "Batch No.: 203, Loss: 0.6162416934967041, Accuracy: 0.80126953125\n",
      "Batch No.: 204, Loss: 0.6071418523788452, Accuracy: 0.8037109375\n",
      "Batch No.: 205, Loss: 0.6205015182495117, Accuracy: 0.8017578125\n",
      "Batch No.: 206, Loss: 0.6650286316871643, Accuracy: 0.7939453125\n",
      "Batch No.: 207, Loss: 0.6069623231887817, Accuracy: 0.8076171875\n",
      "Batch No.: 208, Loss: 0.7046396136283875, Accuracy: 0.78076171875\n",
      "Batch No.: 209, Loss: 0.6491177678108215, Accuracy: 0.797119140625\n",
      "Batch No.: 210, Loss: 0.6046518683433533, Accuracy: 0.811279296875\n",
      "Batch No.: 211, Loss: 0.6872023344039917, Accuracy: 0.781005859375\n",
      "Batch No.: 212, Loss: 0.5993591547012329, Accuracy: 0.810546875\n",
      "Batch No.: 213, Loss: 0.6031599044799805, Accuracy: 0.809326171875\n",
      "Batch No.: 214, Loss: 0.6722111105918884, Accuracy: 0.785888671875\n",
      "Batch No.: 215, Loss: 0.6694525480270386, Accuracy: 0.783203125\n",
      "Batch No.: 216, Loss: 0.6028591990470886, Accuracy: 0.8046875\n",
      "Batch No.: 217, Loss: 0.6237013936042786, Accuracy: 0.7998046875\n",
      "Batch No.: 218, Loss: 0.6551849842071533, Accuracy: 0.784912109375\n",
      "Batch No.: 219, Loss: 0.670594334602356, Accuracy: 0.7822265625\n",
      "Batch No.: 220, Loss: 0.6566706895828247, Accuracy: 0.78662109375\n",
      "Batch No.: 221, Loss: 0.6555940508842468, Accuracy: 0.795166015625\n",
      "Batch No.: 222, Loss: 0.685589611530304, Accuracy: 0.7783203125\n",
      "Batch No.: 223, Loss: 0.6305186748504639, Accuracy: 0.801513671875\n",
      "Batch No.: 224, Loss: 0.6154918670654297, Accuracy: 0.802001953125\n",
      "Batch No.: 225, Loss: 0.6491806507110596, Accuracy: 0.7890625\n",
      "Batch No.: 226, Loss: 0.6176100969314575, Accuracy: 0.799072265625\n",
      "Batch No.: 227, Loss: 0.584139883518219, Accuracy: 0.812744140625\n",
      "Batch No.: 228, Loss: 0.7135210633277893, Accuracy: 0.766357421875\n",
      "Batch No.: 229, Loss: 0.6554064750671387, Accuracy: 0.792236328125\n",
      "Batch No.: 230, Loss: 0.604063868522644, Accuracy: 0.809814453125\n",
      "Batch No.: 231, Loss: 0.6783144474029541, Accuracy: 0.783935546875\n",
      "Batch No.: 232, Loss: 0.6556938886642456, Accuracy: 0.7939453125\n",
      "Batch No.: 233, Loss: 0.5685427188873291, Accuracy: 0.8115234375\n",
      "Batch No.: 234, Loss: 0.6781116127967834, Accuracy: 0.7890625\n",
      "Batch No.: 235, Loss: 0.6367092728614807, Accuracy: 0.80029296875\n",
      "Batch No.: 236, Loss: 0.6377396583557129, Accuracy: 0.795166015625\n",
      "Batch No.: 237, Loss: 0.7180294394493103, Accuracy: 0.763671875\n",
      "Batch No.: 238, Loss: 0.6339584589004517, Accuracy: 0.794677734375\n",
      "Batch No.: 239, Loss: 0.6088469624519348, Accuracy: 0.798828125\n",
      "Batch No.: 240, Loss: 0.6538538336753845, Accuracy: 0.78759765625\n",
      "Batch No.: 241, Loss: 0.6502281427383423, Accuracy: 0.789794921875\n",
      "Batch No.: 242, Loss: 0.5919614434242249, Accuracy: 0.8125\n",
      "Batch No.: 243, Loss: 0.6344050168991089, Accuracy: 0.800048828125\n",
      "Batch No.: 244, Loss: 0.661733090877533, Accuracy: 0.79052734375\n",
      "Batch No.: 245, Loss: 0.5709167122840881, Accuracy: 0.81689453125\n",
      "Batch No.: 246, Loss: 0.606713056564331, Accuracy: 0.812255859375\n",
      "Batch No.: 247, Loss: 0.6326757669448853, Accuracy: 0.79638671875\n",
      "Batch No.: 248, Loss: 0.6272590756416321, Accuracy: 0.80517578125\n",
      "Batch No.: 249, Loss: 0.6671416163444519, Accuracy: 0.790771484375\n",
      "Batch No.: 250, Loss: 0.6134834289550781, Accuracy: 0.802734375\n",
      "Batch No.: 251, Loss: 0.6392596960067749, Accuracy: 0.79248046875\n",
      "Batch No.: 252, Loss: 0.5842810869216919, Accuracy: 0.81591796875\n",
      "Batch No.: 253, Loss: 0.6195214986801147, Accuracy: 0.7958984375\n",
      "Batch No.: 254, Loss: 0.651276707649231, Accuracy: 0.79296875\n",
      "Batch No.: 255, Loss: 0.6690080165863037, Accuracy: 0.78759765625\n",
      "Batch No.: 256, Loss: 0.5925594568252563, Accuracy: 0.811767578125\n",
      "Batch No.: 257, Loss: 0.6910794973373413, Accuracy: 0.779052734375\n",
      "Batch No.: 258, Loss: 0.643207848072052, Accuracy: 0.79736328125\n",
      "Batch No.: 259, Loss: 0.5906212329864502, Accuracy: 0.810302734375\n",
      "Batch No.: 260, Loss: 0.6931172609329224, Accuracy: 0.782470703125\n",
      "Batch No.: 261, Loss: 0.6751847267150879, Accuracy: 0.783935546875\n",
      "Batch No.: 262, Loss: 0.5807729363441467, Accuracy: 0.810791015625\n",
      "Batch No.: 263, Loss: 0.6482382416725159, Accuracy: 0.7919921875\n",
      "Batch No.: 264, Loss: 0.5850083231925964, Accuracy: 0.816650390625\n",
      "Epoch 66/80\n",
      "Batch No.: 1, Loss: 1.0279638767242432, Accuracy: 0.724365234375\n",
      "Batch No.: 2, Loss: 0.5811436176300049, Accuracy: 0.810791015625\n",
      "Batch No.: 3, Loss: 0.5920277833938599, Accuracy: 0.806396484375\n",
      "Batch No.: 4, Loss: 0.5889782309532166, Accuracy: 0.810546875\n",
      "Batch No.: 5, Loss: 0.652495265007019, Accuracy: 0.796142578125\n",
      "Batch No.: 6, Loss: 0.5732195377349854, Accuracy: 0.81787109375\n",
      "Batch No.: 7, Loss: 0.612214207649231, Accuracy: 0.80419921875\n",
      "Batch No.: 8, Loss: 0.650105357170105, Accuracy: 0.794189453125\n",
      "Batch No.: 9, Loss: 0.5130124092102051, Accuracy: 0.83203125\n",
      "Batch No.: 10, Loss: 0.608741044998169, Accuracy: 0.80908203125\n",
      "Batch No.: 11, Loss: 0.6214965581893921, Accuracy: 0.80078125\n",
      "Batch No.: 12, Loss: 0.6347781419754028, Accuracy: 0.80419921875\n",
      "Batch No.: 13, Loss: 0.6841801404953003, Accuracy: 0.78076171875\n",
      "Batch No.: 14, Loss: 0.6420170664787292, Accuracy: 0.791015625\n",
      "Batch No.: 15, Loss: 0.6640915870666504, Accuracy: 0.791015625\n",
      "Batch No.: 16, Loss: 0.6050909161567688, Accuracy: 0.8076171875\n",
      "Batch No.: 17, Loss: 0.6596519947052002, Accuracy: 0.78662109375\n",
      "Batch No.: 18, Loss: 0.6778720021247864, Accuracy: 0.785400390625\n",
      "Batch No.: 19, Loss: 0.6077073216438293, Accuracy: 0.8076171875\n",
      "Batch No.: 20, Loss: 0.6206316947937012, Accuracy: 0.802978515625\n",
      "Batch No.: 21, Loss: 0.6815636157989502, Accuracy: 0.7802734375\n",
      "Batch No.: 22, Loss: 0.5909637212753296, Accuracy: 0.810302734375\n",
      "Batch No.: 23, Loss: 0.5535097122192383, Accuracy: 0.822998046875\n",
      "Batch No.: 24, Loss: 0.7062405943870544, Accuracy: 0.7744140625\n",
      "Batch No.: 25, Loss: 0.6965460777282715, Accuracy: 0.77734375\n",
      "Batch No.: 26, Loss: 0.5589080452919006, Accuracy: 0.81787109375\n",
      "Batch No.: 27, Loss: 0.6752737760543823, Accuracy: 0.787353515625\n",
      "Batch No.: 28, Loss: 0.6519358158111572, Accuracy: 0.78857421875\n",
      "Batch No.: 29, Loss: 0.5416458249092102, Accuracy: 0.82275390625\n",
      "Batch No.: 30, Loss: 0.6986442804336548, Accuracy: 0.776123046875\n",
      "Batch No.: 31, Loss: 0.6696197986602783, Accuracy: 0.785400390625\n",
      "Batch No.: 32, Loss: 0.542730450630188, Accuracy: 0.82763671875\n",
      "Batch No.: 33, Loss: 0.6174002885818481, Accuracy: 0.806396484375\n",
      "Batch No.: 34, Loss: 0.6508601903915405, Accuracy: 0.79931640625\n",
      "Batch No.: 35, Loss: 0.578327476978302, Accuracy: 0.8095703125\n",
      "Batch No.: 36, Loss: 0.6149393320083618, Accuracy: 0.802490234375\n",
      "Batch No.: 37, Loss: 0.6511802077293396, Accuracy: 0.791748046875\n",
      "Batch No.: 38, Loss: 0.6532649993896484, Accuracy: 0.79931640625\n",
      "Batch No.: 39, Loss: 0.5703623294830322, Accuracy: 0.812744140625\n",
      "Batch No.: 40, Loss: 0.6116853356361389, Accuracy: 0.80419921875\n",
      "Batch No.: 41, Loss: 0.7054147124290466, Accuracy: 0.77685546875\n",
      "Batch No.: 42, Loss: 0.6373757123947144, Accuracy: 0.7998046875\n",
      "Batch No.: 43, Loss: 0.6145756840705872, Accuracy: 0.806640625\n",
      "Batch No.: 44, Loss: 0.6554241180419922, Accuracy: 0.791259765625\n",
      "Batch No.: 45, Loss: 0.6055794954299927, Accuracy: 0.803466796875\n",
      "Batch No.: 46, Loss: 0.592603862285614, Accuracy: 0.811279296875\n",
      "Batch No.: 47, Loss: 0.6742879152297974, Accuracy: 0.782958984375\n",
      "Batch No.: 48, Loss: 0.6005809903144836, Accuracy: 0.799560546875\n",
      "Batch No.: 49, Loss: 0.6282660365104675, Accuracy: 0.799072265625\n",
      "Batch No.: 50, Loss: 0.6631984710693359, Accuracy: 0.789306640625\n",
      "Batch No.: 51, Loss: 0.6375457644462585, Accuracy: 0.79736328125\n",
      "Batch No.: 52, Loss: 0.6224750876426697, Accuracy: 0.803955078125\n",
      "Batch No.: 53, Loss: 0.5944133400917053, Accuracy: 0.808349609375\n",
      "Batch No.: 54, Loss: 0.679205060005188, Accuracy: 0.78125\n",
      "Batch No.: 55, Loss: 0.6593935489654541, Accuracy: 0.79345703125\n",
      "Batch No.: 56, Loss: 0.6012537479400635, Accuracy: 0.81201171875\n",
      "Batch No.: 57, Loss: 0.6468212604522705, Accuracy: 0.794677734375\n",
      "Batch No.: 58, Loss: 0.5836552381515503, Accuracy: 0.810302734375\n",
      "Batch No.: 59, Loss: 0.6279638409614563, Accuracy: 0.7919921875\n",
      "Batch No.: 60, Loss: 0.6202952861785889, Accuracy: 0.7998046875\n",
      "Batch No.: 61, Loss: 0.5876775979995728, Accuracy: 0.810546875\n",
      "Batch No.: 62, Loss: 0.6581770181655884, Accuracy: 0.792236328125\n",
      "Batch No.: 63, Loss: 0.5938712358474731, Accuracy: 0.80712890625\n",
      "Batch No.: 64, Loss: 0.6644341945648193, Accuracy: 0.786376953125\n",
      "Batch No.: 65, Loss: 0.7163018584251404, Accuracy: 0.765625\n",
      "Batch No.: 66, Loss: 0.5948697924613953, Accuracy: 0.81640625\n",
      "Batch No.: 67, Loss: 0.5788522958755493, Accuracy: 0.816650390625\n",
      "Batch No.: 68, Loss: 0.6937000155448914, Accuracy: 0.7841796875\n",
      "Batch No.: 69, Loss: 0.6665105223655701, Accuracy: 0.794189453125\n",
      "Batch No.: 70, Loss: 0.5741391181945801, Accuracy: 0.819580078125\n",
      "Batch No.: 71, Loss: 0.6656249761581421, Accuracy: 0.78515625\n",
      "Batch No.: 72, Loss: 0.6243654489517212, Accuracy: 0.805419921875\n",
      "Batch No.: 73, Loss: 0.6471697092056274, Accuracy: 0.798095703125\n",
      "Batch No.: 74, Loss: 0.6236500144004822, Accuracy: 0.801513671875\n",
      "Batch No.: 75, Loss: 0.6278563737869263, Accuracy: 0.80615234375\n",
      "Batch No.: 76, Loss: 0.6217705011367798, Accuracy: 0.8017578125\n",
      "Batch No.: 77, Loss: 0.6504392623901367, Accuracy: 0.796630859375\n",
      "Batch No.: 78, Loss: 0.6156505346298218, Accuracy: 0.808837890625\n",
      "Batch No.: 79, Loss: 0.6017451286315918, Accuracy: 0.80810546875\n",
      "Batch No.: 80, Loss: 0.6394095420837402, Accuracy: 0.800048828125\n",
      "Batch No.: 81, Loss: 0.6661826968193054, Accuracy: 0.78564453125\n",
      "Batch No.: 82, Loss: 0.6501072645187378, Accuracy: 0.78466796875\n",
      "Batch No.: 83, Loss: 0.585439145565033, Accuracy: 0.811279296875\n",
      "Batch No.: 84, Loss: 0.6653097867965698, Accuracy: 0.7890625\n",
      "Batch No.: 85, Loss: 0.6496646404266357, Accuracy: 0.79541015625\n",
      "Batch No.: 86, Loss: 0.5704395771026611, Accuracy: 0.814697265625\n",
      "Batch No.: 87, Loss: 0.5904405117034912, Accuracy: 0.813232421875\n",
      "Batch No.: 88, Loss: 0.6212061047554016, Accuracy: 0.80029296875\n",
      "Batch No.: 89, Loss: 0.599107027053833, Accuracy: 0.8037109375\n",
      "Batch No.: 90, Loss: 0.5723413228988647, Accuracy: 0.8134765625\n",
      "Batch No.: 91, Loss: 0.5888447761535645, Accuracy: 0.816162109375\n",
      "Batch No.: 92, Loss: 0.5838674306869507, Accuracy: 0.811767578125\n",
      "Batch No.: 93, Loss: 0.6190602779388428, Accuracy: 0.807373046875\n",
      "Batch No.: 94, Loss: 0.6552218198776245, Accuracy: 0.79248046875\n",
      "Batch No.: 95, Loss: 0.6701276302337646, Accuracy: 0.785888671875\n",
      "Batch No.: 96, Loss: 0.58551424741745, Accuracy: 0.804931640625\n",
      "Batch No.: 97, Loss: 0.6411111354827881, Accuracy: 0.794189453125\n",
      "Batch No.: 98, Loss: 0.6477937698364258, Accuracy: 0.796875\n",
      "Batch No.: 99, Loss: 0.6520286798477173, Accuracy: 0.799072265625\n",
      "Batch No.: 100, Loss: 0.6448941826820374, Accuracy: 0.791748046875\n",
      "Batch No.: 101, Loss: 0.5754628777503967, Accuracy: 0.814697265625\n",
      "Batch No.: 102, Loss: 0.6699486970901489, Accuracy: 0.785400390625\n",
      "Batch No.: 103, Loss: 0.6560227870941162, Accuracy: 0.798095703125\n",
      "Batch No.: 104, Loss: 0.6352341175079346, Accuracy: 0.798583984375\n",
      "Batch No.: 105, Loss: 0.6436915397644043, Accuracy: 0.791748046875\n",
      "Batch No.: 106, Loss: 0.6429853439331055, Accuracy: 0.78759765625\n",
      "Batch No.: 107, Loss: 0.6104307174682617, Accuracy: 0.80419921875\n",
      "Batch No.: 108, Loss: 0.6366742849349976, Accuracy: 0.794921875\n",
      "Batch No.: 109, Loss: 0.6334184408187866, Accuracy: 0.802490234375\n",
      "Batch No.: 110, Loss: 0.6074129939079285, Accuracy: 0.806884765625\n",
      "Batch No.: 111, Loss: 0.5988805294036865, Accuracy: 0.808349609375\n",
      "Batch No.: 112, Loss: 0.5750489234924316, Accuracy: 0.814697265625\n",
      "Batch No.: 113, Loss: 0.6628129482269287, Accuracy: 0.781982421875\n",
      "Batch No.: 114, Loss: 0.6493117809295654, Accuracy: 0.79150390625\n",
      "Batch No.: 115, Loss: 0.6518008708953857, Accuracy: 0.80224609375\n",
      "Batch No.: 116, Loss: 0.7516064643859863, Accuracy: 0.77490234375\n",
      "Batch No.: 117, Loss: 0.6013321280479431, Accuracy: 0.81103515625\n",
      "Batch No.: 118, Loss: 0.6295021772384644, Accuracy: 0.796630859375\n",
      "Batch No.: 119, Loss: 0.6474616527557373, Accuracy: 0.793212890625\n",
      "Batch No.: 120, Loss: 0.667962908744812, Accuracy: 0.78564453125\n",
      "Batch No.: 121, Loss: 0.6621553897857666, Accuracy: 0.789794921875\n",
      "Batch No.: 122, Loss: 0.730868935585022, Accuracy: 0.768310546875\n",
      "Batch No.: 123, Loss: 0.7162110805511475, Accuracy: 0.77978515625\n",
      "Batch No.: 124, Loss: 0.6474872827529907, Accuracy: 0.794677734375\n",
      "Batch No.: 125, Loss: 0.6927722096443176, Accuracy: 0.781494140625\n",
      "Batch No.: 126, Loss: 0.6411117911338806, Accuracy: 0.79443359375\n",
      "Batch No.: 127, Loss: 0.6413337588310242, Accuracy: 0.79345703125\n",
      "Batch No.: 128, Loss: 0.6454557776451111, Accuracy: 0.794189453125\n",
      "Batch No.: 129, Loss: 0.6968371272087097, Accuracy: 0.77734375\n",
      "Batch No.: 130, Loss: 0.6745883226394653, Accuracy: 0.7939453125\n",
      "Batch No.: 131, Loss: 0.6793302893638611, Accuracy: 0.785400390625\n",
      "Batch No.: 132, Loss: 0.7754269242286682, Accuracy: 0.7548828125\n",
      "Batch No.: 133, Loss: 0.6574069261550903, Accuracy: 0.794677734375\n",
      "Batch No.: 134, Loss: 0.6483814716339111, Accuracy: 0.789306640625\n",
      "Batch No.: 135, Loss: 0.7200199365615845, Accuracy: 0.769287109375\n",
      "Batch No.: 136, Loss: 0.6153054237365723, Accuracy: 0.804931640625\n",
      "Batch No.: 137, Loss: 0.6535988450050354, Accuracy: 0.798828125\n",
      "Batch No.: 138, Loss: 0.7104126214981079, Accuracy: 0.78076171875\n",
      "Batch No.: 139, Loss: 0.6781084537506104, Accuracy: 0.787109375\n",
      "Batch No.: 140, Loss: 0.6499377489089966, Accuracy: 0.78955078125\n",
      "Batch No.: 141, Loss: 0.7271149754524231, Accuracy: 0.779541015625\n",
      "Batch No.: 142, Loss: 0.7880436182022095, Accuracy: 0.742919921875\n",
      "Batch No.: 143, Loss: 0.6692277789115906, Accuracy: 0.791259765625\n",
      "Batch No.: 144, Loss: 0.6973475217819214, Accuracy: 0.776611328125\n",
      "Batch No.: 145, Loss: 0.6935080289840698, Accuracy: 0.771728515625\n",
      "Batch No.: 146, Loss: 0.6501748561859131, Accuracy: 0.787353515625\n",
      "Batch No.: 147, Loss: 0.6817538142204285, Accuracy: 0.781005859375\n",
      "Batch No.: 148, Loss: 0.6315454244613647, Accuracy: 0.792724609375\n",
      "Batch No.: 149, Loss: 0.655553936958313, Accuracy: 0.78515625\n",
      "Batch No.: 150, Loss: 0.6896709203720093, Accuracy: 0.7763671875\n",
      "Batch No.: 151, Loss: 0.6638611555099487, Accuracy: 0.7890625\n",
      "Batch No.: 152, Loss: 0.6424263715744019, Accuracy: 0.79443359375\n",
      "Batch No.: 153, Loss: 0.6885077953338623, Accuracy: 0.7822265625\n",
      "Batch No.: 154, Loss: 0.6558386087417603, Accuracy: 0.7880859375\n",
      "Batch No.: 155, Loss: 0.5870915651321411, Accuracy: 0.81103515625\n",
      "Batch No.: 156, Loss: 0.6682013273239136, Accuracy: 0.791748046875\n",
      "Batch No.: 157, Loss: 0.630861759185791, Accuracy: 0.797119140625\n",
      "Batch No.: 158, Loss: 0.6663961410522461, Accuracy: 0.779296875\n",
      "Batch No.: 159, Loss: 0.6572931408882141, Accuracy: 0.795166015625\n",
      "Batch No.: 160, Loss: 0.6876997947692871, Accuracy: 0.7861328125\n",
      "Batch No.: 161, Loss: 0.665898323059082, Accuracy: 0.7880859375\n",
      "Batch No.: 162, Loss: 0.7005445957183838, Accuracy: 0.775390625\n",
      "Batch No.: 163, Loss: 0.6151303052902222, Accuracy: 0.803955078125\n",
      "Batch No.: 164, Loss: 0.7174862623214722, Accuracy: 0.767822265625\n",
      "Batch No.: 165, Loss: 0.6386064291000366, Accuracy: 0.799560546875\n",
      "Batch No.: 166, Loss: 0.6106839179992676, Accuracy: 0.813232421875\n",
      "Batch No.: 167, Loss: 0.7724806070327759, Accuracy: 0.7548828125\n",
      "Batch No.: 168, Loss: 0.6544104814529419, Accuracy: 0.79150390625\n",
      "Batch No.: 169, Loss: 0.7044631242752075, Accuracy: 0.787353515625\n",
      "Batch No.: 170, Loss: 0.7903086543083191, Accuracy: 0.750732421875\n",
      "Batch No.: 171, Loss: 0.7474370002746582, Accuracy: 0.774658203125\n",
      "Batch No.: 172, Loss: 0.6771238446235657, Accuracy: 0.79345703125\n",
      "Batch No.: 173, Loss: 0.6799712181091309, Accuracy: 0.7802734375\n",
      "Batch No.: 174, Loss: 0.6879051923751831, Accuracy: 0.7861328125\n",
      "Batch No.: 175, Loss: 0.6094689965248108, Accuracy: 0.80908203125\n",
      "Batch No.: 176, Loss: 0.7159154415130615, Accuracy: 0.771728515625\n",
      "Batch No.: 177, Loss: 0.6705424785614014, Accuracy: 0.785888671875\n",
      "Batch No.: 178, Loss: 0.6407404541969299, Accuracy: 0.7978515625\n",
      "Batch No.: 179, Loss: 0.6495581269264221, Accuracy: 0.793701171875\n",
      "Batch No.: 180, Loss: 0.6812129020690918, Accuracy: 0.780029296875\n",
      "Batch No.: 181, Loss: 0.596653938293457, Accuracy: 0.811767578125\n",
      "Batch No.: 182, Loss: 0.6650257110595703, Accuracy: 0.78662109375\n",
      "Batch No.: 183, Loss: 0.6212231516838074, Accuracy: 0.80224609375\n",
      "Batch No.: 184, Loss: 0.6313602328300476, Accuracy: 0.803466796875\n",
      "Batch No.: 185, Loss: 0.6807730197906494, Accuracy: 0.787353515625\n",
      "Batch No.: 186, Loss: 0.6329100131988525, Accuracy: 0.793212890625\n",
      "Batch No.: 187, Loss: 0.6147269606590271, Accuracy: 0.797607421875\n",
      "Batch No.: 188, Loss: 0.7159595489501953, Accuracy: 0.771240234375\n",
      "Batch No.: 189, Loss: 0.5964515209197998, Accuracy: 0.81201171875\n",
      "Batch No.: 190, Loss: 0.7435922622680664, Accuracy: 0.765380859375\n",
      "Batch No.: 191, Loss: 0.7137961387634277, Accuracy: 0.769287109375\n",
      "Batch No.: 192, Loss: 0.5544527173042297, Accuracy: 0.822265625\n",
      "Batch No.: 193, Loss: 0.6769108176231384, Accuracy: 0.778564453125\n",
      "Batch No.: 194, Loss: 0.6596815586090088, Accuracy: 0.79052734375\n",
      "Batch No.: 195, Loss: 0.5713887214660645, Accuracy: 0.820556640625\n",
      "Batch No.: 196, Loss: 0.66707444190979, Accuracy: 0.783935546875\n",
      "Batch No.: 197, Loss: 0.6263225078582764, Accuracy: 0.797607421875\n",
      "Batch No.: 198, Loss: 0.5792266130447388, Accuracy: 0.806640625\n",
      "Batch No.: 199, Loss: 0.6616355180740356, Accuracy: 0.78466796875\n",
      "Batch No.: 200, Loss: 0.5953415632247925, Accuracy: 0.807861328125\n",
      "Batch No.: 201, Loss: 0.6529140472412109, Accuracy: 0.794189453125\n",
      "Batch No.: 202, Loss: 0.6742067337036133, Accuracy: 0.781982421875\n",
      "Batch No.: 203, Loss: 0.6158109903335571, Accuracy: 0.793212890625\n",
      "Batch No.: 204, Loss: 0.604895293712616, Accuracy: 0.804443359375\n",
      "Batch No.: 205, Loss: 0.6151718497276306, Accuracy: 0.806396484375\n",
      "Batch No.: 206, Loss: 0.6541897058486938, Accuracy: 0.79296875\n",
      "Batch No.: 207, Loss: 0.6139180660247803, Accuracy: 0.798828125\n",
      "Batch No.: 208, Loss: 0.7071835398674011, Accuracy: 0.771240234375\n",
      "Batch No.: 209, Loss: 0.6488660573959351, Accuracy: 0.795654296875\n",
      "Batch No.: 210, Loss: 0.6155781149864197, Accuracy: 0.810546875\n",
      "Batch No.: 211, Loss: 0.672184944152832, Accuracy: 0.784423828125\n",
      "Batch No.: 212, Loss: 0.6066334247589111, Accuracy: 0.814697265625\n",
      "Batch No.: 213, Loss: 0.5975480079650879, Accuracy: 0.810546875\n",
      "Batch No.: 214, Loss: 0.7007482051849365, Accuracy: 0.7783203125\n",
      "Batch No.: 215, Loss: 0.6543372869491577, Accuracy: 0.798095703125\n",
      "Batch No.: 216, Loss: 0.5957164764404297, Accuracy: 0.808837890625\n",
      "Batch No.: 217, Loss: 0.6152883172035217, Accuracy: 0.7998046875\n",
      "Batch No.: 218, Loss: 0.6420817375183105, Accuracy: 0.783935546875\n",
      "Batch No.: 219, Loss: 0.6919388771057129, Accuracy: 0.77734375\n",
      "Batch No.: 220, Loss: 0.6805187463760376, Accuracy: 0.78271484375\n",
      "Batch No.: 221, Loss: 0.6825048923492432, Accuracy: 0.785888671875\n",
      "Batch No.: 222, Loss: 0.6999350786209106, Accuracy: 0.775390625\n",
      "Batch No.: 223, Loss: 0.6429226398468018, Accuracy: 0.7998046875\n",
      "Batch No.: 224, Loss: 0.6178841590881348, Accuracy: 0.804931640625\n",
      "Batch No.: 225, Loss: 0.6476463079452515, Accuracy: 0.79052734375\n",
      "Batch No.: 226, Loss: 0.6267094612121582, Accuracy: 0.8037109375\n",
      "Batch No.: 227, Loss: 0.5881239175796509, Accuracy: 0.808837890625\n",
      "Batch No.: 228, Loss: 0.7226701974868774, Accuracy: 0.769287109375\n",
      "Batch No.: 229, Loss: 0.678744912147522, Accuracy: 0.784912109375\n",
      "Batch No.: 230, Loss: 0.6125980019569397, Accuracy: 0.80810546875\n",
      "Batch No.: 231, Loss: 0.6832231879234314, Accuracy: 0.78271484375\n",
      "Batch No.: 232, Loss: 0.6524249315261841, Accuracy: 0.793701171875\n",
      "Batch No.: 233, Loss: 0.5784405469894409, Accuracy: 0.81396484375\n",
      "Batch No.: 234, Loss: 0.7161722183227539, Accuracy: 0.773193359375\n",
      "Batch No.: 235, Loss: 0.644910454750061, Accuracy: 0.790283203125\n",
      "Batch No.: 236, Loss: 0.6455479860305786, Accuracy: 0.789306640625\n",
      "Batch No.: 237, Loss: 0.7327671647071838, Accuracy: 0.768798828125\n",
      "Batch No.: 238, Loss: 0.6501330733299255, Accuracy: 0.793212890625\n",
      "Batch No.: 239, Loss: 0.604873776435852, Accuracy: 0.802490234375\n",
      "Batch No.: 240, Loss: 0.6385387778282166, Accuracy: 0.79541015625\n",
      "Batch No.: 241, Loss: 0.6455965042114258, Accuracy: 0.792236328125\n",
      "Batch No.: 242, Loss: 0.5885194540023804, Accuracy: 0.810546875\n",
      "Batch No.: 243, Loss: 0.6530237793922424, Accuracy: 0.79052734375\n",
      "Batch No.: 244, Loss: 0.6725715398788452, Accuracy: 0.788330078125\n",
      "Batch No.: 245, Loss: 0.5678151249885559, Accuracy: 0.822998046875\n",
      "Batch No.: 246, Loss: 0.5970337986946106, Accuracy: 0.806640625\n",
      "Batch No.: 247, Loss: 0.6158450841903687, Accuracy: 0.802490234375\n",
      "Batch No.: 248, Loss: 0.6196115016937256, Accuracy: 0.79833984375\n",
      "Batch No.: 249, Loss: 0.680202305316925, Accuracy: 0.784912109375\n",
      "Batch No.: 250, Loss: 0.637122631072998, Accuracy: 0.798828125\n",
      "Batch No.: 251, Loss: 0.6437177658081055, Accuracy: 0.78759765625\n",
      "Batch No.: 252, Loss: 0.5919166207313538, Accuracy: 0.81103515625\n",
      "Batch No.: 253, Loss: 0.6439640522003174, Accuracy: 0.796875\n",
      "Batch No.: 254, Loss: 0.6476343870162964, Accuracy: 0.789306640625\n",
      "Batch No.: 255, Loss: 0.6463079452514648, Accuracy: 0.797119140625\n",
      "Batch No.: 256, Loss: 0.5918726921081543, Accuracy: 0.811767578125\n",
      "Batch No.: 257, Loss: 0.687696099281311, Accuracy: 0.775634765625\n",
      "Batch No.: 258, Loss: 0.631676435470581, Accuracy: 0.796630859375\n",
      "Batch No.: 259, Loss: 0.587928831577301, Accuracy: 0.81005859375\n",
      "Batch No.: 260, Loss: 0.6841752529144287, Accuracy: 0.78564453125\n",
      "Batch No.: 261, Loss: 0.670993447303772, Accuracy: 0.78076171875\n",
      "Batch No.: 262, Loss: 0.5923936367034912, Accuracy: 0.811767578125\n",
      "Batch No.: 263, Loss: 0.6518394947052002, Accuracy: 0.7978515625\n",
      "Batch No.: 264, Loss: 0.5925617218017578, Accuracy: 0.81103515625\n",
      "Epoch 67/80\n",
      "Batch No.: 1, Loss: 1.0208749771118164, Accuracy: 0.723388671875\n",
      "Batch No.: 2, Loss: 0.5792325735092163, Accuracy: 0.8154296875\n",
      "Batch No.: 3, Loss: 0.5884140729904175, Accuracy: 0.80712890625\n",
      "Batch No.: 4, Loss: 0.5936641693115234, Accuracy: 0.806396484375\n",
      "Batch No.: 5, Loss: 0.65994793176651, Accuracy: 0.794189453125\n",
      "Batch No.: 6, Loss: 0.5643907785415649, Accuracy: 0.82373046875\n",
      "Batch No.: 7, Loss: 0.6052147150039673, Accuracy: 0.795654296875\n",
      "Batch No.: 8, Loss: 0.6617159843444824, Accuracy: 0.785888671875\n",
      "Batch No.: 9, Loss: 0.4981430768966675, Accuracy: 0.839599609375\n",
      "Batch No.: 10, Loss: 0.6225394606590271, Accuracy: 0.797119140625\n",
      "Batch No.: 11, Loss: 0.6035643815994263, Accuracy: 0.806884765625\n",
      "Batch No.: 12, Loss: 0.6306089162826538, Accuracy: 0.8046875\n",
      "Batch No.: 13, Loss: 0.657717227935791, Accuracy: 0.79345703125\n",
      "Batch No.: 14, Loss: 0.640550971031189, Accuracy: 0.796630859375\n",
      "Batch No.: 15, Loss: 0.6577317714691162, Accuracy: 0.794921875\n",
      "Batch No.: 16, Loss: 0.5823051929473877, Accuracy: 0.80859375\n",
      "Batch No.: 17, Loss: 0.6254459619522095, Accuracy: 0.79736328125\n",
      "Batch No.: 18, Loss: 0.6583878993988037, Accuracy: 0.7890625\n",
      "Batch No.: 19, Loss: 0.6036641597747803, Accuracy: 0.80712890625\n",
      "Batch No.: 20, Loss: 0.6112933158874512, Accuracy: 0.80322265625\n",
      "Batch No.: 21, Loss: 0.6616116762161255, Accuracy: 0.7900390625\n",
      "Batch No.: 22, Loss: 0.5857585668563843, Accuracy: 0.814453125\n",
      "Batch No.: 23, Loss: 0.5542246699333191, Accuracy: 0.82373046875\n",
      "Batch No.: 24, Loss: 0.6899437308311462, Accuracy: 0.779541015625\n",
      "Batch No.: 25, Loss: 0.7213223576545715, Accuracy: 0.774658203125\n",
      "Batch No.: 26, Loss: 0.5549827814102173, Accuracy: 0.82568359375\n",
      "Batch No.: 27, Loss: 0.6681783199310303, Accuracy: 0.790771484375\n",
      "Batch No.: 28, Loss: 0.6278687715530396, Accuracy: 0.798828125\n",
      "Batch No.: 29, Loss: 0.537636399269104, Accuracy: 0.82275390625\n",
      "Batch No.: 30, Loss: 0.6978002190589905, Accuracy: 0.77490234375\n",
      "Batch No.: 31, Loss: 0.6561542749404907, Accuracy: 0.78515625\n",
      "Batch No.: 32, Loss: 0.5289183855056763, Accuracy: 0.839111328125\n",
      "Batch No.: 33, Loss: 0.6393402218818665, Accuracy: 0.787841796875\n",
      "Batch No.: 34, Loss: 0.6403005123138428, Accuracy: 0.7978515625\n",
      "Batch No.: 35, Loss: 0.568713903427124, Accuracy: 0.81640625\n",
      "Batch No.: 36, Loss: 0.613384485244751, Accuracy: 0.802978515625\n",
      "Batch No.: 37, Loss: 0.6718343496322632, Accuracy: 0.7861328125\n",
      "Batch No.: 38, Loss: 0.6412671208381653, Accuracy: 0.7998046875\n",
      "Batch No.: 39, Loss: 0.5798386931419373, Accuracy: 0.819091796875\n",
      "Batch No.: 40, Loss: 0.6050702333450317, Accuracy: 0.80615234375\n",
      "Batch No.: 41, Loss: 0.6870609521865845, Accuracy: 0.78662109375\n",
      "Batch No.: 42, Loss: 0.612764835357666, Accuracy: 0.8056640625\n",
      "Batch No.: 43, Loss: 0.6112331748008728, Accuracy: 0.803466796875\n",
      "Batch No.: 44, Loss: 0.6402000188827515, Accuracy: 0.79248046875\n",
      "Batch No.: 45, Loss: 0.6068605184555054, Accuracy: 0.802734375\n",
      "Batch No.: 46, Loss: 0.5736336708068848, Accuracy: 0.812255859375\n",
      "Batch No.: 47, Loss: 0.663770854473114, Accuracy: 0.7841796875\n",
      "Batch No.: 48, Loss: 0.6022114157676697, Accuracy: 0.80224609375\n",
      "Batch No.: 49, Loss: 0.6222639679908752, Accuracy: 0.796630859375\n",
      "Batch No.: 50, Loss: 0.6586276292800903, Accuracy: 0.7880859375\n",
      "Batch No.: 51, Loss: 0.626664400100708, Accuracy: 0.796875\n",
      "Batch No.: 52, Loss: 0.618435800075531, Accuracy: 0.802001953125\n",
      "Batch No.: 53, Loss: 0.586711049079895, Accuracy: 0.812255859375\n",
      "Batch No.: 54, Loss: 0.6887573599815369, Accuracy: 0.778564453125\n",
      "Batch No.: 55, Loss: 0.6576431393623352, Accuracy: 0.796630859375\n",
      "Batch No.: 56, Loss: 0.6323075294494629, Accuracy: 0.805419921875\n",
      "Batch No.: 57, Loss: 0.644074559211731, Accuracy: 0.7939453125\n",
      "Batch No.: 58, Loss: 0.5934644937515259, Accuracy: 0.811767578125\n",
      "Batch No.: 59, Loss: 0.6273851990699768, Accuracy: 0.788818359375\n",
      "Batch No.: 60, Loss: 0.6213778257369995, Accuracy: 0.806884765625\n",
      "Batch No.: 61, Loss: 0.5774558782577515, Accuracy: 0.81396484375\n",
      "Batch No.: 62, Loss: 0.6341521739959717, Accuracy: 0.800537109375\n",
      "Batch No.: 63, Loss: 0.613378643989563, Accuracy: 0.80322265625\n",
      "Batch No.: 64, Loss: 0.6582326889038086, Accuracy: 0.7880859375\n",
      "Batch No.: 65, Loss: 0.7086499929428101, Accuracy: 0.778076171875\n",
      "Batch No.: 66, Loss: 0.5888848304748535, Accuracy: 0.815185546875\n",
      "Batch No.: 67, Loss: 0.5807246565818787, Accuracy: 0.813720703125\n",
      "Batch No.: 68, Loss: 0.6785594820976257, Accuracy: 0.781982421875\n",
      "Batch No.: 69, Loss: 0.6377443075180054, Accuracy: 0.7958984375\n",
      "Batch No.: 70, Loss: 0.5846365094184875, Accuracy: 0.814697265625\n",
      "Batch No.: 71, Loss: 0.6593502163887024, Accuracy: 0.7919921875\n",
      "Batch No.: 72, Loss: 0.6142218112945557, Accuracy: 0.811767578125\n",
      "Batch No.: 73, Loss: 0.6327450275421143, Accuracy: 0.80078125\n",
      "Batch No.: 74, Loss: 0.6216717958450317, Accuracy: 0.8017578125\n",
      "Batch No.: 75, Loss: 0.6250662803649902, Accuracy: 0.7998046875\n",
      "Batch No.: 76, Loss: 0.6191738843917847, Accuracy: 0.7998046875\n",
      "Batch No.: 77, Loss: 0.651114821434021, Accuracy: 0.794677734375\n",
      "Batch No.: 78, Loss: 0.6146326661109924, Accuracy: 0.8076171875\n",
      "Batch No.: 79, Loss: 0.6170334219932556, Accuracy: 0.802734375\n",
      "Batch No.: 80, Loss: 0.6561819314956665, Accuracy: 0.788818359375\n",
      "Batch No.: 81, Loss: 0.6541336178779602, Accuracy: 0.78955078125\n",
      "Batch No.: 82, Loss: 0.645840048789978, Accuracy: 0.80029296875\n",
      "Batch No.: 83, Loss: 0.5774016380310059, Accuracy: 0.817138671875\n",
      "Batch No.: 84, Loss: 0.6742799282073975, Accuracy: 0.7880859375\n",
      "Batch No.: 85, Loss: 0.6182180643081665, Accuracy: 0.8046875\n",
      "Batch No.: 86, Loss: 0.5719418525695801, Accuracy: 0.810546875\n",
      "Batch No.: 87, Loss: 0.571045994758606, Accuracy: 0.819091796875\n",
      "Batch No.: 88, Loss: 0.6310824155807495, Accuracy: 0.798095703125\n",
      "Batch No.: 89, Loss: 0.5820046663284302, Accuracy: 0.820556640625\n",
      "Batch No.: 90, Loss: 0.5786900520324707, Accuracy: 0.810302734375\n",
      "Batch No.: 91, Loss: 0.5944229364395142, Accuracy: 0.811279296875\n",
      "Batch No.: 92, Loss: 0.5868465900421143, Accuracy: 0.80078125\n",
      "Batch No.: 93, Loss: 0.6304892897605896, Accuracy: 0.80078125\n",
      "Batch No.: 94, Loss: 0.6358337998390198, Accuracy: 0.794677734375\n",
      "Batch No.: 95, Loss: 0.6566068530082703, Accuracy: 0.784912109375\n",
      "Batch No.: 96, Loss: 0.5778077840805054, Accuracy: 0.8125\n",
      "Batch No.: 97, Loss: 0.6315799951553345, Accuracy: 0.798583984375\n",
      "Batch No.: 98, Loss: 0.6269556283950806, Accuracy: 0.8017578125\n",
      "Batch No.: 99, Loss: 0.6500351428985596, Accuracy: 0.795654296875\n",
      "Batch No.: 100, Loss: 0.6317088603973389, Accuracy: 0.799072265625\n",
      "Batch No.: 101, Loss: 0.5637103915214539, Accuracy: 0.815185546875\n",
      "Batch No.: 102, Loss: 0.6532755494117737, Accuracy: 0.7890625\n",
      "Batch No.: 103, Loss: 0.6447256803512573, Accuracy: 0.7939453125\n",
      "Batch No.: 104, Loss: 0.6318351626396179, Accuracy: 0.80224609375\n",
      "Batch No.: 105, Loss: 0.6566512584686279, Accuracy: 0.789794921875\n",
      "Batch No.: 106, Loss: 0.640657901763916, Accuracy: 0.7939453125\n",
      "Batch No.: 107, Loss: 0.6034444570541382, Accuracy: 0.805419921875\n",
      "Batch No.: 108, Loss: 0.604272723197937, Accuracy: 0.8056640625\n",
      "Batch No.: 109, Loss: 0.6354688405990601, Accuracy: 0.802490234375\n",
      "Batch No.: 110, Loss: 0.5901693105697632, Accuracy: 0.810791015625\n",
      "Batch No.: 111, Loss: 0.5830289125442505, Accuracy: 0.811279296875\n",
      "Batch No.: 112, Loss: 0.5681392550468445, Accuracy: 0.814208984375\n",
      "Batch No.: 113, Loss: 0.6319520473480225, Accuracy: 0.80224609375\n",
      "Batch No.: 114, Loss: 0.6560632586479187, Accuracy: 0.78857421875\n",
      "Batch No.: 115, Loss: 0.6315453052520752, Accuracy: 0.7998046875\n",
      "Batch No.: 116, Loss: 0.7012600898742676, Accuracy: 0.775634765625\n",
      "Batch No.: 117, Loss: 0.6013975143432617, Accuracy: 0.803955078125\n",
      "Batch No.: 118, Loss: 0.6145732998847961, Accuracy: 0.7978515625\n",
      "Batch No.: 119, Loss: 0.6444753408432007, Accuracy: 0.79296875\n",
      "Batch No.: 120, Loss: 0.6734653115272522, Accuracy: 0.785888671875\n",
      "Batch No.: 121, Loss: 0.6458215117454529, Accuracy: 0.798828125\n",
      "Batch No.: 122, Loss: 0.6795287132263184, Accuracy: 0.788818359375\n",
      "Batch No.: 123, Loss: 0.7058621644973755, Accuracy: 0.777099609375\n",
      "Batch No.: 124, Loss: 0.6433382630348206, Accuracy: 0.7958984375\n",
      "Batch No.: 125, Loss: 0.6690319180488586, Accuracy: 0.790283203125\n",
      "Batch No.: 126, Loss: 0.6333198547363281, Accuracy: 0.794677734375\n",
      "Batch No.: 127, Loss: 0.6101577281951904, Accuracy: 0.8037109375\n",
      "Batch No.: 128, Loss: 0.6230869889259338, Accuracy: 0.803955078125\n",
      "Batch No.: 129, Loss: 0.6658748984336853, Accuracy: 0.781494140625\n",
      "Batch No.: 130, Loss: 0.6385163068771362, Accuracy: 0.800048828125\n",
      "Batch No.: 131, Loss: 0.6527822017669678, Accuracy: 0.800537109375\n",
      "Batch No.: 132, Loss: 0.7178229093551636, Accuracy: 0.7734375\n",
      "Batch No.: 133, Loss: 0.634205162525177, Accuracy: 0.797119140625\n",
      "Batch No.: 134, Loss: 0.6106846332550049, Accuracy: 0.798583984375\n",
      "Batch No.: 135, Loss: 0.6587283611297607, Accuracy: 0.78173828125\n",
      "Batch No.: 136, Loss: 0.5909550189971924, Accuracy: 0.806640625\n",
      "Batch No.: 137, Loss: 0.611357569694519, Accuracy: 0.801025390625\n",
      "Batch No.: 138, Loss: 0.6645081043243408, Accuracy: 0.79150390625\n",
      "Batch No.: 139, Loss: 0.6634414196014404, Accuracy: 0.800048828125\n",
      "Batch No.: 140, Loss: 0.637883722782135, Accuracy: 0.79052734375\n",
      "Batch No.: 141, Loss: 0.7004536390304565, Accuracy: 0.781982421875\n",
      "Batch No.: 142, Loss: 0.7649151086807251, Accuracy: 0.756103515625\n",
      "Batch No.: 143, Loss: 0.6492887735366821, Accuracy: 0.804443359375\n",
      "Batch No.: 144, Loss: 0.6494590640068054, Accuracy: 0.793212890625\n",
      "Batch No.: 145, Loss: 0.665631890296936, Accuracy: 0.786865234375\n",
      "Batch No.: 146, Loss: 0.6308176517486572, Accuracy: 0.7919921875\n",
      "Batch No.: 147, Loss: 0.6628419160842896, Accuracy: 0.787353515625\n",
      "Batch No.: 148, Loss: 0.6272169947624207, Accuracy: 0.79345703125\n",
      "Batch No.: 149, Loss: 0.6232060194015503, Accuracy: 0.79541015625\n",
      "Batch No.: 150, Loss: 0.6772562265396118, Accuracy: 0.78515625\n",
      "Batch No.: 151, Loss: 0.6457937955856323, Accuracy: 0.7939453125\n",
      "Batch No.: 152, Loss: 0.6289535164833069, Accuracy: 0.79736328125\n",
      "Batch No.: 153, Loss: 0.6554098129272461, Accuracy: 0.794189453125\n",
      "Batch No.: 154, Loss: 0.6319581270217896, Accuracy: 0.79833984375\n",
      "Batch No.: 155, Loss: 0.5581223964691162, Accuracy: 0.8212890625\n",
      "Batch No.: 156, Loss: 0.6472380757331848, Accuracy: 0.7958984375\n",
      "Batch No.: 157, Loss: 0.6118409037590027, Accuracy: 0.796630859375\n",
      "Batch No.: 158, Loss: 0.6286601424217224, Accuracy: 0.800048828125\n",
      "Batch No.: 159, Loss: 0.6287140846252441, Accuracy: 0.80029296875\n",
      "Batch No.: 160, Loss: 0.6601506471633911, Accuracy: 0.7880859375\n",
      "Batch No.: 161, Loss: 0.67826247215271, Accuracy: 0.786376953125\n",
      "Batch No.: 162, Loss: 0.6611106395721436, Accuracy: 0.786865234375\n",
      "Batch No.: 163, Loss: 0.5995075106620789, Accuracy: 0.806884765625\n",
      "Batch No.: 164, Loss: 0.690520167350769, Accuracy: 0.7744140625\n",
      "Batch No.: 165, Loss: 0.6135544180870056, Accuracy: 0.802001953125\n",
      "Batch No.: 166, Loss: 0.5929893255233765, Accuracy: 0.80908203125\n",
      "Batch No.: 167, Loss: 0.7374666929244995, Accuracy: 0.767333984375\n",
      "Batch No.: 168, Loss: 0.6256140470504761, Accuracy: 0.804931640625\n",
      "Batch No.: 169, Loss: 0.6652123928070068, Accuracy: 0.791748046875\n",
      "Batch No.: 170, Loss: 0.7167026996612549, Accuracy: 0.76708984375\n",
      "Batch No.: 171, Loss: 0.718229353427887, Accuracy: 0.782470703125\n",
      "Batch No.: 172, Loss: 0.6612482070922852, Accuracy: 0.794921875\n",
      "Batch No.: 173, Loss: 0.6609577536582947, Accuracy: 0.78466796875\n",
      "Batch No.: 174, Loss: 0.6911585330963135, Accuracy: 0.78662109375\n",
      "Batch No.: 175, Loss: 0.6058891415596008, Accuracy: 0.8125\n",
      "Batch No.: 176, Loss: 0.6919344663619995, Accuracy: 0.7783203125\n",
      "Batch No.: 177, Loss: 0.6579618453979492, Accuracy: 0.78759765625\n",
      "Batch No.: 178, Loss: 0.6286466717720032, Accuracy: 0.802734375\n",
      "Batch No.: 179, Loss: 0.6404398083686829, Accuracy: 0.797607421875\n",
      "Batch No.: 180, Loss: 0.6813148260116577, Accuracy: 0.787353515625\n",
      "Batch No.: 181, Loss: 0.5977574586868286, Accuracy: 0.811279296875\n",
      "Batch No.: 182, Loss: 0.6383990049362183, Accuracy: 0.7880859375\n",
      "Batch No.: 183, Loss: 0.6075055599212646, Accuracy: 0.80322265625\n",
      "Batch No.: 184, Loss: 0.6140331029891968, Accuracy: 0.807373046875\n",
      "Batch No.: 185, Loss: 0.6759719252586365, Accuracy: 0.78759765625\n",
      "Batch No.: 186, Loss: 0.6308818459510803, Accuracy: 0.794189453125\n",
      "Batch No.: 187, Loss: 0.6300923228263855, Accuracy: 0.79638671875\n",
      "Batch No.: 188, Loss: 0.7071164846420288, Accuracy: 0.77197265625\n",
      "Batch No.: 189, Loss: 0.5887534618377686, Accuracy: 0.81689453125\n",
      "Batch No.: 190, Loss: 0.707983136177063, Accuracy: 0.776611328125\n",
      "Batch No.: 191, Loss: 0.6949142217636108, Accuracy: 0.7744140625\n",
      "Batch No.: 192, Loss: 0.5640332698822021, Accuracy: 0.81689453125\n",
      "Batch No.: 193, Loss: 0.6764283776283264, Accuracy: 0.777099609375\n",
      "Batch No.: 194, Loss: 0.6653202176094055, Accuracy: 0.79052734375\n",
      "Batch No.: 195, Loss: 0.5453545451164246, Accuracy: 0.830810546875\n",
      "Batch No.: 196, Loss: 0.6377630233764648, Accuracy: 0.799072265625\n",
      "Batch No.: 197, Loss: 0.6196320652961731, Accuracy: 0.804443359375\n",
      "Batch No.: 198, Loss: 0.5672731399536133, Accuracy: 0.815185546875\n",
      "Batch No.: 199, Loss: 0.6490463018417358, Accuracy: 0.794189453125\n",
      "Batch No.: 200, Loss: 0.5959653854370117, Accuracy: 0.8095703125\n",
      "Batch No.: 201, Loss: 0.6659561991691589, Accuracy: 0.79150390625\n",
      "Batch No.: 202, Loss: 0.6573002338409424, Accuracy: 0.78271484375\n",
      "Batch No.: 203, Loss: 0.6077229380607605, Accuracy: 0.8056640625\n",
      "Batch No.: 204, Loss: 0.6000775098800659, Accuracy: 0.80859375\n",
      "Batch No.: 205, Loss: 0.61644446849823, Accuracy: 0.80810546875\n",
      "Batch No.: 206, Loss: 0.6480333209037781, Accuracy: 0.794677734375\n",
      "Batch No.: 207, Loss: 0.6094611883163452, Accuracy: 0.802734375\n",
      "Batch No.: 208, Loss: 0.7035154700279236, Accuracy: 0.779296875\n",
      "Batch No.: 209, Loss: 0.6446868181228638, Accuracy: 0.794189453125\n",
      "Batch No.: 210, Loss: 0.6098588705062866, Accuracy: 0.81298828125\n",
      "Batch No.: 211, Loss: 0.6753878593444824, Accuracy: 0.779296875\n",
      "Batch No.: 212, Loss: 0.6043906807899475, Accuracy: 0.8173828125\n",
      "Batch No.: 213, Loss: 0.5964006185531616, Accuracy: 0.805419921875\n",
      "Batch No.: 214, Loss: 0.6912974715232849, Accuracy: 0.775146484375\n",
      "Batch No.: 215, Loss: 0.6479707956314087, Accuracy: 0.799072265625\n",
      "Batch No.: 216, Loss: 0.5891436338424683, Accuracy: 0.807861328125\n",
      "Batch No.: 217, Loss: 0.6100529432296753, Accuracy: 0.807861328125\n",
      "Batch No.: 218, Loss: 0.6347368955612183, Accuracy: 0.78857421875\n",
      "Batch No.: 219, Loss: 0.6979912519454956, Accuracy: 0.77734375\n",
      "Batch No.: 220, Loss: 0.6619723439216614, Accuracy: 0.783935546875\n",
      "Batch No.: 221, Loss: 0.6461904644966125, Accuracy: 0.79296875\n",
      "Batch No.: 222, Loss: 0.6881934404373169, Accuracy: 0.77587890625\n",
      "Batch No.: 223, Loss: 0.634452223777771, Accuracy: 0.796142578125\n",
      "Batch No.: 224, Loss: 0.6112821102142334, Accuracy: 0.800048828125\n",
      "Batch No.: 225, Loss: 0.6335488557815552, Accuracy: 0.794189453125\n",
      "Batch No.: 226, Loss: 0.6017518043518066, Accuracy: 0.8046875\n",
      "Batch No.: 227, Loss: 0.5782445073127747, Accuracy: 0.8115234375\n",
      "Batch No.: 228, Loss: 0.7027236223220825, Accuracy: 0.77587890625\n",
      "Batch No.: 229, Loss: 0.6562595963478088, Accuracy: 0.791015625\n",
      "Batch No.: 230, Loss: 0.6122407913208008, Accuracy: 0.803955078125\n",
      "Batch No.: 231, Loss: 0.6618314981460571, Accuracy: 0.78662109375\n",
      "Batch No.: 232, Loss: 0.6607698798179626, Accuracy: 0.78857421875\n",
      "Batch No.: 233, Loss: 0.5691776871681213, Accuracy: 0.814453125\n",
      "Batch No.: 234, Loss: 0.6966633796691895, Accuracy: 0.77978515625\n",
      "Batch No.: 235, Loss: 0.6221997737884521, Accuracy: 0.804443359375\n",
      "Batch No.: 236, Loss: 0.6484538912773132, Accuracy: 0.796630859375\n",
      "Batch No.: 237, Loss: 0.705318808555603, Accuracy: 0.775634765625\n",
      "Batch No.: 238, Loss: 0.6383835673332214, Accuracy: 0.791015625\n",
      "Batch No.: 239, Loss: 0.5877939462661743, Accuracy: 0.813232421875\n",
      "Batch No.: 240, Loss: 0.6482291221618652, Accuracy: 0.797607421875\n",
      "Batch No.: 241, Loss: 0.6385418772697449, Accuracy: 0.79931640625\n",
      "Batch No.: 242, Loss: 0.5912532210350037, Accuracy: 0.809814453125\n",
      "Batch No.: 243, Loss: 0.6357662677764893, Accuracy: 0.79443359375\n",
      "Batch No.: 244, Loss: 0.6623893976211548, Accuracy: 0.78662109375\n",
      "Batch No.: 245, Loss: 0.5737862586975098, Accuracy: 0.819580078125\n",
      "Batch No.: 246, Loss: 0.5942508578300476, Accuracy: 0.812744140625\n",
      "Batch No.: 247, Loss: 0.6046276092529297, Accuracy: 0.809326171875\n",
      "Batch No.: 248, Loss: 0.6453944444656372, Accuracy: 0.796142578125\n",
      "Batch No.: 249, Loss: 0.6730185747146606, Accuracy: 0.79296875\n",
      "Batch No.: 250, Loss: 0.6306585073471069, Accuracy: 0.80419921875\n",
      "Batch No.: 251, Loss: 0.6355617046356201, Accuracy: 0.7919921875\n",
      "Batch No.: 252, Loss: 0.5854722857475281, Accuracy: 0.817626953125\n",
      "Batch No.: 253, Loss: 0.6180164813995361, Accuracy: 0.8017578125\n",
      "Batch No.: 254, Loss: 0.6525523066520691, Accuracy: 0.79052734375\n",
      "Batch No.: 255, Loss: 0.640413224697113, Accuracy: 0.795654296875\n",
      "Batch No.: 256, Loss: 0.598438024520874, Accuracy: 0.81005859375\n",
      "Batch No.: 257, Loss: 0.6704466938972473, Accuracy: 0.784912109375\n",
      "Batch No.: 258, Loss: 0.6558035612106323, Accuracy: 0.78857421875\n",
      "Batch No.: 259, Loss: 0.5588619709014893, Accuracy: 0.8212890625\n",
      "Batch No.: 260, Loss: 0.6509050726890564, Accuracy: 0.79248046875\n",
      "Batch No.: 261, Loss: 0.6579388380050659, Accuracy: 0.787109375\n",
      "Batch No.: 262, Loss: 0.562085747718811, Accuracy: 0.819580078125\n",
      "Batch No.: 263, Loss: 0.6599743366241455, Accuracy: 0.7880859375\n",
      "Batch No.: 264, Loss: 0.5865291357040405, Accuracy: 0.81201171875\n",
      "Epoch 68/80\n",
      "Batch No.: 1, Loss: 1.0377880334854126, Accuracy: 0.72119140625\n",
      "Batch No.: 2, Loss: 0.5869483351707458, Accuracy: 0.810791015625\n",
      "Batch No.: 3, Loss: 0.5796727538108826, Accuracy: 0.8056640625\n",
      "Batch No.: 4, Loss: 0.5749967098236084, Accuracy: 0.8134765625\n",
      "Batch No.: 5, Loss: 0.6513183116912842, Accuracy: 0.793701171875\n",
      "Batch No.: 6, Loss: 0.5603135824203491, Accuracy: 0.826171875\n",
      "Batch No.: 7, Loss: 0.6150498390197754, Accuracy: 0.800537109375\n",
      "Batch No.: 8, Loss: 0.6459519863128662, Accuracy: 0.788818359375\n",
      "Batch No.: 9, Loss: 0.5012304186820984, Accuracy: 0.837158203125\n",
      "Batch No.: 10, Loss: 0.590827465057373, Accuracy: 0.805419921875\n",
      "Batch No.: 11, Loss: 0.6029642224311829, Accuracy: 0.807861328125\n",
      "Batch No.: 12, Loss: 0.6225022673606873, Accuracy: 0.804931640625\n",
      "Batch No.: 13, Loss: 0.6484934687614441, Accuracy: 0.786865234375\n",
      "Batch No.: 14, Loss: 0.6542595624923706, Accuracy: 0.793701171875\n",
      "Batch No.: 15, Loss: 0.6692456007003784, Accuracy: 0.791015625\n",
      "Batch No.: 16, Loss: 0.5890293121337891, Accuracy: 0.817138671875\n",
      "Batch No.: 17, Loss: 0.6481807231903076, Accuracy: 0.79296875\n",
      "Batch No.: 18, Loss: 0.6646097898483276, Accuracy: 0.788818359375\n",
      "Batch No.: 19, Loss: 0.5965571403503418, Accuracy: 0.809326171875\n",
      "Batch No.: 20, Loss: 0.5934568643569946, Accuracy: 0.80810546875\n",
      "Batch No.: 21, Loss: 0.6634145975112915, Accuracy: 0.78515625\n",
      "Batch No.: 22, Loss: 0.6019402742385864, Accuracy: 0.80615234375\n",
      "Batch No.: 23, Loss: 0.5597806572914124, Accuracy: 0.8271484375\n",
      "Batch No.: 24, Loss: 0.6735354661941528, Accuracy: 0.77880859375\n",
      "Batch No.: 25, Loss: 0.7191997766494751, Accuracy: 0.76416015625\n",
      "Batch No.: 26, Loss: 0.5694873929023743, Accuracy: 0.824951171875\n",
      "Batch No.: 27, Loss: 0.6559059619903564, Accuracy: 0.788818359375\n",
      "Batch No.: 28, Loss: 0.6404958963394165, Accuracy: 0.79736328125\n",
      "Batch No.: 29, Loss: 0.5425702929496765, Accuracy: 0.8232421875\n",
      "Batch No.: 30, Loss: 0.6964994668960571, Accuracy: 0.7763671875\n",
      "Batch No.: 31, Loss: 0.6527770757675171, Accuracy: 0.7880859375\n",
      "Batch No.: 32, Loss: 0.5459343791007996, Accuracy: 0.825439453125\n",
      "Batch No.: 33, Loss: 0.6304962635040283, Accuracy: 0.7978515625\n",
      "Batch No.: 34, Loss: 0.6427298784255981, Accuracy: 0.79541015625\n",
      "Batch No.: 35, Loss: 0.5729173421859741, Accuracy: 0.81494140625\n",
      "Batch No.: 36, Loss: 0.6171900629997253, Accuracy: 0.806396484375\n",
      "Batch No.: 37, Loss: 0.6652915477752686, Accuracy: 0.78125\n",
      "Batch No.: 38, Loss: 0.6451395750045776, Accuracy: 0.800048828125\n",
      "Batch No.: 39, Loss: 0.574920654296875, Accuracy: 0.813720703125\n",
      "Batch No.: 40, Loss: 0.6049220561981201, Accuracy: 0.7998046875\n",
      "Batch No.: 41, Loss: 0.6882421970367432, Accuracy: 0.787109375\n",
      "Batch No.: 42, Loss: 0.6217308044433594, Accuracy: 0.8037109375\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_dir, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.671352</td>\n",
       "      <td>0.161133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.408862</td>\n",
       "      <td>0.158203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.964650</td>\n",
       "      <td>0.232666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.505745</td>\n",
       "      <td>0.350708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.146323</td>\n",
       "      <td>0.435181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.894940</td>\n",
       "      <td>0.494019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.533325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.608731</td>\n",
       "      <td>0.558228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.502052</td>\n",
       "      <td>0.583984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.421677</td>\n",
       "      <td>0.606689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.365275</td>\n",
       "      <td>0.614380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.306255</td>\n",
       "      <td>0.628540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.279212</td>\n",
       "      <td>0.635010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.240677</td>\n",
       "      <td>0.644531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.207377</td>\n",
       "      <td>0.650391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.179725</td>\n",
       "      <td>0.651611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.159500</td>\n",
       "      <td>0.656616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.134023</td>\n",
       "      <td>0.664673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.106729</td>\n",
       "      <td>0.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.082522</td>\n",
       "      <td>0.675903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1.070642</td>\n",
       "      <td>0.679321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.049520</td>\n",
       "      <td>0.683105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1.034955</td>\n",
       "      <td>0.687134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.034713</td>\n",
       "      <td>0.688110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1.000687</td>\n",
       "      <td>0.697388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.987889</td>\n",
       "      <td>0.701294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.970626</td>\n",
       "      <td>0.704346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.973256</td>\n",
       "      <td>0.705688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.948106</td>\n",
       "      <td>0.712280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.941232</td>\n",
       "      <td>0.713013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>0.765800</td>\n",
       "      <td>0.760620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>0.754982</td>\n",
       "      <td>0.759399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>0.748249</td>\n",
       "      <td>0.762939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>0.741930</td>\n",
       "      <td>0.765381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>0.741336</td>\n",
       "      <td>0.761597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>0.731126</td>\n",
       "      <td>0.771362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>0.733812</td>\n",
       "      <td>0.767822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>0.732745</td>\n",
       "      <td>0.768433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>0.722530</td>\n",
       "      <td>0.773682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>0.719090</td>\n",
       "      <td>0.774048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>0.708377</td>\n",
       "      <td>0.775635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>0.701222</td>\n",
       "      <td>0.778564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>0.702050</td>\n",
       "      <td>0.776001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>0.704302</td>\n",
       "      <td>0.770508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>0.685987</td>\n",
       "      <td>0.779907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>0.680192</td>\n",
       "      <td>0.785278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>0.673174</td>\n",
       "      <td>0.790527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>0.683359</td>\n",
       "      <td>0.784668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>0.669535</td>\n",
       "      <td>0.785156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>0.665349</td>\n",
       "      <td>0.788574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>0.670746</td>\n",
       "      <td>0.786377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>0.662878</td>\n",
       "      <td>0.786499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.794189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>0.654724</td>\n",
       "      <td>0.794434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>0.642127</td>\n",
       "      <td>0.795044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>0.639489</td>\n",
       "      <td>0.791382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>0.651422</td>\n",
       "      <td>0.795654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>0.641493</td>\n",
       "      <td>0.795898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>0.632992</td>\n",
       "      <td>0.799194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>0.631255</td>\n",
       "      <td>0.798950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch      Loss  Accuracy\n",
       "0       1  3.671352  0.161133\n",
       "1       2  3.408862  0.158203\n",
       "2       3  2.964650  0.232666\n",
       "3       4  2.505745  0.350708\n",
       "4       5  2.146323  0.435181\n",
       "5       6  1.894940  0.494019\n",
       "6       7  1.736072  0.533325\n",
       "7       8  1.608731  0.558228\n",
       "8       9  1.502052  0.583984\n",
       "9      10  1.421677  0.606689\n",
       "10     11  1.365275  0.614380\n",
       "11     12  1.306255  0.628540\n",
       "12     13  1.279212  0.635010\n",
       "13     14  1.240677  0.644531\n",
       "14     15  1.207377  0.650391\n",
       "15     16  1.179725  0.651611\n",
       "16     17  1.159500  0.656616\n",
       "17     18  1.134023  0.664673\n",
       "18     19  1.106729  0.669800\n",
       "19     20  1.082522  0.675903\n",
       "20     21  1.070642  0.679321\n",
       "21     22  1.049520  0.683105\n",
       "22     23  1.034955  0.687134\n",
       "23     24  1.034713  0.688110\n",
       "24     25  1.000687  0.697388\n",
       "25     26  0.987889  0.701294\n",
       "26     27  0.970626  0.704346\n",
       "27     28  0.973256  0.705688\n",
       "28     29  0.948106  0.712280\n",
       "29     30  0.941232  0.713013\n",
       "..    ...       ...       ...\n",
       "50     51  0.765800  0.760620\n",
       "51     52  0.754982  0.759399\n",
       "52     53  0.748249  0.762939\n",
       "53     54  0.741930  0.765381\n",
       "54     55  0.741336  0.761597\n",
       "55     56  0.731126  0.771362\n",
       "56     57  0.733812  0.767822\n",
       "57     58  0.732745  0.768433\n",
       "58     59  0.722530  0.773682\n",
       "59     60  0.719090  0.774048\n",
       "60     61  0.708377  0.775635\n",
       "61     62  0.701222  0.778564\n",
       "62     63  0.702050  0.776001\n",
       "63     64  0.704302  0.770508\n",
       "64     65  0.685987  0.779907\n",
       "65     66  0.680192  0.785278\n",
       "66     67  0.673174  0.790527\n",
       "67     68  0.683359  0.784668\n",
       "68     69  0.669535  0.785156\n",
       "69     70  0.665349  0.788574\n",
       "70     71  0.670746  0.786377\n",
       "71     72  0.662878  0.786499\n",
       "72     73  0.655462  0.794189\n",
       "73     74  0.654724  0.794434\n",
       "74     75  0.642127  0.795044\n",
       "75     76  0.639489  0.791382\n",
       "76     77  0.651422  0.795654\n",
       "77     78  0.641493  0.795898\n",
       "78     79  0.632992  0.799194\n",
       "79     80  0.631255  0.798950\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(log_dir)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
